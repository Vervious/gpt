Threshold: 0.1
Enable layer loss: False
MAX LEARNING RATE: 0.0006
Experiment name: 19-funexperiment
MLPSCALE: 4
Experiment description: 
```
Transformer, max LR 0.0006 n_layer 12
Setting:
==details======
 machine_modules
        self.compiler = BenCompilerNoOp(config)
        self.execute = VanillaExecute(config)
----------------
 block_logic
        y = self.ln_1(x)
        attn, newKvCache = self.attn(y, y, print_weights=print_weights, kvCache=kvCache)
        program = self.compiler(x)
        machineOutput = self.execute(program, attn)
        newx = x + machineOutput
----------------
 attn_weights [TIE_ATTN_WEIGHTS]
                if TIE_ATTN_WEIGHTS:
                    # Tie model weights together
                    firstBlock = self.transformer.h[0]
                    for block in self.transformer.h:
                        block.attn.c_attn.weight = firstBlock.attn.c_attn.weight
                        # block.attn = firstBlock.attn
----------------
========
VALUEMATRIX=True
REUSE_WEIGHTS=False
MLP_SCALE=4
ATTENTION_SINK=False
TIE_ATTN_WEIGHTS=True
LOW_RANK_ATTN=True
```
![caption](img/19-funexperiment.jpg)

Warmup steps: 100
total desired batch size: 163840
Mini-batch size: 1280*128
=> calculated gradient accumulation steps: 1
=> calculated gradient accumulation steps: 1
Training max steps: 300001Num GPUs: 1{'block_size': 128, 'vocab_size': 50304, 'n_layer': 12, 'n_head': 12, 'n_embd': 768}
num decayed parameter tensors: 51, with 110,690,304 parameters
num non-decayed parameter tensors: 74, with 84,480 parameters
rank 0 sample 0: A Poem for you! Roses are red, Potatoes are 
------
		( remotely:0.0002 paint:0.0001down:0.0001 dances:0.0001irmed:0.0001odynamic:0.0001 Todd:0.0001)
 remotely
------
		( differe:0.0002msg:0.0002igl:0.0002enh:0.0002 procedure:0.0002 Duo:0.0001olly:0.0001)
 differe decidesÎ½well remediesvelt Sax Roll rangingholdersintestinal tinAv PAL papers
@ 0 train 11.0342 , allloss: 11.0342, dt: 12768.03ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 27.1687, norm(y): 128.0004, norm:17.9651, tok/sec: 12832.05, flops:1.11, batch-reuse:1
rank 0 sample 0: A Poem for you! Roses are red, Potatoes are 
------
		( remotely:0.0002 paint:0.0001 dances:0.0001down:0.0001 Todd:0.0001odynamic:0.0001irmed:0.0001)
 remotely
------
		( differe:0.0002msg:0.0002enh:0.0002 procedure:0.0002olly:0.0001igl:0.0001 Duo:0.0001)
 differe differe pair batting cartoons Feelalth unfocused Vegasatche wirelessCompared605ishable arose
@ 1 train 10.7271 , allloss: 10.7271, dt: 4335.05ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 27.2000, norm(y): 128.0004, norm:15.8952, tok/sec: 37794.27, flops:3.28, batch-reuse:1
@ 2 train 10.3135 , allloss: 10.3135, dt: 1741.98ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 27.3331, norm(y): 128.0005, norm:11.2412, tok/sec: 94054.04, flops:8.16, batch-reuse:1
@ 3 train 10.1055 , allloss: 10.1055, dt: 1803.39ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 27.6842, norm(y): 128.0006, norm:7.6804, tok/sec: 90851.09, flops:7.89, batch-reuse:1
@ 4 train 9.8587 , allloss: 9.8587, dt: 1812.51ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 28.3514, norm(y): 128.0008, norm:6.0596, tok/sec: 90393.76, flops:7.85, batch-reuse:1
@ 5 train 9.6974 , allloss: 9.6974, dt: 1818.63ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 29.3455, norm(y): 128.0011, norm:5.2571, tok/sec: 90089.58, flops:7.82, batch-reuse:1
@ 6 train 9.7485 , allloss: 9.7485, dt: 1836.68ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 30.6257, norm(y): 128.0015, norm:4.1419, tok/sec: 89204.21, flops:7.74, batch-reuse:1
@ 7 train 9.5256 , allloss: 9.5256, dt: 1930.23ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 32.3920, norm(y): 128.0019, norm:4.3100, tok/sec: 84881.20, flops:7.37, batch-reuse:1
@ 8 train 9.4548 , allloss: 9.4548, dt: 1828.80ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 34.1537, norm(y): 128.0024, norm:4.0251, tok/sec: 89588.99, flops:7.78, batch-reuse:1
@ 9 train 9.4851 , allloss: 9.4851, dt: 1814.85ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 36.8072, norm(y): 128.0031, norm:3.1382, tok/sec: 90277.37, flops:7.84, batch-reuse:1
@ 10 train 9.3983 , allloss: 9.3983, dt: 1825.81ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 40.1222, norm(y): 128.0040, norm:3.2100, tok/sec: 89735.73, flops:7.79, batch-reuse:1
@ 11 train 9.5178 , allloss: 9.5178, dt: 1808.34ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 43.6421, norm(y): 128.0049, norm:2.6137, tok/sec: 90602.38, flops:7.87, batch-reuse:1
@ 12 train 9.3210 , allloss: 9.3210, dt: 1960.40ms, norm(attn): 2.0000, norm(output): 4.0000, norm(x): 47.7268, norm(y): 128.0057, norm:2.8234, tok/sec: 83574.82, flops:7.26, batch-reuse:1
@ 13 train 9.3801 , allloss: 9.3801, dt: 1794.68ms, norm(attn): 2.0000, norm(output): 4.0312, norm(x): 51.7829, norm(y): 128.0067, norm:3.0383, tok/sec: 91291.96, flops:7.93, batch-reuse:1
@ 14 train 9.2846 , allloss: 9.2846, dt: 1839.53ms, norm(attn): 2.0000, norm(output): 4.7188, norm(x): 57.0027, norm(y): 128.0076, norm:2.5985, tok/sec: 89066.31, flops:7.73, batch-reuse:1
@ 15 train 9.1956 , allloss: 9.1956, dt: 1843.40ms, norm(attn): 2.0000, norm(output): 8.0000, norm(x): 63.1131, norm(y): 128.0084, norm:3.4535, tok/sec: 88879.39, flops:7.72, batch-reuse:1
@ 16 train 9.0873 , allloss: 9.0873, dt: 1826.70ms, norm(attn): 2.0938, norm(output): 8.0000, norm(x): 68.6319, norm(y): 128.0092, norm:2.3433, tok/sec: 89691.85, flops:7.79, batch-reuse:1
@ 17 train 8.9155 , allloss: 8.9155, dt: 1958.18ms, norm(attn): 2.8281, norm(output): 8.0000, norm(x): 74.2892, norm(y): 128.0099, norm:4.0532, tok/sec: 83669.73, flops:7.26, batch-reuse:1
@ 18 train 8.9722 , allloss: 8.9722, dt: 1828.33ms, norm(attn): 4.0000, norm(output): 8.0000, norm(x): 80.1159, norm(y): 128.0104, norm:2.1013, tok/sec: 89611.78, flops:7.78, batch-reuse:1
@ 19 train 9.0224 , allloss: 9.0224, dt: 1826.67ms, norm(attn): 4.0000, norm(output): 8.0000, norm(x): 85.4381, norm(y): 128.0109, norm:3.0104, tok/sec: 89693.43, flops:7.79, batch-reuse:1
@ 20 train 8.8079 , allloss: 8.8079, dt: 1827.63ms, norm(attn): 4.0000, norm(output): 8.0000, norm(x): 91.0969, norm(y): 128.0116, norm:2.9036, tok/sec: 89646.32, flops:7.78, batch-reuse:1
@ 21 train 8.8097 , allloss: 8.8097, dt: 1821.51ms, norm(attn): 4.0000, norm(output): 8.0000, norm(x): 97.1952, norm(y): 128.0118, norm:2.4323, tok/sec: 89947.24, flops:7.81, batch-reuse:1
@ 22 train 8.7728 , allloss: 8.7728, dt: 1941.42ms, norm(attn): 4.0000, norm(output): 8.0000, norm(x): 101.4916, norm(y): 128.0122, norm:3.0849, tok/sec: 84391.81, flops:7.33, batch-reuse:1
@ 23 train 8.7244 , allloss: 8.7244, dt: 1807.44ms, norm(attn): 4.0000, norm(output): 8.0625, norm(x): 105.2943, norm(y): 128.0125, norm:1.8298, tok/sec: 90647.53, flops:7.87, batch-reuse:1
@ 24 train 8.4898 , allloss: 8.4898, dt: 1795.67ms, norm(attn): 4.0000, norm(output): 8.9375, norm(x): 109.9259, norm(y): 128.0129, norm:2.7587, tok/sec: 91241.78, flops:7.92, batch-reuse:1
@ 25 train 8.3964 , allloss: 8.3964, dt: 1804.60ms, norm(attn): 4.0000, norm(output): 11.5625, norm(x): 116.2007, norm(y): 128.0132, norm:2.3051, tok/sec: 90790.23, flops:7.88, batch-reuse:1
@ 26 train 8.3707 , allloss: 8.3707, dt: 1815.39ms, norm(attn): 4.0000, norm(output): 14.1875, norm(x): 123.4234, norm(y): 128.0137, norm:1.7693, tok/sec: 90250.55, flops:7.83, batch-reuse:1
@ 27 train 8.2516 , allloss: 8.2516, dt: 1930.78ms, norm(attn): 4.0000, norm(output): 15.4375, norm(x): 127.8045, norm(y): 128.0140, norm:1.9609, tok/sec: 84856.70, flops:7.37, batch-reuse:1
@ 28 train 8.2391 , allloss: 8.2391, dt: 1819.78ms, norm(attn): 4.0000, norm(output): 16.0000, norm(x): 132.6390, norm(y): 128.0141, norm:1.6031, tok/sec: 90033.00, flops:7.82, batch-reuse:1
@ 29 train 8.1565 , allloss: 8.1565, dt: 1828.31ms, norm(attn): 4.0000, norm(output): 16.0000, norm(x): 138.9351, norm(y): 128.0141, norm:1.4369, tok/sec: 89612.66, flops:7.78, batch-reuse:1
@ 30 train 7.8266 , allloss: 7.8266, dt: 1819.36ms, norm(attn): 4.0312, norm(output): 16.0000, norm(x): 145.7763, norm(y): 128.0143, norm:1.6030, tok/sec: 90053.60, flops:7.82, batch-reuse:1
@ 31 train 7.9300 , allloss: 7.9300, dt: 1850.07ms, norm(attn): 4.2188, norm(output): 16.0000, norm(x): 151.3010, norm(y): 128.0144, norm:2.1318, tok/sec: 88558.70, flops:7.69, batch-reuse:1
@ 32 train 7.8476 , allloss: 7.8476, dt: 1945.26ms, norm(attn): 5.9375, norm(output): 16.0000, norm(x): 159.3469, norm(y): 128.0147, norm:1.5962, tok/sec: 84225.40, flops:7.31, batch-reuse:1
@ 33 train 7.8057 , allloss: 7.8057, dt: 1815.28ms, norm(attn): 7.0938, norm(output): 16.0000, norm(x): 168.6227, norm(y): 128.0151, norm:1.5963, tok/sec: 90256.26, flops:7.84, batch-reuse:1
@ 34 train 7.7637 , allloss: 7.7637, dt: 1819.65ms, norm(attn): 8.0000, norm(output): 16.0000, norm(x): 175.3590, norm(y): 128.0155, norm:1.4848, tok/sec: 90039.37, flops:7.82, batch-reuse:1
@ 35 train 7.8673 , allloss: 7.8673, dt: 1809.95ms, norm(attn): 8.0000, norm(output): 16.0000, norm(x): 174.4404, norm(y): 128.0145, norm:1.4593, tok/sec: 90521.93, flops:7.86, batch-reuse:1
@ 36 train 7.8758 , allloss: 7.8758, dt: 1824.58ms, norm(attn): 7.1250, norm(output): 16.0000, norm(x): 173.9423, norm(y): 128.0137, norm:1.2891, tok/sec: 89796.17, flops:7.80, batch-reuse:1
@ 37 train 7.6836 , allloss: 7.6836, dt: 1917.93ms, norm(attn): 6.9062, norm(output): 16.0000, norm(x): 175.3284, norm(y): 128.0132, norm:2.3852, tok/sec: 85425.58, flops:7.42, batch-reuse:1
@ 38 train 7.6990 , allloss: 7.6990, dt: 1823.00ms, norm(attn): 7.5312, norm(output): 16.0000, norm(x): 179.7415, norm(y): 128.0128, norm:1.2942, tok/sec: 89874.01, flops:7.80, batch-reuse:1
@ 39 train 7.6939 , allloss: 7.6939, dt: 1818.39ms, norm(attn): 8.0000, norm(output): 16.1250, norm(x): 185.3922, norm(y): 128.0128, norm:1.7660, tok/sec: 90101.72, flops:7.82, batch-reuse:1
@ 40 train 7.7558 , allloss: 7.7558, dt: 1844.05ms, norm(attn): 8.0000, norm(output): 16.1250, norm(x): 190.3506, norm(y): 128.0126, norm:1.5406, tok/sec: 88847.75, flops:7.71, batch-reuse:1
@ 41 train 7.6859 , allloss: 7.6859, dt: 1823.52ms, norm(attn): 8.0000, norm(output): 16.0000, norm(x): 193.2809, norm(y): 128.0126, norm:1.9595, tok/sec: 89848.13, flops:7.80, batch-reuse:1
@ 42 train 7.5606 , allloss: 7.5606, dt: 1980.50ms, norm(attn): 8.0000, norm(output): 16.3750, norm(x): 200.0411, norm(y): 128.0124, norm:1.6383, tok/sec: 82726.38, flops:7.18, batch-reuse:1
@ 43 train 7.5837 , allloss: 7.5837, dt: 1821.24ms, norm(attn): 8.0000, norm(output): 19.0000, norm(x): 207.7174, norm(y): 128.0120, norm:1.1746, tok/sec: 89960.76, flops:7.81, batch-reuse:1
@ 44 train 7.6554 , allloss: 7.6554, dt: 1850.38ms, norm(attn): 8.0000, norm(output): 16.3750, norm(x): 209.7383, norm(y): 128.0116, norm:1.9234, tok/sec: 88543.93, flops:7.69, batch-reuse:1
@ 45 train 7.6683 , allloss: 7.6683, dt: 1822.02ms, norm(attn): 8.0000, norm(output): 28.5000, norm(x): 230.4647, norm(y): 128.0123, norm:1.4365, tok/sec: 89922.27, flops:7.81, batch-reuse:1
@ 46 train 7.5847 , allloss: 7.5847, dt: 1790.73ms, norm(attn): 8.0000, norm(output): 29.1250, norm(x): 241.9702, norm(y): 128.0122, norm:1.3821, tok/sec: 91493.50, flops:7.94, batch-reuse:1
@ 47 train 7.5928 , allloss: 7.5928, dt: 1949.75ms, norm(attn): 8.0000, norm(output): 28.5000, norm(x): 249.3680, norm(y): 128.0107, norm:1.5622, tok/sec: 84031.43, flops:7.29, batch-reuse:1
@ 48 train 7.6076 , allloss: 7.6076, dt: 1810.65ms, norm(attn): 8.0000, norm(output): 25.1250, norm(x): 254.5288, norm(y): 128.0088, norm:1.5828, tok/sec: 90486.78, flops:7.86, batch-reuse:1
@ 49 train 7.6153 , allloss: 7.6153, dt: 1822.86ms, norm(attn): 8.0000, norm(output): 16.6250, norm(x): 258.5132, norm(y): 128.0069, norm:1.2868, tok/sec: 89880.70, flops:7.80, batch-reuse:1
rank 0 sample 0: A Poem for you! Roses are red, Potatoes are 
------
		(.:0.0664,:0.0586-:0.0286 of:0.0229 and:0.0190s:0.0127ï¿½:0.0119)
.
------
		(
:0.1787 The:0.0283 It:0.0200 In:0.0151 This:0.0067 They:0.0027 A:0.0025)

TheThe be the âTheTheTheTheTheThe be the
@ 50 train 7.6072 , allloss: 7.6072, dt: 4399.44ms, norm(attn): 8.0000, norm(output): 16.1250, norm(x): 263.5623, norm(y): 128.0043, norm:1.4958, tok/sec: 37241.08, flops:3.23, batch-reuse:1
@ 51 train 7.3238 , allloss: 7.3238, dt: 1798.20ms, norm(attn): 8.0000, norm(output): 16.1250, norm(x): 270.9243, norm(y): 128.0033, norm:1.8360, tok/sec: 91113.16, flops:7.91, batch-reuse:1
@ 52 train 7.7176 , allloss: 7.7176, dt: 1924.36ms, norm(attn): 8.0000, norm(output): 16.2500, norm(x): 278.3877, norm(y): 128.0023, norm:1.5344, tok/sec: 85139.89, flops:7.39, batch-reuse:1
@ 53 train 7.5365 , allloss: 7.5365, dt: 1817.93ms, norm(attn): 8.0000, norm(output): 16.1250, norm(x): 289.5086, norm(y): 128.0011, norm:1.3869, tok/sec: 90124.60, flops:7.82, batch-reuse:1
@ 54 train 7.4854 , allloss: 7.4854, dt: 1784.71ms, norm(attn): 8.0000, norm(output): 16.0000, norm(x): 305.0960, norm(y): 127.9997, norm:1.2235, tok/sec: 91801.93, flops:7.97, batch-reuse:1
@ 55 train 7.5213 , allloss: 7.5213, dt: 1789.45ms, norm(attn): 8.0000, norm(output): 16.0000, norm(x): 315.2087, norm(y): 127.9979, norm:1.4845, tok/sec: 91559.06, flops:7.95, batch-reuse:1
@ 56 train 7.6076 , allloss: 7.6076, dt: 1790.09ms, norm(attn): 8.0000, norm(output): 16.3750, norm(x): 325.1914, norm(y): 127.9963, norm:1.4104, tok/sec: 91526.05, flops:7.95, batch-reuse:1
@ 57 train 7.6308 , allloss: 7.6308, dt: 1901.98ms, norm(attn): 8.0000, norm(output): 18.0000, norm(x): 334.3557, norm(y): 127.9946, norm:1.3890, tok/sec: 86141.71, flops:7.48, batch-reuse:1
@ 58 train 7.6806 , allloss: 7.6806, dt: 1806.19ms, norm(attn): 8.0000, norm(output): 20.3750, norm(x): 342.7656, norm(y): 127.9925, norm:1.4256, tok/sec: 90710.39, flops:7.87, batch-reuse:1
@ 59 train 7.5910 , allloss: 7.5910, dt: 1791.57ms, norm(attn): 8.0000, norm(output): 17.2500, norm(x): 349.5105, norm(y): 127.9909, norm:1.5929, tok/sec: 91450.69, flops:7.94, batch-reuse:1
@ 60 train 7.9922 , allloss: 7.9922, dt: 1790.42ms, norm(attn): 8.0000, norm(output): 17.3750, norm(x): 359.1051, norm(y): 127.9896, norm:1.5455, tok/sec: 91509.24, flops:7.94, batch-reuse:1
@ 61 train 7.5999 , allloss: 7.5999, dt: 1781.15ms, norm(attn): 8.0000, norm(output): 16.3750, norm(x): 369.2708, norm(y): 127.9875, norm:2.4740, tok/sec: 91985.65, flops:7.99, batch-reuse:1
@ 62 train 8.4471 , allloss: 8.4471, dt: 1865.54ms, norm(attn): 8.0000, norm(output): 22.1250, norm(x): 386.7297, norm(y): 127.9861, norm:2.2393, tok/sec: 87824.66, flops:7.62, batch-reuse:1
@ 63 train 7.5332 , allloss: 7.5332, dt: 1800.08ms, norm(attn): 8.0000, norm(output): 17.5000, norm(x): 387.9362, norm(y): 127.9829, norm:2.2111, tok/sec: 91018.07, flops:7.90, batch-reuse:1
@ 64 train 7.6177 , allloss: 7.6177, dt: 1783.26ms, norm(attn): 8.0000, norm(output): 26.3750, norm(x): 396.9322, norm(y): 127.9801, norm:1.2794, tok/sec: 91876.51, flops:7.98, batch-reuse:1
@ 65 train 7.5130 , allloss: 7.5130, dt: 1821.77ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 405.7864, norm(y): 127.9768, norm:1.2742, tok/sec: 89934.27, flops:7.81, batch-reuse:1
@ 66 train 7.5380 , allloss: 7.5380, dt: 1788.15ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 413.0471, norm(y): 127.9745, norm:1.9782, tok/sec: 91625.24, flops:7.95, batch-reuse:1
@ 67 train 7.5715 , allloss: 7.5715, dt: 1902.15ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 422.6796, norm(y): 127.9725, norm:1.3989, tok/sec: 86134.08, flops:7.48, batch-reuse:1
@ 68 train 7.5552 , allloss: 7.5552, dt: 1804.59ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 431.1713, norm(y): 127.9706, norm:1.4548, tok/sec: 90790.86, flops:7.88, batch-reuse:1
@ 69 train 7.5363 , allloss: 7.5363, dt: 1784.20ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 446.2715, norm(y): 127.9682, norm:1.3875, tok/sec: 91828.48, flops:7.97, batch-reuse:1
@ 70 train 7.5948 , allloss: 7.5948, dt: 1771.56ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 460.5874, norm(y): 127.9671, norm:1.6447, tok/sec: 92483.55, flops:8.03, batch-reuse:1
@ 71 train 7.3212 , allloss: 7.3212, dt: 1804.59ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 471.3022, norm(y): 127.9633, norm:1.4582, tok/sec: 90790.53, flops:7.88, batch-reuse:1
@ 72 train 7.4988 , allloss: 7.4988, dt: 1884.46ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 481.0671, norm(y): 127.9593, norm:1.2729, tok/sec: 86942.82, flops:7.55, batch-reuse:1
@ 73 train 7.4759 , allloss: 7.4759, dt: 1793.75ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 488.6261, norm(y): 127.9560, norm:1.2282, tok/sec: 91339.58, flops:7.93, batch-reuse:1
@ 74 train 7.3283 , allloss: 7.3283, dt: 1804.80ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 500.3877, norm(y): 127.9524, norm:1.5986, tok/sec: 90779.96, flops:7.88, batch-reuse:1
@ 75 train 7.6461 , allloss: 7.6461, dt: 1798.86ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 516.4150, norm(y): 127.9507, norm:1.4856, tok/sec: 91079.85, flops:7.91, batch-reuse:1
@ 76 train 7.4248 , allloss: 7.4248, dt: 1782.22ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 528.6599, norm(y): 127.9466, norm:1.7534, tok/sec: 91930.38, flops:7.98, batch-reuse:1
@ 77 train 7.2563 , allloss: 7.2563, dt: 1904.46ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 542.6270, norm(y): 127.9435, norm:1.1854, tok/sec: 86029.63, flops:7.47, batch-reuse:1
@ 78 train 7.3804 , allloss: 7.3804, dt: 1782.16ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 551.9944, norm(y): 127.9409, norm:2.6020, tok/sec: 91933.31, flops:7.98, batch-reuse:1
@ 79 train 7.5191 , allloss: 7.5191, dt: 1790.62ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 554.9431, norm(y): 127.9379, norm:2.3729, tok/sec: 91498.98, flops:7.94, batch-reuse:1
@ 80 train 7.2630 , allloss: 7.2630, dt: 1808.19ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 561.7083, norm(y): 127.9354, norm:1.6900, tok/sec: 90610.08, flops:7.87, batch-reuse:1
@ 81 train 7.2087 , allloss: 7.2087, dt: 1831.65ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 574.7840, norm(y): 127.9334, norm:1.8769, tok/sec: 89449.61, flops:7.77, batch-reuse:1
@ 82 train 7.3547 , allloss: 7.3547, dt: 1914.11ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 587.4364, norm(y): 127.9310, norm:1.9292, tok/sec: 85596.07, flops:7.43, batch-reuse:1
@ 83 train 7.4487 , allloss: 7.4487, dt: 1826.39ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 602.9209, norm(y): 127.9275, norm:1.3847, tok/sec: 89707.03, flops:7.79, batch-reuse:1
@ 84 train 7.4166 , allloss: 7.4166, dt: 1816.50ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 617.2509, norm(y): 127.9228, norm:1.7932, tok/sec: 90195.27, flops:7.83, batch-reuse:1
@ 85 train 7.2083 , allloss: 7.2083, dt: 1818.22ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 629.8224, norm(y): 127.9186, norm:1.5999, tok/sec: 90110.35, flops:7.82, batch-reuse:1
@ 86 train 7.1650 , allloss: 7.1650, dt: 1806.76ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 646.7661, norm(y): 127.9143, norm:1.8393, tok/sec: 90681.73, flops:7.87, batch-reuse:1
@ 87 train 7.0778 , allloss: 7.0778, dt: 1936.32ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 664.6268, norm(y): 127.9096, norm:1.4169, tok/sec: 84613.93, flops:7.35, batch-reuse:1
@ 88 train 7.2446 , allloss: 7.2446, dt: 1820.06ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 683.9361, norm(y): 127.9053, norm:1.5092, tok/sec: 90019.26, flops:7.81, batch-reuse:1
@ 89 train 7.3386 , allloss: 7.3386, dt: 1820.68ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 697.5578, norm(y): 127.9014, norm:1.5505, tok/sec: 89988.55, flops:7.81, batch-reuse:1
@ 90 train 7.3032 , allloss: 7.3032, dt: 1816.97ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 707.0499, norm(y): 127.8983, norm:1.0345, tok/sec: 90172.04, flops:7.83, batch-reuse:1
@ 91 train 7.5045 , allloss: 7.5045, dt: 1827.89ms, norm(attn): 8.0000, norm(output): 32.0000, norm(x): 721.8484, norm(y): 127.8952, norm:1.2969, tok/sec: 89633.52, flops:7.78, batch-reuse:1
@ 92 train 7.3633 , allloss: 7.3633, dt: 1931.54ms, norm(attn): 8.1250, norm(output): 32.0000, norm(x): 737.3412, norm(y): 127.8913, norm:1.3008, tok/sec: 84823.41, flops:7.36, batch-reuse:1
@ 93 train 7.0914 , allloss: 7.0914, dt: 1852.59ms, norm(attn): 8.1250, norm(output): 32.2500, norm(x): 749.4400, norm(y): 127.8861, norm:2.1444, tok/sec: 88438.17, flops:7.68, batch-reuse:1
@ 94 train 7.2195 , allloss: 7.2195, dt: 1836.51ms, norm(attn): 8.1875, norm(output): 32.2500, norm(x): 762.2577, norm(y): 127.8803, norm:2.0883, tok/sec: 89212.80, flops:7.74, batch-reuse:1
@ 95 train 7.1831 , allloss: 7.1831, dt: 1831.29ms, norm(attn): 8.3125, norm(output): 32.2500, norm(x): 776.3797, norm(y): 127.8745, norm:1.3855, tok/sec: 89467.06, flops:7.77, batch-reuse:1
@ 96 train 7.3407 , allloss: 7.3407, dt: 1869.36ms, norm(attn): 8.3750, norm(output): 34.2500, norm(x): 796.1261, norm(y): 127.8703, norm:1.7815, tok/sec: 87644.81, flops:7.61, batch-reuse:1
@ 97 train 7.3346 , allloss: 7.3346, dt: 1947.91ms, norm(attn): 8.6250, norm(output): 34.5000, norm(x): 802.1400, norm(y): 127.8664, norm:1.6472, tok/sec: 84110.79, flops:7.30, batch-reuse:1
@ 98 train 7.2896 , allloss: 7.2896, dt: 1858.22ms, norm(attn): 9.3750, norm(output): 35.5000, norm(x): 803.5901, norm(y): 127.8616, norm:1.0652, tok/sec: 88170.51, flops:7.65, batch-reuse:1
@ 99 train 7.0659 , allloss: 7.0659, dt: 1829.82ms, norm(attn): 9.9375, norm(output): 38.2500, norm(x): 812.2753, norm(y): 127.8565, norm:1.3065, tok/sec: 89538.91, flops:7.77, batch-reuse:1
@ 100 train 7.3347 , allloss: 7.3347, dt: 1798.66ms, norm(attn): 12.7500, norm(output): 45.0000, norm(x): 827.9874, norm(y): 127.8507, norm:1.2064, tok/sec: 91090.04, flops:7.91, batch-reuse:1
@ 101 train 7.3955 , allloss: 7.3955, dt: 1810.56ms, norm(attn): 16.0000, norm(output): 52.5000, norm(x): 837.2522, norm(y): 127.8443, norm:1.4700, tok/sec: 90491.19, flops:7.86, batch-reuse:1
@ 102 train 7.0802 , allloss: 7.0802, dt: 1928.18ms, norm(attn): 15.1875, norm(output): 61.7500, norm(x): 856.5029, norm(y): 127.8371, norm:1.2565, tok/sec: 84971.25, flops:7.38, batch-reuse:1
@ 103 train 7.4167 , allloss: 7.4167, dt: 1825.83ms, norm(attn): 12.2500, norm(output): 64.0000, norm(x): 878.8925, norm(y): 127.8309, norm:1.6823, tok/sec: 89734.37, flops:7.79, batch-reuse:1
@ 104 train 7.1839 , allloss: 7.1839, dt: 1836.14ms, norm(attn): 11.8125, norm(output): 64.0000, norm(x): 898.6404, norm(y): 127.8272, norm:1.2933, tok/sec: 89230.87, flops:7.75, batch-reuse:1
@ 105 train 7.2408 , allloss: 7.2408, dt: 1839.08ms, norm(attn): 12.7500, norm(output): 64.0000, norm(x): 910.2715, norm(y): 127.8235, norm:1.4726, tok/sec: 89088.25, flops:7.73, batch-reuse:1
@ 106 train 7.1899 , allloss: 7.1899, dt: 1849.80ms, norm(attn): 13.2500, norm(output): 64.0000, norm(x): 915.4090, norm(y): 127.8181, norm:1.2024, tok/sec: 88571.95, flops:7.69, batch-reuse:1
@ 107 train 7.3390 , allloss: 7.3390, dt: 1934.29ms, norm(attn): 13.2500, norm(output): 64.0000, norm(x): 924.4138, norm(y): 127.8135, norm:1.3097, tok/sec: 84702.98, flops:7.35, batch-reuse:1
@ 108 train 7.0194 , allloss: 7.0194, dt: 1854.26ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 929.5220, norm(y): 127.8102, norm:1.1951, tok/sec: 88358.93, flops:7.67, batch-reuse:1
@ 109 train 7.1057 , allloss: 7.1057, dt: 1840.24ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 947.5061, norm(y): 127.8031, norm:1.2884, tok/sec: 89031.73, flops:7.73, batch-reuse:1
@ 110 train 7.1329 , allloss: 7.1329, dt: 1829.26ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 953.3754, norm(y): 127.7933, norm:1.4558, tok/sec: 89566.27, flops:7.78, batch-reuse:1
@ 111 train 7.2568 , allloss: 7.2568, dt: 1807.47ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 965.9506, norm(y): 127.7880, norm:1.5616, tok/sec: 90646.19, flops:7.87, batch-reuse:1
@ 112 train 7.1114 , allloss: 7.1114, dt: 1944.64ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 970.6954, norm(y): 127.7840, norm:1.0825, tok/sec: 84251.89, flops:7.31, batch-reuse:1
@ 113 train 7.1768 , allloss: 7.1768, dt: 1812.36ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 984.2638, norm(y): 127.7804, norm:1.1822, tok/sec: 90401.28, flops:7.85, batch-reuse:1
@ 114 train 7.2585 , allloss: 7.2585, dt: 1832.04ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 994.3169, norm(y): 127.7741, norm:1.5805, tok/sec: 89430.44, flops:7.76, batch-reuse:1
@ 115 train 6.9417 , allloss: 6.9417, dt: 1818.96ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1014.6586, norm(y): 127.7666, norm:1.3312, tok/sec: 90073.49, flops:7.82, batch-reuse:1
@ 116 train 7.1396 , allloss: 7.1396, dt: 1845.31ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1040.4823, norm(y): 127.7589, norm:1.4831, tok/sec: 88787.23, flops:7.71, batch-reuse:1
@ 117 train 7.1762 , allloss: 7.1762, dt: 1938.20ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1051.0215, norm(y): 127.7524, norm:1.3454, tok/sec: 84531.83, flops:7.34, batch-reuse:1
@ 118 train 7.0974 , allloss: 7.0974, dt: 1832.71ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1055.2687, norm(y): 127.7485, norm:1.2171, tok/sec: 89397.83, flops:7.76, batch-reuse:1
@ 119 train 6.9259 , allloss: 6.9259, dt: 1836.42ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1058.6119, norm(y): 127.7434, norm:1.4118, tok/sec: 89216.84, flops:7.75, batch-reuse:1
@ 120 train 7.2197 , allloss: 7.2197, dt: 1838.33ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1080.8569, norm(y): 127.7380, norm:1.6234, tok/sec: 89124.54, flops:7.74, batch-reuse:1
@ 121 train 7.0371 , allloss: 7.0371, dt: 1839.91ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1090.4891, norm(y): 127.7302, norm:1.4772, tok/sec: 89047.83, flops:7.73, batch-reuse:1
@ 122 train 7.0017 , allloss: 7.0017, dt: 1941.77ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1110.5060, norm(y): 127.7232, norm:1.1723, tok/sec: 84376.46, flops:7.32, batch-reuse:1
@ 123 train 7.1632 , allloss: 7.1632, dt: 1831.44ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1119.4607, norm(y): 127.7151, norm:1.5106, tok/sec: 89459.51, flops:7.77, batch-reuse:1
@ 124 train 7.0889 , allloss: 7.0889, dt: 1805.78ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1135.8829, norm(y): 127.7113, norm:1.1910, tok/sec: 90730.72, flops:7.88, batch-reuse:1
@ 125 train 7.1716 , allloss: 7.1716, dt: 1827.45ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1139.6165, norm(y): 127.7073, norm:2.3687, tok/sec: 89655.13, flops:7.78, batch-reuse:1
@ 126 train 7.0642 , allloss: 7.0642, dt: 1826.75ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1150.1371, norm(y): 127.6989, norm:1.3632, tok/sec: 89689.50, flops:7.79, batch-reuse:1
@ 127 train 7.3119 , allloss: 7.3119, dt: 1939.08ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1168.7179, norm(y): 127.6913, norm:1.9615, tok/sec: 84493.69, flops:7.34, batch-reuse:1
@ 128 train 7.1455 , allloss: 7.1455, dt: 1846.00ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1187.6960, norm(y): 127.6864, norm:1.3648, tok/sec: 88753.93, flops:7.70, batch-reuse:1
@ 129 train 7.2514 , allloss: 7.2514, dt: 1850.76ms, norm(attn): 16.0000, norm(output): 64.0000, norm(x): 1223.2627, norm(y): 127.6870, norm:1.9150, tok/sec: 88525.97, flops:7.69, batch-reuse:1
@ 130 train 7.2196 , allloss: 7.2196, dt: 1845.34ms, norm(attn): 16.0000, norm(output): 64.5000, norm(x): 1237.1465, norm(y): 127.6825, norm:2.0647, tok/sec: 88785.70, flops:7.71, batch-reuse:1
@ 131 train 7.1851 , allloss: 7.1851, dt: 1831.07ms, norm(attn): 16.0000, norm(output): 64.5000, norm(x): 1244.3528, norm(y): 127.6744, norm:1.2903, tok/sec: 89477.95, flops:7.77, batch-reuse:1
@ 132 train 7.0178 , allloss: 7.0178, dt: 1939.00ms, norm(attn): 16.0000, norm(output): 64.5000, norm(x): 1266.9456, norm(y): 127.6681, norm:1.3083, tok/sec: 84497.34, flops:7.34, batch-reuse:1
@ 133 train 7.1103 , allloss: 7.1103, dt: 1832.09ms, norm(attn): 16.0000, norm(output): 64.5000, norm(x): 1293.5227, norm(y): 127.6629, norm:1.2503, tok/sec: 89428.11, flops:7.76, batch-reuse:1
@ 134 train 7.2003 , allloss: 7.2003, dt: 1829.86ms, norm(attn): 16.0000, norm(output): 64.5000, norm(x): 1300.1401, norm(y): 127.6562, norm:1.4362, tok/sec: 89536.96, flops:7.77, batch-reuse:1
@ 135 train 6.9400 , allloss: 6.9400, dt: 1839.40ms, norm(attn): 16.0000, norm(output): 64.5000, norm(x): 1303.8805, norm(y): 127.6507, norm:1.1961, tok/sec: 89072.54, flops:7.73, batch-reuse:1
@ 136 train 6.9602 , allloss: 6.9602, dt: 1815.41ms, norm(attn): 16.0000, norm(output): 65.0000, norm(x): 1303.7390, norm(y): 127.6415, norm:1.3042, tok/sec: 90249.60, flops:7.83, batch-reuse:1
@ 137 train 7.1864 , allloss: 7.1864, dt: 1959.17ms, norm(attn): 16.0000, norm(output): 67.5000, norm(x): 1309.9707, norm(y): 127.6330, norm:1.2391, tok/sec: 83627.14, flops:7.26, batch-reuse:1
@ 138 train 7.2008 , allloss: 7.2008, dt: 1804.08ms, norm(attn): 16.0000, norm(output): 76.5000, norm(x): 1329.4022, norm(y): 127.6270, norm:1.2285, tok/sec: 90816.37, flops:7.88, batch-reuse:1
@ 139 train 7.2851 , allloss: 7.2851, dt: 1815.61ms, norm(attn): 16.0000, norm(output): 84.0000, norm(x): 1349.9724, norm(y): 127.6209, norm:1.1126, tok/sec: 90239.45, flops:7.83, batch-reuse:1
@ 140 train 7.1123 , allloss: 7.1123, dt: 1810.41ms, norm(attn): 16.0000, norm(output): 97.5000, norm(x): 1376.3539, norm(y): 127.6190, norm:1.7405, tok/sec: 90498.78, flops:7.86, batch-reuse:1
@ 141 train 7.1166 , allloss: 7.1166, dt: 1824.07ms, norm(attn): 16.0000, norm(output): 104.0000, norm(x): 1392.6930, norm(y): 127.6104, norm:1.3594, tok/sec: 89821.28, flops:7.80, batch-reuse:1
@ 142 train 7.1031 , allloss: 7.1031, dt: 1927.48ms, norm(attn): 16.0000, norm(output): 107.5000, norm(x): 1411.3190, norm(y): 127.6084, norm:1.1867, tok/sec: 85002.00, flops:7.38, batch-reuse:1
@ 143 train 7.0285 , allloss: 7.0285, dt: 1845.21ms, norm(attn): 16.0000, norm(output): 108.0000, norm(x): 1406.1711, norm(y): 127.6031, norm:1.2443, tok/sec: 88792.08, flops:7.71, batch-reuse:1
@ 144 train 7.1263 , allloss: 7.1263, dt: 1841.99ms, norm(attn): 16.0000, norm(output): 109.0000, norm(x): 1418.3405, norm(y): 127.5954, norm:1.2451, tok/sec: 88947.28, flops:7.72, batch-reuse:1
@ 145 train 7.1075 , allloss: 7.1075, dt: 1865.11ms, norm(attn): 16.0000, norm(output): 109.0000, norm(x): 1423.9991, norm(y): 127.5798, norm:1.5466, tok/sec: 87844.55, flops:7.63, batch-reuse:1
@ 146 train 7.0473 , allloss: 7.0473, dt: 1832.15ms, norm(attn): 16.0000, norm(output): 109.0000, norm(x): 1438.4027, norm(y): 127.5673, norm:1.3380, tok/sec: 89425.18, flops:7.76, batch-reuse:1
@ 147 train 6.7421 , allloss: 6.7421, dt: 1932.78ms, norm(attn): 16.0000, norm(output): 109.0000, norm(x): 1442.2095, norm(y): 127.5545, norm:1.7004, tok/sec: 84769.00, flops:7.36, batch-reuse:1
@ 148 train 7.0523 , allloss: 7.0523, dt: 1821.39ms, norm(attn): 16.0000, norm(output): 109.0000, norm(x): 1464.3674, norm(y): 127.5446, norm:1.2478, tok/sec: 89953.40, flops:7.81, batch-reuse:1
@ 149 train 7.3694 , allloss: 7.3694, dt: 1790.46ms, norm(attn): 16.0000, norm(output): 110.0000, norm(x): 1491.3629, norm(y): 127.5396, norm:1.4088, tok/sec: 91507.12, flops:7.94, batch-reuse:1
@ 150 train 7.2049 , allloss: 7.2049, dt: 1824.54ms, norm(attn): 16.0000, norm(output): 110.0000, norm(x): 1498.4382, norm(y): 127.5357, norm:1.6219, tok/sec: 89798.08, flops:7.80, batch-reuse:1
@ 151 train 7.2267 , allloss: 7.2267, dt: 1847.71ms, norm(attn): 16.0000, norm(output): 111.0000, norm(x): 1502.3925, norm(y): 127.5320, norm:1.5104, tok/sec: 88672.15, flops:7.70, batch-reuse:1
@ 152 train 7.1985 , allloss: 7.1985, dt: 1953.74ms, norm(attn): 16.0000, norm(output): 111.0000, norm(x): 1521.8450, norm(y): 127.5249, norm:1.2696, tok/sec: 83859.62, flops:7.28, batch-reuse:1
@ 153 train 7.1820 , allloss: 7.1820, dt: 1818.48ms, norm(attn): 16.0000, norm(output): 111.0000, norm(x): 1536.7898, norm(y): 127.5178, norm:1.2842, tok/sec: 90097.02, flops:7.82, batch-reuse:1
@ 154 train 7.1357 , allloss: 7.1357, dt: 1812.06ms, norm(attn): 16.0000, norm(output): 111.0000, norm(x): 1541.8950, norm(y): 127.5128, norm:1.1926, tok/sec: 90416.26, flops:7.85, batch-reuse:1
@ 155 train 7.2822 , allloss: 7.2822, dt: 1833.04ms, norm(attn): 16.0000, norm(output): 111.0000, norm(x): 1549.6199, norm(y): 127.5094, norm:1.6663, tok/sec: 89381.74, flops:7.76, batch-reuse:1
@ 156 train 7.1787 , allloss: 7.1787, dt: 1858.92ms, norm(attn): 16.0000, norm(output): 113.0000, norm(x): 1567.7009, norm(y): 127.4991, norm:1.2907, tok/sec: 88137.16, flops:7.65, batch-reuse:1
@ 157 train 7.2150 , allloss: 7.2150, dt: 1943.37ms, norm(attn): 16.0000, norm(output): 115.0000, norm(x): 1579.6523, norm(y): 127.4866, norm:1.4456, tok/sec: 84307.14, flops:7.32, batch-reuse:1
