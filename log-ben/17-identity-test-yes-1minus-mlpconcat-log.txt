Threshold: 0.1
Enable layer loss: False
MAX LEARNING RATE: 0.00015
Experiment name: 17-identity-test-yes-1minus-mlpconcat
MLPSCALE: 4
Experiment description: Transformer, max LR 6e-4
Setting:
========
self.compiler = BenCompilerNoOp(config)
self.execute = BenExecute(config) 
========
y = self.ln_1(x)
attn, xWeights, scores = self.attn(y, y, print_weights=print_weights)
program = self.compiler(y)
machineOutput = self.execute(program, attn)
x = xWeights * x + (1-xWeights)*machineOutput
======== 
VALUEMATRIX=True
REUSE_WEIGHTS=False
MLP_SCALE=4
MEASURE_SELF_CONTRIBUTION=False
NEW_ALL_LAYER_LOSS=False
MATRIX_NUM_PARAMS=4096
MLPMAT_INNER_SIZE=64
DELETE_SELF_CONTRIBUTION=False
EXTRACT_SELF_CONTRIBUTION=False
ATTENTION_SINK=True
IDENTITY_LOSS=True

Warmup steps: 1000
total desired batch size: 131072
Mini-batch size: 8*1024
=> calculated gradient accumulation steps: 16
=> calculated gradient accumulation steps: 16
Training max steps: 300001Num GPUs: 1{'block_size': 1024, 'vocab_size': 50304, 'n_layer': 12, 'n_head': 12, 'n_embd': 768}
num decayed parameter tensors: 50, with 152,666,112 parameters
num non-decayed parameter tensors: 74, with 84,480 parameters
@ 0 train 10.9643 , allloss: 20.9378, dt: 4418.26ms, fracRes: 0.0065, norm(attn): 0.0510, norm(output): 0.1099, norm(x): 0.1100, norm(y): 0.9997, norm:43.2886, tok/sec: 29665.96, flops:31.14, batch-reuse:1
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.4883, 0.5117, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3770, 0.3301, 0.2930, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2012, 0.2246, 0.4316, 0.1426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1953, 0.1055, 0.1777, 0.3691, 0.1523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1514, 0.1797, 0.1504, 0.0977, 0.2080, 0.2119, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1436, 0.1514, 0.1128, 0.1533, 0.0737, 0.2021, 0.1631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1245, 0.1826, 0.0938, 0.1348, 0.0947, 0.0762, 0.1348, 0.1572, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1279, 0.0845, 0.0649, 0.1650, 0.1240, 0.1089, 0.1035, 0.1396, 0.0815, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0786, 0.0620, 0.1367, 0.1221, 0.0796, 0.0732, 0.0432, 0.1201, 0.1719, 0.1123, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0845, 0.0708, 0.0635, 0.0688, 0.1680, 0.0693, 0.0527, 0.0830, 0.0898, 0.1611, 0.0898, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0820, 0.0625, 0.0879, 0.0713, 0.0957, 0.0845, 0.0581, 0.1299, 0.0708, 0.0820, 0.0938, 0.0815, 0.0000, 0.0000, 0.0000],
        [0.0688, 0.0781, 0.0422, 0.0747, 0.0815, 0.0933, 0.0913, 0.0854, 0.0708, 0.1309, 0.0520, 0.0786, 0.0522, 0.0000, 0.0000],
        [0.0791, 0.0559, 0.0635, 0.0845, 0.0854, 0.0510, 0.0576, 0.0791, 0.0625, 0.0723, 0.0562, 0.0630, 0.1104, 0.0796, 0.0000],
        [0.0623, 0.1260, 0.0669, 0.0530, 0.1104, 0.0737, 0.0408, 0.0649, 0.0703, 0.0693, 0.0410, 0.0703, 0.0586, 0.0703, 0.0222]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[-0.0275,  0.0097, -0.0176,  ..., -0.0094,  0.0110, -0.0214],
        [-0.0333, -0.0172,  0.0206,  ...,  0.0209, -0.0063,  0.0131],
        [ 0.0541,  0.0276,  0.0411,  ..., -0.0130,  0.0157, -0.0058],
        ...,
        [ 0.0016,  0.0530, -0.0108,  ...,  0.0215, -0.0278, -0.0242],
        [ 0.0133,  0.0072, -0.0103,  ..., -0.0005, -0.0287,  0.0381],
        [-0.0242, -0.0101,  0.0079,  ...,  0.0027,  0.0053,  0.0074]], device='cuda:0', requires_grad=True)
K: tensor([-0.4316, -0.7070, -0.4102, -0.9219,  0.7305,  0.0913, -0.1260, -1.4688,  0.5195,  0.5273,  0.3848,  0.4746, -1.2812, -0.9219, -0.4082, -0.7266,  0.4277, -0.7383, -0.8906, -0.5820,  0.0293,  0.5117, -1.3125,  0.5117,  0.7969,  0.2119, -0.0559, -0.4512, -0.4414,  0.7266,  0.4219, -1.0391,
        -0.1445, -0.5391, -0.4609,  0.9219,  0.2637, -0.6758, -0.0193, -0.0359,  0.5391, -0.5195,  0.1738,  0.2715,  0.4102, -0.2910,  0.0415, -0.0139,  0.2490, -1.0312, -0.6680,  0.4609,  0.3418,  0.2354,  0.9180,  0.6641, -0.1855,  1.1406,  0.3848, -0.5742,  0.1934, -0.1621, -0.2539,  0.4297],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[-0.0412, -0.0246,  0.0261,  ...,  0.0205,  0.0180,  0.0222],
        [-0.0086, -0.0027,  0.0008,  ...,  0.0054,  0.0037, -0.0098],
        [ 0.0501, -0.0127, -0.0241,  ..., -0.0526, -0.0054,  0.0167],
        ...,
        [ 0.0067,  0.0228, -0.0020,  ...,  0.0114, -0.0336, -0.0166],
        [-0.0084,  0.0116,  0.0048,  ..., -0.0168, -0.0195, -0.0052],
        [-0.0132, -0.0065,  0.0123,  ...,  0.0088,  0.0108,  0.0360]], device='cuda:0', requires_grad=True)
Q: tensor([ 0.1348,  0.1045,  0.8555,  0.8242, -0.0505, -0.9727,  0.9141,  0.7969, -0.0166,  0.4980, -0.6055, -0.3652,  0.7656, -0.7539, -0.6055, -0.0986, -0.6719,  0.7930,  0.2412,  0.4316, -0.3027, -0.3984, -0.4531, -0.0133, -0.0835, -0.3027, -0.3047,  0.5586,  0.3945, -0.4277, -0.0107, -0.1143,
        -0.6328,  0.2393, -0.2373, -0.0811,  0.2412,  1.1016, -0.1221,  0.5859, -1.1641,  1.6562,  0.2334, -0.3418, -0.2275,  0.4512, -1.0938,  0.6445, -0.1050,  0.3457, -0.3574,  0.1152, -0.5469,  0.4375, -0.1826,  0.2227, -0.4902, -0.6250, -0.5234,  0.3945,  0.4805, -0.0522, -0.3027, -0.4004],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[     0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000],
        [     0.0000,      0.0498,     -0.8789,     -0.5156,      0.1689,      0.4316,     -0.2275,     -0.3203,      0.0124,      0.1211,      0.2217,      0.4824,      0.1816,      0.2285,      0.2754],
        [     0.0000,     -0.1328,     -0.2500,     -0.2432,      0.0430,      0.6328,     -0.1367,      0.7773,      0.1738,     -0.3340,      0.1338,      0.6953,     -0.0332,      0.3789,     -0.0752],
        [     0.0000,      0.1094,      0.7617,     -0.3418,      0.0952,     -0.0293,     -0.0312,      0.1768,     -0.2090,     -0.2031,     -0.2734,     -0.0776,      0.1611,      0.3809,      0.2217],
        [     0.0000,     -0.6172,     -0.0933,      0.6328,     -0.2461,     -0.3262,     -0.2383,      0.2773,     -0.0269,      0.0332,      0.6523,      0.2334,      0.6836,      0.0118,     -0.2871],
        [     0.0000,      0.1719,     -0.0079,     -0.4375,      0.3184,      0.3379,      0.1572,     -0.0928,      0.0693,      0.3574,      0.3613,      0.5156,     -0.6172,     -0.1982,     -0.3184],
        [     0.0000,      0.0569,     -0.2363,      0.0659,     -0.6602,      0.3477,      0.1299,     -0.5234,     -0.3516,      0.2422,     -0.4023,      0.1777,     -0.2773,      0.0282,      0.0977],
        [     0.0000,      0.3828,     -0.2871,      0.0796,     -0.2734,     -0.4922,      0.0815,      0.2354,      0.2422,      0.0110,      0.0007,     -0.3105,      0.0688,     -0.1001,      0.2109],
        [     0.0000,     -0.4160,     -0.6797,      0.2539,     -0.0312,     -0.1602,     -0.2100,      0.0898,     -0.4492,      0.2754,     -0.4668,      0.1426,      0.0030,      0.0869,     -0.2793],
        [     0.0000,     -0.2383,      0.5547,      0.4434,      0.0160,     -0.0684,     -0.5977,      0.4258,      0.7812,      0.3594,      0.1289,      0.6016,     -0.4629,      0.2695,     -0.5117],
        [     0.0000,     -0.1729,     -0.2871,     -0.2051,      0.6875,     -0.1992,     -0.4688,     -0.0160,      0.0659,      0.6445,      0.0610,     -0.6328,     -0.1504,      0.0635,     -0.0825],
        [     0.0000,     -0.2715,      0.0664,     -0.1416,      0.1553,      0.0292,     -0.3438,      0.4551,     -0.1445,     -0.0012,      0.1348,     -0.0082,      0.4492,      0.0339,     -0.0337],
        [     0.0000,      0.1270,     -0.4883,      0.0859,      0.1748,      0.3066,      0.2852,      0.2168,      0.0315,      0.6484,     -0.2793,      0.1367,     -0.2734,      0.4375,     -0.3477],
        [     0.0000,     -0.3457,     -0.2197,      0.0674,      0.0757,     -0.4395,     -0.3184,     -0.0020,     -0.2354,     -0.0898,     -0.3418,     -0.2256,      0.3340,      0.0040,     -0.4531],
        [     0.0000,      0.7031,      0.0713,     -0.1641,      0.5742,      0.1709,     -0.4219,      0.0413,      0.1201,      0.1099,     -0.4199,      0.1230,     -0.0618,      0.1182,     -1.0312]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.4956],
        [0.3346],
        [0.2479],
        [0.1840],
        [0.1539],
        [0.1344],
        [0.1158],
        [0.1133],
        [0.0961],
        [0.0836],
        [0.0794],
        [0.0740],
        [0.0720],
        [0.0658]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.4902, 0.5078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3945, 0.2695, 0.3379, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2852, 0.2471, 0.2676, 0.1992, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2129, 0.1436, 0.2363, 0.2021, 0.2041, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1895, 0.1455, 0.1777, 0.1543, 0.1377, 0.1953, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1572, 0.1167, 0.1416, 0.1738, 0.1367, 0.1592, 0.1143, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1318, 0.0894, 0.1387, 0.1377, 0.1309, 0.1396, 0.0947, 0.1377, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1074, 0.0806, 0.1094, 0.0938, 0.1494, 0.1445, 0.1177, 0.1201, 0.0771, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1016, 0.1113, 0.0967, 0.1055, 0.0879, 0.1299, 0.0684, 0.0957, 0.0947, 0.1074, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0801, 0.0679, 0.1011, 0.0659, 0.1021, 0.1055, 0.0723, 0.1230, 0.0986, 0.0923, 0.0913, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0918, 0.0554, 0.0957, 0.0898, 0.0923, 0.0903, 0.0815, 0.0869, 0.0679, 0.0830, 0.0752, 0.0898, 0.0000, 0.0000, 0.0000],
        [0.0576, 0.0664, 0.0859, 0.0554, 0.0830, 0.1299, 0.0981, 0.0889, 0.0610, 0.0596, 0.0557, 0.0698, 0.0879, 0.0000, 0.0000],
        [0.0603, 0.0688, 0.0649, 0.0571, 0.0762, 0.0903, 0.0762, 0.0757, 0.0669, 0.0618, 0.0620, 0.0903, 0.0771, 0.0718, 0.0000],
        [0.0625, 0.0693, 0.1030, 0.0791, 0.0752, 0.0752, 0.0535, 0.0781, 0.0596, 0.0540, 0.0703, 0.0449, 0.0654, 0.0513, 0.0583]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[-0.0119, -0.0047,  0.0011,  ..., -0.0081, -0.0060, -0.0092],
        [ 0.0187, -0.0082,  0.0038,  ..., -0.0152, -0.0190,  0.0115],
        [ 0.0028,  0.0050, -0.0192,  ...,  0.0022, -0.0247,  0.0201],
        ...,
        [-0.0035,  0.0182, -0.0326,  ..., -0.0015,  0.0055, -0.0150],
        [-0.0103, -0.0333, -0.0322,  ..., -0.0265,  0.0246, -0.0175],
        [-0.0140, -0.0063,  0.0021,  ...,  0.0249,  0.0402,  0.0057]], device='cuda:0', requires_grad=True)
K: tensor([-0.3809,  0.7188,  0.8086,  0.0894, -0.4609,  0.5625,  0.5156,  1.1719, -0.0674, -0.7500, -0.2969,  0.7969,  0.6914,  0.3691,  0.8984, -0.3691, -0.3633,  0.9922,  0.6289,  1.1484, -0.6211,  0.1348,  0.3184,  0.2578,  0.3105, -0.3652,  0.6562, -0.5547,  0.2471,  0.6367, -0.1719,  0.0664,
         0.1689,  0.0679,  1.1484, -0.3281, -0.5469,  0.3516, -0.1904, -0.2188, -0.2422,  1.1406, -0.5000,  0.2480, -0.1553,  0.0903,  0.2441,  0.7227,  0.0327, -0.2305, -0.4707,  0.0105, -0.2891, -0.2559,  0.3496, -0.6562, -0.5391,  0.3730, -0.8906, -0.6328,  0.4453,  0.0674,  0.8164, -0.6602],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[-0.0103,  0.0028,  0.0054,  ...,  0.0059,  0.0166, -0.0213],
        [-0.0111,  0.0116,  0.0083,  ...,  0.0199,  0.0142,  0.0013],
        [ 0.0100,  0.0125, -0.0286,  ..., -0.0330, -0.0051,  0.0081],
        ...,
        [ 0.0136, -0.0419,  0.0096,  ...,  0.0092,  0.0011,  0.0057],
        [ 0.0192, -0.0127, -0.0111,  ...,  0.0010, -0.0016,  0.0165],
        [-0.0306,  0.0079, -0.0413,  ...,  0.0036, -0.0163,  0.0064]], device='cuda:0', requires_grad=True)
Q: tensor([    -0.6055,     -0.0447,      0.1777,     -0.0859,     -0.6680,     -0.5469,     -0.9102,      0.2578,      0.4102,      0.3301,     -0.6328,     -0.9453,     -0.2754,      0.3320,      0.4043,     -0.1069,     -0.0012,      0.0322,     -0.1240,      0.0908,      0.1719,      0.4453,
            -0.1436,     -0.0444,     -0.9414,      0.3242,     -0.3789,      0.2559,     -1.1875,      0.2520,     -0.1406,     -1.5469,      0.6680,      0.5547,     -0.4746,     -0.2227,      0.6953,      0.9727,      0.3379,      0.0942,      0.8633,      0.4121,     -0.7227,     -0.7930,
             0.0432,     -1.0000,     -0.5547,      0.1816,     -1.0156,      0.4199,      0.6992,      0.2021,     -1.0625,     -0.4102,     -2.0781,      0.8438,     -0.0410,      0.3184,     -1.3047,     -0.4688,      0.2539,      0.2178,      0.4102,     -0.3164], device='cuda:0',
       dtype=torch.bfloat16)
RAWVALUES
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0378, -0.0771, -0.6641,  0.0708,  0.2656, -0.3203, -0.4004, -0.6992, -0.6016, -0.2178, -0.3223, -0.4902, -0.4336, -0.4180],
        [ 0.0000, -0.3809, -0.1562, -0.5703, -0.6016, -0.0806, -0.8438, -0.6250, -0.4551, -0.3105, -0.2285, -0.4004, -0.4629, -0.2832, -0.5469],
        [ 0.0000, -0.1465, -0.0635, -0.3574, -0.2480,  0.0884, -0.2949, -0.4258, -0.2393,  0.0074, -0.3418, -0.3418, -0.3418, -0.0603, -0.2969],
        [ 0.0000, -0.3926,  0.1050, -0.0508, -0.0427,  0.3906, -0.0830,  0.1504,  0.0251, -0.1514,  0.0649,  0.1582,  0.5469,  0.1982, -0.0669],
        [ 0.0000, -0.2637, -0.0659, -0.2070, -0.3164,  0.0298, -0.5273, -0.3379, -0.4121, -0.6094, -0.2451, -0.2432, -0.1367, -0.3906, -0.2891],
        [ 0.0000, -0.2988, -0.1079,  0.1006, -0.1445,  0.0112, -0.3223, -0.2832, -0.2295, -0.3477, -0.2100, -0.1309,  0.0894, -0.2812, -0.4844],
        [ 0.0000, -0.3867,  0.0522,  0.0420, -0.0074,  0.0620, -0.3301,  0.0422, -0.0947, -0.0259,  0.1406, -0.0464, -0.0135,  0.1006, -0.1914],
        [ 0.0000, -0.2871,  0.0170, -0.1387,  0.3281,  0.2969,  0.0918,  0.1128, -0.3340, -0.1855, -0.2793,  0.1436,  0.0845, -0.1338, -0.1338],
        [ 0.0000,  0.0908, -0.0481,  0.0344, -0.1436,  0.2480, -0.3945, -0.0625, -0.0684,  0.0544,  0.0045, -0.1973, -0.2012, -0.0859,  0.1758],
        [ 0.0000, -0.1680,  0.2344, -0.1934,  0.2432,  0.2754, -0.1006,  0.4316,  0.2061,  0.1426,  0.1338,  0.2012,  0.2930,  0.2812,  0.1602],
        [ 0.0000, -0.5039,  0.0439, -0.0170,  0.0073, -0.0114, -0.1182, -0.0505, -0.2988, -0.1006, -0.1982, -0.0178, -0.0571, -0.1157, -0.0586],
        [ 0.0000,  0.1387,  0.3984, -0.0388,  0.3652,  0.8125,  0.5312,  0.4336,  0.0552,  0.0317, -0.0354,  0.1943,  0.4219,  0.3027, -0.0178],
        [ 0.0000,  0.1309,  0.0752, -0.0530,  0.2363,  0.4082,  0.2354,  0.2324,  0.1084,  0.0278,  0.0297,  0.4062,  0.2500,  0.1748,  0.2031],
        [ 0.0000,  0.1045,  0.4980,  0.2334,  0.1826,  0.1865, -0.1562,  0.2227, -0.0496, -0.1484,  0.1177, -0.3301,  0.0479, -0.1973, -0.0713]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.5140],
        [0.3485],
        [0.2436],
        [0.1929],
        [0.1710],
        [0.1359],
        [0.1262],
        [0.1100],
        [0.0950],
        [0.0913],
        [0.0841],
        [0.0725],
        [0.0679],
        [0.0651]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.6992, 0.3027, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3965, 0.2773, 0.3262, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3340, 0.1846, 0.1826, 0.2988, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2256, 0.1270, 0.1934, 0.2275, 0.2256, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1768, 0.0864, 0.1191, 0.1885, 0.1826, 0.2480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1572, 0.1025, 0.1250, 0.1504, 0.1436, 0.1768, 0.1436, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1357, 0.0889, 0.1094, 0.1533, 0.1211, 0.1641, 0.1133, 0.1147, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0938, 0.0562, 0.0854, 0.1436, 0.1108, 0.1465, 0.1182, 0.1357, 0.1099, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0928, 0.0703, 0.0796, 0.1240, 0.1162, 0.1328, 0.1006, 0.1011, 0.1074, 0.0752, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0801, 0.0566, 0.0757, 0.1074, 0.0898, 0.1074, 0.0972, 0.1152, 0.1030, 0.0850, 0.0825, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0786, 0.0583, 0.0598, 0.0981, 0.0825, 0.1099, 0.0942, 0.0767, 0.1123, 0.0569, 0.0845, 0.0879, 0.0000, 0.0000, 0.0000],
        [0.0684, 0.0520, 0.0588, 0.1128, 0.0801, 0.1045, 0.0879, 0.0771, 0.0864, 0.0557, 0.0698, 0.0742, 0.0723, 0.0000, 0.0000],
        [0.0544, 0.0349, 0.0737, 0.0884, 0.0840, 0.1167, 0.0728, 0.0869, 0.0718, 0.0508, 0.0613, 0.0840, 0.0674, 0.0530, 0.0000],
        [0.0845, 0.0488, 0.0679, 0.0894, 0.0815, 0.0835, 0.0898, 0.0679, 0.0684, 0.0547, 0.0564, 0.0608, 0.0562, 0.0483, 0.0420]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[ 0.0025, -0.0244,  0.0174,  ...,  0.0147, -0.0301,  0.0010],
        [ 0.0179, -0.0041,  0.0163,  ..., -0.0059, -0.0047,  0.0203],
        [-0.0113, -0.0015,  0.0100,  ...,  0.0356, -0.0032, -0.0066],
        ...,
        [ 0.0055,  0.0003, -0.0242,  ..., -0.0004, -0.0250,  0.0196],
        [-0.0149, -0.0121, -0.0228,  ..., -0.0119, -0.0077,  0.0164],
        [ 0.0217,  0.0198,  0.0369,  ...,  0.0206, -0.0047, -0.0125]], device='cuda:0', requires_grad=True)
K: tensor([ 0.4551, -0.2471,  0.6992,  0.2520, -0.0640,  0.3145,  0.4219,  0.3125,  1.0000,  0.8242, -0.7891, -0.7852, -0.2393, -0.5625,  0.1465,  0.3281,  0.2129,  0.4551,  0.2949, -1.1641,  0.1885, -0.1055,  1.1250, -0.4863,  1.4922, -0.3633, -0.6758, -0.2852, -0.0498,  0.5430,  0.4102, -0.2734,
        -0.3691,  1.1875, -0.6523,  0.0654,  0.6602,  0.4004, -0.5352, -0.3828,  0.5391, -0.1758, -0.2559, -0.5391,  0.2129,  0.4336,  0.9609,  0.8281, -1.0469,  0.5625,  1.0156,  0.1206,  0.2676, -0.1074, -0.1133,  0.8906, -0.3574, -1.4297,  0.5938, -0.0182, -0.1865, -0.1006,  0.1719,  1.6094],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[ 0.0100,  0.0127,  0.0005,  ...,  0.0086,  0.0308, -0.0047],
        [-0.0315,  0.0238, -0.0319,  ...,  0.0104,  0.0585, -0.0112],
        [-0.0011, -0.0082, -0.0050,  ..., -0.0202, -0.0049, -0.0053],
        ...,
        [ 0.0277,  0.0169, -0.0133,  ..., -0.0225, -0.0377,  0.0407],
        [ 0.0460,  0.0140, -0.0307,  ...,  0.0384,  0.0032,  0.0214],
        [ 0.0186, -0.0104, -0.0026,  ...,  0.0253,  0.0090,  0.0085]], device='cuda:0', requires_grad=True)
Q: tensor([-0.4473,  0.8281, -0.5195,  0.4570, -0.5469,  0.1484,  0.3027, -0.6484, -0.5430, -0.9961,  0.2178,  0.4199, -0.7461, -0.3125, -0.8633, -0.5234, -0.1475,  0.3828,  1.1484, -0.1279, -0.5547,  0.5469, -0.5234,  0.3184,  0.5352,  0.4824,  0.0583,  0.1699, -0.0305,  0.0747,  0.2422, -0.5469,
         0.3594,  0.4863,  0.1245, -1.3672, -0.4082,  0.5430,  0.8633,  0.0444,  0.0430, -0.1836, -1.1328, -0.1426,  0.3555,  0.2275,  0.1089, -1.1016, -0.0381, -0.0601,  0.0061, -0.0718,  0.7578,  0.5820,  0.6016, -0.9570,  0.0171,  0.8398, -0.3984,  0.0339,  0.0097,  0.1309,  0.3145, -0.6484],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[     0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000],
        [     0.0000,     -0.8359,     -0.4766,     -0.5820,     -0.5664,     -0.4570,     -0.5820,     -0.1260,     -0.3555,     -0.3574,     -0.6562,     -0.4141,     -0.4824,     -0.6680,     -0.7227],
        [     0.0000,     -0.3633,     -0.1982,      0.1660,      0.0894,      0.3027,     -0.0527,      0.0439,     -0.0752,     -0.3633,     -0.1055,      0.0898,     -0.1377,     -0.2852,     -0.3438],
        [     0.0000,     -0.5938,     -0.6016,     -0.1118,     -0.2871,      0.1270,     -0.1562,     -0.1436,     -0.3809,     -0.5781,     -0.2930,     -0.1279,     -0.3105,     -0.7148,     -0.4551],
        [     0.0000,     -0.5742,     -0.1543,      0.0095,     -0.0002,      0.2021,     -0.0630,      0.1445,      0.0098,     -0.2373,     -0.1865,     -0.0474,     -0.1924,     -0.2793,     -0.1250],
        [     0.0000,     -0.7148,     -0.3906,      0.0645,      0.0327,      0.3398,      0.1816,      0.1602,      0.0728,     -0.4609,     -0.0173,      0.0593,     -0.0654,     -0.3516,     -0.1611],
        [     0.0000,     -0.4316,     -0.2275,     -0.0464,     -0.0908,      0.1147,     -0.0894,     -0.0854,     -0.0669,     -0.3789,     -0.1680,     -0.1094,     -0.0947,     -0.2832,     -0.3594],
        [     0.0000,     -0.4219,     -0.2148,      0.1226,     -0.1099,      0.1943,     -0.1797,     -0.1660,     -0.2383,     -0.5469,     -0.3223,     -0.2227,     -0.2012,     -0.5117,     -0.5469],
        [     0.0000,     -0.5117,     -0.0957,      0.4277,      0.1680,      0.4434,      0.2324,      0.3691,      0.1602,     -0.3867,      0.0933,      0.3164,      0.0079,     -0.1445,     -0.0747],
        [     0.0000,     -0.2734,     -0.1514,      0.2910,      0.2256,      0.3613,      0.0825,      0.0854,      0.1465,     -0.2080,      0.0562,      0.0400,     -0.0325,     -0.1260,     -0.2754],
        [     0.0000,     -0.3418,     -0.0510,      0.2949,      0.1162,      0.2969,      0.1973,      0.3652,      0.2539,      0.0596,      0.0311,      0.1045,      0.0530,     -0.2539,     -0.1426],
        [     0.0000,     -0.3008,     -0.2734,      0.2227,      0.0479,      0.3359,      0.1787,     -0.0259,      0.3555,     -0.3242,      0.0698,      0.1084,      0.0522,     -0.1758,     -0.1631],
        [     0.0000,     -0.2754,     -0.1514,      0.5000,      0.1572,      0.4219,      0.2520,      0.1187,      0.2305,     -0.2070,      0.0222,      0.0811,      0.0530,     -0.2324,     -0.0447],
        [     0.0000,     -0.4473,      0.3047,      0.4824,      0.4336,      0.7617,      0.2891,      0.4668,      0.2773,     -0.0703,      0.1162,      0.4316,      0.2129,     -0.0293,      0.1816],
        [     0.0000,     -0.5508,     -0.2246,      0.0564,     -0.0400,     -0.0130,      0.0613,     -0.2188,     -0.2178,     -0.4375,     -0.4062,     -0.3320,     -0.4121,     -0.5586,     -0.6992]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.5140],
        [0.3179],
        [0.2545],
        [0.1956],
        [0.1635],
        [0.1455],
        [0.1193],
        [0.1079],
        [0.0979],
        [0.0841],
        [0.0826],
        [0.0734],
        [0.0660],
        [0.0682]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3223, 0.6797, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2158, 0.3535, 0.4316, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1572, 0.2432, 0.3008, 0.2988, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1260, 0.1885, 0.2314, 0.2285, 0.2256, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1084, 0.1514, 0.1875, 0.1865, 0.1846, 0.1816, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0923, 0.1299, 0.1611, 0.1592, 0.1562, 0.1533, 0.1484, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0815, 0.1113, 0.1396, 0.1387, 0.1367, 0.1348, 0.1299, 0.1279, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0708, 0.0986, 0.1230, 0.1226, 0.1201, 0.1187, 0.1157, 0.1138, 0.1157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0645, 0.0884, 0.1104, 0.1099, 0.1074, 0.1064, 0.1040, 0.1021, 0.1040, 0.1025, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0571, 0.0796, 0.1001, 0.0996, 0.0981, 0.0967, 0.0942, 0.0928, 0.0942, 0.0928, 0.0952, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0520, 0.0732, 0.0918, 0.0908, 0.0894, 0.0884, 0.0859, 0.0845, 0.0859, 0.0850, 0.0869, 0.0859, 0.0000, 0.0000, 0.0000],
        [0.0476, 0.0679, 0.0845, 0.0835, 0.0820, 0.0811, 0.0791, 0.0781, 0.0791, 0.0781, 0.0801, 0.0791, 0.0801, 0.0000, 0.0000],
        [0.0437, 0.0630, 0.0786, 0.0776, 0.0762, 0.0752, 0.0737, 0.0723, 0.0732, 0.0723, 0.0742, 0.0732, 0.0742, 0.0723, 0.0000],
        [0.0405, 0.0586, 0.0737, 0.0723, 0.0708, 0.0703, 0.0688, 0.0674, 0.0684, 0.0674, 0.0688, 0.0684, 0.0693, 0.0674, 0.0688]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[-0.0270,  0.0144, -0.0105,  ...,  0.0230, -0.0266, -0.0376],
        [ 0.0066, -0.0190,  0.0259,  ...,  0.0312, -0.0141, -0.0039],
        [ 0.0164,  0.0075,  0.0237,  ..., -0.0004,  0.0267,  0.0252],
        ...,
        [-0.0104,  0.0167,  0.0194,  ...,  0.0075, -0.0205, -0.0081],
        [ 0.0013, -0.0273,  0.0104,  ...,  0.0107, -0.0095, -0.0018],
        [-0.0105, -0.0185,  0.0159,  ...,  0.0026,  0.0266, -0.0309]], device='cuda:0', requires_grad=True)
K: tensor([ 0.8125,  0.1455,  0.1416, -0.5742,  0.4414, -0.7344, -1.2188, -1.0391,  1.0234, -0.1289,  0.5508,  1.2344,  0.0635, -0.7109, -0.0161, -0.5469, -0.2832, -0.1270, -0.2461,  0.5586,  0.4336,  0.3672,  0.3145,  0.6133, -0.0361,  0.0947,  0.1133, -0.5430, -0.3184, -0.1357, -0.2676,  0.0087,
         0.4316, -0.3184, -1.0156, -0.6562, -0.5781, -0.5859,  0.5430, -0.0659, -0.7930,  0.0981,  0.9180, -0.6992,  1.9141,  0.1904, -0.3574, -0.0806, -0.5000, -0.5938, -0.4102, -0.0811,  0.3613,  0.4707, -0.0791,  0.1357,  0.1865, -0.1328, -0.0339, -0.8555,  0.0571,  1.1562,  0.4004,  0.5938],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[-0.0017,  0.0221, -0.0117,  ..., -0.0137,  0.0003, -0.0199],
        [ 0.0015, -0.0108, -0.0004,  ..., -0.0093, -0.0173,  0.0084],
        [-0.0246,  0.0235, -0.0224,  ..., -0.0182,  0.0023,  0.0058],
        ...,
        [-0.0348,  0.0194, -0.0249,  ..., -0.0130,  0.0346,  0.0209],
        [-0.0096,  0.0033, -0.0469,  ...,  0.0146,  0.0022,  0.0087],
        [ 0.0094, -0.0135,  0.0140,  ..., -0.0386,  0.0043, -0.0198]], device='cuda:0', requires_grad=True)
Q: tensor([ 0.2930, -0.4062, -0.4707,  0.2480, -0.3770,  0.1045, -0.8672,  0.1504, -0.1436, -0.1128,  0.4062,  1.1406, -0.1699,  0.4609, -0.2305, -0.0452,  0.1099, -0.4258,  0.6914,  0.4355,  0.0535, -0.1484, -0.4160,  0.1289,  0.5820,  0.0055, -0.0923,  0.4219, -0.0928,  0.0247,  0.1768,  0.2139,
         0.1504,  0.8906, -0.4453,  0.0232, -0.1660,  0.0154,  1.3047, -0.0259,  0.0986, -0.4219,  0.0442,  0.1226,  1.0547, -0.1377, -0.6211,  0.8516, -0.6875,  0.3926,  0.3398, -0.7344,  0.5156,  0.6875, -0.3594, -0.1162, -0.1855, -0.9102,  0.4102,  0.4688,  0.0693, -0.5156,  0.2461, -0.0393],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.7461, 0.9297, 0.9023, 0.8867, 0.8594, 0.8359, 0.7969, 0.7891, 0.7852, 0.8086, 0.7812, 0.8086, 0.7617, 0.7930],
        [0.0000, 0.4922, 0.6953, 0.6758, 0.6719, 0.6367, 0.6016, 0.5703, 0.5781, 0.5547, 0.5898, 0.5703, 0.5938, 0.5508, 0.5859],
        [0.0000, 0.4395, 0.6523, 0.6445, 0.6367, 0.6133, 0.5742, 0.5508, 0.5625, 0.5391, 0.5703, 0.5547, 0.5820, 0.5430, 0.5703],
        [0.0000, 0.4062, 0.6094, 0.5977, 0.5859, 0.5625, 0.5273, 0.5078, 0.5273, 0.5039, 0.5352, 0.5234, 0.5430, 0.5117, 0.5312],
        [0.0000, 0.3359, 0.5508, 0.5430, 0.5352, 0.5156, 0.4785, 0.4629, 0.4805, 0.4570, 0.4883, 0.4766, 0.4961, 0.4668, 0.4844],
        [0.0000, 0.3398, 0.5547, 0.5430, 0.5273, 0.5078, 0.4766, 0.4570, 0.4785, 0.4551, 0.4883, 0.4785, 0.4961, 0.4688, 0.4863],
        [0.0000, 0.3145, 0.5352, 0.5312, 0.5156, 0.5000, 0.4707, 0.4551, 0.4727, 0.4551, 0.4824, 0.4727, 0.4902, 0.4629, 0.4805],
        [0.0000, 0.3301, 0.5508, 0.5469, 0.5273, 0.5156, 0.4883, 0.4746, 0.4922, 0.4785, 0.5078, 0.5000, 0.5156, 0.4863, 0.5039],
        [0.0000, 0.3145, 0.5352, 0.5273, 0.5117, 0.5000, 0.4746, 0.4590, 0.4766, 0.4629, 0.4883, 0.4785, 0.4941, 0.4688, 0.4863],
        [0.0000, 0.3320, 0.5586, 0.5547, 0.5391, 0.5234, 0.5000, 0.4824, 0.5000, 0.4863, 0.5117, 0.5000, 0.5156, 0.4902, 0.5078],
        [0.0000, 0.3438, 0.5703, 0.5586, 0.5430, 0.5312, 0.5039, 0.4883, 0.5000, 0.4902, 0.5156, 0.5039, 0.5195, 0.4922, 0.5117],
        [0.0000, 0.3535, 0.5742, 0.5625, 0.5469, 0.5352, 0.5117, 0.4961, 0.5078, 0.4980, 0.5234, 0.5117, 0.5234, 0.5000, 0.5195],
        [0.0000, 0.3633, 0.5898, 0.5742, 0.5586, 0.5430, 0.5234, 0.5039, 0.5156, 0.5078, 0.5273, 0.5195, 0.5312, 0.5078, 0.5273],
        [0.0000, 0.3691, 0.5977, 0.5820, 0.5625, 0.5508, 0.5312, 0.5078, 0.5234, 0.5117, 0.5312, 0.5234, 0.5352, 0.5117, 0.5312]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.5155],
        [0.3603],
        [0.2744],
        [0.2206],
        [0.1842],
        [0.1573],
        [0.1369],
        [0.1202],
        [0.1085],
        [0.0979],
        [0.0893],
        [0.0819],
        [0.0758],
        [0.0707]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5078, 0.4922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3809, 0.3398, 0.2773, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3008, 0.2754, 0.2227, 0.2002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2441, 0.2354, 0.1885, 0.1680, 0.1641, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2061, 0.2031, 0.1641, 0.1465, 0.1426, 0.1377, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1855, 0.1787, 0.1436, 0.1279, 0.1260, 0.1211, 0.1177, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1650, 0.1602, 0.1289, 0.1157, 0.1133, 0.1089, 0.1060, 0.1030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1484, 0.1445, 0.1172, 0.1055, 0.1030, 0.0991, 0.0962, 0.0938, 0.0923, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1357, 0.1309, 0.1074, 0.0967, 0.0947, 0.0913, 0.0884, 0.0859, 0.0850, 0.0835, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1260, 0.1206, 0.0986, 0.0894, 0.0874, 0.0840, 0.0820, 0.0796, 0.0786, 0.0776, 0.0762, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1182, 0.1123, 0.0923, 0.0830, 0.0815, 0.0781, 0.0762, 0.0737, 0.0728, 0.0718, 0.0703, 0.0693, 0.0000, 0.0000, 0.0000],
        [0.1089, 0.1050, 0.0864, 0.0781, 0.0767, 0.0732, 0.0713, 0.0693, 0.0684, 0.0669, 0.0659, 0.0649, 0.0645, 0.0000, 0.0000],
        [0.1021, 0.0972, 0.0806, 0.0732, 0.0718, 0.0693, 0.0674, 0.0654, 0.0645, 0.0635, 0.0625, 0.0615, 0.0610, 0.0608, 0.0000],
        [0.0952, 0.0908, 0.0762, 0.0693, 0.0679, 0.0654, 0.0635, 0.0618, 0.0608, 0.0601, 0.0591, 0.0581, 0.0576, 0.0574, 0.0571]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[ 0.0353,  0.0366, -0.0231,  ...,  0.0067, -0.0056, -0.0058],
        [-0.0104,  0.0271,  0.0010,  ..., -0.0300,  0.0166, -0.0354],
        [ 0.0024,  0.0232,  0.0206,  ..., -0.0037, -0.0193,  0.0150],
        ...,
        [ 0.0153,  0.0099, -0.0126,  ...,  0.0209, -0.0164, -0.0023],
        [-0.0210, -0.0034, -0.0080,  ..., -0.0130,  0.0063, -0.0297],
        [-0.0117, -0.0123, -0.0246,  ..., -0.0036, -0.0130, -0.0051]], device='cuda:0', requires_grad=True)
K: tensor([-0.5117,  0.0540,  0.4883, -0.2139,  0.3711, -0.4668,  0.2412, -1.2188,  0.1118,  0.1543,  0.1602, -0.1406, -0.4473, -0.5547,  0.2988, -0.0630, -0.7930, -0.4180,  0.0306,  0.0308, -0.2559,  0.1465,  0.3438, -0.2930,  0.2617, -0.6328, -0.4980, -0.2715,  0.6953,  1.5938,  0.2871,  0.0938,
        -1.0078,  0.2617, -0.5586,  0.1719, -0.6328, -0.5039,  0.0806,  1.1172,  0.2734, -0.1406, -0.4375, -0.4570, -0.0242, -0.3477, -0.4570,  0.5195,  0.4980,  0.1001, -0.5156,  0.4297,  0.9492,  0.7227,  0.3672, -0.3984,  0.1836,  0.5234,  0.0369, -0.0947,  0.3809,  0.2559, -1.2109, -0.2637],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[ 0.0146, -0.0263, -0.0038,  ..., -0.0029, -0.0350,  0.0012],
        [ 0.0273,  0.0017, -0.0052,  ...,  0.0205,  0.0074,  0.0271],
        [ 0.0158, -0.0193, -0.0129,  ...,  0.0132,  0.0179, -0.0349],
        ...,
        [-0.0016, -0.0228,  0.0101,  ...,  0.0134,  0.0393,  0.0112],
        [-0.0111, -0.0362,  0.0392,  ..., -0.0030, -0.0043, -0.0263],
        [-0.0306,  0.0018, -0.0472,  ...,  0.0161,  0.0059, -0.0008]], device='cuda:0', requires_grad=True)
Q: tensor([ 0.5781,  0.4180, -0.0413, -0.0210, -0.8203, -0.2832, -1.3828,  0.0850,  0.5703, -0.3398,  0.2393, -0.2432, -0.4492,  0.0334, -0.1543,  0.2891, -0.0405,  0.0172, -0.1904, -0.9492,  0.4375,  0.2070, -0.4355, -0.4902,  0.2695,  0.4316, -0.0952, -0.9727,  0.2715, -0.8594,  0.0366, -0.6836,
         0.0294,  0.1982,  0.3574, -0.2988,  0.8594, -0.7812,  0.6523, -0.7773, -0.2852,  0.7305, -0.0767, -0.1089,  0.0400,  0.6719,  0.1855, -0.2441, -0.3867, -0.2754, -0.7031, -0.3047, -0.8320,  0.4473,  0.1094, -0.3203, -0.5898,  1.3281,  0.3125, -0.4180, -0.4941,  0.4473,  0.5391,  0.1191],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000, -0.0347, -0.2207, -0.3145, -0.3262, -0.3457, -0.3496, -0.3809, -0.3809, -0.4062, -0.4121, -0.4102, -0.4199, -0.4180, -0.4297],
        [ 0.0000, -0.1128, -0.3145, -0.4180, -0.4258, -0.4492, -0.4609, -0.4844, -0.4902, -0.4980, -0.5078, -0.5039, -0.5117, -0.5117, -0.5039],
        [ 0.0000, -0.0840, -0.2988, -0.4043, -0.4141, -0.4414, -0.4590, -0.4805, -0.4883, -0.4922, -0.5039, -0.5039, -0.5078, -0.5117, -0.5039],
        [ 0.0000, -0.0354, -0.2578, -0.3730, -0.3945, -0.4316, -0.4531, -0.4785, -0.4902, -0.4961, -0.5078, -0.5117, -0.5195, -0.5234, -0.5195],
        [ 0.0000, -0.0109, -0.2285, -0.3438, -0.3633, -0.4004, -0.4258, -0.4512, -0.4629, -0.4727, -0.4844, -0.4902, -0.4980, -0.5039, -0.4980],
        [ 0.0000, -0.0391, -0.2539, -0.3672, -0.3887, -0.4277, -0.4551, -0.4805, -0.4941, -0.5039, -0.5195, -0.5273, -0.5352, -0.5391, -0.5391],
        [ 0.0000, -0.0317, -0.2451, -0.3555, -0.3770, -0.4141, -0.4414, -0.4688, -0.4824, -0.4941, -0.5117, -0.5195, -0.5273, -0.5352, -0.5312],
        [ 0.0000, -0.0293, -0.2373, -0.3457, -0.3672, -0.4062, -0.4355, -0.4648, -0.4785, -0.4902, -0.5078, -0.5156, -0.5273, -0.5352, -0.5352],
        [ 0.0000, -0.0344, -0.2354, -0.3398, -0.3613, -0.4004, -0.4297, -0.4570, -0.4707, -0.4844, -0.5000, -0.5117, -0.5195, -0.5273, -0.5273],
        [ 0.0000, -0.0452, -0.2451, -0.3457, -0.3652, -0.4023, -0.4316, -0.4590, -0.4727, -0.4863, -0.5000, -0.5156, -0.5234, -0.5312, -0.5312],
        [ 0.0000, -0.0498, -0.2490, -0.3496, -0.3691, -0.4102, -0.4395, -0.4707, -0.4844, -0.5000, -0.5156, -0.5312, -0.5391, -0.5469, -0.5469],
        [ 0.0000, -0.0364, -0.2275, -0.3281, -0.3496, -0.3926, -0.4219, -0.4531, -0.4668, -0.4824, -0.4980, -0.5156, -0.5234, -0.5312, -0.5312],
        [ 0.0000, -0.0471, -0.2373, -0.3340, -0.3496, -0.3887, -0.4160, -0.4453, -0.4570, -0.4727, -0.4863, -0.5039, -0.5117, -0.5195, -0.5195],
        [ 0.0000, -0.0469, -0.2246, -0.3164, -0.3340, -0.3730, -0.4004, -0.4316, -0.4453, -0.4590, -0.4746, -0.4922, -0.5000, -0.5078, -0.5078]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.5024],
        [0.3312],
        [0.2462],
        [0.1973],
        [0.1652],
        [0.1426],
        [0.1260],
        [0.1134],
        [0.1024],
        [0.0941],
        [0.0869],
        [0.0801],
        [0.0746],
        [0.0696]], device='cuda:0')
rank 0 sample 0: A Poem for you! Roses are red, Potatoes are 
------
		( Franc:0.0001 Franc:0.0002 Franc:0.0002 Franc:0.0002 Franc:0.0002 Franc:0.0002 Franc:0.0002 Franc:0.0002)
 Franc
------
		( Franc:0.0002 Franc:0.0002 Franc:0.0002 Franc:0.0002 Franc:0.0002 Franc:0.0002 Franc:0.0002 Franc:0.0002)
 Franc Franc Franc Franc Franc Franc Franc Franc Franc Franc Franc Franc Franc Franc Franc
@ 1 train 10.9506 , allloss: 20.9026, dt: 2434.72ms, fracRes: 0.0065, norm(attn): 0.0513, norm(output): 0.1099, norm(x): 0.1102, norm(y): 0.9997, norm:45.1237, tok/sec: 53834.45, flops:56.51, batch-reuse:1
@ 2 train 10.9156 , allloss: 20.8398, dt: 1265.53ms, fracRes: 0.0065, norm(attn): 0.0510, norm(output): 0.1099, norm(x): 0.1102, norm(y): 0.9997, norm:43.6807, tok/sec: 103570.96, flops:108.71, batch-reuse:1
@ 3 train 10.8701 , allloss: 20.7733, dt: 1283.85ms, fracRes: 0.0065, norm(attn): 0.0510, norm(output): 0.1099, norm(x): 0.1101, norm(y): 0.9997, norm:42.9322, tok/sec: 102092.83, flops:107.16, batch-reuse:1
@ 4 train 10.8139 , allloss: 20.6752, dt: 1290.83ms, fracRes: 0.0065, norm(attn): 0.0513, norm(output): 0.1104, norm(x): 0.1105, norm(y): 0.9998, norm:41.4590, tok/sec: 101540.82, flops:106.58, batch-reuse:1
@ 5 train 10.7588 , allloss: 20.5323, dt: 1290.27ms, fracRes: 0.0065, norm(attn): 0.0515, norm(output): 0.1104, norm(x): 0.1108, norm(y): 0.9998, norm:40.3410, tok/sec: 101585.16, flops:106.63, batch-reuse:1
@ 6 train 10.6863 , allloss: 20.3933, dt: 1290.40ms, fracRes: 0.0065, norm(attn): 0.0518, norm(output): 0.1108, norm(x): 0.1113, norm(y): 0.9998, norm:41.2359, tok/sec: 101574.40, flops:106.62, batch-reuse:1
@ 7 train 10.6239 , allloss: 20.2397, dt: 1288.06ms, fracRes: 0.0064, norm(attn): 0.0518, norm(output): 0.1113, norm(x): 0.1119, norm(y): 0.9998, norm:40.3454, tok/sec: 101759.60, flops:106.81, batch-reuse:1
@ 8 train 10.5808 , allloss: 20.1010, dt: 1283.08ms, fracRes: 0.0064, norm(attn): 0.0525, norm(output): 0.1113, norm(x): 0.1126, norm(y): 0.9998, norm:39.4875, tok/sec: 102154.26, flops:107.22, batch-reuse:1
@ 9 train 10.5047 , allloss: 19.8983, dt: 1284.86ms, fracRes: 0.0064, norm(attn): 0.0537, norm(output): 0.1152, norm(x): 0.1135, norm(y): 0.9998, norm:40.0069, tok/sec: 102013.02, flops:107.08, batch-reuse:1
@ 10 train 10.4488 , allloss: 19.7224, dt: 1281.65ms, fracRes: 0.0064, norm(attn): 0.0537, norm(output): 0.1162, norm(x): 0.1145, norm(y): 0.9998, norm:39.3658, tok/sec: 102268.45, flops:107.34, batch-reuse:1
@ 11 train 10.4218 , allloss: 19.5572, dt: 1285.24ms, fracRes: 0.0064, norm(attn): 0.0540, norm(output): 0.1167, norm(x): 0.1155, norm(y): 0.9998, norm:38.6155, tok/sec: 101982.25, flops:107.04, batch-reuse:1
@ 12 train 10.3411 , allloss: 19.3117, dt: 1272.40ms, fracRes: 0.0064, norm(attn): 0.0544, norm(output): 0.1172, norm(x): 0.1165, norm(y): 0.9998, norm:38.8707, tok/sec: 103011.66, flops:108.12, batch-reuse:1
@ 13 train 10.2999 , allloss: 19.0929, dt: 1288.19ms, fracRes: 0.0064, norm(attn): 0.0544, norm(output): 0.1177, norm(x): 0.1175, norm(y): 0.9998, norm:38.2954, tok/sec: 101749.28, flops:106.80, batch-reuse:1
@ 14 train 10.2563 , allloss: 18.8649, dt: 1259.03ms, fracRes: 0.0064, norm(attn): 0.0544, norm(output): 0.1177, norm(x): 0.1184, norm(y): 0.9998, norm:38.0823, tok/sec: 104105.24, flops:109.27, batch-reuse:1
@ 15 train 10.2073 , allloss: 18.6047, dt: 1255.06ms, fracRes: 0.0064, norm(attn): 0.0547, norm(output): 0.1191, norm(x): 0.1194, norm(y): 0.9998, norm:37.8937, tok/sec: 104434.57, flops:109.62, batch-reuse:1
@ 16 train 10.1762 , allloss: 18.3688, dt: 1270.64ms, fracRes: 0.0064, norm(attn): 0.0549, norm(output): 0.1230, norm(x): 0.1204, norm(y): 0.9998, norm:37.2638, tok/sec: 103154.29, flops:108.27, batch-reuse:1
@ 17 train 10.1208 , allloss: 18.1004, dt: 1271.73ms, fracRes: 0.0064, norm(attn): 0.0554, norm(output): 0.1230, norm(x): 0.1213, norm(y): 0.9998, norm:36.6887, tok/sec: 103066.02, flops:108.18, batch-reuse:1
@ 18 train 10.0946 , allloss: 17.8266, dt: 1285.90ms, fracRes: 0.0064, norm(attn): 0.0554, norm(output): 0.1245, norm(x): 0.1224, norm(y): 0.9998, norm:36.1656, tok/sec: 101930.52, flops:106.99, batch-reuse:1
@ 19 train 10.0420 , allloss: 17.5323, dt: 1296.94ms, fracRes: 0.0064, norm(attn): 0.0554, norm(output): 0.1245, norm(x): 0.1232, norm(y): 0.9998, norm:35.6653, tok/sec: 101062.85, flops:106.08, batch-reuse:1
@ 20 train 10.0030 , allloss: 17.2303, dt: 1295.02ms, fracRes: 0.0064, norm(attn): 0.0557, norm(output): 0.1250, norm(x): 0.1242, norm(y): 0.9998, norm:35.0937, tok/sec: 101212.42, flops:106.24, batch-reuse:1
@ 21 train 9.9594 , allloss: 16.9154, dt: 1303.87ms, fracRes: 0.0064, norm(attn): 0.0562, norm(output): 0.1260, norm(x): 0.1251, norm(y): 0.9999, norm:34.3972, tok/sec: 100525.34, flops:105.51, batch-reuse:1
@ 22 train 9.9472 , allloss: 16.6163, dt: 1287.19ms, fracRes: 0.0064, norm(attn): 0.0576, norm(output): 0.1260, norm(x): 0.1261, norm(y): 0.9999, norm:33.3713, tok/sec: 101827.73, flops:106.88, batch-reuse:1
@ 23 train 9.9313 , allloss: 16.3352, dt: 1296.39ms, fracRes: 0.0064, norm(attn): 0.0576, norm(output): 0.1270, norm(x): 0.1270, norm(y): 0.9999, norm:32.6591, tok/sec: 101105.48, flops:106.12, batch-reuse:1
@ 24 train 9.9195 , allloss: 16.0125, dt: 1302.45ms, fracRes: 0.0064, norm(attn): 0.0579, norm(output): 0.1270, norm(x): 0.1280, norm(y): 0.9999, norm:31.6712, tok/sec: 100634.92, flops:105.63, batch-reuse:1
@ 25 train 9.8089 , allloss: 15.5689, dt: 1288.64ms, fracRes: 0.0064, norm(attn): 0.0579, norm(output): 0.1289, norm(x): 0.1290, norm(y): 0.9999, norm:30.7074, tok/sec: 101713.55, flops:106.76, batch-reuse:1
@ 26 train 9.8458 , allloss: 15.3155, dt: 1297.18ms, fracRes: 0.0064, norm(attn): 0.0581, norm(output): 0.1318, norm(x): 0.1300, norm(y): 0.9999, norm:29.4257, tok/sec: 101043.92, flops:106.06, batch-reuse:1
@ 27 train 9.8203 , allloss: 15.0022, dt: 1281.67ms, fracRes: 0.0064, norm(attn): 0.0583, norm(output): 0.1318, norm(x): 0.1310, norm(y): 0.9999, norm:28.3255, tok/sec: 102266.49, flops:107.34, batch-reuse:1
@ 28 train 9.7967 , allloss: 14.6714, dt: 1300.96ms, fracRes: 0.0064, norm(attn): 0.0583, norm(output): 0.1328, norm(x): 0.1319, norm(y): 0.9999, norm:27.1360, tok/sec: 100750.17, flops:105.75, batch-reuse:1
@ 29 train 9.7821 , allloss: 14.3692, dt: 1290.43ms, fracRes: 0.0064, norm(attn): 0.0586, norm(output): 0.1338, norm(x): 0.1328, norm(y): 0.9999, norm:25.9037, tok/sec: 101572.51, flops:106.61, batch-reuse:1
@ 30 train 9.7385 , allloss: 14.0311, dt: 1304.94ms, fracRes: 0.0063, norm(attn): 0.0586, norm(output): 0.1338, norm(x): 0.1338, norm(y): 0.9999, norm:24.8232, tok/sec: 100443.04, flops:105.43, batch-reuse:1
@ 31 train 9.7541 , allloss: 13.7717, dt: 1312.57ms, fracRes: 0.0063, norm(attn): 0.0588, norm(output): 0.1387, norm(x): 0.1348, norm(y): 0.9999, norm:23.5320, tok/sec: 99859.34, flops:104.82, batch-reuse:1
@ 32 train 9.7230 , allloss: 13.4714, dt: 1298.25ms, fracRes: 0.0063, norm(attn): 0.0588, norm(output): 0.1387, norm(x): 0.1357, norm(y): 0.9999, norm:22.3321, tok/sec: 100960.51, flops:105.97, batch-reuse:1
@ 33 train 9.6629 , allloss: 13.1351, dt: 1299.45ms, fracRes: 0.0063, norm(attn): 0.0588, norm(output): 0.1387, norm(x): 0.1368, norm(y): 0.9999, norm:21.1639, tok/sec: 100867.31, flops:105.87, batch-reuse:1
@ 34 train 9.6851 , allloss: 12.8963, dt: 1301.28ms, fracRes: 0.0063, norm(attn): 0.0588, norm(output): 0.1396, norm(x): 0.1379, norm(y): 0.9999, norm:19.8106, tok/sec: 100725.55, flops:105.72, batch-reuse:1
@ 35 train 9.6826 , allloss: 12.6714, dt: 1280.31ms, fracRes: 0.0063, norm(attn): 0.0588, norm(output): 0.1406, norm(x): 0.1389, norm(y): 0.9999, norm:18.7293, tok/sec: 102374.89, flops:107.46, batch-reuse:1
@ 36 train 9.6523 , allloss: 12.3800, dt: 1298.92ms, fracRes: 0.0063, norm(attn): 0.0593, norm(output): 0.1416, norm(x): 0.1402, norm(y): 0.9999, norm:17.4813, tok/sec: 100908.71, flops:105.92, batch-reuse:1
@ 37 train 9.6539 , allloss: 12.1599, dt: 1290.45ms, fracRes: 0.0063, norm(attn): 0.0596, norm(output): 0.1416, norm(x): 0.1414, norm(y): 0.9999, norm:16.3306, tok/sec: 101571.12, flops:106.61, batch-reuse:1
@ 38 train 9.6297 , allloss: 11.9303, dt: 1307.83ms, fracRes: 0.0063, norm(attn): 0.0598, norm(output): 0.1416, norm(x): 0.1426, norm(y): 0.9999, norm:15.4237, tok/sec: 100220.62, flops:105.19, batch-reuse:1
@ 39 train 9.6503 , allloss: 11.7625, dt: 1319.42ms, fracRes: 0.0063, norm(attn): 0.0601, norm(output): 0.1445, norm(x): 0.1437, norm(y): 1.0000, norm:14.0629, tok/sec: 99340.40, flops:104.27, batch-reuse:1
@ 40 train 9.6037 , allloss: 11.5273, dt: 1298.01ms, fracRes: 0.0063, norm(attn): 0.0610, norm(output): 0.1455, norm(x): 0.1449, norm(y): 1.0000, norm:13.1550, tok/sec: 100979.54, flops:105.99, batch-reuse:1
@ 41 train 9.5994 , allloss: 11.3548, dt: 1320.19ms, fracRes: 0.0063, norm(attn): 0.0615, norm(output): 0.1465, norm(x): 0.1460, norm(y): 1.0000, norm:12.2164, tok/sec: 99282.57, flops:104.21, batch-reuse:1
@ 42 train 9.6080 , allloss: 11.2197, dt: 1332.35ms, fracRes: 0.0063, norm(attn): 0.0615, norm(output): 0.1475, norm(x): 0.1471, norm(y): 1.0000, norm:11.3906, tok/sec: 98376.71, flops:103.26, batch-reuse:1
@ 43 train 9.6235 , allloss: 11.0965, dt: 1305.64ms, fracRes: 0.0063, norm(attn): 0.0620, norm(output): 0.1504, norm(x): 0.1483, norm(y): 1.0000, norm:10.5146, tok/sec: 100389.06, flops:105.37, batch-reuse:1
@ 44 train 9.6365 , allloss: 10.9756, dt: 1288.51ms, fracRes: 0.0063, norm(attn): 0.0623, norm(output): 0.1504, norm(x): 0.1496, norm(y): 1.0000, norm:9.6794, tok/sec: 101723.93, flops:106.77, batch-reuse:1
@ 45 train 9.6110 , allloss: 10.8309, dt: 1312.84ms, fracRes: 0.0063, norm(attn): 0.0623, norm(output): 0.1514, norm(x): 0.1508, norm(y): 1.0000, norm:8.9894, tok/sec: 99838.21, flops:104.79, batch-reuse:1
@ 46 train 9.5890 , allloss: 10.6965, dt: 1312.31ms, fracRes: 0.0062, norm(attn): 0.0623, norm(output): 0.1543, norm(x): 0.1521, norm(y): 1.0000, norm:8.2518, tok/sec: 99878.88, flops:104.84, batch-reuse:1
@ 47 train 9.5669 , allloss: 10.5756, dt: 1301.99ms, fracRes: 0.0062, norm(attn): 0.0623, norm(output): 0.1553, norm(x): 0.1534, norm(y): 1.0000, norm:7.6505, tok/sec: 100670.36, flops:105.67, batch-reuse:1
@ 48 train 9.5718 , allloss: 10.4954, dt: 1323.09ms, fracRes: 0.0062, norm(attn): 0.0623, norm(output): 0.1553, norm(x): 0.1547, norm(y): 1.0000, norm:7.0579, tok/sec: 99065.03, flops:103.98, batch-reuse:1
@ 49 train 9.5835 , allloss: 10.4361, dt: 1314.54ms, fracRes: 0.0062, norm(attn): 0.0625, norm(output): 0.1572, norm(x): 0.1559, norm(y): 1.0000, norm:6.4733, tok/sec: 99709.23, flops:104.66, batch-reuse:1
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.4863, 0.5117, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3750, 0.3320, 0.2930, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2002, 0.2236, 0.4355, 0.1406, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1953, 0.1050, 0.1797, 0.3691, 0.1514, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1514, 0.1787, 0.1514, 0.0977, 0.2061, 0.2148, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1426, 0.1504, 0.1128, 0.1523, 0.0737, 0.2041, 0.1631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1245, 0.1836, 0.0928, 0.1348, 0.0947, 0.0767, 0.1357, 0.1572, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1279, 0.0840, 0.0649, 0.1650, 0.1235, 0.1104, 0.1030, 0.1396, 0.0820, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0786, 0.0618, 0.1357, 0.1226, 0.0801, 0.0737, 0.0430, 0.1191, 0.1729, 0.1128, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0845, 0.0713, 0.0635, 0.0688, 0.1670, 0.0693, 0.0527, 0.0830, 0.0908, 0.1602, 0.0894, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0820, 0.0630, 0.0879, 0.0713, 0.0957, 0.0850, 0.0581, 0.1289, 0.0713, 0.0825, 0.0942, 0.0811, 0.0000, 0.0000, 0.0000],
        [0.0688, 0.0776, 0.0425, 0.0747, 0.0820, 0.0938, 0.0913, 0.0850, 0.0713, 0.1318, 0.0520, 0.0786, 0.0515, 0.0000, 0.0000],
        [0.0791, 0.0559, 0.0640, 0.0845, 0.0845, 0.0513, 0.0576, 0.0786, 0.0625, 0.0723, 0.0564, 0.0630, 0.1104, 0.0796, 0.0000],
        [0.0623, 0.1260, 0.0669, 0.0530, 0.1104, 0.0737, 0.0408, 0.0649, 0.0703, 0.0693, 0.0413, 0.0703, 0.0588, 0.0703, 0.0222]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[-0.0274,  0.0097, -0.0176,  ..., -0.0095,  0.0110, -0.0214],
        [-0.0334, -0.0172,  0.0208,  ...,  0.0210, -0.0064,  0.0132],
        [ 0.0541,  0.0275,  0.0412,  ..., -0.0129,  0.0156, -0.0057],
        ...,
        [ 0.0017,  0.0530, -0.0109,  ...,  0.0214, -0.0276, -0.0243],
        [ 0.0134,  0.0073, -0.0105,  ..., -0.0007, -0.0286,  0.0381],
        [-0.0242, -0.0100,  0.0078,  ...,  0.0026,  0.0054,  0.0072]], device='cuda:0', requires_grad=True)
K: tensor([-0.4375, -0.7070, -0.4062, -0.9258,  0.7344,  0.0967, -0.1270, -1.4688,  0.5117,  0.5273,  0.3828,  0.4824, -1.2812, -0.9180, -0.4141, -0.7266,  0.4375, -0.7383, -0.8867, -0.5781,  0.0298,  0.5156, -1.3125,  0.5117,  0.7930,  0.2100, -0.0613, -0.4434, -0.4414,  0.7266,  0.4180, -1.0391,
        -0.1494, -0.5391, -0.4629,  0.9297,  0.2598, -0.6758, -0.0146, -0.0400,  0.5352, -0.5156,  0.1709,  0.2734,  0.4082, -0.2812,  0.0400, -0.0145,  0.2480, -1.0312, -0.6602,  0.4629,  0.3379,  0.2393,  0.9180,  0.6680, -0.1826,  1.1406,  0.3809, -0.5703,  0.2051, -0.1631, -0.2559,  0.4277],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[-0.0411, -0.0246,  0.0262,  ...,  0.0203,  0.0179,  0.0223],
        [-0.0085, -0.0028,  0.0007,  ...,  0.0053,  0.0037, -0.0097],
        [ 0.0500, -0.0126, -0.0241,  ..., -0.0527, -0.0054,  0.0167],
        ...,
        [ 0.0067,  0.0229, -0.0020,  ...,  0.0114, -0.0334, -0.0166],
        [-0.0084,  0.0115,  0.0047,  ..., -0.0168, -0.0195, -0.0052],
        [-0.0133, -0.0065,  0.0122,  ...,  0.0088,  0.0109,  0.0359]], device='cuda:0', requires_grad=True)
Q: tensor([ 0.1377,  0.1104,  0.8555,  0.8281, -0.0486, -0.9688,  0.9141,  0.8008, -0.0150,  0.5000, -0.6055, -0.3613,  0.7695, -0.7578, -0.6094, -0.1011, -0.6797,  0.7930,  0.2422,  0.4336, -0.2988, -0.3945, -0.4512, -0.0141, -0.0928, -0.3027, -0.2969,  0.5625,  0.3945, -0.4297, -0.0127, -0.1211,
        -0.6328,  0.2354, -0.2373, -0.0776,  0.2422,  1.1016, -0.1221,  0.5859, -1.1641,  1.6484,  0.2266, -0.3418, -0.2246,  0.4531, -1.0938,  0.6445, -0.1133,  0.3477, -0.3574,  0.1177, -0.5508,  0.4355, -0.1865,  0.2188, -0.4863, -0.6289, -0.5312,  0.4004,  0.4824, -0.0530, -0.3027, -0.4004],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0532, -0.8750, -0.5117,  0.1689,  0.4297, -0.2285, -0.3145,  0.0135,  0.1201,  0.2285,  0.4766,  0.1816,  0.2266,  0.2734],
        [ 0.0000, -0.1270, -0.2500, -0.2441,  0.0430,  0.6406, -0.1387,  0.7773,  0.1787, -0.3301,  0.1338,  0.6914, -0.0332,  0.3789, -0.0723],
        [ 0.0000,  0.1089,  0.7773, -0.3555,  0.0903, -0.0256, -0.0337,  0.1826, -0.2129, -0.2080, -0.2676, -0.0820,  0.1553,  0.3828,  0.2236],
        [ 0.0000, -0.6211, -0.0811,  0.6367, -0.2520, -0.3184, -0.2344,  0.2734, -0.0256,  0.0322,  0.6602,  0.2305,  0.6836,  0.0128, -0.2891],
        [ 0.0000,  0.1670, -0.0014, -0.4355,  0.3086,  0.3477,  0.1572, -0.0898,  0.0688,  0.3496,  0.3633,  0.5156, -0.6133, -0.2021, -0.3203],
        [ 0.0000,  0.0522, -0.2373,  0.0659, -0.6641,  0.3555,  0.1289, -0.5234, -0.3535,  0.2344, -0.4023,  0.1738, -0.2715,  0.0306,  0.1006],
        [ 0.0000,  0.3867, -0.2949,  0.0806, -0.2734, -0.4863,  0.0864,  0.2314,  0.2373,  0.0140,  0.0017, -0.3066,  0.0723, -0.0996,  0.2158],
        [ 0.0000, -0.4199, -0.6797,  0.2520, -0.0359, -0.1494, -0.2148,  0.0854, -0.4473,  0.2715, -0.4629,  0.1396,  0.0073,  0.0820, -0.2812],
        [ 0.0000, -0.2402,  0.5508,  0.4453,  0.0168, -0.0645, -0.6016,  0.4160,  0.7891,  0.3594,  0.1299,  0.5977, -0.4609,  0.2637, -0.5156],
        [ 0.0000, -0.1680, -0.2871, -0.2041,  0.6836, -0.1953, -0.4688, -0.0154,  0.0737,  0.6406,  0.0583, -0.6328, -0.1543,  0.0598, -0.0869],
        [ 0.0000, -0.2656,  0.0679, -0.1416,  0.1562,  0.0349, -0.3438,  0.4492, -0.1396,  0.0039,  0.1396, -0.0096,  0.4414,  0.0378, -0.0322],
        [ 0.0000,  0.1240, -0.4824,  0.0820,  0.1787,  0.3125,  0.2832,  0.2139,  0.0386,  0.6523, -0.2773,  0.1328, -0.2871,  0.4395, -0.3457],
        [ 0.0000, -0.3477, -0.2129,  0.0645,  0.0674, -0.4355, -0.3164, -0.0043, -0.2354, -0.0923, -0.3398, -0.2305,  0.3340,  0.0058, -0.4512],
        [ 0.0000,  0.7031,  0.0693, -0.1611,  0.5742,  0.1729, -0.4199,  0.0405,  0.1250,  0.1099, -0.4121,  0.1206, -0.0574,  0.1201, -1.0312]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.4935],
        [0.3345],
        [0.2480],
        [0.1839],
        [0.1541],
        [0.1343],
        [0.1157],
        [0.1135],
        [0.0959],
        [0.0835],
        [0.0793],
        [0.0739],
        [0.0719],
        [0.0658]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5586, 0.4414, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.4434, 0.2520, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3379, 0.2324, 0.2363, 0.1924, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2441, 0.1455, 0.2178, 0.2021, 0.1904, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2119, 0.1445, 0.1621, 0.1533, 0.1338, 0.1953, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1758, 0.1167, 0.1309, 0.1660, 0.1309, 0.1621, 0.1182, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1338, 0.0942, 0.1299, 0.1387, 0.1245, 0.1445, 0.1006, 0.1338, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1299, 0.0791, 0.0972, 0.0933, 0.1357, 0.1406, 0.1162, 0.1172, 0.0908, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1074, 0.1055, 0.0884, 0.1030, 0.0864, 0.1279, 0.0742, 0.0942, 0.1045, 0.1089, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0972, 0.0674, 0.0884, 0.0688, 0.0967, 0.1069, 0.0767, 0.1157, 0.1016, 0.0913, 0.0898, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1069, 0.0554, 0.0850, 0.0859, 0.0859, 0.0913, 0.0811, 0.0854, 0.0757, 0.0835, 0.0776, 0.0869, 0.0000, 0.0000, 0.0000],
        [0.0723, 0.0659, 0.0771, 0.0579, 0.0801, 0.1221, 0.0947, 0.0884, 0.0688, 0.0635, 0.0593, 0.0693, 0.0801, 0.0000, 0.0000],
        [0.0732, 0.0654, 0.0596, 0.0574, 0.0728, 0.0889, 0.0771, 0.0737, 0.0728, 0.0649, 0.0649, 0.0840, 0.0723, 0.0728, 0.0000],
        [0.0649, 0.0654, 0.0835, 0.0732, 0.0703, 0.0767, 0.0566, 0.0767, 0.0688, 0.0598, 0.0723, 0.0481, 0.0630, 0.0569, 0.0635]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[-0.0121, -0.0045,  0.0012,  ..., -0.0082, -0.0058, -0.0090],
        [ 0.0187, -0.0082,  0.0038,  ..., -0.0151, -0.0191,  0.0113],
        [ 0.0030,  0.0048, -0.0193,  ...,  0.0024, -0.0249,  0.0199],
        ...,
        [-0.0035,  0.0181, -0.0325,  ..., -0.0014,  0.0054, -0.0151],
        [-0.0105, -0.0331, -0.0321,  ..., -0.0267,  0.0248, -0.0173],
        [-0.0141, -0.0062,  0.0021,  ...,  0.0248,  0.0402,  0.0058]], device='cuda:0', requires_grad=True)
K: tensor([-0.6914,  0.8086,  0.8555, -0.0413, -0.2051,  0.3125,  0.2285,  0.9961, -0.0796, -0.4844, -0.1553,  0.5898,  0.8242,  0.6250,  0.9336, -0.1357, -0.2051,  0.5742,  0.4336,  1.1172, -0.5938,  0.3223,  0.3145,  0.1250,  0.3105, -0.2275,  0.4785, -0.4375,  0.2871,  0.4102, -0.2910,  0.1094,
         0.3281,  0.0903,  1.1094, -0.0525, -0.6055,  0.2949, -0.4375, -0.0894, -0.0065,  1.1875, -0.3008, -0.1104,  0.1338,  0.2480,  0.4180,  0.9414, -0.0391, -0.0576, -0.6211, -0.2275, -0.3301, -0.1846,  0.1924, -0.8633, -0.6953,  0.5547, -0.4219, -0.8672,  0.3008,  0.0432,  0.7344, -0.5039],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[-0.0103,  0.0026,  0.0054,  ...,  0.0061,  0.0165, -0.0215],
        [-0.0111,  0.0117,  0.0082,  ...,  0.0197,  0.0144,  0.0015],
        [ 0.0099,  0.0126, -0.0287,  ..., -0.0331, -0.0049,  0.0083],
        ...,
        [ 0.0137, -0.0418,  0.0095,  ...,  0.0090,  0.0012,  0.0059],
        [ 0.0192, -0.0125, -0.0112,  ...,  0.0008, -0.0015,  0.0167],
        [-0.0306,  0.0081, -0.0414,  ...,  0.0034, -0.0162,  0.0066]], device='cuda:0', requires_grad=True)
Q: tensor([-0.9180, -0.0322,  0.0544,  0.3027, -0.9102, -0.7617, -0.8828,  0.5977,  0.3809,  0.1729, -0.7422, -1.0781, -0.0625,  0.1865,  0.3359, -0.2148, -0.1758,  0.0962, -0.0850,  0.2041,  0.0308,  0.3750, -0.7188, -0.4199, -0.8633,  0.0693, -0.4531,  0.0194, -1.3125,  0.3164,  0.1011, -1.4531,
         0.4082,  0.2441, -0.2617, -0.1914,  0.3672,  0.7188,  0.3555, -0.1006,  0.8633,  0.2520, -0.4375, -0.5312, -0.1011, -0.9453, -0.7383, -0.0527, -1.1953,  0.3145,  0.5859,  0.1543, -0.9258, -0.5391, -2.0156,  0.9609,  0.1592,  0.5078, -1.3438, -0.3594,  0.2617,  0.3594,  0.2100, -0.3242],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[     0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000],
        [     0.0000,     -0.2363,     -0.3086,     -0.7617,     -0.1826,      0.0569,     -0.4199,     -0.5117,     -0.6914,     -0.6406,     -0.3320,     -0.4668,     -0.6406,     -0.5195,     -0.4766],
        [     0.0000,     -0.5625,     -0.3711,     -0.6719,     -0.7578,     -0.2305,     -0.9102,     -0.7070,     -0.5469,     -0.4121,     -0.3555,     -0.5195,     -0.6094,     -0.4238,     -0.5977],
        [     0.0000,     -0.3770,     -0.3574,     -0.5625,     -0.4668,     -0.1113,     -0.4863,     -0.5859,     -0.4141,     -0.2275,     -0.4961,     -0.5195,     -0.5703,     -0.3066,     -0.4688],
        [     0.0000,     -0.5156,     -0.1177,     -0.1914,     -0.2490,      0.2197,     -0.2129,     -0.0439,     -0.0708,     -0.2383,     -0.0703,     -0.0260,      0.2695,      0.0250,     -0.1367],
        [     0.0000,     -0.3848,     -0.2656,     -0.3242,     -0.4570,     -0.0815,     -0.5664,     -0.4492,     -0.4531,     -0.6328,     -0.3438,     -0.3613,     -0.3086,     -0.4785,     -0.3516],
        [     0.0000,     -0.4082,     -0.2910,     -0.0557,     -0.2949,     -0.0820,     -0.3945,     -0.3848,     -0.2734,     -0.3906,     -0.2949,     -0.2373,     -0.0977,     -0.3652,     -0.4727],
        [     0.0000,     -0.3535,     -0.0332,      0.0311,     -0.0737,      0.0752,     -0.2852,     -0.0000,     -0.0542,     -0.0254,      0.1055,     -0.0693,     -0.0669,      0.0659,     -0.1377],
        [     0.0000,     -0.4961,     -0.2930,     -0.3340,      0.0386,      0.0762,     -0.1147,     -0.1074,     -0.3613,     -0.3008,     -0.3750,     -0.0835,     -0.1602,     -0.2812,     -0.2539],
        [     0.0000,     -0.0201,     -0.1982,     -0.0432,     -0.2197,      0.1777,     -0.3730,     -0.1328,     -0.0299,      0.0107,     -0.0206,     -0.2324,     -0.2500,     -0.0903,      0.1221],
        [     0.0000,     -0.3691,     -0.0986,     -0.3496,     -0.0090,      0.0923,     -0.2383,      0.1729,      0.0425,     -0.0645,     -0.0815,     -0.0503,      0.0111,      0.0386,     -0.0294],
        [     0.0000,     -0.6562,     -0.2305,     -0.2158,     -0.2158,     -0.1582,     -0.2773,     -0.2217,     -0.3477,     -0.2490,     -0.3203,     -0.2070,     -0.2852,     -0.2852,     -0.1982],
        [     0.0000,     -0.0947,      0.0623,     -0.2256,      0.1035,      0.5234,      0.2695,      0.2002,     -0.0508,     -0.1299,     -0.2012,     -0.0447,      0.1030,      0.0645,     -0.1729],
        [     0.0000,     -0.1099,     -0.2051,     -0.2441,     -0.0070,      0.1953,      0.0522,      0.0104,     -0.0044,     -0.1211,     -0.1216,      0.1396,     -0.0132,     -0.0085,      0.0184],
        [     0.0000,      0.0025,      0.2500,      0.1191,      0.0796,      0.1650,     -0.1367,      0.1621,      0.0596,     -0.0854,      0.1035,     -0.3027,     -0.0366,     -0.1328,     -0.0256]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.5311],
        [0.3607],
        [0.2579],
        [0.1987],
        [0.1794],
        [0.1437],
        [0.1305],
        [0.1169],
        [0.1008],
        [0.0933],
        [0.0898],
        [0.0796],
        [0.0697],
        [0.0670]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.6367, 0.3652, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3672, 0.3066, 0.3262, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2891, 0.2100, 0.2207, 0.2793, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1855, 0.1592, 0.2031, 0.2236, 0.2285, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1670, 0.1147, 0.1406, 0.1865, 0.1855, 0.2051, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1348, 0.1206, 0.1338, 0.1523, 0.1543, 0.1562, 0.1475, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1250, 0.1055, 0.1172, 0.1426, 0.1348, 0.1387, 0.1191, 0.1172, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1035, 0.0786, 0.0967, 0.1377, 0.1099, 0.1221, 0.1147, 0.1162, 0.1201, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0967, 0.0859, 0.0879, 0.1157, 0.1167, 0.1128, 0.1040, 0.0967, 0.1123, 0.0718, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0903, 0.0713, 0.0806, 0.1030, 0.0957, 0.0947, 0.0918, 0.1030, 0.1021, 0.0703, 0.0962, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0889, 0.0762, 0.0708, 0.0947, 0.0840, 0.0879, 0.0850, 0.0786, 0.1055, 0.0569, 0.0928, 0.0791, 0.0000, 0.0000, 0.0000],
        [0.0796, 0.0664, 0.0679, 0.0986, 0.0835, 0.0845, 0.0815, 0.0723, 0.0854, 0.0532, 0.0796, 0.0713, 0.0767, 0.0000, 0.0000],
        [0.0645, 0.0515, 0.0752, 0.0869, 0.0825, 0.0869, 0.0708, 0.0781, 0.0771, 0.0493, 0.0728, 0.0737, 0.0718, 0.0593, 0.0000],
        [0.0825, 0.0588, 0.0684, 0.0825, 0.0767, 0.0732, 0.0771, 0.0669, 0.0703, 0.0476, 0.0669, 0.0579, 0.0601, 0.0571, 0.0542]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[ 0.0026, -0.0243,  0.0172,  ...,  0.0146, -0.0302,  0.0010],
        [ 0.0180, -0.0040,  0.0162,  ..., -0.0060, -0.0047,  0.0204],
        [-0.0112, -0.0013,  0.0098,  ...,  0.0354, -0.0033, -0.0065],
        ...,
        [ 0.0056,  0.0004, -0.0244,  ..., -0.0006, -0.0251,  0.0197],
        [-0.0147, -0.0119, -0.0230,  ..., -0.0120, -0.0078,  0.0165],
        [ 0.0218,  0.0200,  0.0367,  ...,  0.0204, -0.0048, -0.0124]], device='cuda:0', requires_grad=True)
K: tensor([     0.4512,     -0.4570,      0.2832,      0.0084,     -0.0155,      0.1680,      0.4551,      0.1934,      0.5195,      0.5508,     -0.3066,     -0.5586,     -0.6172,     -0.5195,      0.1387,      0.2910,      0.4121,      0.4570,     -0.0004,     -0.7891,     -0.0251,     -0.0698,
             0.4688,     -0.8398,      1.7578,     -0.6758,     -1.0781,     -0.4766,     -0.0265,      0.4688,     -0.0747,     -0.0264,      0.1177,      0.7188,     -0.2031,      0.5469,      0.9883,      0.1270,     -0.5117,     -0.3613,      0.9570,     -0.2100,     -0.1084,     -0.5117,
             0.3516,      0.4121,      1.1797,      0.6016,     -0.8633,      0.2656,      0.6758,      0.4023,     -0.0938,     -0.3848,     -0.3281,      0.8555,     -0.7109,     -1.1953,     -0.0161,     -0.2188,     -0.2207,      0.2891,      0.1426,      1.0156], device='cuda:0',
       dtype=torch.bfloat16)
Qweights
tensor([[ 0.0099,  0.0127,  0.0007,  ...,  0.0087,  0.0309, -0.0047],
        [-0.0313,  0.0239, -0.0321,  ...,  0.0102,  0.0583, -0.0113],
        [-0.0013, -0.0082, -0.0048,  ..., -0.0200, -0.0048, -0.0052],
        ...,
        [ 0.0278,  0.0171, -0.0135,  ..., -0.0226, -0.0378,  0.0407],
        [ 0.0458,  0.0138, -0.0305,  ...,  0.0385,  0.0033,  0.0214],
        [ 0.0185, -0.0105, -0.0024,  ...,  0.0254,  0.0090,  0.0084]], device='cuda:0', requires_grad=True)
Q: tensor([-0.3535,  0.3203, -0.6016, -0.1982, -0.9297,  0.2500, -0.1504, -0.4414,  0.2520, -0.5078,  0.2100,  0.2383, -0.5859, -0.2500, -0.5469, -0.6094, -0.0771,  0.2754,  0.6484, -0.7266, -0.5859,  0.4336, -0.5508,  0.0283,  0.3672,  0.3809,  0.1611,  0.1328, -0.0325,  0.2988,  0.5977, -0.2773,
         0.2773,  0.5820,  0.2461, -0.7656, -0.5312,  0.1611,  0.7305,  0.3105,  0.1040, -0.9414, -0.5547, -0.4219,  0.7422,  0.1426,  0.6016, -1.0312, -0.2021, -0.1865,  0.1523,  0.2197,  0.8516,  0.5078,  0.8398, -1.0078,  0.2285,  0.7148, -0.4902, -0.3379,  0.5703, -0.1309,  0.3613, -1.1094],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000, -0.5547, -0.2949, -0.3945, -0.3555, -0.4004, -0.4473, -0.1270, -0.2676, -0.4570, -0.3477, -0.4199, -0.3535, -0.4844, -0.4961],
        [ 0.0000, -0.1768, -0.1162,  0.1006,  0.0815,  0.1245, -0.0796,  0.0294,  0.0131, -0.4004,  0.0952,  0.0085, -0.0571, -0.1279, -0.2334],
        [ 0.0000, -0.3203, -0.2695, -0.0332, -0.0649,  0.0801, -0.0615, -0.0334, -0.0796, -0.4453, -0.0022, -0.0447, -0.0762, -0.3574, -0.2217],
        [ 0.0000, -0.1562,  0.0889,  0.1855,  0.2080,  0.2051,  0.1006,  0.2383,  0.2500, -0.1680,  0.1787,  0.0674,  0.0452,  0.0469,  0.1309],
        [ 0.0000, -0.3730, -0.1670,  0.1143,  0.1084,  0.2090,  0.1602,  0.1162,  0.2334, -0.3965,  0.2119,  0.0566,  0.0762, -0.1040,  0.0378],
        [ 0.0000, -0.1128, -0.0087,  0.1221,  0.1318,  0.1445,  0.0874,  0.0732,  0.1807, -0.2812,  0.2070, -0.0114,  0.0947,  0.0142, -0.0718],
        [ 0.0000, -0.1699, -0.0635,  0.1328,  0.0762,  0.1016, -0.0469, -0.0654,  0.0530, -0.3789,  0.0193, -0.1079, -0.0510, -0.1934, -0.1846],
        [ 0.0000, -0.2754, -0.0698,  0.2871,  0.0610,  0.1660,  0.1011,  0.1167,  0.1465, -0.4941,  0.1436,  0.1079, -0.0146, -0.1562, -0.0659],
        [ 0.0000, -0.1201, -0.0981,  0.1797,  0.1875,  0.1533,  0.0742, -0.0008,  0.1504, -0.3008,  0.1123, -0.0471, -0.0154, -0.0771, -0.1240],
        [ 0.0000, -0.2363, -0.1138,  0.1289,  0.0576,  0.0457,  0.0128,  0.1299,  0.1201, -0.2490,  0.0630, -0.0830, -0.0280, -0.1855, -0.1162],
        [ 0.0000, -0.1533, -0.2266,  0.0664, -0.0522, -0.0073, -0.0425, -0.1235,  0.1738, -0.4434,  0.0442, -0.1157, -0.0471, -0.2002, -0.1621],
        [ 0.0000, -0.1836, -0.1582,  0.2148,  0.0496,  0.0603,  0.0228, -0.0928,  0.0732, -0.4023,  0.0018, -0.1123, -0.0398, -0.2402, -0.1201],
        [ 0.0000, -0.2207,  0.1553,  0.3008,  0.2480,  0.3008,  0.0942,  0.1953,  0.1836, -0.2656,  0.1245,  0.1367,  0.1089, -0.0801,  0.0879],
        [ 0.0000, -0.3398, -0.1895,  0.0010, -0.0767, -0.1221, -0.0664, -0.2061, -0.1572, -0.5508, -0.2119, -0.3555, -0.3164, -0.3691, -0.4199]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.5151],
        [0.3258],
        [0.2467],
        [0.1971],
        [0.1647],
        [0.1461],
        [0.1276],
        [0.1128],
        [0.1027],
        [0.0906],
        [0.0848],
        [0.0795],
        [0.0715],
        [0.0715]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3691, 0.6289, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2217, 0.3730, 0.4043, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1602, 0.2656, 0.2852, 0.2891, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1260, 0.2061, 0.2207, 0.2227, 0.2236, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1045, 0.1680, 0.1807, 0.1816, 0.1826, 0.1816, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0894, 0.1426, 0.1523, 0.1533, 0.1543, 0.1543, 0.1543, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0776, 0.1230, 0.1318, 0.1328, 0.1338, 0.1328, 0.1328, 0.1338, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0693, 0.1089, 0.1162, 0.1172, 0.1177, 0.1177, 0.1177, 0.1182, 0.1172, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0623, 0.0972, 0.1040, 0.1050, 0.1055, 0.1050, 0.1050, 0.1055, 0.1050, 0.1055, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0566, 0.0879, 0.0942, 0.0947, 0.0952, 0.0952, 0.0952, 0.0957, 0.0947, 0.0952, 0.0952, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0518, 0.0806, 0.0859, 0.0864, 0.0869, 0.0869, 0.0869, 0.0874, 0.0864, 0.0869, 0.0869, 0.0869, 0.0000, 0.0000, 0.0000],
        [0.0479, 0.0737, 0.0791, 0.0796, 0.0801, 0.0796, 0.0801, 0.0801, 0.0796, 0.0801, 0.0801, 0.0801, 0.0801, 0.0000, 0.0000],
        [0.0444, 0.0684, 0.0732, 0.0737, 0.0742, 0.0737, 0.0737, 0.0742, 0.0737, 0.0742, 0.0742, 0.0742, 0.0742, 0.0737, 0.0000],
        [0.0415, 0.0635, 0.0679, 0.0688, 0.0688, 0.0688, 0.0688, 0.0693, 0.0688, 0.0688, 0.0688, 0.0688, 0.0693, 0.0688, 0.0688]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[-0.0270,  0.0143, -0.0106,  ...,  0.0229, -0.0267, -0.0376],
        [ 0.0066, -0.0190,  0.0257,  ...,  0.0311, -0.0142, -0.0039],
        [ 0.0165,  0.0075,  0.0236,  ..., -0.0005,  0.0265,  0.0253],
        ...,
        [-0.0103,  0.0167,  0.0192,  ...,  0.0074, -0.0207, -0.0081],
        [ 0.0013, -0.0272,  0.0105,  ...,  0.0107, -0.0095, -0.0019],
        [-0.0106, -0.0185,  0.0159,  ...,  0.0027,  0.0267, -0.0310]], device='cuda:0', requires_grad=True)
K: tensor([ 0.2949,  0.5820,  0.6211,  0.1973,  0.5703,  0.0864, -0.2598, -0.9688,  0.9102,  0.5430, -0.5781,  0.4023,  0.3301, -0.7031, -0.6562,  0.4766,  0.2676, -0.1523, -0.0256,  0.5820, -0.1143, -0.5156,  0.1455,  1.0000,  0.1230,  0.6523,  0.0713, -0.0420,  0.0942, -0.0991, -0.6289,  0.5469,
         0.5977, -0.2363, -0.8125,  0.4062, -0.4863, -0.3711, -0.1309,  0.4219, -0.6602,  0.1729, -0.1406, -0.4844,  1.1875,  0.5781, -0.8086, -0.2949, -0.5898, -0.1963, -0.0164, -0.5742,  0.3320,  0.7891,  0.4648, -0.2334,  0.1040, -0.4238,  0.3164, -1.0469,  0.6562,  0.7148,  0.3340, -0.3887],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[-0.0018,  0.0220, -0.0115,  ..., -0.0135,  0.0005, -0.0199],
        [ 0.0014, -0.0109, -0.0003,  ..., -0.0092, -0.0171,  0.0084],
        [-0.0246,  0.0235, -0.0226,  ..., -0.0183,  0.0022,  0.0058],
        ...,
        [-0.0348,  0.0194, -0.0247,  ..., -0.0129,  0.0347,  0.0209],
        [-0.0096,  0.0033, -0.0469,  ...,  0.0146,  0.0022,  0.0088],
        [ 0.0094, -0.0135,  0.0139,  ..., -0.0386,  0.0043, -0.0198]], device='cuda:0', requires_grad=True)
Q: tensor([-0.4375,  0.4414, -0.4414, -0.3281, -0.4844, -0.4121,  0.2100, -0.4512,  0.4336, -1.3281, -0.4844,  0.3184, -0.4766, -0.3281, -0.6211, -1.2031, -0.6328,  0.2432, -0.1001, -0.0405, -0.6016, -0.3184, -0.2344,  1.0234, -0.9023,  0.1934, -0.4824, -0.3477,  0.6758,  0.2305, -0.0723,  1.3438,
         0.1982, -0.2539, -1.0312,  1.1328, -0.1226, -0.5195,  1.1797,  0.6172, -0.0361,  1.2188, -0.0432, -0.0952,  0.3086,  0.0510,  0.2480,  0.4688, -0.7305, -0.2422,  0.0107, -0.9297,  1.0000, -0.1943, -0.9258, -0.2207, -0.0811,  0.4004,  1.0234,  0.2148, -0.5586, -0.4805,  0.6992,  0.2070],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.5352, 0.6289, 0.6445, 0.6523, 0.6484, 0.6484, 0.6562, 0.6484, 0.6523, 0.6523, 0.6523, 0.6562, 0.6523, 0.6523],
        [0.0000, 0.5234, 0.6055, 0.6133, 0.6172, 0.6133, 0.6133, 0.6172, 0.6133, 0.6172, 0.6133, 0.6133, 0.6172, 0.6133, 0.6094],
        [0.0000, 0.5078, 0.5820, 0.5898, 0.5938, 0.5898, 0.5898, 0.5938, 0.5859, 0.5898, 0.5898, 0.5898, 0.5898, 0.5859, 0.5859],
        [0.0000, 0.4922, 0.5625, 0.5703, 0.5742, 0.5703, 0.5703, 0.5742, 0.5664, 0.5742, 0.5703, 0.5703, 0.5703, 0.5664, 0.5664],
        [0.0000, 0.4805, 0.5508, 0.5586, 0.5625, 0.5586, 0.5586, 0.5625, 0.5547, 0.5586, 0.5586, 0.5586, 0.5586, 0.5547, 0.5547],
        [0.0000, 0.4668, 0.5352, 0.5430, 0.5469, 0.5430, 0.5430, 0.5469, 0.5430, 0.5469, 0.5430, 0.5430, 0.5469, 0.5430, 0.5391],
        [0.0000, 0.4590, 0.5273, 0.5352, 0.5391, 0.5391, 0.5391, 0.5430, 0.5352, 0.5391, 0.5391, 0.5391, 0.5391, 0.5352, 0.5352],
        [0.0000, 0.4531, 0.5195, 0.5273, 0.5312, 0.5312, 0.5312, 0.5352, 0.5273, 0.5312, 0.5312, 0.5312, 0.5312, 0.5273, 0.5273],
        [0.0000, 0.4473, 0.5156, 0.5234, 0.5273, 0.5234, 0.5234, 0.5273, 0.5234, 0.5273, 0.5234, 0.5234, 0.5273, 0.5234, 0.5195],
        [0.0000, 0.4414, 0.5078, 0.5156, 0.5234, 0.5195, 0.5195, 0.5234, 0.5156, 0.5234, 0.5195, 0.5195, 0.5234, 0.5195, 0.5156],
        [0.0000, 0.4375, 0.5039, 0.5117, 0.5156, 0.5156, 0.5156, 0.5195, 0.5117, 0.5195, 0.5156, 0.5156, 0.5195, 0.5156, 0.5117],
        [0.0000, 0.4336, 0.5000, 0.5078, 0.5156, 0.5117, 0.5117, 0.5156, 0.5078, 0.5156, 0.5117, 0.5117, 0.5156, 0.5117, 0.5078],
        [0.0000, 0.4277, 0.4961, 0.5039, 0.5117, 0.5078, 0.5078, 0.5117, 0.5078, 0.5117, 0.5078, 0.5078, 0.5117, 0.5078, 0.5078],
        [0.0000, 0.4238, 0.4922, 0.5000, 0.5039, 0.5039, 0.5039, 0.5078, 0.5000, 0.5078, 0.5039, 0.5039, 0.5078, 0.5039, 0.5000]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.4451],
        [0.2782],
        [0.2033],
        [0.1602],
        [0.1326],
        [0.1132],
        [0.0985],
        [0.0873],
        [0.0784],
        [0.0714],
        [0.0652],
        [0.0601],
        [0.0559],
        [0.0521]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5078, 0.4902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3320, 0.3438, 0.3242, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2500, 0.2637, 0.2480, 0.2383, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2041, 0.2139, 0.2012, 0.1934, 0.1885, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1729, 0.1797, 0.1699, 0.1631, 0.1582, 0.1562, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1504, 0.1562, 0.1465, 0.1416, 0.1377, 0.1348, 0.1328, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1328, 0.1377, 0.1299, 0.1250, 0.1216, 0.1191, 0.1177, 0.1162, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1196, 0.1235, 0.1162, 0.1118, 0.1089, 0.1069, 0.1055, 0.1040, 0.1035, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1089, 0.1118, 0.1055, 0.1016, 0.0986, 0.0972, 0.0957, 0.0942, 0.0938, 0.0928, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1001, 0.1021, 0.0962, 0.0928, 0.0903, 0.0889, 0.0874, 0.0864, 0.0859, 0.0850, 0.0850, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0923, 0.0942, 0.0889, 0.0854, 0.0830, 0.0820, 0.0806, 0.0796, 0.0791, 0.0786, 0.0781, 0.0781, 0.0000, 0.0000, 0.0000],
        [0.0859, 0.0874, 0.0825, 0.0791, 0.0771, 0.0762, 0.0747, 0.0737, 0.0732, 0.0728, 0.0728, 0.0723, 0.0723, 0.0000, 0.0000],
        [0.0801, 0.0815, 0.0767, 0.0742, 0.0718, 0.0708, 0.0698, 0.0688, 0.0684, 0.0679, 0.0679, 0.0674, 0.0674, 0.0669, 0.0000],
        [0.0757, 0.0762, 0.0723, 0.0693, 0.0674, 0.0664, 0.0654, 0.0645, 0.0645, 0.0635, 0.0635, 0.0635, 0.0630, 0.0625, 0.0625]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[ 0.0351,  0.0365, -0.0233,  ...,  0.0068, -0.0055, -0.0057],
        [-0.0106,  0.0269,  0.0009,  ..., -0.0298,  0.0168, -0.0352],
        [ 0.0025,  0.0233,  0.0207,  ..., -0.0037, -0.0194,  0.0150],
        ...,
        [ 0.0151,  0.0099, -0.0126,  ...,  0.0210, -0.0162, -0.0022],
        [-0.0212, -0.0035, -0.0082,  ..., -0.0130,  0.0065, -0.0296],
        [-0.0119, -0.0124, -0.0248,  ..., -0.0036, -0.0129, -0.0050]], device='cuda:0', requires_grad=True)
K: tensor([ 0.0403,  0.2295, -0.0737, -0.3047,  0.5781, -1.3672, -0.6641, -0.8242,  0.2061, -0.1309,  0.0118, -0.7344,  0.2178, -0.0576,  0.5039, -0.4668,  0.1289,  0.3535, -0.6602,  0.5820,  0.2910, -0.0322,  0.4219,  0.0050,  0.5000, -0.8398,  0.4883, -0.3086,  0.6172,  0.0908, -0.0238, -0.1245,
        -0.4746,  0.2969, -0.6367, -0.4336, -0.4746,  0.0481, -0.5039,  0.1670,  0.5781,  0.6328, -0.3887, -0.5625, -0.2324,  0.0732, -0.3867, -0.1216,  0.3867,  0.7305,  0.2852, -0.5469,  0.2246,  0.6562,  0.3320, -0.4238, -0.6211,  0.2891,  0.2871,  0.6875, -0.6680,  0.4355, -0.1787, -1.2656],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[ 0.0147, -0.0263, -0.0036,  ..., -0.0030, -0.0351,  0.0011],
        [ 0.0275,  0.0018, -0.0050,  ...,  0.0205,  0.0073,  0.0270],
        [ 0.0156, -0.0193, -0.0131,  ...,  0.0133,  0.0180, -0.0348],
        ...,
        [-0.0018, -0.0230,  0.0100,  ...,  0.0135,  0.0394,  0.0112],
        [-0.0110, -0.0361,  0.0394,  ..., -0.0032, -0.0045, -0.0265],
        [-0.0307,  0.0018, -0.0473,  ...,  0.0161,  0.0060, -0.0008]], device='cuda:0', requires_grad=True)
Q: tensor([    -0.5469,     -0.2305,     -0.1338,      0.0481,      0.0552,      0.3145,      0.7656,     -0.0542,     -0.7656,      0.1465,      0.8008,     -0.1216,     -0.7461,     -0.5938,     -0.6406,     -0.5664,     -0.6992,     -0.7930,      0.0579,     -0.3105,      0.5898,      0.4316,
            -0.2021,     -0.5430,     -0.7383,      0.4746,     -0.0244,     -0.2070,     -0.1885,     -0.9883,      0.0136,      0.0452,     -0.1328,      1.3125,     -0.3457,     -0.9609,      1.1094,     -0.7188,      0.1064,      0.0615,     -0.2656,      1.0625,     -0.3516,      0.2930,
             0.6797,      0.3066,      0.0518,      1.1094,     -0.2373,      0.2988,      1.2031,     -0.0008,      0.7422,     -1.3047,     -0.0806,     -0.8398,     -0.5312,      0.9336,     -0.5195,      0.6172,      0.5039,     -0.8203,      0.3535,     -0.1816], device='cuda:0',
       dtype=torch.bfloat16)
RAWVALUES
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000, -0.0371, -0.0708, -0.0986, -0.1182, -0.1299, -0.1426, -0.1504, -0.1572, -0.1631, -0.1650, -0.1670, -0.1699, -0.1738, -0.1768],
        [ 0.0000,  0.0359, -0.0188, -0.0559, -0.0815, -0.0972, -0.1128, -0.1230, -0.1299, -0.1377, -0.1406, -0.1436, -0.1475, -0.1523, -0.1553],
        [ 0.0000,  0.0469, -0.0126, -0.0515, -0.0791, -0.0952, -0.1113, -0.1221, -0.1299, -0.1387, -0.1406, -0.1436, -0.1475, -0.1523, -0.1562],
        [ 0.0000,  0.0469, -0.0132, -0.0525, -0.0806, -0.0967, -0.1133, -0.1240, -0.1318, -0.1406, -0.1426, -0.1465, -0.1494, -0.1553, -0.1582],
        [ 0.0000,  0.0420, -0.0182, -0.0574, -0.0854, -0.1021, -0.1182, -0.1289, -0.1367, -0.1455, -0.1475, -0.1514, -0.1553, -0.1602, -0.1641],
        [ 0.0000,  0.0381, -0.0222, -0.0615, -0.0894, -0.1060, -0.1221, -0.1328, -0.1406, -0.1494, -0.1514, -0.1553, -0.1592, -0.1641, -0.1680],
        [ 0.0000,  0.0342, -0.0261, -0.0654, -0.0933, -0.1099, -0.1260, -0.1367, -0.1445, -0.1533, -0.1553, -0.1592, -0.1631, -0.1680, -0.1719],
        [ 0.0000,  0.0317, -0.0283, -0.0674, -0.0952, -0.1118, -0.1279, -0.1387, -0.1455, -0.1553, -0.1572, -0.1611, -0.1641, -0.1699, -0.1738],
        [ 0.0000,  0.0275, -0.0322, -0.0708, -0.0986, -0.1147, -0.1309, -0.1416, -0.1494, -0.1582, -0.1602, -0.1641, -0.1680, -0.1729, -0.1768],
        [ 0.0000,  0.0220, -0.0371, -0.0757, -0.1035, -0.1196, -0.1357, -0.1465, -0.1533, -0.1621, -0.1641, -0.1680, -0.1719, -0.1768, -0.1807],
        [ 0.0000,  0.0182, -0.0400, -0.0781, -0.1055, -0.1216, -0.1377, -0.1484, -0.1553, -0.1641, -0.1660, -0.1699, -0.1729, -0.1787, -0.1826],
        [ 0.0000,  0.0170, -0.0420, -0.0806, -0.1079, -0.1240, -0.1406, -0.1514, -0.1582, -0.1670, -0.1689, -0.1729, -0.1758, -0.1816, -0.1855],
        [ 0.0000,  0.0160, -0.0427, -0.0806, -0.1084, -0.1240, -0.1406, -0.1514, -0.1582, -0.1670, -0.1689, -0.1729, -0.1758, -0.1816, -0.1846],
        [ 0.0000,  0.0117, -0.0469, -0.0850, -0.1123, -0.1279, -0.1445, -0.1553, -0.1621, -0.1709, -0.1729, -0.1768, -0.1797, -0.1855, -0.1885]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.4619],
        [0.3038],
        [0.2270],
        [0.1813],
        [0.1512],
        [0.1295],
        [0.1135],
        [0.1010],
        [0.0910],
        [0.0828],
        [0.0759],
        [0.0700],
        [0.0652],
        [0.0608]], device='cuda:0')
rank 0 sample 0: A Poem for you! Roses are red, Potatoes are 
------
		( the:0.0095 the:0.0095 the:0.0095 the:0.0095 the:0.0095 the:0.0095 the:0.0095 the:0.0095)
 the
------
		( the:0.0095 the:0.0095 the:0.0095 the:0.0095 the:0.0095 the:0.0095 the:0.0095 the:0.0095)
 the the the the the the the the the the the the the the the
@ 50 train 9.5664 , allloss: 10.3490, dt: 1690.09ms, fracRes: 0.0062, norm(attn): 0.0625, norm(output): 0.1572, norm(x): 0.1573, norm(y): 1.0000, norm:6.1990, tok/sec: 77553.37, flops:81.40, batch-reuse:1
@ 51 train 9.6009 , allloss: 10.3316, dt: 1307.08ms, fracRes: 0.0062, norm(attn): 0.0625, norm(output): 0.1582, norm(x): 0.1586, norm(y): 1.0000, norm:5.7522, tok/sec: 100278.21, flops:105.26, batch-reuse:1
@ 52 train 9.5313 , allloss: 10.2044, dt: 1337.16ms, fracRes: 0.0062, norm(attn): 0.0630, norm(output): 0.1602, norm(x): 0.1600, norm(y): 1.0000, norm:5.3549, tok/sec: 98022.98, flops:102.89, batch-reuse:1
@ 53 train 9.5694 , allloss: 10.2020, dt: 1340.34ms, fracRes: 0.0061, norm(attn): 0.0630, norm(output): 0.1621, norm(x): 0.1613, norm(y): 1.0000, norm:5.0401, tok/sec: 97790.29, flops:102.64, batch-reuse:1
@ 54 train 9.5514 , allloss: 10.1431, dt: 1343.04ms, fracRes: 0.0061, norm(attn): 0.0630, norm(output): 0.1621, norm(x): 0.1627, norm(y): 1.0000, norm:4.7418, tok/sec: 97593.42, flops:102.44, batch-reuse:1
@ 55 train 9.6006 , allloss: 10.1774, dt: 1319.74ms, fracRes: 0.0061, norm(attn): 0.0630, norm(output): 0.1641, norm(x): 0.1640, norm(y): 1.0000, norm:4.5401, tok/sec: 99316.74, flops:104.25, batch-reuse:1
@ 56 train 9.5233 , allloss: 10.0543, dt: 1309.23ms, fracRes: 0.0061, norm(attn): 0.0635, norm(output): 0.1670, norm(x): 0.1655, norm(y): 1.0000, norm:4.3313, tok/sec: 100113.62, flops:105.08, batch-reuse:1
@ 57 train 9.4896 , allloss: 9.9898, dt: 1289.28ms, fracRes: 0.0061, norm(attn): 0.0635, norm(output): 0.1709, norm(x): 0.1669, norm(y): 1.0000, norm:4.2004, tok/sec: 101663.27, flops:106.71, batch-reuse:1
@ 58 train 9.5307 , allloss: 10.0128, dt: 1315.02ms, fracRes: 0.0061, norm(attn): 0.0635, norm(output): 0.1709, norm(x): 0.1684, norm(y): 1.0000, norm:4.0259, tok/sec: 99673.29, flops:104.62, batch-reuse:1
@ 59 train 9.4556 , allloss: 9.9119, dt: 1315.83ms, fracRes: 0.0060, norm(attn): 0.0635, norm(output): 0.1709, norm(x): 0.1699, norm(y): 1.0000, norm:4.0414, tok/sec: 99611.85, flops:104.56, batch-reuse:1
@ 60 train 9.4833 , allloss: 9.9207, dt: 1306.06ms, fracRes: 0.0060, norm(attn): 0.0635, norm(output): 0.1719, norm(x): 0.1714, norm(y): 1.0000, norm:3.7185, tok/sec: 100357.07, flops:105.34, batch-reuse:1
@ 61 train 9.4928 , allloss: 9.9194, dt: 1329.38ms, fracRes: 0.0060, norm(attn): 0.0649, norm(output): 0.1729, norm(x): 0.1728, norm(y): 1.0000, norm:3.6091, tok/sec: 98596.37, flops:103.49, batch-reuse:1
@ 62 train 9.4282 , allloss: 9.8393, dt: 1321.87ms, fracRes: 0.0060, norm(attn): 0.0659, norm(output): 0.1738, norm(x): 0.1744, norm(y): 1.0000, norm:5.0623, tok/sec: 99156.29, flops:104.08, batch-reuse:1
@ 63 train 9.4841 , allloss: 9.8878, dt: 1291.53ms, fracRes: 0.0060, norm(attn): 0.0659, norm(output): 0.1738, norm(x): 0.1757, norm(y): 1.0000, norm:3.5686, tok/sec: 101486.14, flops:106.52, batch-reuse:1
@ 64 train 9.4652 , allloss: 9.8502, dt: 1309.59ms, fracRes: 0.0060, norm(attn): 0.0659, norm(output): 0.1768, norm(x): 0.1773, norm(y): 1.0001, norm:3.4186, tok/sec: 100086.39, flops:105.05, batch-reuse:1
@ 65 train 9.4861 , allloss: 9.8632, dt: 1319.58ms, fracRes: 0.0060, norm(attn): 0.0659, norm(output): 0.1816, norm(x): 0.1787, norm(y): 1.0001, norm:3.4056, tok/sec: 99328.42, flops:104.26, batch-reuse:1
@ 66 train 9.4688 , allloss: 9.8287, dt: 1308.21ms, fracRes: 0.0060, norm(attn): 0.0664, norm(output): 0.1826, norm(x): 0.1802, norm(y): 1.0001, norm:3.6436, tok/sec: 100191.71, flops:105.16, batch-reuse:1
@ 67 train 9.3925 , allloss: 9.7383, dt: 1305.28ms, fracRes: 0.0060, norm(attn): 0.0664, norm(output): 0.1855, norm(x): 0.1818, norm(y): 1.0001, norm:3.3666, tok/sec: 100416.86, flops:105.40, batch-reuse:1
@ 68 train 9.4460 , allloss: 9.7891, dt: 1321.40ms, fracRes: 0.0060, norm(attn): 0.0659, norm(output): 0.1865, norm(x): 0.1833, norm(y): 1.0001, norm:3.2227, tok/sec: 99191.43, flops:104.11, batch-reuse:1
@ 69 train 9.4064 , allloss: 9.7376, dt: 1348.54ms, fracRes: 0.0060, norm(attn): 0.0669, norm(output): 0.1865, norm(x): 0.1850, norm(y): 1.0001, norm:3.1797, tok/sec: 97195.31, flops:102.02, batch-reuse:1
@ 70 train 9.4085 , allloss: 9.7266, dt: 1325.67ms, fracRes: 0.0060, norm(attn): 0.0669, norm(output): 0.1875, norm(x): 0.1866, norm(y): 1.0001, norm:3.0729, tok/sec: 98872.55, flops:103.78, batch-reuse:1
@ 71 train 9.4028 , allloss: 9.7138, dt: 1303.55ms, fracRes: 0.0060, norm(attn): 0.0669, norm(output): 0.1895, norm(x): 0.1883, norm(y): 1.0001, norm:3.0669, tok/sec: 100550.15, flops:105.54, batch-reuse:1
@ 72 train 9.3842 , allloss: 9.6862, dt: 1314.69ms, fracRes: 0.0061, norm(attn): 0.0669, norm(output): 0.1895, norm(x): 0.1900, norm(y): 1.0001, norm:3.0229, tok/sec: 99697.86, flops:104.65, batch-reuse:1
@ 73 train 9.4112 , allloss: 9.7135, dt: 1299.80ms, fracRes: 0.0061, norm(attn): 0.0674, norm(output): 0.1895, norm(x): 0.1917, norm(y): 1.0001, norm:3.3461, tok/sec: 100840.08, flops:105.84, batch-reuse:1
@ 74 train 9.3898 , allloss: 9.6826, dt: 1349.90ms, fracRes: 0.0061, norm(attn): 0.0674, norm(output): 0.1934, norm(x): 0.1934, norm(y): 1.0001, norm:2.9482, tok/sec: 97097.72, flops:101.92, batch-reuse:1
@ 75 train 9.6081 , allloss: 9.9247, dt: 1319.53ms, fracRes: 0.0061, norm(attn): 0.0669, norm(output): 0.1982, norm(x): 0.1946, norm(y): 1.0001, norm:4.0368, tok/sec: 99332.71, flops:104.26, batch-reuse:1
@ 76 train 9.3734 , allloss: 9.6585, dt: 1336.98ms, fracRes: 0.0061, norm(attn): 0.0684, norm(output): 0.1982, norm(x): 0.1968, norm(y): 1.0001, norm:2.9205, tok/sec: 98035.85, flops:102.90, batch-reuse:1
@ 77 train 9.5594 , allloss: 9.8915, dt: 1316.70ms, fracRes: 0.0061, norm(attn): 0.0688, norm(output): 0.2021, norm(x): 0.1979, norm(y): 1.0001, norm:4.7242, tok/sec: 99545.66, flops:104.49, batch-reuse:1
@ 78 train 9.4171 , allloss: 9.7124, dt: 1304.63ms, fracRes: 0.0061, norm(attn): 0.0693, norm(output): 0.2021, norm(x): 0.2000, norm(y): 1.0001, norm:3.6339, tok/sec: 100466.92, flops:105.45, batch-reuse:1
@ 79 train 9.3204 , allloss: 9.5826, dt: 1317.69ms, fracRes: 0.0062, norm(attn): 0.0693, norm(output): 0.2031, norm(x): 0.2020, norm(y): 1.0001, norm:2.9237, tok/sec: 99470.67, flops:104.41, batch-reuse:1
@ 80 train 9.3410 , allloss: 9.5985, dt: 1308.09ms, fracRes: 0.0062, norm(attn): 0.0693, norm(output): 0.2041, norm(x): 0.2038, norm(y): 1.0001, norm:2.8930, tok/sec: 100200.71, flops:105.17, batch-reuse:1
@ 81 train 9.3293 , allloss: 9.5797, dt: 1309.08ms, fracRes: 0.0062, norm(attn): 0.0693, norm(output): 0.2041, norm(x): 0.2056, norm(y): 1.0001, norm:2.8162, tok/sec: 100125.54, flops:105.09, batch-reuse:1
@ 82 train 9.2703 , allloss: 9.5154, dt: 1304.19ms, fracRes: 0.0062, norm(attn): 0.0698, norm(output): 0.2070, norm(x): 0.2075, norm(y): 1.0001, norm:2.8465, tok/sec: 100501.01, flops:105.49, batch-reuse:1
@ 83 train 9.2941 , allloss: 9.5369, dt: 1303.76ms, fracRes: 0.0063, norm(attn): 0.0698, norm(output): 0.2070, norm(x): 0.2091, norm(y): 1.0001, norm:2.7635, tok/sec: 100533.58, flops:105.52, batch-reuse:1
@ 84 train 9.2943 , allloss: 9.5352, dt: 1308.98ms, fracRes: 0.0063, norm(attn): 0.0698, norm(output): 0.2148, norm(x): 0.2110, norm(y): 1.0001, norm:2.7677, tok/sec: 100132.95, flops:105.10, batch-reuse:1
@ 85 train 9.2579 , allloss: 9.4966, dt: 1307.83ms, fracRes: 0.0063, norm(attn): 0.0698, norm(output): 0.2148, norm(x): 0.2126, norm(y): 1.0001, norm:2.7713, tok/sec: 100220.73, flops:105.19, batch-reuse:1
@ 86 train 9.2297 , allloss: 9.4597, dt: 1299.72ms, fracRes: 0.0064, norm(attn): 0.0703, norm(output): 0.2178, norm(x): 0.2146, norm(y): 1.0001, norm:2.7133, tok/sec: 100846.07, flops:105.85, batch-reuse:1
@ 87 train 9.2417 , allloss: 9.4778, dt: 1297.55ms, fracRes: 0.0064, norm(attn): 0.0703, norm(output): 0.2178, norm(x): 0.2163, norm(y): 1.0001, norm:2.8936, tok/sec: 101014.97, flops:106.03, batch-reuse:1
@ 88 train 9.2434 , allloss: 9.4697, dt: 1301.55ms, fracRes: 0.0064, norm(attn): 0.0708, norm(output): 0.2197, norm(x): 0.2181, norm(y): 1.0001, norm:2.6010, tok/sec: 100704.33, flops:105.70, batch-reuse:1
@ 89 train 9.1943 , allloss: 9.4196, dt: 1311.50ms, fracRes: 0.0065, norm(attn): 0.0708, norm(output): 0.2197, norm(x): 0.2197, norm(y): 1.0001, norm:2.6534, tok/sec: 99940.30, flops:104.90, batch-reuse:1
@ 90 train 9.2118 , allloss: 9.4374, dt: 1326.52ms, fracRes: 0.0065, norm(attn): 0.0708, norm(output): 0.2207, norm(x): 0.2215, norm(y): 1.0001, norm:2.9393, tok/sec: 98808.90, flops:103.71, batch-reuse:1
@ 91 train 9.2107 , allloss: 9.4300, dt: 1310.90ms, fracRes: 0.0065, norm(attn): 0.0708, norm(output): 0.2227, norm(x): 0.2233, norm(y): 1.0001, norm:2.7071, tok/sec: 99986.53, flops:104.95, batch-reuse:1
@ 92 train 9.1611 , allloss: 9.3793, dt: 1303.29ms, fracRes: 0.0066, norm(attn): 0.0708, norm(output): 0.2227, norm(x): 0.2250, norm(y): 1.0001, norm:2.5715, tok/sec: 100570.20, flops:105.56, batch-reuse:1
@ 93 train 9.1787 , allloss: 9.3968, dt: 1316.27ms, fracRes: 0.0066, norm(attn): 0.0708, norm(output): 0.2305, norm(x): 0.2265, norm(y): 1.0001, norm:2.5126, tok/sec: 99578.22, flops:104.52, batch-reuse:1
@ 94 train 9.2401 , allloss: 9.4670, dt: 1318.21ms, fracRes: 0.0066, norm(attn): 0.0723, norm(output): 0.2305, norm(x): 0.2282, norm(y): 1.0002, norm:3.0524, tok/sec: 99431.99, flops:104.37, batch-reuse:1
@ 95 train 9.1503 , allloss: 9.3569, dt: 1307.03ms, fracRes: 0.0067, norm(attn): 0.0728, norm(output): 0.2334, norm(x): 0.2301, norm(y): 1.0002, norm:2.4718, tok/sec: 100282.47, flops:105.26, batch-reuse:1
@ 96 train 9.0876 , allloss: 9.2885, dt: 1296.64ms, fracRes: 0.0067, norm(attn): 0.0728, norm(output): 0.2344, norm(x): 0.2320, norm(y): 1.0002, norm:2.4917, tok/sec: 101085.65, flops:106.10, batch-reuse:1
@ 97 train 9.1113 , allloss: 9.3129, dt: 1322.19ms, fracRes: 0.0067, norm(attn): 0.0732, norm(output): 0.2344, norm(x): 0.2336, norm(y): 1.0002, norm:2.4994, tok/sec: 99132.64, flops:104.05, batch-reuse:1
@ 98 train 9.0794 , allloss: 9.2802, dt: 1311.66ms, fracRes: 0.0067, norm(attn): 0.0732, norm(output): 0.2354, norm(x): 0.2353, norm(y): 1.0002, norm:2.6756, tok/sec: 99928.22, flops:104.89, batch-reuse:1
@ 99 train 9.0991 , allloss: 9.2958, dt: 1321.79ms, fracRes: 0.0068, norm(attn): 0.0732, norm(output): 0.2354, norm(x): 0.2371, norm(y): 1.0002, norm:2.3635, tok/sec: 99162.70, flops:104.08, batch-reuse:1
@ 100 train 9.0595 , allloss: 9.2566, dt: 1343.64ms, fracRes: 0.0068, norm(attn): 0.0732, norm(output): 0.2383, norm(x): 0.2388, norm(y): 1.0002, norm:2.4029, tok/sec: 97550.23, flops:102.39, batch-reuse:1
@ 101 train 9.0105 , allloss: 9.2022, dt: 1327.82ms, fracRes: 0.0068, norm(attn): 0.0732, norm(output): 0.2412, norm(x): 0.2406, norm(y): 1.0002, norm:2.3843, tok/sec: 98712.13, flops:103.61, batch-reuse:1
@ 102 train 9.0416 , allloss: 9.2364, dt: 1315.32ms, fracRes: 0.0069, norm(attn): 0.0742, norm(output): 0.2461, norm(x): 0.2420, norm(y): 1.0002, norm:2.3221, tok/sec: 99649.95, flops:104.60, batch-reuse:1
@ 103 train 9.0540 , allloss: 9.2506, dt: 1326.59ms, fracRes: 0.0069, norm(attn): 0.0742, norm(output): 0.2471, norm(x): 0.2438, norm(y): 1.0002, norm:2.2979, tok/sec: 98803.61, flops:103.71, batch-reuse:1
@ 104 train 9.0389 , allloss: 9.2341, dt: 1353.72ms, fracRes: 0.0069, norm(attn): 0.0742, norm(output): 0.2471, norm(x): 0.2454, norm(y): 1.0002, norm:2.3157, tok/sec: 96823.72, flops:101.63, batch-reuse:1
@ 105 train 9.0068 , allloss: 9.2007, dt: 1352.93ms, fracRes: 0.0069, norm(attn): 0.0742, norm(output): 0.2500, norm(x): 0.2471, norm(y): 1.0002, norm:2.3235, tok/sec: 96880.24, flops:101.69, batch-reuse:1
@ 106 train 9.0103 , allloss: 9.2065, dt: 1321.60ms, fracRes: 0.0070, norm(attn): 0.0752, norm(output): 0.2500, norm(x): 0.2487, norm(y): 1.0002, norm:2.2492, tok/sec: 99176.72, flops:104.10, batch-reuse:1
@ 107 train 8.9746 , allloss: 9.1669, dt: 1348.95ms, fracRes: 0.0070, norm(attn): 0.0752, norm(output): 0.2520, norm(x): 0.2502, norm(y): 1.0002, norm:2.2283, tok/sec: 97165.66, flops:101.99, batch-reuse:1
@ 108 train 8.9706 , allloss: 9.1647, dt: 1298.00ms, fracRes: 0.0071, norm(attn): 0.0752, norm(output): 0.2520, norm(x): 0.2518, norm(y): 1.0002, norm:2.2777, tok/sec: 100980.15, flops:105.99, batch-reuse:1
@ 109 train 8.9034 , allloss: 9.0944, dt: 1307.41ms, fracRes: 0.0071, norm(attn): 0.0757, norm(output): 0.2539, norm(x): 0.2534, norm(y): 1.0002, norm:2.3120, tok/sec: 100253.43, flops:105.23, batch-reuse:1
@ 110 train 8.9584 , allloss: 9.1546, dt: 1305.45ms, fracRes: 0.0071, norm(attn): 0.0762, norm(output): 0.2539, norm(x): 0.2549, norm(y): 1.0002, norm:2.1082, tok/sec: 100403.62, flops:105.39, batch-reuse:1
@ 111 train 8.9250 , allloss: 9.1193, dt: 1313.81ms, fracRes: 0.0072, norm(attn): 0.0757, norm(output): 0.2539, norm(x): 0.2565, norm(y): 1.0002, norm:2.1330, tok/sec: 99764.49, flops:104.72, batch-reuse:1
@ 112 train 8.9143 , allloss: 9.1087, dt: 1322.97ms, fracRes: 0.0072, norm(attn): 0.0771, norm(output): 0.2617, norm(x): 0.2580, norm(y): 1.0002, norm:2.1041, tok/sec: 99074.22, flops:103.99, batch-reuse:1
@ 113 train 8.8857 , allloss: 9.0808, dt: 1312.26ms, fracRes: 0.0073, norm(attn): 0.0771, norm(output): 0.2637, norm(x): 0.2595, norm(y): 1.0002, norm:2.1194, tok/sec: 99882.83, flops:104.84, batch-reuse:1
@ 114 train 8.8843 , allloss: 9.0791, dt: 1327.20ms, fracRes: 0.0073, norm(attn): 0.0771, norm(output): 0.2637, norm(x): 0.2612, norm(y): 1.0002, norm:2.0865, tok/sec: 98758.65, flops:103.66, batch-reuse:1
@ 115 train 8.8545 , allloss: 9.0595, dt: 1328.28ms, fracRes: 0.0074, norm(attn): 0.0771, norm(output): 0.2637, norm(x): 0.2626, norm(y): 1.0002, norm:2.1489, tok/sec: 98678.04, flops:103.58, batch-reuse:1
@ 116 train 8.8336 , allloss: 9.0349, dt: 1305.38ms, fracRes: 0.0074, norm(attn): 0.0771, norm(output): 0.2676, norm(x): 0.2642, norm(y): 1.0002, norm:2.0531, tok/sec: 100408.81, flops:105.39, batch-reuse:1
@ 117 train 8.8126 , allloss: 9.0165, dt: 1317.88ms, fracRes: 0.0075, norm(attn): 0.0771, norm(output): 0.2676, norm(x): 0.2657, norm(y): 1.0002, norm:2.0763, tok/sec: 99456.75, flops:104.39, batch-reuse:1
@ 118 train 8.8024 , allloss: 9.0087, dt: 1303.72ms, fracRes: 0.0075, norm(attn): 0.0771, norm(output): 0.2676, norm(x): 0.2673, norm(y): 1.0003, norm:2.1016, tok/sec: 100536.98, flops:105.53, batch-reuse:1
@ 119 train 8.8076 , allloss: 9.0229, dt: 1312.91ms, fracRes: 0.0075, norm(attn): 0.0771, norm(output): 0.2676, norm(x): 0.2688, norm(y): 1.0003, norm:2.1189, tok/sec: 99832.95, flops:104.79, batch-reuse:1
@ 120 train 8.8588 , allloss: 9.0791, dt: 1300.06ms, fracRes: 0.0076, norm(attn): 0.0776, norm(output): 0.2773, norm(x): 0.2704, norm(y): 1.0003, norm:1.9571, tok/sec: 100820.02, flops:105.82, batch-reuse:1
@ 121 train 8.8574 , allloss: 9.0820, dt: 1310.48ms, fracRes: 0.0076, norm(attn): 0.0776, norm(output): 0.2773, norm(x): 0.2720, norm(y): 1.0003, norm:2.1415, tok/sec: 100018.51, flops:104.98, batch-reuse:1
@ 122 train 8.8378 , allloss: 9.0577, dt: 1291.33ms, fracRes: 0.0077, norm(attn): 0.0776, norm(output): 0.2773, norm(x): 0.2736, norm(y): 1.0003, norm:1.9885, tok/sec: 101501.30, flops:106.54, batch-reuse:1
@ 123 train 8.7588 , allloss: 8.9766, dt: 1313.84ms, fracRes: 0.0077, norm(attn): 0.0781, norm(output): 0.2793, norm(x): 0.2752, norm(y): 1.0003, norm:2.0624, tok/sec: 99762.61, flops:104.71, batch-reuse:1
@ 124 train 8.7535 , allloss: 8.9685, dt: 1332.04ms, fracRes: 0.0077, norm(attn): 0.0781, norm(output): 0.2793, norm(x): 0.2770, norm(y): 1.0003, norm:1.9510, tok/sec: 98399.18, flops:103.28, batch-reuse:1
@ 125 train 8.7427 , allloss: 8.9597, dt: 1312.73ms, fracRes: 0.0078, norm(attn): 0.0781, norm(output): 0.2812, norm(x): 0.2786, norm(y): 1.0003, norm:1.9600, tok/sec: 99846.55, flops:104.80, batch-reuse:1
@ 126 train 8.7251 , allloss: 8.9447, dt: 1302.59ms, fracRes: 0.0078, norm(attn): 0.0781, norm(output): 0.2812, norm(x): 0.2802, norm(y): 1.0003, norm:1.9812, tok/sec: 100624.46, flops:105.62, batch-reuse:1
@ 127 train 8.6908 , allloss: 8.9017, dt: 1338.35ms, fracRes: 0.0078, norm(attn): 0.0781, norm(output): 0.2832, norm(x): 0.2819, norm(y): 1.0003, norm:1.9569, tok/sec: 97935.39, flops:102.80, batch-reuse:1
@ 128 train 8.6730 , allloss: 8.8837, dt: 1331.78ms, fracRes: 0.0079, norm(attn): 0.0781, norm(output): 0.2832, norm(x): 0.2833, norm(y): 1.0003, norm:1.9578, tok/sec: 98418.40, flops:103.30, batch-reuse:1
@ 129 train 8.7374 , allloss: 8.9576, dt: 1350.83ms, fracRes: 0.0079, norm(attn): 0.0781, norm(output): 0.2832, norm(x): 0.2848, norm(y): 1.0003, norm:1.9244, tok/sec: 97030.90, flops:101.85, batch-reuse:1
@ 130 train 8.6814 , allloss: 8.8871, dt: 1342.83ms, fracRes: 0.0079, norm(attn): 0.0781, norm(output): 0.2852, norm(x): 0.2864, norm(y): 1.0003, norm:1.8750, tok/sec: 97608.96, flops:102.45, batch-reuse:1
@ 131 train 8.6659 , allloss: 8.8672, dt: 1317.70ms, fracRes: 0.0079, norm(attn): 0.0786, norm(output): 0.2852, norm(x): 0.2880, norm(y): 1.0003, norm:1.8563, tok/sec: 99470.03, flops:104.41, batch-reuse:1
@ 132 train 8.6708 , allloss: 8.8762, dt: 1306.68ms, fracRes: 0.0079, norm(attn): 0.0786, norm(output): 0.2930, norm(x): 0.2893, norm(y): 1.0003, norm:2.0513, tok/sec: 100309.24, flops:105.29, batch-reuse:1
@ 133 train 8.6400 , allloss: 8.8389, dt: 1318.22ms, fracRes: 0.0080, norm(attn): 0.0781, norm(output): 0.2930, norm(x): 0.2909, norm(y): 1.0004, norm:1.8691, tok/sec: 99431.38, flops:104.37, batch-reuse:1
@ 134 train 8.6077 , allloss: 8.7957, dt: 1312.67ms, fracRes: 0.0080, norm(attn): 0.0781, norm(output): 0.2930, norm(x): 0.2926, norm(y): 1.0004, norm:1.9095, tok/sec: 99851.38, flops:104.81, batch-reuse:1
@ 135 train 8.5905 , allloss: 8.7734, dt: 1284.96ms, fracRes: 0.0080, norm(attn): 0.0786, norm(output): 0.2969, norm(x): 0.2941, norm(y): 1.0004, norm:1.7995, tok/sec: 102004.37, flops:107.07, batch-reuse:1
@ 136 train 8.5827 , allloss: 8.7620, dt: 1305.04ms, fracRes: 0.0080, norm(attn): 0.0786, norm(output): 0.2969, norm(x): 0.2957, norm(y): 1.0004, norm:1.8683, tok/sec: 100435.10, flops:105.42, batch-reuse:1
@ 137 train 8.5351 , allloss: 8.7036, dt: 1304.85ms, fracRes: 0.0080, norm(attn): 0.0786, norm(output): 0.3008, norm(x): 0.2973, norm(y): 1.0004, norm:1.9257, tok/sec: 100449.80, flops:105.44, batch-reuse:1
@ 138 train 8.5051 , allloss: 8.6659, dt: 1307.78ms, fracRes: 0.0081, norm(attn): 0.0786, norm(output): 0.3008, norm(x): 0.2990, norm(y): 1.0004, norm:1.8642, tok/sec: 100224.81, flops:105.20, batch-reuse:1
@ 139 train 8.4233 , allloss: 8.5730, dt: 1326.03ms, fracRes: 0.0081, norm(attn): 0.0786, norm(output): 0.3027, norm(x): 0.3007, norm(y): 1.0004, norm:2.1255, tok/sec: 98845.28, flops:103.75, batch-reuse:1
@ 140 train 8.4937 , allloss: 8.6416, dt: 1318.69ms, fracRes: 0.0081, norm(attn): 0.0786, norm(output): 0.3086, norm(x): 0.3020, norm(y): 1.0004, norm:1.8339, tok/sec: 99395.93, flops:104.33, batch-reuse:1
@ 141 train 8.4769 , allloss: 8.6175, dt: 1320.15ms, fracRes: 0.0081, norm(attn): 0.0786, norm(output): 0.3086, norm(x): 0.3035, norm(y): 1.0004, norm:1.7995, tok/sec: 99285.73, flops:104.21, batch-reuse:1
@ 142 train 8.5105 , allloss: 8.6480, dt: 1326.12ms, fracRes: 0.0081, norm(attn): 0.0786, norm(output): 0.3086, norm(x): 0.3048, norm(y): 1.0004, norm:1.7731, tok/sec: 98839.03, flops:103.74, batch-reuse:1
@ 143 train 8.4918 , allloss: 8.6272, dt: 1316.30ms, fracRes: 0.0082, norm(attn): 0.0786, norm(output): 0.3086, norm(x): 0.3061, norm(y): 1.0004, norm:1.7626, tok/sec: 99575.77, flops:104.52, batch-reuse:1
@ 144 train 8.4523 , allloss: 8.5762, dt: 1310.92ms, fracRes: 0.0082, norm(attn): 0.0786, norm(output): 0.3105, norm(x): 0.3075, norm(y): 1.0005, norm:1.8319, tok/sec: 99984.73, flops:104.95, batch-reuse:1
@ 145 train 8.4768 , allloss: 8.5993, dt: 1345.34ms, fracRes: 0.0082, norm(attn): 0.0786, norm(output): 0.3125, norm(x): 0.3086, norm(y): 1.0005, norm:1.7596, tok/sec: 97426.72, flops:102.26, batch-reuse:1
@ 146 train 8.5138 , allloss: 8.6272, dt: 1327.34ms, fracRes: 0.0082, norm(attn): 0.0786, norm(output): 0.3125, norm(x): 0.3097, norm(y): 1.0005, norm:1.7144, tok/sec: 98748.13, flops:103.65, batch-reuse:1
@ 147 train 8.4317 , allloss: 8.5408, dt: 1344.49ms, fracRes: 0.0082, norm(attn): 0.0791, norm(output): 0.3125, norm(x): 0.3106, norm(y): 1.0005, norm:1.7046, tok/sec: 97488.23, flops:102.33, batch-reuse:1
@ 148 train 8.4048 , allloss: 8.5077, dt: 1335.32ms, fracRes: 0.0082, norm(attn): 0.0786, norm(output): 0.3125, norm(x): 0.3115, norm(y): 1.0005, norm:1.6673, tok/sec: 98157.52, flops:103.03, batch-reuse:1
@ 149 train 8.3303 , allloss: 8.4235, dt: 1338.67ms, fracRes: 0.0082, norm(attn): 0.0786, norm(output): 0.3145, norm(x): 0.3125, norm(y): 1.0005, norm:1.7435, tok/sec: 97912.44, flops:102.77, batch-reuse:1
@ 150 train 8.4261 , allloss: 8.5186, dt: 1341.57ms, fracRes: 0.0082, norm(attn): 0.0791, norm(output): 0.3145, norm(x): 0.3133, norm(y): 1.0005, norm:1.6740, tok/sec: 97700.39, flops:102.55, batch-reuse:1
@ 151 train 8.3224 , allloss: 8.4057, dt: 1344.79ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3145, norm(x): 0.3139, norm(y): 1.0005, norm:1.7025, tok/sec: 97466.71, flops:102.30, batch-reuse:1
@ 152 train 8.2710 , allloss: 8.3444, dt: 1293.00ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3145, norm(x): 0.3146, norm(y): 1.0005, norm:2.0012, tok/sec: 101370.08, flops:106.40, batch-reuse:1
@ 153 train 8.3004 , allloss: 8.3777, dt: 1313.34ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3145, norm(x): 0.3150, norm(y): 1.0005, norm:1.6507, tok/sec: 99800.20, flops:104.75, batch-reuse:1
@ 154 train 8.3266 , allloss: 8.3998, dt: 1289.63ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3164, norm(x): 0.3157, norm(y): 1.0005, norm:1.5438, tok/sec: 101635.66, flops:106.68, batch-reuse:1
@ 155 train 8.3615 , allloss: 8.4263, dt: 1309.18ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3164, norm(x): 0.3163, norm(y): 1.0005, norm:1.5457, tok/sec: 100117.34, flops:105.09, batch-reuse:1
@ 156 train 8.2903 , allloss: 8.3528, dt: 1321.23ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3164, norm(x): 0.3168, norm(y): 1.0005, norm:1.5546, tok/sec: 99204.19, flops:104.13, batch-reuse:1
@ 157 train 8.3353 , allloss: 8.3934, dt: 1297.92ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3164, norm(x): 0.3174, norm(y): 1.0005, norm:1.5308, tok/sec: 100986.40, flops:106.00, batch-reuse:1
@ 158 train 8.2971 , allloss: 8.3500, dt: 1327.58ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3164, norm(x): 0.3178, norm(y): 1.0006, norm:1.5084, tok/sec: 98729.70, flops:103.63, batch-reuse:1
@ 159 train 8.3106 , allloss: 8.3628, dt: 1362.53ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3164, norm(x): 0.3183, norm(y): 1.0006, norm:1.4769, tok/sec: 96197.38, flops:100.97, batch-reuse:1
@ 160 train 8.2508 , allloss: 8.2966, dt: 1345.82ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3164, norm(x): 0.3187, norm(y): 1.0006, norm:1.5006, tok/sec: 97391.67, flops:102.23, batch-reuse:1
@ 161 train 8.2412 , allloss: 8.2850, dt: 1339.67ms, fracRes: 0.0082, norm(attn): 0.0791, norm(output): 0.3223, norm(x): 0.3191, norm(y): 1.0006, norm:1.4446, tok/sec: 97839.30, flops:102.70, batch-reuse:1
@ 162 train 8.2812 , allloss: 8.3235, dt: 1333.42ms, fracRes: 0.0082, norm(attn): 0.0791, norm(output): 0.3223, norm(x): 0.3195, norm(y): 1.0006, norm:1.4220, tok/sec: 98297.43, flops:103.18, batch-reuse:1
@ 163 train 8.2279 , allloss: 8.2621, dt: 1296.06ms, fracRes: 0.0082, norm(attn): 0.0791, norm(output): 0.3223, norm(x): 0.3199, norm(y): 1.0006, norm:1.4022, tok/sec: 101131.41, flops:106.15, batch-reuse:1
@ 164 train 8.1624 , allloss: 8.1925, dt: 1321.85ms, fracRes: 0.0082, norm(attn): 0.0791, norm(output): 0.3223, norm(x): 0.3203, norm(y): 1.0006, norm:1.4846, tok/sec: 99158.03, flops:104.08, batch-reuse:1
@ 165 train 8.2113 , allloss: 8.2371, dt: 1322.79ms, fracRes: 0.0082, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3206, norm(y): 1.0006, norm:1.3766, tok/sec: 99087.61, flops:104.01, batch-reuse:1
@ 166 train 8.1150 , allloss: 8.1371, dt: 1297.31ms, fracRes: 0.0082, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3212, norm(y): 1.0006, norm:1.7328, tok/sec: 101033.41, flops:106.05, batch-reuse:1
@ 167 train 8.1358 , allloss: 8.1556, dt: 1313.71ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3217, norm(y): 1.0006, norm:1.5969, tok/sec: 99772.69, flops:104.72, batch-reuse:1
@ 168 train 8.1012 , allloss: 8.1197, dt: 1319.62ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3218, norm(y): 1.0006, norm:1.3695, tok/sec: 99325.59, flops:104.26, batch-reuse:1
@ 169 train 8.1271 , allloss: 8.1464, dt: 1347.01ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3220, norm(y): 1.0006, norm:1.3634, tok/sec: 97305.67, flops:102.14, batch-reuse:1
@ 170 train 8.1193 , allloss: 8.1339, dt: 1340.96ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3224, norm(y): 1.0006, norm:1.3223, tok/sec: 97744.67, flops:102.60, batch-reuse:1
@ 171 train 8.0926 , allloss: 8.1111, dt: 1338.95ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3225, norm(y): 1.0006, norm:1.3072, tok/sec: 97891.34, flops:102.75, batch-reuse:1
@ 172 train 8.0871 , allloss: 8.0971, dt: 1346.41ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3230, norm(y): 1.0006, norm:1.3891, tok/sec: 97349.43, flops:102.18, batch-reuse:1
@ 173 train 8.0512 , allloss: 8.0592, dt: 1333.15ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3233, norm(y): 1.0006, norm:1.3680, tok/sec: 98317.28, flops:103.20, batch-reuse:1
@ 174 train 8.1466 , allloss: 8.1558, dt: 1318.04ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3236, norm(y): 1.0006, norm:1.2470, tok/sec: 99444.51, flops:104.38, batch-reuse:1
@ 175 train 8.0682 , allloss: 8.0795, dt: 1306.86ms, fracRes: 0.0083, norm(attn): 0.0801, norm(output): 0.3242, norm(x): 0.3239, norm(y): 1.0006, norm:2.6423, tok/sec: 100295.26, flops:105.27, batch-reuse:1
@ 176 train 8.0787 , allloss: 8.0865, dt: 1328.51ms, fracRes: 0.0083, norm(attn): 0.0796, norm(output): 0.3242, norm(x): 0.3242, norm(y): 1.0006, norm:1.2061, tok/sec: 98660.94, flops:103.56, batch-reuse:1
@ 177 train 8.0465 , allloss: 8.0532, dt: 1318.16ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3245, norm(y): 1.0006, norm:1.2549, tok/sec: 99435.27, flops:104.37, batch-reuse:1
@ 178 train 8.0773 , allloss: 8.0839, dt: 1307.45ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3247, norm(y): 1.0006, norm:1.1985, tok/sec: 100250.14, flops:105.23, batch-reuse:1
@ 179 train 7.9917 , allloss: 7.9959, dt: 1334.97ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3251, norm(y): 1.0007, norm:1.2228, tok/sec: 98183.66, flops:103.06, batch-reuse:1
@ 180 train 8.0591 , allloss: 8.0633, dt: 1296.31ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3255, norm(y): 1.0007, norm:1.2717, tok/sec: 101111.43, flops:106.13, batch-reuse:1
@ 181 train 8.0298 , allloss: 8.0467, dt: 1310.33ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3257, norm(y): 1.0007, norm:1.2611, tok/sec: 100029.64, flops:104.99, batch-reuse:1
@ 182 train 8.0328 , allloss: 8.0369, dt: 1297.77ms, fracRes: 0.0083, norm(attn): 0.0791, norm(output): 0.3242, norm(x): 0.3261, norm(y): 1.0007, norm:1.1085, tok/sec: 100998.22, flops:106.01, batch-reuse:1
@ 183 train 7.9839 , allloss: 7.9869, dt: 1339.36ms, fracRes: 0.0083, norm(attn): 0.0796, norm(output): 0.3281, norm(x): 0.3263, norm(y): 1.0007, norm:1.2165, tok/sec: 97861.75, flops:102.72, batch-reuse:1
@ 184 train 7.8860 , allloss: 7.8879, dt: 1323.30ms, fracRes: 0.0083, norm(attn): 0.0806, norm(output): 0.3320, norm(x): 0.3271, norm(y): 1.0007, norm:1.2444, tok/sec: 99049.41, flops:103.97, batch-reuse:1
@ 185 train 7.9317 , allloss: 7.9339, dt: 1328.35ms, fracRes: 0.0083, norm(attn): 0.0806, norm(output): 0.3281, norm(x): 0.3274, norm(y): 1.0007, norm:1.1637, tok/sec: 98672.73, flops:103.57, batch-reuse:1
@ 186 train 8.0365 , allloss: 8.0383, dt: 1347.00ms, fracRes: 0.0083, norm(attn): 0.0806, norm(output): 0.3301, norm(x): 0.3281, norm(y): 1.0007, norm:1.2003, tok/sec: 97306.65, flops:102.14, batch-reuse:1
@ 187 train 8.0414 , allloss: 8.0433, dt: 1322.89ms, fracRes: 0.0083, norm(attn): 0.0811, norm(output): 0.3320, norm(x): 0.3285, norm(y): 1.0007, norm:1.2652, tok/sec: 99080.38, flops:104.00, batch-reuse:1
@ 188 train 7.9219 , allloss: 7.9230, dt: 1302.15ms, fracRes: 0.0083, norm(attn): 0.0811, norm(output): 0.3320, norm(x): 0.3292, norm(y): 1.0007, norm:1.2548, tok/sec: 100658.38, flops:105.65, batch-reuse:1
@ 189 train 8.0060 , allloss: 8.0075, dt: 1315.50ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3340, norm(x): 0.3296, norm(y): 1.0007, norm:1.0832, tok/sec: 99636.51, flops:104.58, batch-reuse:1
@ 190 train 7.9689 , allloss: 7.9708, dt: 1316.27ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3340, norm(x): 0.3302, norm(y): 1.0007, norm:1.1325, tok/sec: 99578.07, flops:104.52, batch-reuse:1
@ 191 train 7.9459 , allloss: 7.9467, dt: 1309.23ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3340, norm(x): 0.3307, norm(y): 1.0007, norm:1.1188, tok/sec: 100113.58, flops:105.08, batch-reuse:1
@ 192 train 7.9692 , allloss: 7.9710, dt: 1328.59ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3340, norm(x): 0.3311, norm(y): 1.0007, norm:0.9265, tok/sec: 98654.85, flops:103.55, batch-reuse:1
@ 193 train 7.8925 , allloss: 7.8933, dt: 1313.68ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3340, norm(x): 0.3317, norm(y): 1.0007, norm:1.1362, tok/sec: 99774.94, flops:104.73, batch-reuse:1
@ 194 train 7.9560 , allloss: 7.9566, dt: 1319.07ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3340, norm(x): 0.3325, norm(y): 1.0007, norm:1.0725, tok/sec: 99366.65, flops:104.30, batch-reuse:1
@ 195 train 7.9432 , allloss: 7.9443, dt: 1287.42ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3340, norm(x): 0.3327, norm(y): 1.0007, norm:0.8837, tok/sec: 101809.54, flops:106.86, batch-reuse:1
@ 196 train 7.8637 , allloss: 7.8643, dt: 1316.88ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3340, norm(x): 0.3336, norm(y): 1.0007, norm:0.9302, tok/sec: 99532.01, flops:104.47, batch-reuse:1
@ 197 train 7.8740 , allloss: 7.8744, dt: 1305.82ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3340, norm(x): 0.3342, norm(y): 1.0007, norm:0.9480, tok/sec: 100375.39, flops:105.36, batch-reuse:1
@ 198 train 7.8402 , allloss: 7.8407, dt: 1313.57ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3398, norm(x): 0.3347, norm(y): 1.0007, norm:0.9481, tok/sec: 99782.98, flops:104.74, batch-reuse:1
@ 199 train 7.8852 , allloss: 7.8857, dt: 1350.57ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3418, norm(x): 0.3353, norm(y): 1.0007, norm:1.0506, tok/sec: 97049.14, flops:101.87, batch-reuse:1
@ 200 train 7.9030 , allloss: 7.9035, dt: 1350.05ms, fracRes: 0.0084, norm(attn): 0.0811, norm(output): 0.3418, norm(x): 0.3361, norm(y): 1.0007, norm:0.8760, tok/sec: 97087.12, flops:101.91, batch-reuse:1
@ 201 train 7.9003 , allloss: 7.9015, dt: 1301.52ms, fracRes: 0.0084, norm(attn): 0.0830, norm(output): 0.3418, norm(x): 0.3366, norm(y): 1.0007, norm:0.9559, tok/sec: 100706.82, flops:105.71, batch-reuse:1
@ 202 train 7.9266 , allloss: 7.9270, dt: 1306.58ms, fracRes: 0.0085, norm(attn): 0.0830, norm(output): 0.3418, norm(x): 0.3375, norm(y): 1.0007, norm:0.8505, tok/sec: 100316.60, flops:105.30, batch-reuse:1
@ 203 train 7.8900 , allloss: 7.8907, dt: 1334.15ms, fracRes: 0.0085, norm(attn): 0.0830, norm(output): 0.3418, norm(x): 0.3379, norm(y): 1.0007, norm:0.9849, tok/sec: 98243.93, flops:103.12, batch-reuse:1
@ 204 train 7.8664 , allloss: 7.8668, dt: 1296.33ms, fracRes: 0.0085, norm(attn): 0.0830, norm(output): 0.3418, norm(x): 0.3383, norm(y): 1.0007, norm:0.8116, tok/sec: 101109.69, flops:106.13, batch-reuse:1
@ 205 train 7.8434 , allloss: 7.8439, dt: 1331.75ms, fracRes: 0.0085, norm(attn): 0.0830, norm(output): 0.3418, norm(x): 0.3391, norm(y): 1.0007, norm:0.8409, tok/sec: 98420.79, flops:103.31, batch-reuse:1
@ 206 train 7.8697 , allloss: 7.8702, dt: 1360.20ms, fracRes: 0.0085, norm(attn): 0.0830, norm(output): 0.3418, norm(x): 0.3396, norm(y): 1.0007, norm:0.7759, tok/sec: 96362.25, flops:101.14, batch-reuse:1
@ 207 train 7.7579 , allloss: 7.7585, dt: 1307.09ms, fracRes: 0.0086, norm(attn): 0.0830, norm(output): 0.3418, norm(x): 0.3403, norm(y): 1.0007, norm:0.9850, tok/sec: 100277.86, flops:105.25, batch-reuse:1
@ 208 train 7.8402 , allloss: 7.8407, dt: 1319.60ms, fracRes: 0.0086, norm(attn): 0.0830, norm(output): 0.3438, norm(x): 0.3408, norm(y): 1.0007, norm:0.8156, tok/sec: 99326.94, flops:104.26, batch-reuse:1
@ 209 train 7.8660 , allloss: 7.8665, dt: 1347.72ms, fracRes: 0.0086, norm(attn): 0.0830, norm(output): 0.3438, norm(x): 0.3415, norm(y): 1.0007, norm:0.7087, tok/sec: 97254.37, flops:102.08, batch-reuse:1
@ 210 train 7.8360 , allloss: 7.8365, dt: 1345.26ms, fracRes: 0.0086, norm(attn): 0.0835, norm(output): 0.3457, norm(x): 0.3419, norm(y): 1.0007, norm:0.7782, tok/sec: 97432.37, flops:102.27, batch-reuse:1
@ 211 train 7.7771 , allloss: 7.7775, dt: 1344.63ms, fracRes: 0.0087, norm(attn): 0.0835, norm(output): 0.3457, norm(x): 0.3427, norm(y): 1.0007, norm:0.7150, tok/sec: 97478.25, flops:102.32, batch-reuse:1
@ 212 train 7.8405 , allloss: 7.8409, dt: 1344.81ms, fracRes: 0.0087, norm(attn): 0.0850, norm(output): 0.3457, norm(x): 0.3429, norm(y): 1.0007, norm:0.6940, tok/sec: 97464.95, flops:102.30, batch-reuse:1
@ 213 train 7.7646 , allloss: 7.7650, dt: 1341.96ms, fracRes: 0.0087, norm(attn): 0.0850, norm(output): 0.3457, norm(x): 0.3433, norm(y): 1.0007, norm:0.9158, tok/sec: 97671.87, flops:102.52, batch-reuse:1
@ 214 train 7.7886 , allloss: 7.7890, dt: 1297.70ms, fracRes: 0.0087, norm(attn): 0.0850, norm(output): 0.3457, norm(x): 0.3439, norm(y): 1.0007, norm:0.6578, tok/sec: 101003.26, flops:106.02, batch-reuse:1
@ 215 train 7.7294 , allloss: 7.7299, dt: 1305.25ms, fracRes: 0.0087, norm(attn): 0.0850, norm(output): 0.3457, norm(x): 0.3445, norm(y): 1.0007, norm:0.8326, tok/sec: 100418.73, flops:105.40, batch-reuse:1
@ 216 train 7.7324 , allloss: 7.7329, dt: 1309.89ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3457, norm(x): 0.3451, norm(y): 1.0007, norm:0.7792, tok/sec: 100063.47, flops:105.03, batch-reuse:1
@ 217 train 7.7950 , allloss: 7.7957, dt: 1294.80ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3457, norm(x): 0.3457, norm(y): 1.0007, norm:0.6488, tok/sec: 101229.51, flops:106.25, batch-reuse:1
@ 218 train 7.7826 , allloss: 7.7877, dt: 1291.39ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3457, norm(x): 0.3463, norm(y): 1.0007, norm:0.6439, tok/sec: 101496.49, flops:106.53, batch-reuse:1
@ 219 train 7.8610 , allloss: 7.8621, dt: 1320.56ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3457, norm(x): 0.3468, norm(y): 1.0007, norm:0.6322, tok/sec: 99254.67, flops:104.18, batch-reuse:1
@ 220 train 7.7979 , allloss: 7.7983, dt: 1315.01ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3457, norm(x): 0.3474, norm(y): 1.0007, norm:0.6567, tok/sec: 99674.12, flops:104.62, batch-reuse:1
@ 221 train 7.7961 , allloss: 7.7965, dt: 1290.56ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3477, norm(x): 0.3482, norm(y): 1.0007, norm:1.0091, tok/sec: 101561.94, flops:106.60, batch-reuse:1
@ 222 train 7.7553 , allloss: 7.7557, dt: 1324.43ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3477, norm(x): 0.3486, norm(y): 1.0007, norm:0.7721, tok/sec: 98964.86, flops:103.88, batch-reuse:1
@ 223 train 7.7919 , allloss: 7.7929, dt: 1352.14ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3535, norm(x): 0.3492, norm(y): 1.0007, norm:0.9121, tok/sec: 96936.47, flops:101.75, batch-reuse:1
@ 224 train 7.7316 , allloss: 7.7323, dt: 1350.99ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3535, norm(x): 0.3498, norm(y): 1.0007, norm:0.5952, tok/sec: 97019.46, flops:101.83, batch-reuse:1
@ 225 train 7.7446 , allloss: 7.7450, dt: 1350.47ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3535, norm(x): 0.3503, norm(y): 1.0007, norm:0.7337, tok/sec: 97056.82, flops:101.87, batch-reuse:1
@ 226 train 7.7858 , allloss: 7.7865, dt: 1333.80ms, fracRes: 0.0088, norm(attn): 0.0854, norm(output): 0.3535, norm(x): 0.3506, norm(y): 1.0007, norm:0.9671, tok/sec: 98269.44, flops:103.15, batch-reuse:1
@ 227 train 7.7779 , allloss: 7.7794, dt: 1319.35ms, fracRes: 0.0088, norm(attn): 0.0859, norm(output): 0.3535, norm(x): 0.3511, norm(y): 1.0007, norm:0.6226, tok/sec: 99346.05, flops:104.28, batch-reuse:1
@ 228 train 7.7547 , allloss: 7.7550, dt: 1306.16ms, fracRes: 0.0088, norm(attn): 0.0859, norm(output): 0.3535, norm(x): 0.3518, norm(y): 1.0007, norm:0.5854, tok/sec: 100349.30, flops:105.33, batch-reuse:1
@ 229 train 7.7845 , allloss: 7.7859, dt: 1324.09ms, fracRes: 0.0088, norm(attn): 0.0859, norm(output): 0.3535, norm(x): 0.3523, norm(y): 1.0007, norm:0.6301, tok/sec: 98990.20, flops:103.90, batch-reuse:1
@ 230 train 7.7793 , allloss: 7.7797, dt: 1295.76ms, fracRes: 0.0089, norm(attn): 0.0859, norm(output): 0.3535, norm(x): 0.3529, norm(y): 1.0007, norm:0.7186, tok/sec: 101154.43, flops:106.17, batch-reuse:1
@ 231 train 7.7214 , allloss: 7.7218, dt: 1305.35ms, fracRes: 0.0089, norm(attn): 0.0859, norm(output): 0.3535, norm(x): 0.3533, norm(y): 1.0007, norm:0.5979, tok/sec: 100411.36, flops:105.39, batch-reuse:1
@ 232 train 7.7020 , allloss: 7.7031, dt: 1302.99ms, fracRes: 0.0089, norm(attn): 0.0859, norm(output): 0.3535, norm(x): 0.3537, norm(y): 1.0007, norm:0.6955, tok/sec: 100593.33, flops:105.59, batch-reuse:1
@ 233 train 7.7615 , allloss: 7.7623, dt: 1299.29ms, fracRes: 0.0090, norm(attn): 0.0859, norm(output): 0.3535, norm(x): 0.3541, norm(y): 1.0007, norm:0.7087, tok/sec: 100879.85, flops:105.89, batch-reuse:1
@ 234 train 7.6468 , allloss: 7.6474, dt: 1286.62ms, fracRes: 0.0090, norm(attn): 0.0859, norm(output): 0.3535, norm(x): 0.3544, norm(y): 1.0007, norm:0.6751, tok/sec: 101873.21, flops:106.93, batch-reuse:1
@ 235 train 7.7353 , allloss: 7.7361, dt: 1326.28ms, fracRes: 0.0091, norm(attn): 0.0859, norm(output): 0.3555, norm(x): 0.3551, norm(y): 1.0007, norm:0.6316, tok/sec: 98826.73, flops:103.73, batch-reuse:1
@ 236 train 7.6498 , allloss: 7.6504, dt: 1303.71ms, fracRes: 0.0091, norm(attn): 0.0859, norm(output): 0.3633, norm(x): 0.3555, norm(y): 1.0007, norm:0.6435, tok/sec: 100537.62, flops:105.53, batch-reuse:1
@ 237 train 7.7436 , allloss: 7.7442, dt: 1294.49ms, fracRes: 0.0092, norm(attn): 0.0864, norm(output): 0.3594, norm(x): 0.3558, norm(y): 1.0007, norm:0.5410, tok/sec: 101254.05, flops:106.28, batch-reuse:1
@ 238 train 7.7044 , allloss: 7.7053, dt: 1309.67ms, fracRes: 0.0093, norm(attn): 0.0859, norm(output): 0.3633, norm(x): 0.3564, norm(y): 1.0007, norm:0.6071, tok/sec: 100080.48, flops:105.05, batch-reuse:1
@ 239 train 7.7088 , allloss: 7.7102, dt: 1315.67ms, fracRes: 0.0093, norm(attn): 0.0864, norm(output): 0.3633, norm(x): 0.3569, norm(y): 1.0007, norm:0.4573, tok/sec: 99624.11, flops:104.57, batch-reuse:1
@ 240 train 7.7698 , allloss: 7.7705, dt: 1333.83ms, fracRes: 0.0094, norm(attn): 0.0864, norm(output): 0.3633, norm(x): 0.3575, norm(y): 1.0007, norm:0.6040, tok/sec: 98267.56, flops:103.14, batch-reuse:1
@ 241 train 7.7194 , allloss: 7.7200, dt: 1336.40ms, fracRes: 0.0094, norm(attn): 0.0864, norm(output): 0.3633, norm(x): 0.3582, norm(y): 1.0007, norm:0.5121, tok/sec: 98078.56, flops:102.95, batch-reuse:1
@ 242 train 7.7563 , allloss: 7.7603, dt: 1324.00ms, fracRes: 0.0095, norm(attn): 0.0864, norm(output): 0.3652, norm(x): 0.3587, norm(y): 1.0007, norm:0.6048, tok/sec: 98996.79, flops:103.91, batch-reuse:1
@ 243 train 7.6246 , allloss: 7.6261, dt: 1332.11ms, fracRes: 0.0096, norm(attn): 0.0864, norm(output): 0.3652, norm(x): 0.3592, norm(y): 1.0007, norm:0.4749, tok/sec: 98393.93, flops:103.28, batch-reuse:1
@ 244 train 7.7693 , allloss: 7.7706, dt: 1334.04ms, fracRes: 0.0097, norm(attn): 0.0869, norm(output): 0.3652, norm(x): 0.3598, norm(y): 1.0007, norm:0.4460, tok/sec: 98251.76, flops:103.13, batch-reuse:1
@ 245 train 7.6389 , allloss: 7.6420, dt: 1326.18ms, fracRes: 0.0097, norm(attn): 0.0869, norm(output): 0.3652, norm(x): 0.3603, norm(y): 1.0007, norm:0.6777, tok/sec: 98834.19, flops:103.74, batch-reuse:1
@ 246 train 7.8200 , allloss: 7.8263, dt: 1305.41ms, fracRes: 0.0098, norm(attn): 0.0869, norm(output): 0.3652, norm(x): 0.3610, norm(y): 1.0007, norm:0.4085, tok/sec: 100406.54, flops:105.39, batch-reuse:1
@ 247 train 7.7365 , allloss: 7.7369, dt: 1333.00ms, fracRes: 0.0098, norm(attn): 0.0869, norm(output): 0.3652, norm(x): 0.3616, norm(y): 1.0007, norm:0.4966, tok/sec: 98328.29, flops:103.21, batch-reuse:1
@ 248 train 7.6927 , allloss: 7.6934, dt: 1318.04ms, fracRes: 0.0098, norm(attn): 0.0869, norm(output): 0.3652, norm(x): 0.3619, norm(y): 1.0007, norm:0.4504, tok/sec: 99444.48, flops:104.38, batch-reuse:1
@ 249 train 7.6528 , allloss: 7.6535, dt: 1305.99ms, fracRes: 0.0098, norm(attn): 0.0869, norm(output): 0.3652, norm(x): 0.3625, norm(y): 1.0007, norm:0.4099, tok/sec: 100361.87, flops:105.34, batch-reuse:1
@ 250 train 7.7040 , allloss: 7.7073, dt: 1318.10ms, fracRes: 0.0097, norm(attn): 0.0869, norm(output): 0.3711, norm(x): 0.3629, norm(y): 1.0007, norm:0.4286, tok/sec: 99440.02, flops:104.38, batch-reuse:1
@ 251 train 7.6305 , allloss: 7.6326, dt: 1340.47ms, fracRes: 0.0096, norm(attn): 0.0869, norm(output): 0.3711, norm(x): 0.3635, norm(y): 1.0007, norm:0.4749, tok/sec: 97780.41, flops:102.63, batch-reuse:1
@ 252 train 7.7737 , allloss: 7.7747, dt: 1336.87ms, fracRes: 0.0095, norm(attn): 0.0874, norm(output): 0.3711, norm(x): 0.3638, norm(y): 1.0007, norm:0.6039, tok/sec: 98043.61, flops:102.91, batch-reuse:1
@ 253 train 7.6560 , allloss: 7.6571, dt: 1319.76ms, fracRes: 0.0095, norm(attn): 0.0884, norm(output): 0.3711, norm(x): 0.3641, norm(y): 1.0007, norm:0.6153, tok/sec: 99315.31, flops:104.24, batch-reuse:1
@ 254 train 7.6073 , allloss: 7.6081, dt: 1308.36ms, fracRes: 0.0094, norm(attn): 0.0884, norm(output): 0.3711, norm(x): 0.3645, norm(y): 1.0007, norm:0.4550, tok/sec: 100180.57, flops:105.15, batch-reuse:1
@ 255 train 7.6322 , allloss: 7.6361, dt: 1296.76ms, fracRes: 0.0094, norm(attn): 0.0884, norm(output): 0.3711, norm(x): 0.3650, norm(y): 1.0007, norm:0.4862, tok/sec: 101076.19, flops:106.09, batch-reuse:1
@ 256 train 7.6424 , allloss: 7.6456, dt: 1300.69ms, fracRes: 0.0094, norm(attn): 0.0884, norm(output): 0.3711, norm(x): 0.3658, norm(y): 1.0007, norm:0.4631, tok/sec: 100770.84, flops:105.77, batch-reuse:1
@ 257 train 7.6944 , allloss: 7.6981, dt: 1324.09ms, fracRes: 0.0093, norm(attn): 0.0884, norm(output): 0.3730, norm(x): 0.3663, norm(y): 1.0007, norm:0.4880, tok/sec: 98990.12, flops:103.90, batch-reuse:1
@ 258 train 7.6519 , allloss: 7.6573, dt: 1349.99ms, fracRes: 0.0093, norm(attn): 0.0884, norm(output): 0.3730, norm(x): 0.3670, norm(y): 1.0007, norm:0.4657, tok/sec: 97091.08, flops:101.91, batch-reuse:1
@ 259 train 7.6521 , allloss: 7.6644, dt: 1336.90ms, fracRes: 0.0092, norm(attn): 0.0884, norm(output): 0.3730, norm(x): 0.3676, norm(y): 1.0007, norm:0.4216, tok/sec: 98042.00, flops:102.91, batch-reuse:1
@ 260 train 7.7328 , allloss: 7.7457, dt: 1339.90ms, fracRes: 0.0092, norm(attn): 0.0884, norm(output): 0.3730, norm(x): 0.3677, norm(y): 1.0007, norm:0.4723, tok/sec: 97822.42, flops:102.68, batch-reuse:1
@ 261 train 7.6750 , allloss: 7.6873, dt: 1347.47ms, fracRes: 0.0092, norm(attn): 0.0884, norm(output): 0.3730, norm(x): 0.3681, norm(y): 1.0007, norm:0.5087, tok/sec: 97272.92, flops:102.10, batch-reuse:1
@ 262 train 7.6982 , allloss: 7.7250, dt: 1323.61ms, fracRes: 0.0092, norm(attn): 0.0884, norm(output): 0.3730, norm(x): 0.3682, norm(y): 1.0007, norm:0.5330, tok/sec: 99026.07, flops:103.94, batch-reuse:1
@ 263 train 7.6816 , allloss: 7.7193, dt: 1309.19ms, fracRes: 0.0092, norm(attn): 0.0898, norm(output): 0.3730, norm(x): 0.3689, norm(y): 1.0007, norm:0.6337, tok/sec: 100116.88, flops:105.09, batch-reuse:1
@ 264 train 7.6677 , allloss: 7.6953, dt: 1325.95ms, fracRes: 0.0093, norm(attn): 0.0908, norm(output): 0.3750, norm(x): 0.3691, norm(y): 1.0007, norm:0.5667, tok/sec: 98851.73, flops:103.76, batch-reuse:1
@ 265 train 7.6628 , allloss: 7.7040, dt: 1348.89ms, fracRes: 0.0093, norm(attn): 0.0894, norm(output): 0.3730, norm(x): 0.3695, norm(y): 1.0007, norm:0.5041, tok/sec: 97170.33, flops:101.99, batch-reuse:1
@ 266 train 7.6646 , allloss: 7.7315, dt: 1331.75ms, fracRes: 0.0093, norm(attn): 0.0894, norm(output): 0.3730, norm(x): 0.3694, norm(y): 1.0007, norm:0.5043, tok/sec: 98420.60, flops:103.31, batch-reuse:1
@ 267 train 7.6320 , allloss: 7.6819, dt: 1343.31ms, fracRes: 0.0093, norm(attn): 0.0889, norm(output): 0.3730, norm(x): 0.3699, norm(y): 1.0007, norm:0.5824, tok/sec: 97574.12, flops:102.42, batch-reuse:1
@ 268 train 7.7146 , allloss: 7.7619, dt: 1340.76ms, fracRes: 0.0093, norm(attn): 0.0908, norm(output): 0.3750, norm(x): 0.3701, norm(y): 1.0007, norm:0.6006, tok/sec: 97759.69, flops:102.61, batch-reuse:1
@ 269 train 7.6519 , allloss: 7.6988, dt: 1341.15ms, fracRes: 0.0093, norm(attn): 0.0908, norm(output): 0.3750, norm(x): 0.3702, norm(y): 1.0007, norm:0.6406, tok/sec: 97730.89, flops:102.58, batch-reuse:1
@ 270 train 7.7296 , allloss: 7.7978, dt: 1315.33ms, fracRes: 0.0093, norm(attn): 0.0908, norm(output): 0.3750, norm(x): 0.3701, norm(y): 1.0007, norm:0.5837, tok/sec: 99649.55, flops:104.60, batch-reuse:1
@ 271 train 7.6343 , allloss: 7.6994, dt: 1352.98ms, fracRes: 0.0094, norm(attn): 0.0908, norm(output): 0.3750, norm(x): 0.3704, norm(y): 1.0007, norm:0.5107, tok/sec: 96876.28, flops:101.68, batch-reuse:1
@ 272 train 7.6522 , allloss: 7.7009, dt: 1353.97ms, fracRes: 0.0095, norm(attn): 0.0908, norm(output): 0.3750, norm(x): 0.3710, norm(y): 1.0007, norm:0.5446, tok/sec: 96805.55, flops:101.61, batch-reuse:1
@ 273 train 7.8020 , allloss: 7.8742, dt: 1337.58ms, fracRes: 0.0095, norm(attn): 0.0908, norm(output): 0.3750, norm(x): 0.3712, norm(y): 1.0007, norm:0.8289, tok/sec: 97991.74, flops:102.86, batch-reuse:1
@ 274 train 7.6769 , allloss: 7.7345, dt: 1320.47ms, fracRes: 0.0095, norm(attn): 0.0908, norm(output): 0.3750, norm(x): 0.3714, norm(y): 1.0006, norm:0.5335, tok/sec: 99261.78, flops:104.19, batch-reuse:1
@ 275 train 7.6646 , allloss: 7.7241, dt: 1305.79ms, fracRes: 0.0095, norm(attn): 0.0908, norm(output): 0.3750, norm(x): 0.3716, norm(y): 1.0006, norm:0.5389, tok/sec: 100377.83, flops:105.36, batch-reuse:1
@ 276 train 7.6454 , allloss: 7.7007, dt: 1316.32ms, fracRes: 0.0095, norm(attn): 0.0913, norm(output): 0.3750, norm(x): 0.3722, norm(y): 1.0006, norm:0.6746, tok/sec: 99574.72, flops:104.52, batch-reuse:1
@ 277 train 7.5617 , allloss: 7.6276, dt: 1335.21ms, fracRes: 0.0096, norm(attn): 0.0913, norm(output): 0.3750, norm(x): 0.3727, norm(y): 1.0006, norm:0.6678, tok/sec: 98165.77, flops:103.04, batch-reuse:1
@ 278 train 7.6496 , allloss: 7.7165, dt: 1298.42ms, fracRes: 0.0096, norm(attn): 0.0913, norm(output): 0.3770, norm(x): 0.3731, norm(y): 1.0006, norm:0.6141, tok/sec: 100947.01, flops:105.96, batch-reuse:1
@ 279 train 7.6102 , allloss: 7.6630, dt: 1296.79ms, fracRes: 0.0096, norm(attn): 0.0913, norm(output): 0.3770, norm(x): 0.3739, norm(y): 1.0006, norm:0.4794, tok/sec: 101074.40, flops:106.09, batch-reuse:1
@ 280 train 7.7049 , allloss: 7.7528, dt: 1298.53ms, fracRes: 0.0096, norm(attn): 0.0913, norm(output): 0.3770, norm(x): 0.3743, norm(y): 1.0006, norm:0.8343, tok/sec: 100938.99, flops:105.95, batch-reuse:1
@ 281 train 7.6393 , allloss: 7.7163, dt: 1305.75ms, fracRes: 0.0097, norm(attn): 0.0918, norm(output): 0.3770, norm(x): 0.3744, norm(y): 1.0006, norm:0.5285, tok/sec: 100380.96, flops:105.36, batch-reuse:1
@ 282 train 7.6049 , allloss: 7.6605, dt: 1324.62ms, fracRes: 0.0097, norm(attn): 0.0923, norm(output): 0.3770, norm(x): 0.3750, norm(y): 1.0006, norm:0.5216, tok/sec: 98950.50, flops:103.86, batch-reuse:1
@ 283 train 7.5632 , allloss: 7.6178, dt: 1341.80ms, fracRes: 0.0098, norm(attn): 0.0928, norm(output): 0.3770, norm(x): 0.3753, norm(y): 1.0006, norm:0.5711, tok/sec: 97683.36, flops:102.53, batch-reuse:1
@ 284 train 7.6668 , allloss: 7.7446, dt: 1342.61ms, fracRes: 0.0099, norm(attn): 0.0928, norm(output): 0.3770, norm(x): 0.3756, norm(y): 1.0006, norm:0.5398, tok/sec: 97624.97, flops:102.47, batch-reuse:1
@ 285 train 7.6681 , allloss: 7.7110, dt: 1325.67ms, fracRes: 0.0100, norm(attn): 0.0933, norm(output): 0.3770, norm(x): 0.3760, norm(y): 1.0006, norm:0.6448, tok/sec: 98872.61, flops:103.78, batch-reuse:1
@ 286 train 7.6830 , allloss: 7.7200, dt: 1302.32ms, fracRes: 0.0101, norm(attn): 0.0933, norm(output): 0.3770, norm(x): 0.3763, norm(y): 1.0006, norm:0.4542, tok/sec: 100645.13, flops:105.64, batch-reuse:1
@ 287 train 7.6743 , allloss: 7.7180, dt: 1291.25ms, fracRes: 0.0102, norm(attn): 0.0933, norm(output): 0.3770, norm(x): 0.3768, norm(y): 1.0005, norm:0.5530, tok/sec: 101507.64, flops:106.55, batch-reuse:1
@ 288 train 7.6902 , allloss: 7.7418, dt: 1323.77ms, fracRes: 0.0103, norm(attn): 0.0933, norm(output): 0.3789, norm(x): 0.3772, norm(y): 1.0005, norm:0.6433, tok/sec: 99014.39, flops:103.93, batch-reuse:1
@ 289 train 7.6575 , allloss: 7.7107, dt: 1307.47ms, fracRes: 0.0104, norm(attn): 0.0933, norm(output): 0.3789, norm(x): 0.3775, norm(y): 1.0005, norm:0.4186, tok/sec: 100248.55, flops:105.22, batch-reuse:1
@ 290 train 7.6327 , allloss: 7.6618, dt: 1302.52ms, fracRes: 0.0105, norm(attn): 0.0933, norm(output): 0.3789, norm(x): 0.3777, norm(y): 1.0005, norm:0.4350, tok/sec: 100629.79, flops:105.62, batch-reuse:1
@ 291 train 7.5684 , allloss: 7.5927, dt: 1302.28ms, fracRes: 0.0105, norm(attn): 0.0933, norm(output): 0.3770, norm(x): 0.3776, norm(y): 1.0005, norm:0.5547, tok/sec: 100648.28, flops:105.64, batch-reuse:1
@ 292 train 7.6008 , allloss: 7.6359, dt: 1314.77ms, fracRes: 0.0107, norm(attn): 0.0933, norm(output): 0.3789, norm(x): 0.3776, norm(y): 1.0005, norm:0.4538, tok/sec: 99691.98, flops:104.64, batch-reuse:1
@ 293 train 7.6692 , allloss: 7.7243, dt: 1296.57ms, fracRes: 0.0108, norm(attn): 0.0933, norm(output): 0.3770, norm(x): 0.3777, norm(y): 1.0005, norm:0.4744, tok/sec: 101091.45, flops:106.11, batch-reuse:1
@ 294 train 7.6361 , allloss: 7.6688, dt: 1302.00ms, fracRes: 0.0111, norm(attn): 0.0933, norm(output): 0.3789, norm(x): 0.3782, norm(y): 1.0005, norm:0.4719, tok/sec: 100669.97, flops:105.67, batch-reuse:1
@ 295 train 7.6535 , allloss: 7.6764, dt: 1313.04ms, fracRes: 0.0113, norm(attn): 0.0933, norm(output): 0.3789, norm(x): 0.3787, norm(y): 1.0005, norm:0.6015, tok/sec: 99822.98, flops:104.78, batch-reuse:1
@ 296 train 7.5714 , allloss: 7.5944, dt: 1323.47ms, fracRes: 0.0117, norm(attn): 0.0938, norm(output): 0.3789, norm(x): 0.3790, norm(y): 1.0005, norm:0.5148, tok/sec: 99036.58, flops:103.95, batch-reuse:1
@ 297 train 7.5385 , allloss: 7.5619, dt: 1345.82ms, fracRes: 0.0119, norm(attn): 0.0933, norm(output): 0.3828, norm(x): 0.3791, norm(y): 1.0005, norm:0.5163, tok/sec: 97391.81, flops:102.23, batch-reuse:1
@ 298 train 7.6447 , allloss: 7.6864, dt: 1336.88ms, fracRes: 0.0121, norm(attn): 0.0938, norm(output): 0.3828, norm(x): 0.3799, norm(y): 1.0004, norm:0.4425, tok/sec: 98043.02, flops:102.91, batch-reuse:1
@ 299 train 7.6464 , allloss: 7.6934, dt: 1335.30ms, fracRes: 0.0123, norm(attn): 0.0938, norm(output): 0.3848, norm(x): 0.3807, norm(y): 1.0004, norm:0.4043, tok/sec: 98159.52, flops:103.03, batch-reuse:1
@ 300 train 7.6236 , allloss: 7.6660, dt: 1317.08ms, fracRes: 0.0125, norm(attn): 0.0938, norm(output): 0.3848, norm(x): 0.3815, norm(y): 1.0004, norm:0.5192, tok/sec: 99516.99, flops:104.46, batch-reuse:1
@ 301 train 7.7712 , allloss: 7.8234, dt: 1341.09ms, fracRes: 0.0125, norm(attn): 0.0942, norm(output): 0.3848, norm(x): 0.3823, norm(y): 1.0004, norm:0.6407, tok/sec: 97735.10, flops:102.59, batch-reuse:1
@ 302 train 7.6116 , allloss: 7.6497, dt: 1309.56ms, fracRes: 0.0123, norm(attn): 0.0942, norm(output): 0.3848, norm(x): 0.3826, norm(y): 1.0004, norm:0.4431, tok/sec: 100088.94, flops:105.06, batch-reuse:1
@ 303 train 7.6357 , allloss: 7.6982, dt: 1311.42ms, fracRes: 0.0120, norm(attn): 0.0942, norm(output): 0.3848, norm(x): 0.3833, norm(y): 1.0004, norm:0.5621, tok/sec: 99946.43, flops:104.91, batch-reuse:1
@ 304 train 7.6061 , allloss: 7.6621, dt: 1305.06ms, fracRes: 0.0117, norm(attn): 0.0942, norm(output): 0.3848, norm(x): 0.3831, norm(y): 1.0004, norm:0.5799, tok/sec: 100433.58, flops:105.42, batch-reuse:1
@ 305 train 7.5455 , allloss: 7.5863, dt: 1306.51ms, fracRes: 0.0115, norm(attn): 0.0942, norm(output): 0.3848, norm(x): 0.3831, norm(y): 1.0004, norm:0.5459, tok/sec: 100322.20, flops:105.30, batch-reuse:1
@ 306 train 7.5505 , allloss: 7.5962, dt: 1312.72ms, fracRes: 0.0112, norm(attn): 0.0947, norm(output): 0.3848, norm(x): 0.3828, norm(y): 1.0004, norm:0.5334, tok/sec: 99847.64, flops:104.80, batch-reuse:1
@ 307 train 7.7413 , allloss: 7.7765, dt: 1312.31ms, fracRes: 0.0110, norm(attn): 0.0947, norm(output): 0.3848, norm(x): 0.3827, norm(y): 1.0004, norm:0.6916, tok/sec: 99878.99, flops:104.84, batch-reuse:1
@ 308 train 7.6085 , allloss: 7.6373, dt: 1326.36ms, fracRes: 0.0110, norm(attn): 0.0957, norm(output): 0.3848, norm(x): 0.3830, norm(y): 1.0004, norm:0.7544, tok/sec: 98820.96, flops:103.73, batch-reuse:1
@ 309 train 7.6372 , allloss: 7.6620, dt: 1341.27ms, fracRes: 0.0110, norm(attn): 0.0957, norm(output): 0.3848, norm(x): 0.3832, norm(y): 1.0004, norm:0.5577, tok/sec: 97722.08, flops:102.57, batch-reuse:1
@ 310 train 7.6668 , allloss: 7.6939, dt: 1331.19ms, fracRes: 0.0111, norm(attn): 0.0957, norm(output): 0.3848, norm(x): 0.3836, norm(y): 1.0004, norm:0.6139, tok/sec: 98462.01, flops:103.35, batch-reuse:1
@ 311 train 7.6798 , allloss: 7.7117, dt: 1339.43ms, fracRes: 0.0111, norm(attn): 0.0957, norm(output): 0.3848, norm(x): 0.3838, norm(y): 1.0004, norm:0.6793, tok/sec: 97856.61, flops:102.71, batch-reuse:1
@ 312 train 7.7660 , allloss: 7.7887, dt: 1300.12ms, fracRes: 0.0111, norm(attn): 0.0957, norm(output): 0.3848, norm(x): 0.3840, norm(y): 1.0004, norm:0.6214, tok/sec: 100815.52, flops:105.82, batch-reuse:1
@ 313 train 7.5810 , allloss: 7.6062, dt: 1321.75ms, fracRes: 0.0111, norm(attn): 0.0962, norm(output): 0.3848, norm(x): 0.3842, norm(y): 1.0004, norm:0.4755, tok/sec: 99165.20, flops:104.09, batch-reuse:1
@ 314 train 7.5867 , allloss: 7.6017, dt: 1343.16ms, fracRes: 0.0112, norm(attn): 0.0962, norm(output): 0.3848, norm(x): 0.3843, norm(y): 1.0004, norm:0.5182, tok/sec: 97584.51, flops:102.43, batch-reuse:1
@ 315 train 7.6352 , allloss: 7.6546, dt: 1348.16ms, fracRes: 0.0113, norm(attn): 0.0962, norm(output): 0.3848, norm(x): 0.3845, norm(y): 1.0004, norm:0.5547, tok/sec: 97223.19, flops:102.05, batch-reuse:1
@ 316 train 7.6476 , allloss: 7.6669, dt: 1324.70ms, fracRes: 0.0116, norm(attn): 0.0962, norm(output): 0.3867, norm(x): 0.3841, norm(y): 1.0003, norm:0.5233, tok/sec: 98945.01, flops:103.86, batch-reuse:1
@ 317 train 7.6740 , allloss: 7.6959, dt: 1328.52ms, fracRes: 0.0115, norm(attn): 0.0962, norm(output): 0.3848, norm(x): 0.3837, norm(y): 1.0003, norm:0.4514, tok/sec: 98659.84, flops:103.56, batch-reuse:1
@ 318 train 7.5795 , allloss: 7.6006, dt: 1347.11ms, fracRes: 0.0115, norm(attn): 0.0962, norm(output): 0.3848, norm(x): 0.3832, norm(y): 1.0003, norm:0.4879, tok/sec: 97298.93, flops:102.13, batch-reuse:1
@ 319 train 7.5442 , allloss: 7.5611, dt: 1343.92ms, fracRes: 0.0115, norm(attn): 0.0962, norm(output): 0.3848, norm(x): 0.3832, norm(y): 1.0003, norm:0.5288, tok/sec: 97529.60, flops:102.37, batch-reuse:1
@ 320 train 7.6071 , allloss: 7.6224, dt: 1307.47ms, fracRes: 0.0116, norm(attn): 0.0962, norm(output): 0.3848, norm(x): 0.3840, norm(y): 1.0003, norm:0.6508, tok/sec: 100248.88, flops:105.22, batch-reuse:1
@ 321 train 7.6483 , allloss: 7.6648, dt: 1315.55ms, fracRes: 0.0117, norm(attn): 0.0967, norm(output): 0.3867, norm(x): 0.3850, norm(y): 1.0003, norm:0.3182, tok/sec: 99632.65, flops:104.58, batch-reuse:1
@ 322 train 7.5721 , allloss: 7.5893, dt: 1344.36ms, fracRes: 0.0118, norm(attn): 0.0967, norm(output): 0.3867, norm(x): 0.3858, norm(y): 1.0003, norm:0.5108, tok/sec: 97497.74, flops:102.34, batch-reuse:1
@ 323 train 7.6549 , allloss: 7.6802, dt: 1310.00ms, fracRes: 0.0120, norm(attn): 0.0991, norm(output): 0.3867, norm(x): 0.3857, norm(y): 1.0003, norm:0.6627, tok/sec: 100054.71, flops:105.02, batch-reuse:1
@ 324 train 7.5886 , allloss: 7.5942, dt: 1354.62ms, fracRes: 0.0123, norm(attn): 0.0991, norm(output): 0.3906, norm(x): 0.3858, norm(y): 1.0003, norm:0.4656, tok/sec: 96759.10, flops:101.56, batch-reuse:1
@ 325 train 7.6269 , allloss: 7.6434, dt: 1353.79ms, fracRes: 0.0129, norm(attn): 0.0991, norm(output): 0.3867, norm(x): 0.3857, norm(y): 1.0003, norm:0.3388, tok/sec: 96818.25, flops:101.62, batch-reuse:1
@ 326 train 7.6542 , allloss: 7.6758, dt: 1354.55ms, fracRes: 0.0131, norm(attn): 0.0991, norm(output): 0.3965, norm(x): 0.3863, norm(y): 1.0003, norm:0.5623, tok/sec: 96764.38, flops:101.57, batch-reuse:1
@ 327 train 7.7245 , allloss: 7.7505, dt: 1337.34ms, fracRes: 0.0131, norm(attn): 0.0991, norm(output): 0.3965, norm(x): 0.3873, norm(y): 1.0003, norm:0.9157, tok/sec: 98009.60, flops:102.87, batch-reuse:1
@ 328 train 7.6199 , allloss: 7.6479, dt: 1318.39ms, fracRes: 0.0125, norm(attn): 0.1006, norm(output): 0.3965, norm(x): 0.3890, norm(y): 1.0003, norm:0.6273, tok/sec: 99418.44, flops:104.35, batch-reuse:1
@ 329 train 7.6403 , allloss: 7.6718, dt: 1311.28ms, fracRes: 0.0120, norm(attn): 0.1006, norm(output): 0.3984, norm(x): 0.3908, norm(y): 1.0003, norm:0.4233, tok/sec: 99957.42, flops:104.92, batch-reuse:1
@ 330 train 7.6253 , allloss: 7.6484, dt: 1306.24ms, fracRes: 0.0117, norm(attn): 0.1011, norm(output): 0.3984, norm(x): 0.3928, norm(y): 1.0003, norm:0.6359, tok/sec: 100342.60, flops:105.32, batch-reuse:1
@ 331 train 7.5723 , allloss: 7.6021, dt: 1312.98ms, fracRes: 0.0116, norm(attn): 0.1011, norm(output): 0.4023, norm(x): 0.3940, norm(y): 1.0003, norm:0.5342, tok/sec: 99827.53, flops:104.78, batch-reuse:1
@ 332 train 7.5800 , allloss: 7.6094, dt: 1320.48ms, fracRes: 0.0116, norm(attn): 0.1011, norm(output): 0.4043, norm(x): 0.3952, norm(y): 1.0003, norm:0.5923, tok/sec: 99261.17, flops:104.19, batch-reuse:1
@ 333 train 7.6356 , allloss: 7.6644, dt: 1292.14ms, fracRes: 0.0118, norm(attn): 0.1011, norm(output): 0.4043, norm(x): 0.3964, norm(y): 1.0003, norm:0.5227, tok/sec: 101438.17, flops:106.47, batch-reuse:1
@ 334 train 7.5776 , allloss: 7.6073, dt: 1303.86ms, fracRes: 0.0119, norm(attn): 0.1016, norm(output): 0.4043, norm(x): 0.3970, norm(y): 1.0003, norm:0.5751, tok/sec: 100526.34, flops:105.52, batch-reuse:1
@ 335 train 7.5783 , allloss: 7.6104, dt: 1328.64ms, fracRes: 0.0122, norm(attn): 0.1021, norm(output): 0.4043, norm(x): 0.3971, norm(y): 1.0003, norm:0.5287, tok/sec: 98651.32, flops:103.55, batch-reuse:1
@ 336 train 7.5951 , allloss: 7.6264, dt: 1297.77ms, fracRes: 0.0125, norm(attn): 0.1021, norm(output): 0.4043, norm(x): 0.3974, norm(y): 1.0003, norm:0.7943, tok/sec: 100997.70, flops:106.01, batch-reuse:1
@ 337 train 7.6102 , allloss: 7.6628, dt: 1302.02ms, fracRes: 0.0130, norm(attn): 0.1021, norm(output): 0.4043, norm(x): 0.3983, norm(y): 1.0003, norm:0.7166, tok/sec: 100668.39, flops:105.66, batch-reuse:1
@ 338 train 7.5776 , allloss: 7.6367, dt: 1325.44ms, fracRes: 0.0135, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.3999, norm(y): 1.0003, norm:0.6936, tok/sec: 98889.20, flops:103.80, batch-reuse:1
@ 339 train 7.6473 , allloss: 7.6809, dt: 1351.65ms, fracRes: 0.0142, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.4013, norm(y): 1.0003, norm:0.5698, tok/sec: 96971.78, flops:101.78, batch-reuse:1
@ 340 train 7.6671 , allloss: 7.6987, dt: 1344.61ms, fracRes: 0.0150, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.4015, norm(y): 1.0003, norm:0.5491, tok/sec: 97479.78, flops:102.32, batch-reuse:1
@ 341 train 7.5933 , allloss: 7.6171, dt: 1334.42ms, fracRes: 0.0161, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.4008, norm(y): 1.0004, norm:0.4887, tok/sec: 98224.02, flops:103.10, batch-reuse:1
@ 342 train 7.5318 , allloss: 7.5540, dt: 1295.18ms, fracRes: 0.0171, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.3997, norm(y): 1.0004, norm:0.4944, tok/sec: 101199.81, flops:106.22, batch-reuse:1
@ 343 train 7.5797 , allloss: 7.5919, dt: 1309.44ms, fracRes: 0.0177, norm(attn): 0.1021, norm(output): 0.4043, norm(x): 0.3990, norm(y): 1.0004, norm:0.5984, tok/sec: 100097.40, flops:105.07, batch-reuse:1
@ 344 train 7.5578 , allloss: 7.5680, dt: 1305.88ms, fracRes: 0.0182, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.3979, norm(y): 1.0005, norm:0.4744, tok/sec: 100370.81, flops:105.35, batch-reuse:1
@ 345 train 7.5776 , allloss: 7.5896, dt: 1313.04ms, fracRes: 0.0190, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.3973, norm(y): 1.0005, norm:0.4022, tok/sec: 99823.67, flops:104.78, batch-reuse:1
@ 346 train 7.6280 , allloss: 7.6454, dt: 1306.08ms, fracRes: 0.0201, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.3978, norm(y): 1.0006, norm:0.5506, tok/sec: 100355.51, flops:105.34, batch-reuse:1
@ 347 train 7.6533 , allloss: 7.6650, dt: 1310.29ms, fracRes: 0.0214, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.3979, norm(y): 1.0006, norm:0.5796, tok/sec: 100032.65, flops:105.00, batch-reuse:1
@ 348 train 7.5950 , allloss: 7.6046, dt: 1300.10ms, fracRes: 0.0232, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.3982, norm(y): 1.0006, norm:0.4755, tok/sec: 100817.06, flops:105.82, batch-reuse:1
@ 349 train 7.6167 , allloss: 7.6207, dt: 1304.08ms, fracRes: 0.0255, norm(attn): 0.1021, norm(output): 0.4062, norm(x): 0.3982, norm(y): 1.0006, norm:0.3185, tok/sec: 100509.13, flops:105.50, batch-reuse:1
@ 350 train 7.6375 , allloss: 7.6430, dt: 1344.74ms, fracRes: 0.0281, norm(attn): 0.1016, norm(output): 0.4062, norm(x): 0.3972, norm(y): 1.0006, norm:0.5021, tok/sec: 97470.22, flops:102.31, batch-reuse:1
@ 351 train 7.6491 , allloss: 7.6605, dt: 1337.01ms, fracRes: 0.0312, norm(attn): 0.1016, norm(output): 0.4043, norm(x): 0.3959, norm(y): 1.0006, norm:0.4916, tok/sec: 98033.98, flops:102.90, batch-reuse:1
@ 352 train 7.6817 , allloss: 7.6847, dt: 1345.12ms, fracRes: 0.0320, norm(attn): 0.1011, norm(output): 0.4043, norm(x): 0.3947, norm(y): 1.0006, norm:0.4902, tok/sec: 97442.84, flops:102.28, batch-reuse:1
@ 353 train 7.6240 , allloss: 7.6251, dt: 1341.00ms, fracRes: 0.0334, norm(attn): 0.1011, norm(output): 0.4023, norm(x): 0.3925, norm(y): 1.0006, norm:0.4491, tok/sec: 97741.65, flops:102.59, batch-reuse:1
@ 354 train 7.5954 , allloss: 7.5961, dt: 1345.19ms, fracRes: 0.0342, norm(attn): 0.1011, norm(output): 0.3984, norm(x): 0.3893, norm(y): 1.0006, norm:0.5424, tok/sec: 97437.67, flops:102.27, batch-reuse:1
@ 355 train 7.5707 , allloss: 7.5742, dt: 1345.88ms, fracRes: 0.0353, norm(attn): 0.0996, norm(output): 0.3848, norm(x): 0.3838, norm(y): 1.0006, norm:0.3949, tok/sec: 97387.53, flops:102.22, batch-reuse:1
@ 356 train 7.6789 , allloss: 7.6821, dt: 1342.64ms, fracRes: 0.0351, norm(attn): 0.0986, norm(output): 0.3770, norm(x): 0.3759, norm(y): 1.0006, norm:0.5195, tok/sec: 97622.70, flops:102.47, batch-reuse:1
@ 357 train 7.6502 , allloss: 7.6851, dt: 1341.51ms, fracRes: 0.0321, norm(attn): 0.0967, norm(output): 0.3711, norm(x): 0.3655, norm(y): 1.0006, norm:1.4592, tok/sec: 97704.79, flops:102.55, batch-reuse:1
@ 358 train 7.5766 , allloss: 7.7293, dt: 1346.08ms, fracRes: 0.0262, norm(attn): 0.0967, norm(output): 0.3535, norm(x): 0.3560, norm(y): 1.0006, norm:4.6883, tok/sec: 97372.97, flops:102.21, batch-reuse:1
@ 359 train 7.7894 , allloss: 7.9454, dt: 1350.40ms, fracRes: 0.0220, norm(attn): 0.0967, norm(output): 0.3477, norm(x): 0.3507, norm(y): 1.0006, norm:6.2213, tok/sec: 97061.87, flops:101.88, batch-reuse:1
@ 360 train 7.6753 , allloss: 7.7533, dt: 1343.13ms, fracRes: 0.0216, norm(attn): 0.0996, norm(output): 0.3535, norm(x): 0.3550, norm(y): 1.0006, norm:2.6697, tok/sec: 97586.71, flops:102.43, batch-reuse:1
@ 361 train 7.6609 , allloss: 7.7155, dt: 1341.86ms, fracRes: 0.0219, norm(attn): 0.1011, norm(output): 0.3652, norm(x): 0.3593, norm(y): 1.0006, norm:3.0084, tok/sec: 97679.61, flops:102.53, batch-reuse:1
@ 362 train 7.5387 , allloss: 7.5752, dt: 1322.20ms, fracRes: 0.0195, norm(attn): 0.1011, norm(output): 0.3652, norm(x): 0.3590, norm(y): 1.0006, norm:1.9929, tok/sec: 99132.05, flops:104.05, batch-reuse:1
@ 363 train 7.6185 , allloss: 7.6514, dt: 1344.14ms, fracRes: 0.0156, norm(attn): 0.1011, norm(output): 0.3633, norm(x): 0.3549, norm(y): 1.0006, norm:1.4536, tok/sec: 97513.80, flops:102.35, batch-reuse:1
@ 364 train 7.6276 , allloss: 7.6503, dt: 1335.44ms, fracRes: 0.0129, norm(attn): 0.1011, norm(output): 0.3535, norm(x): 0.3506, norm(y): 1.0006, norm:1.3579, tok/sec: 98148.74, flops:103.02, batch-reuse:1
@ 365 train 7.6324 , allloss: 7.6489, dt: 1321.63ms, fracRes: 0.0117, norm(attn): 0.1011, norm(output): 0.3535, norm(x): 0.3512, norm(y): 1.0006, norm:0.9533, tok/sec: 99174.15, flops:104.10, batch-reuse:1
@ 366 train 7.6398 , allloss: 7.6588, dt: 1308.65ms, fracRes: 0.0109, norm(attn): 0.1011, norm(output): 0.3535, norm(x): 0.3504, norm(y): 1.0006, norm:0.8972, tok/sec: 100158.18, flops:105.13, batch-reuse:1
@ 367 train 7.5918 , allloss: 7.6412, dt: 1302.56ms, fracRes: 0.0099, norm(attn): 0.1011, norm(output): 0.3457, norm(x): 0.3453, norm(y): 1.0006, norm:1.0620, tok/sec: 100626.36, flops:105.62, batch-reuse:1
@ 368 train 7.6665 , allloss: 7.8096, dt: 1341.92ms, fracRes: 0.0091, norm(attn): 0.1006, norm(output): 0.3418, norm(x): 0.3366, norm(y): 1.0006, norm:3.0187, tok/sec: 97675.17, flops:102.52, batch-reuse:1
@ 369 train 7.6149 , allloss: 7.8357, dt: 1314.40ms, fracRes: 0.0084, norm(attn): 0.0977, norm(output): 0.3242, norm(x): 0.3253, norm(y): 1.0006, norm:6.1584, tok/sec: 99720.15, flops:104.67, batch-reuse:1
@ 370 train 7.6784 , allloss: 8.1273, dt: 1311.89ms, fracRes: 0.0082, norm(attn): 0.0962, norm(output): 0.3125, norm(x): 0.3116, norm(y): 1.0006, norm:12.7720, tok/sec: 99911.01, flops:104.87, batch-reuse:1
@ 371 train 16.4884 , allloss: 20.8905, dt: 1317.02ms, fracRes: 0.0146, norm(attn): 0.0879, norm(output): 0.2070, norm(x): 0.2062, norm(y): 1.0003, norm:222.0874, tok/sec: 99521.45, flops:104.46, batch-reuse:1
@ 372 train 7.7032 , allloss: 7.7298, dt: 1322.67ms, fracRes: 0.0097, norm(attn): 0.1035, norm(output): 0.3848, norm(x): 0.3843, norm(y): 1.0009, norm:1.1062, tok/sec: 99096.54, flops:104.01, batch-reuse:1
@ 373 train 7.7011 , allloss: 8.7950, dt: 1347.14ms, fracRes: 0.0110, norm(attn): 0.1094, norm(output): 0.4043, norm(x): 0.4002, norm(y): 1.0009, norm:12.9619, tok/sec: 97296.64, flops:102.13, batch-reuse:1
@ 374 train 7.6912 , allloss: 9.6003, dt: 1340.39ms, fracRes: 0.0126, norm(attn): 0.1108, norm(output): 0.4043, norm(x): 0.3981, norm(y): 1.0009, norm:14.6118, tok/sec: 97786.59, flops:102.64, batch-reuse:1
@ 375 train 7.7636 , allloss: 9.7024, dt: 1315.40ms, fracRes: 0.0147, norm(attn): 0.1113, norm(output): 0.3945, norm(x): 0.3878, norm(y): 1.0008, norm:13.2437, tok/sec: 99644.12, flops:104.59, batch-reuse:1
@ 376 train 7.8062 , allloss: 10.6533, dt: 1314.44ms, fracRes: 0.0180, norm(attn): 0.1094, norm(output): 0.3711, norm(x): 0.3653, norm(y): 1.0008, norm:11.9548, tok/sec: 99716.79, flops:104.67, batch-reuse:1
@ 377 train 7.7015 , allloss: 10.6202, dt: 1326.47ms, fracRes: 0.0229, norm(attn): 0.1094, norm(output): 0.3711, norm(x): 0.3631, norm(y): 1.0008, norm:10.0873, tok/sec: 98812.56, flops:103.72, batch-reuse:1
@ 378 train 7.6602 , allloss: 10.2487, dt: 1312.54ms, fracRes: 0.0291, norm(attn): 0.1094, norm(output): 0.3750, norm(x): 0.3653, norm(y): 1.0008, norm:8.9772, tok/sec: 99861.01, flops:104.82, batch-reuse:1
@ 379 train 7.7413 , allloss: 9.3785, dt: 1307.24ms, fracRes: 0.0356, norm(attn): 0.1104, norm(output): 0.3906, norm(x): 0.3760, norm(y): 1.0009, norm:7.0784, tok/sec: 100266.28, flops:105.24, batch-reuse:1
@ 380 train 7.7952 , allloss: 8.9564, dt: 1289.28ms, fracRes: 0.0403, norm(attn): 0.1157, norm(output): 0.4199, norm(x): 0.4010, norm(y): 1.0010, norm:5.8907, tok/sec: 101663.21, flops:106.71, batch-reuse:1
@ 381 train 7.7437 , allloss: 8.5999, dt: 1313.75ms, fracRes: 0.0456, norm(attn): 0.1177, norm(output): 0.4453, norm(x): 0.4234, norm(y): 1.0010, norm:5.2764, tok/sec: 99769.47, flops:104.72, batch-reuse:1
@ 382 train 7.6888 , allloss: 8.2525, dt: 1294.36ms, fracRes: 0.0521, norm(attn): 0.1206, norm(output): 0.4668, norm(x): 0.4328, norm(y): 1.0011, norm:4.4989, tok/sec: 101263.60, flops:106.29, batch-reuse:1
@ 383 train 7.6910 , allloss: 8.1593, dt: 1300.79ms, fracRes: 0.0581, norm(attn): 0.1211, norm(output): 0.4707, norm(x): 0.4374, norm(y): 1.0011, norm:3.8860, tok/sec: 100763.69, flops:105.76, batch-reuse:1
@ 384 train 7.6917 , allloss: 8.0630, dt: 1311.35ms, fracRes: 0.0622, norm(attn): 0.1230, norm(output): 0.4805, norm(x): 0.4407, norm(y): 1.0011, norm:2.8881, tok/sec: 99951.75, flops:104.91, batch-reuse:1
@ 385 train 7.6578 , allloss: 7.9463, dt: 1291.80ms, fracRes: 0.0643, norm(attn): 0.1226, norm(output): 0.4902, norm(x): 0.4443, norm(y): 1.0012, norm:2.3959, tok/sec: 101464.38, flops:106.50, batch-reuse:1
@ 386 train 7.7123 , allloss: 8.0601, dt: 1301.46ms, fracRes: 0.0642, norm(attn): 0.1230, norm(output): 0.4922, norm(x): 0.4452, norm(y): 1.0012, norm:1.9180, tok/sec: 100711.62, flops:105.71, batch-reuse:1
@ 387 train 7.6885 , allloss: 7.9738, dt: 1283.32ms, fracRes: 0.0664, norm(attn): 0.1230, norm(output): 0.5000, norm(x): 0.4493, norm(y): 1.0012, norm:1.5468, tok/sec: 102135.32, flops:107.20, batch-reuse:1
@ 388 train 7.6184 , allloss: 7.8094, dt: 1290.35ms, fracRes: 0.0696, norm(attn): 0.1230, norm(output): 0.5117, norm(x): 0.4537, norm(y): 1.0012, norm:1.4712, tok/sec: 101578.72, flops:106.62, batch-reuse:1
@ 389 train 7.6787 , allloss: 7.8835, dt: 1294.22ms, fracRes: 0.0644, norm(attn): 0.1240, norm(output): 0.5078, norm(x): 0.4596, norm(y): 1.0012, norm:1.1131, tok/sec: 101274.68, flops:106.30, batch-reuse:1
@ 390 train 7.7212 , allloss: 7.8593, dt: 1302.69ms, fracRes: 0.0617, norm(attn): 0.1245, norm(output): 0.5156, norm(x): 0.4726, norm(y): 1.0013, norm:0.9229, tok/sec: 100616.75, flops:105.61, batch-reuse:1
@ 391 train 7.6560 , allloss: 7.7573, dt: 1294.28ms, fracRes: 0.0521, norm(attn): 0.1260, norm(output): 0.5234, norm(x): 0.4886, norm(y): 1.0013, norm:0.8102, tok/sec: 101270.22, flops:106.30, batch-reuse:1
@ 392 train 7.7032 , allloss: 7.7824, dt: 1279.47ms, fracRes: 0.0430, norm(attn): 0.1260, norm(output): 0.5273, norm(x): 0.5054, norm(y): 1.0013, norm:1.1364, tok/sec: 102442.71, flops:107.53, batch-reuse:1
@ 393 train 7.6792 , allloss: 7.7464, dt: 1302.54ms, fracRes: 0.0399, norm(attn): 0.1270, norm(output): 0.5352, norm(x): 0.5162, norm(y): 1.0013, norm:1.0323, tok/sec: 100628.29, flops:105.62, batch-reuse:1
@ 394 train 7.6570 , allloss: 7.7641, dt: 1296.00ms, fracRes: 0.0413, norm(attn): 0.1260, norm(output): 0.5391, norm(x): 0.5216, norm(y): 1.0013, norm:1.0187, tok/sec: 101136.16, flops:106.16, batch-reuse:1
@ 395 train 7.7811 , allloss: 7.8890, dt: 1311.57ms, fracRes: 0.0466, norm(attn): 0.1250, norm(output): 0.5508, norm(x): 0.5252, norm(y): 1.0012, norm:1.3474, tok/sec: 99934.94, flops:104.89, batch-reuse:1
@ 396 train 7.5757 , allloss: 7.6498, dt: 1303.91ms, fracRes: 0.0539, norm(attn): 0.1240, norm(output): 0.5547, norm(x): 0.5254, norm(y): 1.0013, norm:1.2201, tok/sec: 100522.13, flops:105.51, batch-reuse:1
@ 397 train 7.6876 , allloss: 7.7488, dt: 1316.47ms, fracRes: 0.0616, norm(attn): 0.1230, norm(output): 0.5586, norm(x): 0.5229, norm(y): 1.0013, norm:0.8577, tok/sec: 99563.38, flops:104.50, batch-reuse:1
@ 398 train 7.7063 , allloss: 7.7648, dt: 1305.90ms, fracRes: 0.0691, norm(attn): 0.1187, norm(output): 0.5586, norm(x): 0.5191, norm(y): 1.0013, norm:0.6792, tok/sec: 100369.45, flops:105.35, batch-reuse:1
@ 399 train 7.6745 , allloss: 7.7176, dt: 1320.64ms, fracRes: 0.0774, norm(attn): 0.1172, norm(output): 0.5625, norm(x): 0.5175, norm(y): 1.0013, norm:0.5884, tok/sec: 99249.20, flops:104.18, batch-reuse:1
@ 400 train 7.6930 , allloss: 7.7380, dt: 1310.12ms, fracRes: 0.0840, norm(attn): 0.1157, norm(output): 0.5586, norm(x): 0.5142, norm(y): 1.0013, norm:0.7924, tok/sec: 100045.50, flops:105.01, batch-reuse:1
@ 401 train 7.7599 , allloss: 7.8133, dt: 1338.20ms, fracRes: 0.0898, norm(attn): 0.1128, norm(output): 0.5469, norm(x): 0.5088, norm(y): 1.0013, norm:0.7387, tok/sec: 97946.30, flops:102.81, batch-reuse:1
@ 402 train 7.7062 , allloss: 7.7578, dt: 1330.63ms, fracRes: 0.0952, norm(attn): 0.1104, norm(output): 0.5508, norm(x): 0.5136, norm(y): 1.0013, norm:0.5291, tok/sec: 98504.08, flops:103.39, batch-reuse:1
@ 403 train 7.7334 , allloss: 7.8194, dt: 1293.32ms, fracRes: 0.0984, norm(attn): 0.1094, norm(output): 0.5430, norm(x): 0.5095, norm(y): 1.0013, norm:0.5288, tok/sec: 101345.23, flops:106.38, batch-reuse:1
@ 404 train 7.6630 , allloss: 7.7234, dt: 1305.09ms, fracRes: 0.1011, norm(attn): 0.1084, norm(output): 0.5391, norm(x): 0.5163, norm(y): 1.0013, norm:0.9222, tok/sec: 100431.69, flops:105.42, batch-reuse:1
@ 405 train 7.6638 , allloss: 7.7034, dt: 1298.63ms, fracRes: 0.1033, norm(attn): 0.1089, norm(output): 0.5469, norm(x): 0.5215, norm(y): 1.0013, norm:0.6057, tok/sec: 100931.35, flops:105.94, batch-reuse:1
@ 406 train 7.6593 , allloss: 7.6953, dt: 1319.92ms, fracRes: 0.1036, norm(attn): 0.1089, norm(output): 0.5391, norm(x): 0.5257, norm(y): 1.0013, norm:0.4465, tok/sec: 99302.62, flops:104.23, batch-reuse:1
@ 407 train 7.6678 , allloss: 7.7062, dt: 1324.19ms, fracRes: 0.1038, norm(attn): 0.1089, norm(output): 0.5312, norm(x): 0.5289, norm(y): 1.0013, norm:0.5153, tok/sec: 98983.01, flops:103.90, batch-reuse:1
@ 408 train 7.6964 , allloss: 7.7427, dt: 1314.54ms, fracRes: 0.1036, norm(attn): 0.1089, norm(output): 0.5273, norm(x): 0.5315, norm(y): 1.0014, norm:0.5410, tok/sec: 99709.10, flops:104.66, batch-reuse:1
@ 409 train 7.6321 , allloss: 7.6624, dt: 1281.51ms, fracRes: 0.1040, norm(attn): 0.1089, norm(output): 0.5234, norm(x): 0.5370, norm(y): 1.0014, norm:0.4204, tok/sec: 102279.31, flops:107.36, batch-reuse:1
@ 410 train 7.6550 , allloss: 7.6940, dt: 1295.59ms, fracRes: 0.1036, norm(attn): 0.1089, norm(output): 0.5117, norm(x): 0.5397, norm(y): 1.0014, norm:0.5376, tok/sec: 101168.04, flops:106.19, batch-reuse:1
@ 411 train 7.6594 , allloss: 7.6887, dt: 1311.31ms, fracRes: 0.1031, norm(attn): 0.1089, norm(output): 0.5078, norm(x): 0.5410, norm(y): 1.0014, norm:0.5366, tok/sec: 99954.80, flops:104.92, batch-reuse:1
@ 412 train 7.6796 , allloss: 7.7128, dt: 1305.30ms, fracRes: 0.1028, norm(attn): 0.1094, norm(output): 0.5117, norm(x): 0.5454, norm(y): 1.0014, norm:0.5464, tok/sec: 100415.54, flops:105.40, batch-reuse:1
@ 413 train 7.4792 , allloss: 7.4883, dt: 1297.10ms, fracRes: 0.1030, norm(attn): 0.1108, norm(output): 0.5234, norm(x): 0.5543, norm(y): 1.0014, norm:1.1871, tok/sec: 101050.16, flops:106.07, batch-reuse:1
@ 414 train 7.6592 , allloss: 7.6765, dt: 1310.91ms, fracRes: 0.1025, norm(attn): 0.1104, norm(output): 0.5195, norm(x): 0.5533, norm(y): 1.0014, norm:0.4815, tok/sec: 99985.54, flops:104.95, batch-reuse:1
@ 415 train 7.5851 , allloss: 7.6079, dt: 1296.73ms, fracRes: 0.1022, norm(attn): 0.1104, norm(output): 0.5234, norm(x): 0.5554, norm(y): 1.0014, norm:0.5312, tok/sec: 101078.62, flops:106.10, batch-reuse:1
@ 416 train 7.6951 , allloss: 7.7150, dt: 1304.98ms, fracRes: 0.1020, norm(attn): 0.1113, norm(output): 0.5273, norm(x): 0.5596, norm(y): 1.0014, norm:0.4583, tok/sec: 100439.59, flops:105.42, batch-reuse:1
@ 417 train 7.6477 , allloss: 7.6703, dt: 1324.59ms, fracRes: 0.1017, norm(attn): 0.1118, norm(output): 0.5273, norm(x): 0.5609, norm(y): 1.0014, norm:0.5396, tok/sec: 98952.97, flops:103.86, batch-reuse:1
@ 418 train 7.7105 , allloss: 7.7401, dt: 1319.46ms, fracRes: 0.1014, norm(attn): 0.1113, norm(output): 0.5273, norm(x): 0.5604, norm(y): 1.0014, norm:0.3863, tok/sec: 99337.78, flops:104.27, batch-reuse:1
@ 419 train 7.6742 , allloss: 7.6910, dt: 1301.80ms, fracRes: 0.1014, norm(attn): 0.1133, norm(output): 0.5312, norm(x): 0.5664, norm(y): 1.0014, norm:0.3393, tok/sec: 100685.44, flops:105.68, batch-reuse:1
@ 420 train 7.6111 , allloss: 7.6299, dt: 1286.10ms, fracRes: 0.1012, norm(attn): 0.1143, norm(output): 0.5312, norm(x): 0.5667, norm(y): 1.0015, norm:0.4839, tok/sec: 101914.09, flops:106.97, batch-reuse:1
@ 421 train 7.7749 , allloss: 7.8007, dt: 1307.99ms, fracRes: 0.1011, norm(attn): 0.1152, norm(output): 0.5312, norm(x): 0.5660, norm(y): 1.0015, norm:0.5299, tok/sec: 100209.10, flops:105.18, batch-reuse:1
@ 422 train 7.7095 , allloss: 7.7500, dt: 1307.04ms, fracRes: 0.1009, norm(attn): 0.1147, norm(output): 0.5312, norm(x): 0.5685, norm(y): 1.0015, norm:0.3804, tok/sec: 100281.32, flops:105.26, batch-reuse:1
@ 423 train 7.7463 , allloss: 7.7887, dt: 1302.64ms, fracRes: 0.1008, norm(attn): 0.1157, norm(output): 0.5391, norm(x): 0.5672, norm(y): 1.0015, norm:0.3960, tok/sec: 100620.37, flops:105.61, batch-reuse:1
@ 424 train 7.6542 , allloss: 7.6654, dt: 1296.80ms, fracRes: 0.1009, norm(attn): 0.1167, norm(output): 0.5469, norm(x): 0.5750, norm(y): 1.0015, norm:0.3034, tok/sec: 101073.72, flops:106.09, batch-reuse:1
@ 425 train 7.7218 , allloss: 7.7280, dt: 1308.73ms, fracRes: 0.1008, norm(attn): 0.1167, norm(output): 0.5469, norm(x): 0.5758, norm(y): 1.0015, norm:0.4509, tok/sec: 100151.81, flops:105.12, batch-reuse:1
@ 426 train 7.6116 , allloss: 7.6166, dt: 1292.42ms, fracRes: 0.1008, norm(attn): 0.1172, norm(output): 0.5469, norm(x): 0.5791, norm(y): 1.0015, norm:0.4699, tok/sec: 101416.33, flops:106.45, batch-reuse:1
@ 427 train 7.6967 , allloss: 7.7045, dt: 1329.56ms, fracRes: 0.1007, norm(attn): 0.1172, norm(output): 0.5508, norm(x): 0.5800, norm(y): 1.0015, norm:0.4681, tok/sec: 98583.23, flops:103.48, batch-reuse:1
@ 428 train 7.6460 , allloss: 7.6606, dt: 1318.85ms, fracRes: 0.1007, norm(attn): 0.1177, norm(output): 0.5586, norm(x): 0.5806, norm(y): 1.0015, norm:0.3471, tok/sec: 99383.78, flops:104.32, batch-reuse:1
@ 429 train 7.5920 , allloss: 7.5965, dt: 1309.26ms, fracRes: 0.1008, norm(attn): 0.1177, norm(output): 0.5547, norm(x): 0.5832, norm(y): 1.0015, norm:0.3664, tok/sec: 100111.61, flops:105.08, batch-reuse:1
@ 430 train 7.6633 , allloss: 7.6665, dt: 1306.73ms, fracRes: 0.1009, norm(attn): 0.1177, norm(output): 0.5586, norm(x): 0.5864, norm(y): 1.0015, norm:0.3527, tok/sec: 100305.18, flops:105.28, batch-reuse:1
@ 431 train 7.6507 , allloss: 7.6547, dt: 1289.65ms, fracRes: 0.1009, norm(attn): 0.1177, norm(output): 0.5586, norm(x): 0.5875, norm(y): 1.0015, norm:0.3463, tok/sec: 101634.14, flops:106.68, batch-reuse:1
@ 432 train 7.6880 , allloss: 7.6989, dt: 1329.70ms, fracRes: 0.1008, norm(attn): 0.1182, norm(output): 0.5586, norm(x): 0.5880, norm(y): 1.0015, norm:0.3722, tok/sec: 98572.54, flops:103.46, batch-reuse:1
@ 433 train 7.7028 , allloss: 7.7085, dt: 1354.08ms, fracRes: 0.1009, norm(attn): 0.1187, norm(output): 0.5625, norm(x): 0.5929, norm(y): 1.0015, norm:0.4212, tok/sec: 96797.73, flops:101.60, batch-reuse:1
@ 434 train 7.7206 , allloss: 7.7263, dt: 1299.02ms, fracRes: 0.1008, norm(attn): 0.1187, norm(output): 0.5586, norm(x): 0.5909, norm(y): 1.0015, norm:0.3960, tok/sec: 100900.77, flops:105.91, batch-reuse:1
@ 435 train 7.6790 , allloss: 7.6854, dt: 1315.59ms, fracRes: 0.1008, norm(attn): 0.1187, norm(output): 0.5625, norm(x): 0.5932, norm(y): 1.0015, norm:0.3812, tok/sec: 99630.10, flops:104.57, batch-reuse:1
@ 436 train 7.7732 , allloss: 7.7769, dt: 1340.07ms, fracRes: 0.1009, norm(attn): 0.1191, norm(output): 0.5625, norm(x): 0.5948, norm(y): 1.0015, norm:0.3919, tok/sec: 97809.95, flops:102.66, batch-reuse:1
@ 437 train 7.6969 , allloss: 7.7025, dt: 1300.17ms, fracRes: 0.1010, norm(attn): 0.1191, norm(output): 0.5664, norm(x): 0.5975, norm(y): 1.0015, norm:0.5518, tok/sec: 100811.21, flops:105.81, batch-reuse:1
@ 438 train 7.8032 , allloss: 7.8055, dt: 1326.07ms, fracRes: 0.1011, norm(attn): 0.1182, norm(output): 0.5664, norm(x): 0.5984, norm(y): 1.0015, norm:0.5233, tok/sec: 98842.78, flops:103.75, batch-reuse:1
@ 439 train 7.6154 , allloss: 7.6174, dt: 1320.03ms, fracRes: 0.1012, norm(attn): 0.1191, norm(output): 0.5703, norm(x): 0.6014, norm(y): 1.0015, norm:0.5124, tok/sec: 99295.02, flops:104.22, batch-reuse:1
@ 440 train 7.5902 , allloss: 7.5961, dt: 1291.87ms, fracRes: 0.1014, norm(attn): 0.1191, norm(output): 0.5664, norm(x): 0.6030, norm(y): 1.0015, norm:0.5366, tok/sec: 101458.93, flops:106.49, batch-reuse:1
@ 441 train 7.6318 , allloss: 7.6398, dt: 1311.38ms, fracRes: 0.1015, norm(attn): 0.1187, norm(output): 0.5664, norm(x): 0.6005, norm(y): 1.0016, norm:0.3839, tok/sec: 99949.79, flops:104.91, batch-reuse:1
@ 442 train 7.7099 , allloss: 7.7170, dt: 1303.64ms, fracRes: 0.1016, norm(attn): 0.1196, norm(output): 0.5703, norm(x): 0.6010, norm(y): 1.0016, norm:0.5371, tok/sec: 100543.18, flops:105.53, batch-reuse:1
@ 443 train 7.7270 , allloss: 7.7298, dt: 1291.50ms, fracRes: 0.1021, norm(attn): 0.1191, norm(output): 0.5664, norm(x): 0.6026, norm(y): 1.0016, norm:0.5709, tok/sec: 101488.03, flops:106.53, batch-reuse:1
@ 444 train 7.6902 , allloss: 7.6928, dt: 1320.77ms, fracRes: 0.1023, norm(attn): 0.1191, norm(output): 0.5703, norm(x): 0.6036, norm(y): 1.0016, norm:0.3730, tok/sec: 99238.83, flops:104.16, batch-reuse:1
@ 445 train 7.6232 , allloss: 7.6272, dt: 1315.03ms, fracRes: 0.1028, norm(attn): 0.1201, norm(output): 0.5703, norm(x): 0.6049, norm(y): 1.0016, norm:0.4458, tok/sec: 99672.32, flops:104.62, batch-reuse:1
@ 446 train 7.6816 , allloss: 7.6944, dt: 1302.82ms, fracRes: 0.1032, norm(attn): 0.1196, norm(output): 0.5703, norm(x): 0.6027, norm(y): 1.0016, norm:0.4385, tok/sec: 100606.10, flops:105.60, batch-reuse:1
@ 447 train 7.6614 , allloss: 7.6663, dt: 1328.59ms, fracRes: 0.1037, norm(attn): 0.1191, norm(output): 0.5742, norm(x): 0.6054, norm(y): 1.0016, norm:0.5393, tok/sec: 98655.29, flops:103.55, batch-reuse:1
@ 448 train 7.6555 , allloss: 7.6582, dt: 1292.84ms, fracRes: 0.1043, norm(attn): 0.1201, norm(output): 0.5742, norm(x): 0.6060, norm(y): 1.0016, norm:0.3581, tok/sec: 101383.15, flops:106.41, batch-reuse:1
@ 449 train 7.5988 , allloss: 7.6026, dt: 1309.93ms, fracRes: 0.1050, norm(attn): 0.1216, norm(output): 0.5703, norm(x): 0.6043, norm(y): 1.0016, norm:0.3027, tok/sec: 100060.34, flops:105.03, batch-reuse:1
@ 450 train 7.6760 , allloss: 7.6794, dt: 1304.68ms, fracRes: 0.1058, norm(attn): 0.1221, norm(output): 0.5781, norm(x): 0.6053, norm(y): 1.0016, norm:0.4376, tok/sec: 100462.57, flops:105.45, batch-reuse:1
@ 451 train 7.6543 , allloss: 7.6615, dt: 1325.56ms, fracRes: 0.1066, norm(attn): 0.1187, norm(output): 0.5820, norm(x): 0.6039, norm(y): 1.0016, norm:0.3838, tok/sec: 98880.38, flops:103.79, batch-reuse:1
@ 452 train 7.6886 , allloss: 7.6899, dt: 1318.68ms, fracRes: 0.1077, norm(attn): 0.1230, norm(output): 0.5859, norm(x): 0.6073, norm(y): 1.0016, norm:0.3409, tok/sec: 99396.61, flops:104.33, batch-reuse:1
@ 453 train 7.6816 , allloss: 7.6869, dt: 1289.28ms, fracRes: 0.1087, norm(attn): 0.1221, norm(output): 0.5820, norm(x): 0.6063, norm(y): 1.0016, norm:0.4040, tok/sec: 101663.25, flops:106.71, batch-reuse:1
@ 454 train 7.6679 , allloss: 7.6703, dt: 1315.81ms, fracRes: 0.1098, norm(attn): 0.1226, norm(output): 0.5859, norm(x): 0.6070, norm(y): 1.0016, norm:0.5315, tok/sec: 99613.24, flops:104.56, batch-reuse:1
@ 455 train 7.7277 , allloss: 7.7308, dt: 1329.80ms, fracRes: 0.1107, norm(attn): 0.1230, norm(output): 0.5859, norm(x): 0.6055, norm(y): 1.0016, norm:0.3872, tok/sec: 98564.91, flops:103.46, batch-reuse:1
@ 456 train 7.6661 , allloss: 7.6703, dt: 1333.90ms, fracRes: 0.1113, norm(attn): 0.1226, norm(output): 0.5859, norm(x): 0.6059, norm(y): 1.0016, norm:0.3600, tok/sec: 98261.87, flops:103.14, batch-reuse:1
@ 457 train 7.7646 , allloss: 7.7692, dt: 1314.90ms, fracRes: 0.1120, norm(attn): 0.1226, norm(output): 0.5859, norm(x): 0.6060, norm(y): 1.0016, norm:0.5205, tok/sec: 99682.00, flops:104.63, batch-reuse:1
@ 458 train 7.7614 , allloss: 7.7659, dt: 1335.73ms, fracRes: 0.1131, norm(attn): 0.1230, norm(output): 0.5859, norm(x): 0.6060, norm(y): 1.0016, norm:0.5125, tok/sec: 98127.29, flops:103.00, batch-reuse:1
@ 459 train 7.6591 , allloss: 7.6650, dt: 1331.94ms, fracRes: 0.1143, norm(attn): 0.1221, norm(output): 0.5859, norm(x): 0.6046, norm(y): 1.0016, norm:0.4149, tok/sec: 98406.65, flops:103.29, batch-reuse:1
@ 460 train 7.6257 , allloss: 7.6279, dt: 1332.00ms, fracRes: 0.1161, norm(attn): 0.1221, norm(output): 0.5859, norm(x): 0.6057, norm(y): 1.0016, norm:0.5784, tok/sec: 98402.59, flops:103.29, batch-reuse:1
@ 461 train 7.6801 , allloss: 7.6832, dt: 1319.65ms, fracRes: 0.1171, norm(attn): 0.1196, norm(output): 0.5859, norm(x): 0.6068, norm(y): 1.0016, norm:0.3390, tok/sec: 99323.53, flops:104.25, batch-reuse:1
@ 462 train 7.7148 , allloss: 7.7182, dt: 1315.56ms, fracRes: 0.1180, norm(attn): 0.1230, norm(output): 0.5938, norm(x): 0.6092, norm(y): 1.0016, norm:0.4322, tok/sec: 99632.25, flops:104.58, batch-reuse:1
@ 463 train 7.6992 , allloss: 7.7049, dt: 1334.62ms, fracRes: 0.1189, norm(attn): 0.1230, norm(output): 0.5938, norm(x): 0.6119, norm(y): 1.0016, norm:0.4074, tok/sec: 98209.54, flops:103.08, batch-reuse:1
@ 464 train 7.6391 , allloss: 7.6424, dt: 1294.24ms, fracRes: 0.1202, norm(attn): 0.1230, norm(output): 0.6016, norm(x): 0.6142, norm(y): 1.0016, norm:0.4437, tok/sec: 101273.19, flops:106.30, batch-reuse:1
@ 465 train 7.6288 , allloss: 7.6331, dt: 1287.80ms, fracRes: 0.1215, norm(attn): 0.1230, norm(output): 0.6016, norm(x): 0.6155, norm(y): 1.0016, norm:0.4252, tok/sec: 101779.42, flops:106.83, batch-reuse:1
@ 466 train 7.6752 , allloss: 7.6813, dt: 1302.77ms, fracRes: 0.1231, norm(attn): 0.1196, norm(output): 0.6016, norm(x): 0.6146, norm(y): 1.0016, norm:0.8314, tok/sec: 100610.01, flops:105.60, batch-reuse:1
@ 467 train 7.6271 , allloss: 7.6312, dt: 1312.40ms, fracRes: 0.1239, norm(attn): 0.1206, norm(output): 0.6016, norm(x): 0.6153, norm(y): 1.0016, norm:0.4062, tok/sec: 99872.18, flops:104.83, batch-reuse:1
@ 468 train 7.5589 , allloss: 7.5631, dt: 1300.27ms, fracRes: 0.1251, norm(attn): 0.1191, norm(output): 0.6016, norm(x): 0.6159, norm(y): 1.0016, norm:0.5092, tok/sec: 100803.47, flops:105.81, batch-reuse:1
@ 469 train 7.5609 , allloss: 7.5652, dt: 1301.83ms, fracRes: 0.1258, norm(attn): 0.1191, norm(output): 0.6055, norm(x): 0.6173, norm(y): 1.0016, norm:0.5036, tok/sec: 100683.12, flops:105.68, batch-reuse:1
@ 470 train 7.6495 , allloss: 7.6552, dt: 1307.65ms, fracRes: 0.1263, norm(attn): 0.1201, norm(output): 0.6172, norm(x): 0.6192, norm(y): 1.0016, norm:0.4595, tok/sec: 100234.62, flops:105.21, batch-reuse:1
@ 471 train 7.5381 , allloss: 7.5425, dt: 1304.66ms, fracRes: 0.1284, norm(attn): 0.1191, norm(output): 0.6172, norm(x): 0.6198, norm(y): 1.0016, norm:0.4876, tok/sec: 100464.54, flops:105.45, batch-reuse:1
@ 472 train 7.6558 , allloss: 7.6588, dt: 1329.64ms, fracRes: 0.1316, norm(attn): 0.1182, norm(output): 0.6172, norm(x): 0.6197, norm(y): 1.0016, norm:0.7110, tok/sec: 98577.21, flops:103.47, batch-reuse:1
@ 473 train 7.6413 , allloss: 7.6456, dt: 1350.97ms, fracRes: 0.1358, norm(attn): 0.1177, norm(output): 0.6172, norm(x): 0.6183, norm(y): 1.0016, norm:0.4634, tok/sec: 97020.73, flops:101.84, batch-reuse:1
@ 474 train 7.5786 , allloss: 7.5817, dt: 1351.94ms, fracRes: 0.1396, norm(attn): 0.1167, norm(output): 0.6172, norm(x): 0.6162, norm(y): 1.0016, norm:0.5018, tok/sec: 96950.83, flops:101.76, batch-reuse:1
@ 475 train 7.5847 , allloss: 7.5872, dt: 1358.37ms, fracRes: 0.1419, norm(attn): 0.1167, norm(output): 0.6172, norm(x): 0.6160, norm(y): 1.0016, norm:0.4894, tok/sec: 96491.86, flops:101.28, batch-reuse:1
@ 476 train 7.6091 , allloss: 7.6117, dt: 1360.97ms, fracRes: 0.1428, norm(attn): 0.1167, norm(output): 0.6172, norm(x): 0.6162, norm(y): 1.0016, norm:0.4674, tok/sec: 96307.71, flops:101.09, batch-reuse:1
@ 477 train 7.6731 , allloss: 7.6764, dt: 1359.18ms, fracRes: 0.1410, norm(attn): 0.1167, norm(output): 0.6211, norm(x): 0.6188, norm(y): 1.0016, norm:0.4377, tok/sec: 96434.77, flops:101.22, batch-reuse:1
@ 478 train 7.6465 , allloss: 7.6510, dt: 1327.87ms, fracRes: 0.1371, norm(attn): 0.1177, norm(output): 0.6211, norm(x): 0.6226, norm(y): 1.0016, norm:0.3829, tok/sec: 98708.13, flops:103.61, batch-reuse:1
@ 479 train 7.7457 , allloss: 7.7496, dt: 1325.06ms, fracRes: 0.1335, norm(attn): 0.1177, norm(output): 0.6211, norm(x): 0.6267, norm(y): 1.0016, norm:0.5540, tok/sec: 98918.08, flops:103.83, batch-reuse:1
@ 480 train 7.5743 , allloss: 7.5805, dt: 1319.33ms, fracRes: 0.1285, norm(attn): 0.1191, norm(output): 0.6250, norm(x): 0.6318, norm(y): 1.0016, norm:0.4780, tok/sec: 99347.54, flops:104.28, batch-reuse:1
@ 481 train 7.6403 , allloss: 7.6431, dt: 1315.29ms, fracRes: 0.1244, norm(attn): 0.1230, norm(output): 0.6250, norm(x): 0.6359, norm(y): 1.0016, norm:0.4825, tok/sec: 99652.55, flops:104.60, batch-reuse:1
@ 482 train 7.6224 , allloss: 7.6254, dt: 1328.97ms, fracRes: 0.1201, norm(attn): 0.1230, norm(output): 0.6289, norm(x): 0.6396, norm(y): 1.0015, norm:0.4137, tok/sec: 98626.94, flops:103.52, batch-reuse:1
@ 483 train 7.6894 , allloss: 7.6941, dt: 1355.36ms, fracRes: 0.1163, norm(attn): 0.1245, norm(output): 0.6289, norm(x): 0.6417, norm(y): 1.0015, norm:0.4338, tok/sec: 96706.15, flops:101.51, batch-reuse:1
@ 484 train 7.5720 , allloss: 7.5771, dt: 1354.89ms, fracRes: 0.1127, norm(attn): 0.1245, norm(output): 0.6289, norm(x): 0.6423, norm(y): 1.0015, norm:0.5956, tok/sec: 96740.05, flops:101.54, batch-reuse:1
@ 485 train 7.5594 , allloss: 7.5631, dt: 1359.23ms, fracRes: 0.1089, norm(attn): 0.1245, norm(output): 0.6289, norm(x): 0.6428, norm(y): 1.0015, norm:0.4514, tok/sec: 96431.34, flops:101.22, batch-reuse:1
@ 486 train 7.7064 , allloss: 7.7099, dt: 1353.34ms, fracRes: 0.1052, norm(attn): 0.1250, norm(output): 0.6289, norm(x): 0.6414, norm(y): 1.0015, norm:0.4325, tok/sec: 96850.54, flops:101.66, batch-reuse:1
@ 487 train 7.7093 , allloss: 7.7139, dt: 1357.18ms, fracRes: 0.1020, norm(attn): 0.1250, norm(output): 0.6250, norm(x): 0.6368, norm(y): 1.0015, norm:0.4373, tok/sec: 96576.80, flops:101.37, batch-reuse:1
@ 488 train 7.5751 , allloss: 7.5795, dt: 1312.93ms, fracRes: 0.1000, norm(attn): 0.1250, norm(output): 0.6211, norm(x): 0.6300, norm(y): 1.0015, norm:0.4974, tok/sec: 99831.34, flops:104.79, batch-reuse:1
@ 489 train 7.6286 , allloss: 7.6330, dt: 1328.07ms, fracRes: 0.0994, norm(attn): 0.1250, norm(output): 0.6172, norm(x): 0.6218, norm(y): 1.0015, norm:0.4485, tok/sec: 98693.51, flops:103.59, batch-reuse:1
@ 490 train 7.6223 , allloss: 7.6258, dt: 1318.42ms, fracRes: 0.0994, norm(attn): 0.1245, norm(output): 0.6055, norm(x): 0.6130, norm(y): 1.0015, norm:0.3873, tok/sec: 99416.06, flops:104.35, batch-reuse:1
@ 491 train 7.7174 , allloss: 7.7208, dt: 1317.30ms, fracRes: 0.0997, norm(attn): 0.1235, norm(output): 0.6016, norm(x): 0.6059, norm(y): 1.0015, norm:0.5477, tok/sec: 99500.70, flops:104.44, batch-reuse:1
@ 492 train 7.6775 , allloss: 7.6958, dt: 1339.21ms, fracRes: 0.1000, norm(attn): 0.1230, norm(output): 0.5977, norm(x): 0.5997, norm(y): 1.0015, norm:0.7254, tok/sec: 97872.83, flops:102.73, batch-reuse:1
@ 493 train 7.6472 , allloss: 7.6590, dt: 1311.02ms, fracRes: 0.0991, norm(attn): 0.1177, norm(output): 0.5898, norm(x): 0.5923, norm(y): 1.0015, norm:0.4649, tok/sec: 99977.34, flops:104.94, batch-reuse:1
@ 494 train 7.6140 , allloss: 7.6498, dt: 1292.78ms, fracRes: 0.0948, norm(attn): 0.1172, norm(output): 0.5938, norm(x): 0.5881, norm(y): 1.0014, norm:0.9794, tok/sec: 101387.51, flops:106.42, batch-reuse:1
@ 495 train 7.5548 , allloss: 7.8463, dt: 1304.86ms, fracRes: 0.0208, norm(attn): 0.1318, norm(output): 0.6250, norm(x): 0.6148, norm(y): 1.0015, norm:7.1181, tok/sec: 100448.92, flops:105.43, batch-reuse:1
@ 496 train 7.6559 , allloss: 7.9218, dt: 1307.86ms, fracRes: 0.0190, norm(attn): 0.1260, norm(output): 0.6211, norm(x): 0.6116, norm(y): 1.0014, norm:6.9991, tok/sec: 100218.43, flops:105.19, batch-reuse:1
@ 497 train 7.5592 , allloss: 7.7093, dt: 1303.17ms, fracRes: 0.0199, norm(attn): 0.1260, norm(output): 0.6250, norm(x): 0.6135, norm(y): 1.0014, norm:6.3670, tok/sec: 100579.16, flops:105.57, batch-reuse:1
@ 498 train 7.7055 , allloss: 7.7671, dt: 1307.23ms, fracRes: 0.0186, norm(attn): 0.1260, norm(output): 0.6250, norm(x): 0.6198, norm(y): 1.0014, norm:1.9627, tok/sec: 100266.94, flops:105.24, batch-reuse:1
@ 499 train 7.7207 , allloss: 7.7992, dt: 1313.19ms, fracRes: 0.0194, norm(attn): 0.1250, norm(output): 0.6289, norm(x): 0.6209, norm(y): 1.0014, norm:3.1238, tok/sec: 99811.57, flops:104.77, batch-reuse:1
@ 500 train 7.6393 , allloss: 7.6732, dt: 1308.23ms, fracRes: 0.0212, norm(attn): 0.1250, norm(output): 0.6289, norm(x): 0.6213, norm(y): 1.0014, norm:1.4529, tok/sec: 100190.19, flops:105.16, batch-reuse:1
@ 501 train 7.6313 , allloss: 7.6575, dt: 1305.64ms, fracRes: 0.0247, norm(attn): 0.1230, norm(output): 0.6250, norm(x): 0.6196, norm(y): 1.0013, norm:1.0715, tok/sec: 100389.41, flops:105.37, batch-reuse:1
@ 502 train 7.6966 , allloss: 7.7166, dt: 1332.35ms, fracRes: 0.0336, norm(attn): 0.1177, norm(output): 0.6211, norm(x): 0.6102, norm(y): 1.0013, norm:0.7067, tok/sec: 98376.67, flops:103.26, batch-reuse:1
@ 503 train 7.6592 , allloss: 7.7726, dt: 1324.72ms, fracRes: 0.0528, norm(attn): 0.1118, norm(output): 0.6094, norm(x): 0.5887, norm(y): 1.0013, norm:29.5135, tok/sec: 98943.48, flops:103.85, batch-reuse:1
@ 504 train 7.7088 , allloss: 7.7545, dt: 1293.10ms, fracRes: 0.0271, norm(attn): 0.1328, norm(output): 0.6484, norm(x): 0.6460, norm(y): 1.0015, norm:0.8232, tok/sec: 101362.85, flops:106.39, batch-reuse:1
@ 505 train 7.6206 , allloss: 7.6745, dt: 1322.96ms, fracRes: 0.0320, norm(attn): 0.1387, norm(output): 0.6289, norm(x): 0.6273, norm(y): 1.0017, norm:1.3425, tok/sec: 99074.61, flops:103.99, batch-reuse:1
@ 506 train 7.6191 , allloss: 7.6649, dt: 1352.75ms, fracRes: 0.0364, norm(attn): 0.1396, norm(output): 0.6133, norm(x): 0.6032, norm(y): 1.0017, norm:1.2349, tok/sec: 96893.32, flops:101.70, batch-reuse:1
@ 507 train 7.6742 , allloss: 7.7125, dt: 1333.71ms, fracRes: 0.0444, norm(attn): 0.1416, norm(output): 0.6016, norm(x): 0.5938, norm(y): 1.0018, norm:0.9265, tok/sec: 98276.56, flops:103.15, batch-reuse:1
@ 508 train 7.5962 , allloss: 7.6462, dt: 1329.36ms, fracRes: 0.0614, norm(attn): 0.1416, norm(output): 0.5938, norm(x): 0.5829, norm(y): 1.0019, norm:0.8961, tok/sec: 98597.54, flops:103.49, batch-reuse:1
@ 509 train 7.6175 , allloss: 7.7010, dt: 1313.89ms, fracRes: 0.0835, norm(attn): 0.1426, norm(output): 0.6016, norm(x): 0.5798, norm(y): 1.0020, norm:0.9447, tok/sec: 99758.61, flops:104.71, batch-reuse:1
@ 510 train 7.5987 , allloss: 7.6860, dt: 1336.11ms, fracRes: 0.1058, norm(attn): 0.1416, norm(output): 0.5820, norm(x): 0.5750, norm(y): 1.0019, norm:1.1289, tok/sec: 98099.63, flops:102.97, batch-reuse:1
@ 511 train 7.6701 , allloss: 7.7246, dt: 1323.89ms, fracRes: 0.1217, norm(attn): 0.1426, norm(output): 0.5898, norm(x): 0.5886, norm(y): 1.0020, norm:0.8482, tok/sec: 99005.40, flops:103.92, batch-reuse:1
@ 512 train 7.6220 , allloss: 7.6617, dt: 1324.83ms, fracRes: 0.1405, norm(attn): 0.1436, norm(output): 0.5977, norm(x): 0.5975, norm(y): 1.0020, norm:0.6740, tok/sec: 98935.17, flops:103.85, batch-reuse:1
@ 513 train 7.6294 , allloss: 7.6659, dt: 1303.93ms, fracRes: 0.1526, norm(attn): 0.1436, norm(output): 0.6133, norm(x): 0.6169, norm(y): 1.0021, norm:0.5005, tok/sec: 100520.47, flops:105.51, batch-reuse:1
@ 514 train 7.6062 , allloss: 7.6459, dt: 1315.87ms, fracRes: 0.1650, norm(attn): 0.1445, norm(output): 0.6289, norm(x): 0.6327, norm(y): 1.0021, norm:0.4047, tok/sec: 99608.87, flops:104.55, batch-reuse:1
@ 515 train 7.5849 , allloss: 7.6253, dt: 1326.56ms, fracRes: 0.1793, norm(attn): 0.1436, norm(output): 0.6289, norm(x): 0.6423, norm(y): 1.0021, norm:0.6046, tok/sec: 98806.02, flops:103.71, batch-reuse:1
@ 516 train 7.5677 , allloss: 7.6023, dt: 1344.78ms, fracRes: 0.1957, norm(attn): 0.1436, norm(output): 0.6328, norm(x): 0.6490, norm(y): 1.0021, norm:0.5198, tok/sec: 97467.47, flops:102.30, batch-reuse:1
@ 517 train 7.5619 , allloss: 7.5970, dt: 1346.05ms, fracRes: 0.2080, norm(attn): 0.1426, norm(output): 0.6328, norm(x): 0.6577, norm(y): 1.0021, norm:0.4940, tok/sec: 97375.35, flops:102.21, batch-reuse:1
@ 518 train 7.6475 , allloss: 7.6871, dt: 1339.07ms, fracRes: 0.2131, norm(attn): 0.1426, norm(output): 0.6445, norm(x): 0.6731, norm(y): 1.0021, norm:0.4739, tok/sec: 97883.06, flops:102.74, batch-reuse:1
@ 519 train 7.6057 , allloss: 7.6525, dt: 1350.17ms, fracRes: 0.2221, norm(attn): 0.1436, norm(output): 0.6406, norm(x): 0.6766, norm(y): 1.0021, norm:0.5148, tok/sec: 97078.43, flops:101.90, batch-reuse:1
@ 520 train 7.6670 , allloss: 7.7100, dt: 1335.89ms, fracRes: 0.2327, norm(attn): 0.1416, norm(output): 0.6445, norm(x): 0.6821, norm(y): 1.0022, norm:0.4940, tok/sec: 98115.84, flops:102.99, batch-reuse:1
@ 521 train 7.7260 , allloss: 7.7774, dt: 1315.45ms, fracRes: 0.2321, norm(attn): 0.1426, norm(output): 0.6562, norm(x): 0.6932, norm(y): 1.0022, norm:0.6240, tok/sec: 99640.09, flops:104.59, batch-reuse:1
@ 522 train 7.5865 , allloss: 7.6458, dt: 1302.56ms, fracRes: 0.2348, norm(attn): 0.1436, norm(output): 0.6523, norm(x): 0.6979, norm(y): 1.0023, norm:0.4628, tok/sec: 100626.30, flops:105.62, batch-reuse:1
@ 523 train 7.6781 , allloss: 7.7397, dt: 1309.74ms, fracRes: 0.2354, norm(attn): 0.1445, norm(output): 0.6602, norm(x): 0.7045, norm(y): 1.0023, norm:0.5720, tok/sec: 100075.18, flops:105.04, batch-reuse:1
@ 524 train 7.6199 , allloss: 7.6853, dt: 1315.14ms, fracRes: 0.2381, norm(attn): 0.1445, norm(output): 0.6641, norm(x): 0.7083, norm(y): 1.0023, norm:0.6423, tok/sec: 99663.86, flops:104.61, batch-reuse:1
@ 525 train 7.6297 , allloss: 7.6975, dt: 1318.11ms, fracRes: 0.2345, norm(attn): 0.1465, norm(output): 0.6641, norm(x): 0.7148, norm(y): 1.0024, norm:0.5353, tok/sec: 99439.49, flops:104.37, batch-reuse:1
@ 526 train 7.6353 , allloss: 7.7003, dt: 1312.87ms, fracRes: 0.2396, norm(attn): 0.1455, norm(output): 0.6641, norm(x): 0.7147, norm(y): 1.0024, norm:0.5245, tok/sec: 99836.40, flops:104.79, batch-reuse:1
@ 527 train 7.6409 , allloss: 7.7043, dt: 1312.10ms, fracRes: 0.2404, norm(attn): 0.1455, norm(output): 0.6680, norm(x): 0.7168, norm(y): 1.0024, norm:0.4674, tok/sec: 99895.16, flops:104.85, batch-reuse:1
@ 528 train 7.6336 , allloss: 7.7004, dt: 1325.67ms, fracRes: 0.2403, norm(attn): 0.1475, norm(output): 0.6758, norm(x): 0.7226, norm(y): 1.0024, norm:0.5064, tok/sec: 98872.59, flops:103.78, batch-reuse:1
@ 529 train 7.5640 , allloss: 7.6285, dt: 1349.01ms, fracRes: 0.2377, norm(attn): 0.1504, norm(output): 0.6758, norm(x): 0.7293, norm(y): 1.0024, norm:0.4537, tok/sec: 97161.64, flops:101.98, batch-reuse:1
@ 530 train 7.6773 , allloss: 7.7398, dt: 1321.13ms, fracRes: 0.2370, norm(attn): 0.1504, norm(output): 0.6875, norm(x): 0.7354, norm(y): 1.0024, norm:0.4174, tok/sec: 99212.32, flops:104.14, batch-reuse:1
@ 531 train 7.6969 , allloss: 7.7503, dt: 1317.62ms, fracRes: 0.2346, norm(attn): 0.1504, norm(output): 0.6914, norm(x): 0.7412, norm(y): 1.0025, norm:0.6193, tok/sec: 99476.43, flops:104.41, batch-reuse:1
@ 532 train 7.5498 , allloss: 7.6030, dt: 1292.85ms, fracRes: 0.2365, norm(attn): 0.1514, norm(output): 0.6836, norm(x): 0.7394, norm(y): 1.0025, norm:0.6724, tok/sec: 101382.50, flops:106.41, batch-reuse:1
@ 533 train 7.5942 , allloss: 7.6448, dt: 1309.71ms, fracRes: 0.2390, norm(attn): 0.1523, norm(output): 0.6914, norm(x): 0.7417, norm(y): 1.0025, norm:0.5392, tok/sec: 100076.88, flops:105.04, batch-reuse:1
@ 534 train 7.5485 , allloss: 7.5966, dt: 1296.13ms, fracRes: 0.2422, norm(attn): 0.1504, norm(output): 0.6953, norm(x): 0.7398, norm(y): 1.0025, norm:0.5068, tok/sec: 101125.94, flops:106.15, batch-reuse:1
@ 535 train 7.6171 , allloss: 7.6768, dt: 1309.24ms, fracRes: 0.2343, norm(attn): 0.1533, norm(output): 0.6992, norm(x): 0.7501, norm(y): 1.0025, norm:0.9236, tok/sec: 100112.91, flops:105.08, batch-reuse:1
@ 536 train 7.6017 , allloss: 7.6456, dt: 1322.75ms, fracRes: 0.2356, norm(attn): 0.1533, norm(output): 0.6953, norm(x): 0.7498, norm(y): 1.0025, norm:0.4424, tok/sec: 99090.79, flops:104.01, batch-reuse:1
@ 537 train 7.5978 , allloss: 7.6499, dt: 1329.32ms, fracRes: 0.2400, norm(attn): 0.1523, norm(output): 0.6953, norm(x): 0.7488, norm(y): 1.0025, norm:0.5315, tok/sec: 98600.84, flops:103.49, batch-reuse:1
@ 538 train 7.4523 , allloss: 7.4992, dt: 1336.01ms, fracRes: 0.2426, norm(attn): 0.1523, norm(output): 0.6914, norm(x): 0.7458, norm(y): 1.0025, norm:0.8528, tok/sec: 98106.77, flops:102.98, batch-reuse:1
@ 539 train 7.6033 , allloss: 7.6455, dt: 1297.49ms, fracRes: 0.2386, norm(attn): 0.1533, norm(output): 0.6992, norm(x): 0.7546, norm(y): 1.0025, norm:0.4861, tok/sec: 101019.35, flops:106.03, batch-reuse:1
@ 540 train 7.6572 , allloss: 7.6999, dt: 1305.36ms, fracRes: 0.2364, norm(attn): 0.1553, norm(output): 0.7031, norm(x): 0.7572, norm(y): 1.0025, norm:0.5368, tok/sec: 100410.72, flops:105.39, batch-reuse:1
@ 541 train 7.5546 , allloss: 7.5941, dt: 1319.04ms, fracRes: 0.2372, norm(attn): 0.1562, norm(output): 0.7070, norm(x): 0.7590, norm(y): 1.0025, norm:0.6476, tok/sec: 99368.91, flops:104.30, batch-reuse:1
@ 542 train 7.6786 , allloss: 7.7217, dt: 1316.06ms, fracRes: 0.2379, norm(attn): 0.1562, norm(output): 0.7070, norm(x): 0.7590, norm(y): 1.0025, norm:0.4976, tok/sec: 99594.49, flops:104.54, batch-reuse:1
@ 543 train 7.7305 , allloss: 7.7852, dt: 1300.88ms, fracRes: 0.2342, norm(attn): 0.1562, norm(output): 0.7109, norm(x): 0.7626, norm(y): 1.0025, norm:0.5473, tok/sec: 100756.51, flops:105.76, batch-reuse:1
@ 544 train 7.6339 , allloss: 7.6735, dt: 1322.68ms, fracRes: 0.2349, norm(attn): 0.1553, norm(output): 0.7109, norm(x): 0.7642, norm(y): 1.0025, norm:0.4432, tok/sec: 99095.53, flops:104.01, batch-reuse:1
@ 545 train 7.6212 , allloss: 7.6503, dt: 1310.59ms, fracRes: 0.2300, norm(attn): 0.1562, norm(output): 0.7188, norm(x): 0.7701, norm(y): 1.0025, norm:0.5266, tok/sec: 100010.12, flops:104.97, batch-reuse:1
@ 546 train 7.5812 , allloss: 7.6038, dt: 1286.31ms, fracRes: 0.2335, norm(attn): 0.1562, norm(output): 0.7227, norm(x): 0.7684, norm(y): 1.0025, norm:0.4915, tok/sec: 101897.57, flops:106.95, batch-reuse:1
@ 547 train 7.7181 , allloss: 7.7419, dt: 1293.36ms, fracRes: 0.2252, norm(attn): 0.1592, norm(output): 0.7305, norm(x): 0.7801, norm(y): 1.0025, norm:0.4839, tok/sec: 101342.41, flops:106.37, batch-reuse:1
@ 548 train 7.7071 , allloss: 7.7324, dt: 1286.30ms, fracRes: 0.2198, norm(attn): 0.1621, norm(output): 0.7422, norm(x): 0.7899, norm(y): 1.0025, norm:0.3915, tok/sec: 101898.28, flops:106.96, batch-reuse:1
@ 549 train 7.6809 , allloss: 7.7025, dt: 1303.08ms, fracRes: 0.2144, norm(attn): 0.1650, norm(output): 0.7461, norm(x): 0.7954, norm(y): 1.0025, norm:0.3660, tok/sec: 100586.68, flops:105.58, batch-reuse:1
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5625, 0.4375, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.4395, 0.2910, 0.2715, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2139, 0.2236, 0.4219, 0.1416, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2402, 0.0703, 0.1436, 0.4258, 0.1187, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3320, 0.1226, 0.1523, 0.1973, 0.1650, 0.0292, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1553, 0.1475, 0.1118, 0.1621, 0.0698, 0.1797, 0.1738, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1182, 0.1924, 0.0928, 0.1289, 0.0991, 0.1060, 0.1152, 0.1465, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1660, 0.0518, 0.0513, 0.2051, 0.0806, 0.0266, 0.1396, 0.2305, 0.0486, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1260, 0.0381, 0.1226, 0.1729, 0.0544, 0.0119, 0.0674, 0.2412, 0.1094, 0.0559, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1406, 0.0515, 0.0579, 0.1250, 0.1270, 0.0216, 0.0894, 0.1758, 0.0669, 0.0869, 0.0566, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0776, 0.0659, 0.0879, 0.0669, 0.1069, 0.0894, 0.0625, 0.1079, 0.0742, 0.0903, 0.0972, 0.0728, 0.0000, 0.0000, 0.0000],
        [0.0386, 0.0830, 0.0381, 0.0437, 0.0850, 0.2100, 0.0525, 0.0383, 0.0703, 0.2012, 0.0549, 0.0649, 0.0193, 0.0000, 0.0000],
        [0.0825, 0.0542, 0.0598, 0.0928, 0.0835, 0.0513, 0.0593, 0.0806, 0.0635, 0.0708, 0.0552, 0.0562, 0.1104, 0.0811, 0.0000],
        [0.0874, 0.0938, 0.0603, 0.0767, 0.0854, 0.0247, 0.0623, 0.1123, 0.0491, 0.0427, 0.0265, 0.0669, 0.1201, 0.0781, 0.0142]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[-0.0197,  0.0074, -0.0237,  ..., -0.0024,  0.0049, -0.0088],
        [-0.0300, -0.0148,  0.0172,  ...,  0.0238, -0.0165,  0.0224],
        [ 0.0539,  0.0367,  0.0399,  ..., -0.0210,  0.0174, -0.0111],
        ...,
        [ 0.0086,  0.0502, -0.0169,  ...,  0.0297, -0.0342, -0.0101],
        [ 0.0216,  0.0060, -0.0172,  ...,  0.0070, -0.0350,  0.0524],
        [-0.0314, -0.0074,  0.0135,  ..., -0.0045,  0.0118, -0.0064]], device='cuda:0', requires_grad=True)
K: tensor([-0.6797, -0.8164, -0.2637, -1.1172,  0.5508,  0.2910, -0.0020, -1.2734,  0.6953,  0.2969,  0.5469,  0.7109, -1.4766, -1.0859, -0.6250, -0.5742,  0.6797, -0.8984, -0.6641, -0.3809, -0.1572,  0.3848, -1.5312,  0.6875,  0.5977, -0.0354,  0.0786, -0.2422, -0.3574,  0.8633,  0.5469, -1.2578,
        -0.3496, -0.3242, -0.6289,  1.1875,  0.4355, -0.8438,  0.2188, -0.2637,  0.3477, -0.7656, -0.0508,  0.4258,  0.1709, -0.4277,  0.2119, -0.2559,  0.4062, -1.2031, -0.4414,  0.6641,  0.5195,  0.0625,  1.1016,  0.8594, -0.4141,  1.3516,  0.5508, -0.7656,  0.5000,  0.0123, -0.0520,  0.2598],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[-0.0479, -0.0227,  0.0313,  ...,  0.0142,  0.0236,  0.0106],
        [-0.0144, -0.0035,  0.0063,  ...,  0.0001,  0.0100, -0.0207],
        [ 0.0550, -0.0156, -0.0282,  ..., -0.0466, -0.0113,  0.0273],
        ...,
        [-0.0002,  0.0248,  0.0034,  ...,  0.0045, -0.0275, -0.0289],
        [-0.0164,  0.0121,  0.0113,  ..., -0.0239, -0.0128, -0.0188],
        [-0.0062, -0.0089,  0.0063,  ...,  0.0149,  0.0052,  0.0479]], device='cuda:0', requires_grad=True)
Q: tensor([ 0.3828,  0.3809,  0.7656,  1.0781,  0.2334, -1.1406,  0.6602,  0.5039, -0.2422,  0.6836, -0.8516, -0.5938,  1.0625, -0.5742, -0.3379, -0.3711, -1.0000,  1.0078,  0.0369,  0.2178,  0.0305, -0.2539, -0.2832, -0.1865,  0.1475, -0.0732, -0.4375,  0.3711,  0.1309, -0.6641, -0.2539,  0.1240,
        -0.4180, -0.0845,  0.0031, -0.3086, -0.0060,  1.3516, -0.2871,  0.8789, -0.8867,  1.7266,  0.3027, -0.6133,  0.0762,  0.6445, -1.3438,  0.8516, -0.4395,  0.5898, -0.5664, -0.1011, -0.6836,  0.6758, -0.4707, -0.0923, -0.2275, -0.8984, -0.8477,  0.7148,  0.2852, -0.3203, -0.6250, -0.1572],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[     0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000],
        [     0.0000,     -0.2520,     -0.9844,     -0.5039,     -0.1504,     -0.1650,     -0.1953,     -0.1982,     -0.2793,     -0.0767,     -0.1680,      0.3301,      0.2852,      0.0023,     -0.1562],
        [     0.0000,     -0.4121,     -0.4805,     -0.2559,     -0.1660,     -0.0923,     -0.1855,      0.7891,     -0.0564,     -0.6289,     -0.1611,      0.5859,      0.1562,      0.2930,     -0.4277],
        [     0.0000,      0.0427,      0.6797,     -0.4141,      0.0679,     -0.2168,      0.0728,      0.1367,     -0.2539,     -0.4258,     -0.2676,     -0.1963,      0.1895,      0.5156,      0.2412],
        [     0.0000,     -1.2266,     -0.5117,      0.5742,     -0.7031,     -1.5859,     -0.2314,      0.3262,     -0.5391,     -0.7031,      0.0261,     -0.2432,      0.9297,     -0.1279,     -0.9648],
        [     0.0000,     -1.0000,     -0.7812,     -0.5195,     -0.6992,     -2.4375,      0.2793,      0.1973,     -1.1016,     -1.2188,     -0.9609,     -0.3438,      0.0150,     -0.5625,     -1.7422],
        [     0.0000,     -0.0486,     -0.3262,      0.0444,     -0.7930,      0.1504,      0.1187,     -0.4434,     -0.4316,      0.0476,     -0.4453,      0.1465,     -0.1621,      0.0134,      0.0918],
        [     0.0000,      0.4883,     -0.2461,      0.0874,     -0.1768,     -0.1123,     -0.0250,      0.2129,      0.4258,      0.1118,      0.2148,      0.0623,      0.1147,     -0.0322,      0.4707],
        [     0.0000,     -1.1641,     -1.1719,      0.2148,     -0.7188,     -1.8281,     -0.1719,      0.3320,     -1.2266,     -0.7539,     -1.3125,     -0.4043,      0.4395,     -0.1992,     -1.1406],
        [     0.0000,     -1.1953,     -0.0266,      0.3145,     -0.8359,     -2.3594,     -0.6250,      0.6484,     -0.1436,     -0.8125,     -0.9180,      0.0496,      0.1021,     -0.1885,     -1.7266],
        [     0.0000,     -1.0078,     -0.8906,     -0.1162,     -0.1011,     -1.8750,     -0.4570,      0.2246,     -0.7461,     -0.4844,     -0.9102,     -1.1016,      0.2891,     -0.2422,     -1.0078],
        [     0.0000,     -0.1602,      0.1270,     -0.1484,      0.3242,      0.1426,     -0.2158,      0.3320,     -0.0461,      0.1553,      0.2246,     -0.0623,      0.3027,      0.1147,     -0.0240],
        [     0.0000,      0.7656,     -0.0162,      0.1206,      0.7852,      1.6953,      0.3047,     -0.0072,      0.6016,      1.6484,      0.3516,      0.5156,     -0.6914,      0.5938,      0.2676],
        [     0.0000,     -0.4199,     -0.3203,      0.1167,      0.0151,     -0.4727,     -0.3281,     -0.0208,     -0.2637,     -0.1533,     -0.3984,     -0.3848,      0.2910,     -0.0141,     -0.4941],
        [     0.0000,      0.0669,     -0.3730,     -0.1318,     -0.0280,     -1.2656,     -0.3418,      0.2471,     -0.5781,     -0.7188,     -1.1953,     -0.2695,      0.3125,     -0.1167,     -1.8203]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.6037],
        [0.3957],
        [0.2402],
        [0.2458],
        [0.2781],
        [0.1251],
        [0.0973],
        [0.1443],
        [0.1396],
        [0.1191],
        [0.0832],
        [0.0588],
        [0.0747],
        [0.0814]], device='cuda:0')
tensor([[    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.8555,     0.1455,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.9883,     0.0124,     0.0002,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.9805,     0.0192,     0.0005,     0.0011,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.9805,     0.0170,     0.0003,     0.0008,     0.0006,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.9648,     0.0254,     0.0011,     0.0021,     0.0011,     0.0056,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.8945,     0.0527,     0.0040,     0.0091,     0.0047,     0.0160,     0.0194,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.8867,     0.0420,     0.0035,     0.0090,     0.0046,     0.0123,     0.0228,     0.0199,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.8047,     0.0723,     0.0042,     0.0085,     0.0058,     0.0168,     0.0293,     0.0249,     0.0334,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.7461,     0.0579,     0.0072,     0.0148,     0.0082,     0.0264,     0.0322,     0.0306,     0.0420,     0.0339,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.8516,     0.0457,     0.0025,     0.0053,     0.0028,     0.0091,     0.0156,     0.0154,     0.0262,     0.0161,     0.0087,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.7930,     0.0457,     0.0030,     0.0063,     0.0039,     0.0142,     0.0167,     0.0211,     0.0391,     0.0178,     0.0120,     0.0292,     0.0000,     0.0000,     0.0000],
        [    0.9062,     0.0273,     0.0009,     0.0018,     0.0013,     0.0051,     0.0070,     0.0078,     0.0149,     0.0112,     0.0047,     0.0095,     0.0031,     0.0000,     0.0000],
        [    0.8594,     0.0310,     0.0017,     0.0035,     0.0021,     0.0070,     0.0134,     0.0121,     0.0184,     0.0127,     0.0068,     0.0181,     0.0060,     0.0073,     0.0000],
        [    0.8242,     0.0359,     0.0021,     0.0047,     0.0025,     0.0096,     0.0132,     0.0143,     0.0206,     0.0133,     0.0087,     0.0210,     0.0079,     0.0104,     0.0106]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[    -0.0163,      0.0026,     -0.0040,  ...,     -0.0129,     -0.0067,     -0.0082],
        [     0.0239,     -0.0134,      0.0094,  ...,     -0.0130,     -0.0195,      0.0099],
        [     0.0065,     -0.0010,     -0.0146,  ...,      0.0065,     -0.0268,      0.0188],
        ...,
        [     0.0022,      0.0121,     -0.0280,  ...,      0.0035,      0.0046,     -0.0157],
        [    -0.0154,     -0.0284,     -0.0367,  ...,     -0.0290,      0.0264,     -0.0160],
        [    -0.0206,      0.0000,     -0.0034,  ...,      0.0207,      0.0403,      0.0056]], device='cuda:0', requires_grad=True)
K: tensor([ 0.1709,  1.6797,  0.7148, -0.5430, -0.5977, -0.1650, -0.6758,  0.8281,  1.1875, -0.7383,  0.5703,  0.4629,  1.7109, -0.3164,  0.2656, -0.6250, -0.6055, -0.1040, -0.5938, -1.3125, -0.3984,  1.5000, -1.2344, -1.6172, -0.4668,  1.2969,  1.1562,  0.5781,  0.5742, -1.1484,  0.7383,  0.2119,
        -1.5938, -0.5117,  0.6094,  1.6016, -0.8242, -0.6250,  0.5742,  0.0962,  0.0178, -0.3770,  0.7656, -0.3320,  0.9727, -2.1875,  0.8398,  1.3125,  1.2031, -0.8281, -0.2676,  1.5312, -1.4062, -1.3047,  1.1406, -0.3809,  0.1157, -0.8906,  0.1040, -0.6328,  0.1816,  1.7344,  0.0447, -0.2891],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[-0.0028, -0.0037,  0.0121,  ...,  0.0116,  0.0154, -0.0218],
        [-0.0177,  0.0188,  0.0012,  ...,  0.0140,  0.0159,  0.0023],
        [ 0.0037,  0.0182, -0.0353,  ..., -0.0379, -0.0021,  0.0093],
        ...,
        [ 0.0095, -0.0347,  0.0011,  ...,  0.0036,  0.0014,  0.0080],
        [ 0.0239, -0.0156, -0.0068,  ...,  0.0032, -0.0033,  0.0156],
        [-0.0226,  0.0041, -0.0364,  ...,  0.0060, -0.0170,  0.0055]], device='cuda:0', requires_grad=True)
Q: tensor([-0.9297,  0.1797,  0.4746,  0.1670,  1.2344, -1.2656, -0.1011, -0.6914, -0.5703,  0.0183, -0.4453,  1.0547, -0.6133,  0.2949,  0.3184,  0.8633, -0.0028, -0.5703,  0.0123,  1.1172,  0.3535, -1.2500,  1.4141,  0.5430,  0.4883, -0.6602, -1.5703, -0.2490, -1.2266,  1.4375, -0.1680,  0.7617,
         0.6992,  1.5312,  1.1953, -0.9844,  0.9844,  0.4805, -0.7109, -0.5273,  0.5742, -0.0244, -0.8984,  1.2266, -0.3184,  1.0625, -0.4980, -0.0728, -0.1318,  0.6406,  0.9570, -2.0312,  1.4531,  1.1016, -0.9922,  1.1562, -1.0312,  0.8516, -0.7344, -0.7070,  0.9297, -1.4531, -0.0962,  0.8555],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000, -1.7734, -2.9219, -2.7188, -2.9062, -2.2812, -2.0938, -2.1250, -1.9141, -2.1719, -2.3125, -1.8203, -2.4375, -2.3281, -2.3281],
        [ 0.0000, -4.3750, -8.7500, -7.5312, -8.5625, -6.7812, -5.7812, -5.6250, -5.1875, -5.7188, -6.6562, -5.4375, -7.0625, -6.3750, -6.4375],
        [ 0.0000, -3.9375, -7.6875, -6.8125, -7.4062, -5.9688, -5.2500, -5.2812, -4.7500, -4.9062, -5.5938, -5.0312, -6.3438, -5.8125, -5.5000],
        [ 0.0000, -4.0625, -8.0000, -7.1250, -7.4688, -6.0312, -5.4062, -5.4062, -4.9062, -5.2188, -6.3125, -5.2188, -6.5000, -6.0000, -5.6875],
        [ 0.0000, -3.6406, -6.8125, -6.1250, -6.7812, -5.1562, -4.5312, -4.7500, -4.2500, -4.7188, -5.2812, -4.2500, -5.4375, -5.3125, -4.9688],
        [ 0.0000, -2.8281, -5.4062, -4.5938, -5.2500, -4.0312, -3.8281, -3.6719, -3.1875, -3.8438, -4.0312, -3.3906, -4.3438, -3.9062, -4.0312],
        [ 0.0000, -3.0469, -5.5312, -4.5938, -5.2500, -4.2812, -3.6562, -3.7969, -3.5781, -3.8750, -4.0938, -3.6562, -4.2188, -4.2812, -4.1562],
        [ 0.0000, -2.4062, -5.2500, -4.5312, -4.9375, -3.8750, -3.3125, -3.4844, -3.1875, -3.5156, -3.9688, -3.1406, -3.9688, -3.8438, -3.6875],
        [ 0.0000, -2.5625, -4.6562, -3.9219, -4.5000, -3.3438, -3.1406, -3.1875, -2.8750, -3.0938, -3.5469, -2.8125, -3.5469, -3.5000, -3.3750],
        [ 0.0000, -2.9219, -5.8438, -5.0625, -5.7188, -4.5312, -4.0000, -4.0000, -3.4844, -3.9688, -4.5938, -3.9531, -5.0625, -4.4688, -4.2188],
        [ 0.0000, -2.8438, -5.5938, -4.8438, -5.3125, -4.0312, -3.8594, -3.6250, -3.0000, -3.7969, -4.1875, -3.2969, -4.4688, -4.0312, -4.1562],
        [ 0.0000, -3.5000, -6.9375, -6.1875, -6.5625, -5.1875, -4.8438, -4.7500, -4.0938, -4.4062, -5.2500, -4.5625, -5.6875, -5.1875, -4.9688],
        [ 0.0000, -3.3281, -6.1875, -5.5000, -6.0000, -4.8125, -4.1562, -4.2812, -3.8438, -4.2188, -4.8438, -3.8594, -4.9688, -4.7812, -4.5938],
        [ 0.0000, -3.1406, -5.9688, -5.1562, -5.8125, -4.4375, -4.1250, -4.0625, -3.6875, -4.1250, -4.5625, -3.6719, -4.6562, -4.3750, -4.3438]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.8281],
        [0.9756],
        [0.9648],
        [0.9658],
        [0.9264],
        [0.8783],
        [0.8239],
        [0.7542],
        [0.6960],
        [0.8477],
        [0.7459],
        [0.8747],
        [0.8014],
        [0.7992]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.6367, 0.3652, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3262, 0.3203, 0.3535, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2295, 0.2148, 0.2910, 0.2656, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2061, 0.1611, 0.2119, 0.2031, 0.2188, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1553, 0.1699, 0.1924, 0.1758, 0.1553, 0.1523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1475, 0.1245, 0.1475, 0.1582, 0.1245, 0.1523, 0.1465, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1025, 0.1377, 0.1260, 0.1592, 0.1123, 0.1191, 0.1216, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1143, 0.0977, 0.1108, 0.1162, 0.0884, 0.1064, 0.1143, 0.1338, 0.1177, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1025, 0.1084, 0.0942, 0.1245, 0.0903, 0.0947, 0.0928, 0.0977, 0.0918, 0.1030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0718, 0.0840, 0.0986, 0.1074, 0.0933, 0.0845, 0.0991, 0.1011, 0.0845, 0.0879, 0.0874, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0845, 0.0864, 0.0962, 0.0903, 0.0684, 0.0786, 0.0811, 0.0898, 0.0801, 0.0835, 0.0688, 0.0928, 0.0000, 0.0000, 0.0000],
        [0.0659, 0.0649, 0.0898, 0.0889, 0.0698, 0.0693, 0.0791, 0.0776, 0.0762, 0.0718, 0.0679, 0.0879, 0.0908, 0.0000, 0.0000],
        [0.0669, 0.0625, 0.0713, 0.0825, 0.0549, 0.0654, 0.0679, 0.0767, 0.0762, 0.0732, 0.0576, 0.0771, 0.0781, 0.0898, 0.0000],
        [0.0564, 0.0674, 0.0713, 0.0771, 0.0581, 0.0615, 0.0684, 0.0728, 0.0605, 0.0640, 0.0522, 0.0688, 0.0747, 0.0752, 0.0708]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[ 0.0079, -0.0192,  0.0127,  ...,  0.0179, -0.0318,  0.0052],
        [ 0.0168, -0.0091,  0.0214,  ..., -0.0093, -0.0083,  0.0146],
        [-0.0067,  0.0002,  0.0095,  ...,  0.0383, -0.0041, -0.0050],
        ...,
        [ 0.0072,  0.0068, -0.0304,  ...,  0.0052, -0.0232,  0.0256],
        [-0.0102, -0.0064, -0.0276,  ..., -0.0082, -0.0089,  0.0215],
        [ 0.0239,  0.0249,  0.0328,  ...,  0.0250, -0.0033, -0.0077]], device='cuda:0', requires_grad=True)
K: tensor([-0.2139, -0.2930,  0.2432,  0.0170, -0.4922, -0.2695, -0.1318, -0.3066, -0.6016,  0.3906,  0.7227, -0.5625,  0.9375, -0.1309,  0.4062,  0.8320,  0.0310, -0.3281,  0.3184, -1.2656, -0.1924,  0.1279, -0.0972,  0.2383,  0.0315, -0.8672,  0.0505,  0.1104, -0.5117, -0.0815, -0.3457,  0.3574,
        -0.2178, -0.4512, -0.7305,  0.6055,  0.4766,  0.1426,  0.1055,  0.0535,  0.6914,  0.9961, -0.3730, -1.3438, -0.3691, -0.3457,  0.0640, -0.3125,  0.2021, -0.2129, -0.0962,  0.1475,  0.1484,  0.3086,  1.3516, -0.2402, -0.8008, -0.6367, -1.0469, -0.3027,  0.3066, -0.6133, -0.9492,  0.3320],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[ 0.0075,  0.0056,  0.0077,  ...,  0.0085,  0.0321, -0.0093],
        [-0.0279,  0.0316, -0.0386,  ...,  0.0120,  0.0578, -0.0063],
        [-0.0022, -0.0129, -0.0048,  ..., -0.0246, -0.0082, -0.0046],
        ...,
        [ 0.0263,  0.0124, -0.0076,  ..., -0.0250, -0.0376,  0.0365],
        [ 0.0431,  0.0103, -0.0247,  ...,  0.0395,  0.0057,  0.0179],
        [ 0.0169, -0.0169,  0.0037,  ...,  0.0223,  0.0085,  0.0053]], device='cuda:0', requires_grad=True)
Q: tensor([-0.1826,  0.1396,  0.0640, -0.4941, -0.0066, -0.1904, -0.4316, -0.8516,  0.2305,  0.4922,  0.1729,  0.1826,  0.2344, -0.3535,  0.0479, -0.2393, -0.4160, -0.7344,  0.1367, -0.1475,  0.9922,  0.6328,  0.4707, -0.1089,  0.0752, -0.2480,  0.8281, -0.2754,  0.7266, -0.3164, -0.2227, -0.3926,
        -0.4648, -0.4082,  0.6680,  1.3125, -1.1016,  0.0422,  0.1504,  0.3184,  0.0312, -0.0708,  0.4121, -0.2344, -0.1016, -0.6758, -0.7930, -1.8828, -0.3281, -0.1104, -0.3770,  0.1895, -0.1235, -0.2676, -0.5039,  0.1729, -0.3535,  0.2578, -0.2197, -0.7031, -0.0786, -0.3945, -0.2520, -0.2324],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[     0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000],
        [     0.0000,     -0.5547,     -0.3789,     -0.5781,     -0.6406,     -0.4141,     -0.5469,     -0.3555,     -0.3125,     -0.4004,     -0.3184,     -0.4570,     -0.2480,     -0.1797,     -0.5508],
        [     0.0000,     -0.0187,      0.0796,      0.1040,      0.1455,      0.0801,      0.2285,      0.0278,      0.2217,     -0.0396,     -0.1030,      0.2031,      0.2051,      0.5234,      0.1426],
        [     0.0000,     -0.0669,      0.2354,      0.1445,      0.1689,      0.1245,      0.2578,      0.3555,      0.1562,      0.1777,     -0.0403,      0.2871,      0.3242,      0.4336,      0.3633],
        [     0.0000,     -0.2461,      0.0300,     -0.0125,      0.0596,     -0.0464,      0.0339,      0.1128,      0.0566,      0.0258,     -0.1074,      0.1904,      0.1309,      0.3574,      0.1758],
        [     0.0000,      0.0903,      0.2139,      0.1250,     -0.0011,     -0.0171,      0.1611,      0.2480,      0.1807,      0.0386,     -0.0649,      0.2266,      0.3125,      0.4180,      0.2676],
        [     0.0000,     -0.1670,      0.0001,      0.0713,     -0.1670,      0.0334,     -0.0060,      0.1514,      0.0698,     -0.0322,     -0.1289,      0.1289,      0.1445,      0.1387,      0.1011],
        [     0.0000,      0.2930,      0.2070,      0.4355,      0.0913,      0.1484,      0.1689,      0.1689,      0.1680,      0.1582,      0.0145,      0.1670,      0.2314,      0.2656,      0.1797],
        [     0.0000,     -0.1553,     -0.0303,      0.0176,     -0.2559,     -0.0703,      0.0019,      0.1611,      0.0299,      0.0216,     -0.2500,      0.1157,      0.1924,      0.1299,      0.1094],
        [     0.0000,      0.0552,     -0.0835,      0.1924,     -0.1260,     -0.0791,     -0.0986,     -0.0471,     -0.1099,      0.0040,     -0.2002,      0.0012,      0.0723,     -0.0115,     -0.0884],
        [     0.0000,      0.1543,      0.3184,      0.4043,      0.2617,      0.1650,      0.3223,      0.3438,      0.1631,      0.2012,      0.1953,      0.3848,      0.4629,      0.4238,      0.3047],
        [     0.0000,      0.0229,      0.1309,      0.0684,     -0.2119,     -0.0703,     -0.0425,      0.0654,     -0.0549,     -0.0094,     -0.2031,      0.0928,      0.1167,      0.1924,      0.0374],
        [     0.0000,     -0.0107,      0.3125,      0.2988,      0.0588,      0.0532,      0.1816,      0.1660,      0.1475,      0.0835,      0.0294,      0.2891,      0.3242,      0.4844,      0.2129],
        [     0.0000,     -0.0654,      0.0669,      0.2100,     -0.1934,     -0.0188,      0.0129,      0.1396,      0.1309,      0.0952,     -0.1494,      0.1436,      0.1543,      0.2949,      0.0972],
        [     0.0000,      0.1758,      0.2354,      0.3145,      0.0292,      0.0854,      0.1924,      0.2539,      0.0674,      0.1245,     -0.0796,      0.1992,      0.2773,      0.2852,      0.2256]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.5910],
        [0.3313],
        [0.2660],
        [0.2131],
        [0.1707],
        [0.1620],
        [0.1281],
        [0.1184],
        [0.1038],
        [0.0903],
        [0.0871],
        [0.0845],
        [0.0743],
        [0.0693]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.8828, 0.1177, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.7891, 0.1045, 0.1050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.7188, 0.0942, 0.0947, 0.0942, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.6562, 0.0859, 0.0864, 0.0859, 0.0859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.6055, 0.0791, 0.0796, 0.0791, 0.0791, 0.0791, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5586, 0.0732, 0.0737, 0.0732, 0.0732, 0.0732, 0.0732, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5234, 0.0684, 0.0688, 0.0684, 0.0684, 0.0684, 0.0684, 0.0684, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.4883, 0.0640, 0.0645, 0.0640, 0.0640, 0.0640, 0.0640, 0.0640, 0.0640, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.4590, 0.0601, 0.0605, 0.0603, 0.0601, 0.0601, 0.0601, 0.0601, 0.0601, 0.0601, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.4336, 0.0566, 0.0571, 0.0569, 0.0566, 0.0566, 0.0566, 0.0566, 0.0566, 0.0566, 0.0566, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.4102, 0.0537, 0.0540, 0.0537, 0.0535, 0.0537, 0.0537, 0.0537, 0.0537, 0.0537, 0.0535, 0.0537, 0.0000, 0.0000, 0.0000],
        [0.3887, 0.0510, 0.0513, 0.0510, 0.0508, 0.0508, 0.0510, 0.0510, 0.0510, 0.0510, 0.0508, 0.0510, 0.0510, 0.0000, 0.0000],
        [0.3691, 0.0486, 0.0488, 0.0486, 0.0483, 0.0486, 0.0486, 0.0486, 0.0486, 0.0486, 0.0483, 0.0486, 0.0486, 0.0486, 0.0000],
        [0.3516, 0.0464, 0.0466, 0.0464, 0.0461, 0.0461, 0.0461, 0.0464, 0.0461, 0.0461, 0.0461, 0.0461, 0.0464, 0.0464, 0.0464]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[-0.0251,  0.0136, -0.0128,  ...,  0.0215, -0.0282, -0.0396],
        [ 0.0089, -0.0198,  0.0231,  ...,  0.0295, -0.0167, -0.0060],
        [ 0.0189,  0.0076,  0.0224,  ..., -0.0016,  0.0245,  0.0231],
        ...,
        [-0.0075,  0.0171,  0.0180,  ...,  0.0061, -0.0223, -0.0107],
        [ 0.0029, -0.0279,  0.0083,  ...,  0.0095, -0.0109, -0.0040],
        [-0.0118, -0.0187,  0.0174,  ...,  0.0038,  0.0270, -0.0290]], device='cuda:0', requires_grad=True)
K: tensor([     1.0312,     -0.0427,     -0.5625,     -0.1523,      0.1885,     -1.0859,      0.1504,     -0.5977,      0.3203,     -0.5938,     -0.5781,      0.0918,     -0.8203,     -0.1387,     -0.7148,      0.3496,      0.4980,      0.0352,     -1.1484,      0.2090,     -0.6992,      0.6484,
            -0.3066,      0.7617,     -0.0352,      0.0747,     -0.3750,     -0.2119,     -0.0007,      0.0439,     -0.7461,     -0.2490,      1.2969,      0.4180,      1.1406,     -0.6445,      0.0752,     -0.1660,      0.1182,     -0.0889,      0.7578,      0.2969,      0.5742,     -1.1328,
            -0.0830,      0.0116,     -0.3633,      0.2988,      0.5625,     -0.2236,      0.1807,      0.0034,     -0.2461,      0.1533,      1.2734,     -0.9297,     -0.2188,     -0.7578,      0.2832,      0.7656,      1.3125,      0.7500,      0.2910,     -0.2949], device='cuda:0',
       dtype=torch.bfloat16)
Qweights
tensor([[-0.0043,  0.0223, -0.0092,  ..., -0.0127,  0.0019, -0.0174],
        [-0.0011, -0.0104,  0.0018,  ..., -0.0081, -0.0154,  0.0102],
        [-0.0227,  0.0239, -0.0229,  ..., -0.0184,  0.0012,  0.0037],
        ...,
        [-0.0365,  0.0212, -0.0227,  ..., -0.0109,  0.0372,  0.0234],
        [-0.0118,  0.0054, -0.0457,  ...,  0.0167,  0.0055,  0.0117],
        [ 0.0112, -0.0140,  0.0110,  ..., -0.0388,  0.0020, -0.0225]], device='cuda:0', requires_grad=True)
Q: tensor([-1.2656, -0.5430,  0.9844,  0.9805,  0.1235,  0.9102, -0.0659,  0.9258, -0.6172,  0.8047,  0.0498,  0.4023,  0.4355, -0.1318,  0.7500, -0.4824, -0.1709, -0.1553,  1.3047, -0.5234, -0.0281, -0.8633,  0.6289, -0.0850, -0.6250, -0.0058,  0.7070, -0.9844, -0.1562, -0.1846,  0.3945,  1.0938,
        -0.9883, -0.7031, -1.2188, -0.0302, -0.9453,  0.1602,  0.1514, -0.0405, -0.3477,  0.0625, -0.6562,  0.8359,  0.2988, -0.1514,  0.0564, -0.8828,  0.0167, -0.4004,  0.0972,  0.3359, -0.1768,  0.0908, -1.1328,  0.0649, -0.2031,  0.6055, -0.2344,  0.0957, -0.2002, -0.9648, -0.0164,  0.9375],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000, -2.0156, -2.0000, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156],
        [ 0.0000, -2.0156, -2.0156, -2.0156, -2.0312, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156, -2.0156],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0156, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312],
        [ 0.0000, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312, -2.0312]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.8457],
        [0.7340],
        [0.6502],
        [0.5833],
        [0.5296],
        [0.4845],
        [0.4479],
        [0.4152],
        [0.3873],
        [0.3630],
        [0.3416],
        [0.3223],
        [0.3053],
        [0.2900]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0183, 0.9805, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0091, 0.4980, 0.4922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0068, 0.3535, 0.3359, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0060, 0.2852, 0.2637, 0.2354, 0.2100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0056, 0.2451, 0.2227, 0.1963, 0.1738, 0.1562, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0055, 0.2188, 0.1953, 0.1709, 0.1504, 0.1357, 0.1235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0053, 0.1992, 0.1758, 0.1533, 0.1348, 0.1206, 0.1099, 0.1016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0052, 0.1846, 0.1611, 0.1396, 0.1221, 0.1094, 0.0996, 0.0923, 0.0864, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0052, 0.1719, 0.1494, 0.1289, 0.1128, 0.1006, 0.0918, 0.0845, 0.0796, 0.0752, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0051, 0.1621, 0.1406, 0.1201, 0.1050, 0.0938, 0.0854, 0.0786, 0.0737, 0.0698, 0.0664, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0050, 0.1533, 0.1318, 0.1133, 0.0986, 0.0879, 0.0801, 0.0737, 0.0693, 0.0654, 0.0620, 0.0596, 0.0000, 0.0000, 0.0000],
        [0.0049, 0.1465, 0.1250, 0.1069, 0.0928, 0.0830, 0.0752, 0.0698, 0.0654, 0.0615, 0.0586, 0.0562, 0.0540, 0.0000, 0.0000],
        [0.0049, 0.1396, 0.1196, 0.1016, 0.0884, 0.0786, 0.0713, 0.0659, 0.0618, 0.0583, 0.0554, 0.0532, 0.0510, 0.0496, 0.0000],
        [0.0048, 0.1338, 0.1143, 0.0972, 0.0840, 0.0752, 0.0679, 0.0630, 0.0588, 0.0557, 0.0527, 0.0505, 0.0488, 0.0474, 0.0459]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[ 0.0327,  0.0338, -0.0257,  ...,  0.0062, -0.0074, -0.0049],
        [-0.0130,  0.0246, -0.0014,  ..., -0.0291,  0.0168, -0.0338],
        [ 0.0051,  0.0259,  0.0232,  ..., -0.0037, -0.0183,  0.0138],
        ...,
        [ 0.0165,  0.0124, -0.0111,  ...,  0.0207, -0.0149, -0.0023],
        [-0.0236, -0.0061, -0.0107,  ..., -0.0117,  0.0071, -0.0283],
        [-0.0120, -0.0147, -0.0265,  ..., -0.0049, -0.0151, -0.0065]], device='cuda:0', requires_grad=True)
K: tensor([-0.7148,  0.1416, -0.3086, -0.6953,  0.3477, -1.3828, -0.5625, -1.7500, -2.0312, -0.9609,  0.5469,  0.4316, -0.4492, -1.3672,  0.2383,  0.0659,  0.1113, -0.4297, -1.1797,  0.5547,  0.6484,  0.6836,  0.3008, -0.8203,  0.2168, -0.2852,  0.5742, -0.3438,  1.6562, -0.4980, -0.1797,  0.0142,
        -1.1953,  1.0781, -1.3125, -0.7422, -1.0469,  1.0469, -0.4512, -0.4629,  0.4727,  1.0469, -0.9570, -0.1865,  0.1787,  1.5000, -0.3828, -0.0967,  0.4863,  0.4746,  0.1465, -2.0938,  0.1104, -0.4824,  0.6367,  0.0591, -1.0469,  0.8203,  0.6484,  1.1641,  0.3691, -0.0708, -0.1631, -1.3750],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[ 0.0159, -0.0262, -0.0021,  ..., -0.0052, -0.0376, -0.0012],
        [ 0.0297,  0.0042, -0.0027,  ...,  0.0198,  0.0075,  0.0259],
        [ 0.0139, -0.0197, -0.0150,  ...,  0.0158,  0.0207, -0.0320],
        ...,
        [-0.0044, -0.0248,  0.0072,  ...,  0.0139,  0.0381,  0.0118],
        [-0.0081, -0.0337,  0.0424,  ..., -0.0043, -0.0044, -0.0272],
        [-0.0319, -0.0005, -0.0504,  ...,  0.0149,  0.0039, -0.0023]], device='cuda:0', requires_grad=True)
Q: tensor([ 0.8086, -0.1533, -1.5078,  0.0034,  0.2988, -0.3203,  0.5352, -1.0547, -1.2266,  1.3906,  2.0312, -0.7578, -0.9688, -0.6445, -1.1406, -0.3574,  0.0825, -1.0156, -0.3008,  0.6875,  0.4980,  0.5000, -0.4922,  0.0417, -0.3926, -0.4102,  0.6914,  0.6680,  0.7227, -1.7969, -0.4355, -0.8750,
        -0.8125,  0.7305, -0.7969, -1.6797,  1.3906, -0.3047, -0.7500,  0.4180,  0.0124,  0.4805, -0.7227, -1.2031,  1.0000, -0.3125, -0.5938,  0.5742, -0.8008,  1.2578,  0.3965, -0.3477,  2.2656,  0.3105, -0.0386, -1.3594, -1.9609,  0.6055, -0.5742,  0.9844, -0.7109, -0.4473,  1.4531, -1.0938],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 3.9844, 4.0312, 4.0000, 3.9375, 3.8750, 3.8125, 3.7656, 3.7188, 3.6719, 3.6406, 3.6094, 3.5781, 3.5625, 3.5312],
        [0.0000, 4.0000, 4.0000, 3.9219, 3.8281, 3.7500, 3.6875, 3.6250, 3.5625, 3.5156, 3.4844, 3.4375, 3.4062, 3.3750, 3.3594],
        [0.0000, 3.9375, 3.8906, 3.7969, 3.6875, 3.5938, 3.5156, 3.4531, 3.3906, 3.3438, 3.2969, 3.2656, 3.2188, 3.1875, 3.1719],
        [0.0000, 3.8594, 3.7812, 3.6562, 3.5469, 3.4531, 3.3594, 3.2969, 3.2344, 3.1719, 3.1250, 3.0938, 3.0469, 3.0312, 3.0000],
        [0.0000, 3.7656, 3.6719, 3.5469, 3.4219, 3.3281, 3.2344, 3.1562, 3.0938, 3.0469, 2.9844, 2.9531, 2.9062, 2.8906, 2.8594],
        [0.0000, 3.6875, 3.5781, 3.4375, 3.3125, 3.2031, 3.1250, 3.0469, 2.9844, 2.9219, 2.8750, 2.8281, 2.7969, 2.7656, 2.7344],
        [0.0000, 3.6250, 3.5000, 3.3594, 3.2344, 3.1250, 3.0312, 2.9531, 2.8906, 2.8281, 2.7812, 2.7344, 2.7031, 2.6719, 2.6406],
        [0.0000, 3.5625, 3.4219, 3.2812, 3.1562, 3.0469, 2.9531, 2.8750, 2.7969, 2.7500, 2.7031, 2.6562, 2.6094, 2.5938, 2.5625],
        [0.0000, 3.5156, 3.3750, 3.2188, 3.0781, 2.9688, 2.8750, 2.7969, 2.7344, 2.6719, 2.6250, 2.5938, 2.5469, 2.5156, 2.4844],
        [0.0000, 3.4688, 3.3125, 3.1719, 3.0312, 2.9219, 2.8281, 2.7344, 2.6719, 2.6250, 2.5625, 2.5312, 2.4844, 2.4531, 2.4219],
        [0.0000, 3.4219, 3.2656, 3.1094, 2.9844, 2.8594, 2.7656, 2.6875, 2.6250, 2.5625, 2.5156, 2.4688, 2.4375, 2.4062, 2.3750],
        [0.0000, 3.3906, 3.2344, 3.0781, 2.9375, 2.8125, 2.7188, 2.6406, 2.5781, 2.5156, 2.4688, 2.4219, 2.3906, 2.3594, 2.3281],
        [0.0000, 3.3594, 3.2031, 3.0312, 2.8906, 2.7812, 2.6875, 2.6094, 2.5312, 2.4844, 2.4219, 2.3906, 2.3438, 2.3125, 2.2812],
        [0.0000, 3.3281, 3.1562, 3.0000, 2.8594, 2.7344, 2.6406, 2.5625, 2.5000, 2.4375, 2.3906, 2.3438, 2.3125, 2.2812, 2.2500]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.0484],
        [0.0233],
        [0.0165],
        [0.0137],
        [0.0122],
        [0.0112],
        [0.0105],
        [0.0100],
        [0.0096],
        [0.0092],
        [0.0090],
        [0.0087],
        [0.0084],
        [0.0082]], device='cuda:0')
rank 0 sample 0: A Poem for you! Roses are red, Potatoes are 
------
		(,:0.0471,:0.0486,:0.0486,:0.0486,:0.0486,:0.0486,:0.0471,:0.0471)
,
------
		(,:0.0486,:0.0486,:0.0486,:0.0486,:0.0486,:0.0471,:0.0471,:0.0486)
,,,,,,,,,,,,,,,
@ 550 train 7.6289 , allloss: 7.6546, dt: 1700.80ms, fracRes: 0.2140, norm(attn): 0.1621, norm(output): 0.7383, norm(x): 0.7933, norm(y): 1.0025, norm:0.5747, tok/sec: 77064.79, flops:80.89, batch-reuse:1
@ 551 train 7.6313 , allloss: 7.6597, dt: 1316.98ms, fracRes: 0.2112, norm(attn): 0.1621, norm(output): 0.7500, norm(x): 0.8030, norm(y): 1.0025, norm:0.4688, tok/sec: 99524.68, flops:104.46, batch-reuse:1
@ 552 train 7.5351 , allloss: 7.5703, dt: 1323.13ms, fracRes: 0.2089, norm(attn): 0.1621, norm(output): 0.7539, norm(x): 0.8019, norm(y): 1.0025, norm:0.4193, tok/sec: 99062.33, flops:103.98, batch-reuse:1
@ 553 train 7.6557 , allloss: 7.7001, dt: 1331.60ms, fracRes: 0.2074, norm(attn): 0.1631, norm(output): 0.7539, norm(x): 0.8018, norm(y): 1.0025, norm:0.6559, tok/sec: 98432.23, flops:103.32, batch-reuse:1
@ 554 train 7.6365 , allloss: 7.6868, dt: 1319.33ms, fracRes: 0.2153, norm(attn): 0.1572, norm(output): 0.7383, norm(x): 0.7806, norm(y): 1.0024, norm:1.0886, tok/sec: 99347.31, flops:104.28, batch-reuse:1
@ 555 train 7.5814 , allloss: 7.6236, dt: 1315.47ms, fracRes: 0.2144, norm(attn): 0.1592, norm(output): 0.7461, norm(x): 0.7921, norm(y): 1.0024, norm:0.5588, tok/sec: 99638.55, flops:104.58, batch-reuse:1
@ 556 train 7.5669 , allloss: 7.6070, dt: 1317.53ms, fracRes: 0.2115, norm(attn): 0.1611, norm(output): 0.7500, norm(x): 0.7998, norm(y): 1.0025, norm:0.6125, tok/sec: 99483.04, flops:104.42, batch-reuse:1
@ 557 train 7.6115 , allloss: 7.6496, dt: 1293.75ms, fracRes: 0.2126, norm(attn): 0.1611, norm(output): 0.7461, norm(x): 0.7942, norm(y): 1.0025, norm:0.5657, tok/sec: 101311.78, flops:106.34, batch-reuse:1
@ 558 train 7.6960 , allloss: 7.7308, dt: 1304.57ms, fracRes: 0.2140, norm(attn): 0.1611, norm(output): 0.7461, norm(x): 0.7964, norm(y): 1.0025, norm:0.5671, tok/sec: 100471.33, flops:105.46, batch-reuse:1
@ 559 train 7.8100 , allloss: 7.8501, dt: 1306.66ms, fracRes: 0.2130, norm(attn): 0.1611, norm(output): 0.7539, norm(x): 0.8064, norm(y): 1.0025, norm:0.6821, tok/sec: 100310.90, flops:105.29, batch-reuse:1
@ 560 train 7.7288 , allloss: 7.7664, dt: 1321.31ms, fracRes: 0.2142, norm(attn): 0.1602, norm(output): 0.7539, norm(x): 0.8046, norm(y): 1.0025, norm:0.5548, tok/sec: 99198.39, flops:104.12, batch-reuse:1
@ 561 train 7.8203 , allloss: 7.8618, dt: 1351.29ms, fracRes: 0.2115, norm(attn): 0.1621, norm(output): 0.7578, norm(x): 0.8088, norm(y): 1.0025, norm:0.5209, tok/sec: 96997.92, flops:101.81, batch-reuse:1
@ 562 train 7.6703 , allloss: 7.7109, dt: 1343.18ms, fracRes: 0.2105, norm(attn): 0.1641, norm(output): 0.7617, norm(x): 0.8163, norm(y): 1.0025, norm:0.3831, tok/sec: 97583.44, flops:102.43, batch-reuse:1
@ 563 train 7.7679 , allloss: 7.8025, dt: 1332.64ms, fracRes: 0.2107, norm(attn): 0.1641, norm(output): 0.7539, norm(x): 0.8050, norm(y): 1.0025, norm:0.6716, tok/sec: 98355.13, flops:103.24, batch-reuse:1
@ 564 train 7.6488 , allloss: 7.6864, dt: 1321.78ms, fracRes: 0.2094, norm(attn): 0.1660, norm(output): 0.7695, norm(x): 0.8222, norm(y): 1.0025, norm:0.4805, tok/sec: 99163.29, flops:104.08, batch-reuse:1
@ 565 train 7.5385 , allloss: 7.5714, dt: 1344.71ms, fracRes: 0.2112, norm(attn): 0.1660, norm(output): 0.7617, norm(x): 0.8113, norm(y): 1.0025, norm:1.0112, tok/sec: 97472.27, flops:102.31, batch-reuse:1
@ 566 train 7.7133 , allloss: 7.7462, dt: 1325.99ms, fracRes: 0.2074, norm(attn): 0.1670, norm(output): 0.7656, norm(x): 0.8212, norm(y): 1.0025, norm:0.3678, tok/sec: 98848.62, flops:103.75, batch-reuse:1
@ 567 train 7.7150 , allloss: 7.7465, dt: 1326.40ms, fracRes: 0.2057, norm(attn): 0.1680, norm(output): 0.7695, norm(x): 0.8253, norm(y): 1.0026, norm:0.4579, tok/sec: 98817.74, flops:103.72, batch-reuse:1
@ 568 train 7.7571 , allloss: 7.7885, dt: 1343.44ms, fracRes: 0.2042, norm(attn): 0.1699, norm(output): 0.7695, norm(x): 0.8311, norm(y): 1.0026, norm:0.3935, tok/sec: 97564.73, flops:102.41, batch-reuse:1
@ 569 train 7.7025 , allloss: 7.7334, dt: 1320.94ms, fracRes: 0.2034, norm(attn): 0.1709, norm(output): 0.7734, norm(x): 0.8290, norm(y): 1.0026, norm:0.3966, tok/sec: 99226.25, flops:104.15, batch-reuse:1
@ 570 train 7.7136 , allloss: 7.7486, dt: 1299.59ms, fracRes: 0.2033, norm(attn): 0.1709, norm(output): 0.7734, norm(x): 0.8323, norm(y): 1.0026, norm:0.4505, tok/sec: 100856.51, flops:105.86, batch-reuse:1
@ 571 train 7.6785 , allloss: 7.7085, dt: 1323.66ms, fracRes: 0.2033, norm(attn): 0.1709, norm(output): 0.7695, norm(x): 0.8301, norm(y): 1.0026, norm:0.3845, tok/sec: 99022.18, flops:103.94, batch-reuse:1
@ 572 train 7.6655 , allloss: 7.6960, dt: 1316.36ms, fracRes: 0.2036, norm(attn): 0.1719, norm(output): 0.7773, norm(x): 0.8331, norm(y): 1.0026, norm:0.4199, tok/sec: 99571.29, flops:104.51, batch-reuse:1
@ 573 train 7.6744 , allloss: 7.6991, dt: 1319.89ms, fracRes: 0.2037, norm(attn): 0.1719, norm(output): 0.7656, norm(x): 0.8277, norm(y): 1.0026, norm:0.4434, tok/sec: 99305.60, flops:104.23, batch-reuse:1
@ 574 train 7.6813 , allloss: 7.7097, dt: 1313.28ms, fracRes: 0.2036, norm(attn): 0.1719, norm(output): 0.7734, norm(x): 0.8306, norm(y): 1.0026, norm:0.4359, tok/sec: 99805.33, flops:104.76, batch-reuse:1
@ 575 train 7.6368 , allloss: 7.6588, dt: 1289.10ms, fracRes: 0.2035, norm(attn): 0.1719, norm(output): 0.7656, norm(x): 0.8290, norm(y): 1.0026, norm:0.3903, tok/sec: 101676.99, flops:106.72, batch-reuse:1
@ 576 train 7.5906 , allloss: 7.6159, dt: 1301.13ms, fracRes: 0.2034, norm(attn): 0.1729, norm(output): 0.7734, norm(x): 0.8340, norm(y): 1.0026, norm:0.3503, tok/sec: 100737.03, flops:105.74, batch-reuse:1
@ 577 train 7.7119 , allloss: 7.7400, dt: 1308.11ms, fracRes: 0.2029, norm(attn): 0.1729, norm(output): 0.7812, norm(x): 0.8384, norm(y): 1.0026, norm:0.5022, tok/sec: 100199.84, flops:105.17, batch-reuse:1
@ 578 train 7.6606 , allloss: 7.6847, dt: 1310.85ms, fracRes: 0.2032, norm(attn): 0.1738, norm(output): 0.7695, norm(x): 0.8351, norm(y): 1.0026, norm:0.4182, tok/sec: 99990.33, flops:104.95, batch-reuse:1
@ 579 train 7.6656 , allloss: 7.6952, dt: 1356.06ms, fracRes: 0.2034, norm(attn): 0.1738, norm(output): 0.7695, norm(x): 0.8369, norm(y): 1.0026, norm:0.4452, tok/sec: 96656.28, flops:101.45, batch-reuse:1
@ 580 train 7.7194 , allloss: 7.7495, dt: 1327.11ms, fracRes: 0.2030, norm(attn): 0.1768, norm(output): 0.7734, norm(x): 0.8366, norm(y): 1.0026, norm:0.4562, tok/sec: 98765.11, flops:103.67, batch-reuse:1
@ 581 train 7.6338 , allloss: 7.6634, dt: 1319.26ms, fracRes: 0.2036, norm(attn): 0.1758, norm(output): 0.7734, norm(x): 0.8358, norm(y): 1.0026, norm:0.4830, tok/sec: 99352.75, flops:104.28, batch-reuse:1
@ 582 train 7.6912 , allloss: 7.7215, dt: 1352.30ms, fracRes: 0.2037, norm(attn): 0.1768, norm(output): 0.7852, norm(x): 0.8367, norm(y): 1.0026, norm:0.3828, tok/sec: 96925.40, flops:101.74, batch-reuse:1
@ 583 train 7.6452 , allloss: 7.6716, dt: 1355.44ms, fracRes: 0.2041, norm(attn): 0.1768, norm(output): 0.7695, norm(x): 0.8353, norm(y): 1.0026, norm:0.4681, tok/sec: 96700.74, flops:101.50, batch-reuse:1
@ 584 train 7.6838 , allloss: 7.7138, dt: 1302.36ms, fracRes: 0.2046, norm(attn): 0.1768, norm(output): 0.7695, norm(x): 0.8334, norm(y): 1.0026, norm:0.2842, tok/sec: 100642.00, flops:105.64, batch-reuse:1
@ 585 train 7.6562 , allloss: 7.6873, dt: 1293.89ms, fracRes: 0.2047, norm(attn): 0.1768, norm(output): 0.7695, norm(x): 0.8318, norm(y): 1.0026, norm:0.2781, tok/sec: 101300.52, flops:106.33, batch-reuse:1
@ 586 train 7.6864 , allloss: 7.7171, dt: 1301.06ms, fracRes: 0.2052, norm(attn): 0.1758, norm(output): 0.7695, norm(x): 0.8306, norm(y): 1.0026, norm:0.3041, tok/sec: 100742.70, flops:105.74, batch-reuse:1
@ 587 train 7.6826 , allloss: 7.7135, dt: 1306.84ms, fracRes: 0.2055, norm(attn): 0.1748, norm(output): 0.7656, norm(x): 0.8298, norm(y): 1.0026, norm:0.2712, tok/sec: 100296.74, flops:105.27, batch-reuse:1
@ 588 train 7.6817 , allloss: 7.7148, dt: 1316.51ms, fracRes: 0.2058, norm(attn): 0.1748, norm(output): 0.7656, norm(x): 0.8296, norm(y): 1.0026, norm:0.3030, tok/sec: 99560.55, flops:104.50, batch-reuse:1
@ 589 train 7.6892 , allloss: 7.7193, dt: 1326.40ms, fracRes: 0.2061, norm(attn): 0.1768, norm(output): 0.7656, norm(x): 0.8277, norm(y): 1.0026, norm:0.3986, tok/sec: 98818.19, flops:103.72, batch-reuse:1
@ 590 train 7.6918 , allloss: 7.7238, dt: 1290.22ms, fracRes: 0.2061, norm(attn): 0.1768, norm(output): 0.7656, norm(x): 0.8276, norm(y): 1.0026, norm:0.3282, tok/sec: 101588.80, flops:106.63, batch-reuse:1
@ 591 train 7.6414 , allloss: 7.6733, dt: 1285.76ms, fracRes: 0.2060, norm(attn): 0.1768, norm(output): 0.7656, norm(x): 0.8279, norm(y): 1.0026, norm:0.2682, tok/sec: 101941.01, flops:107.00, batch-reuse:1
@ 592 train 7.6358 , allloss: 7.6693, dt: 1299.38ms, fracRes: 0.2062, norm(attn): 0.1758, norm(output): 0.7695, norm(x): 0.8284, norm(y): 1.0026, norm:0.5127, tok/sec: 100872.39, flops:105.88, batch-reuse:1
@ 593 train 7.6407 , allloss: 7.6729, dt: 1302.15ms, fracRes: 0.2064, norm(attn): 0.1768, norm(output): 0.7695, norm(x): 0.8298, norm(y): 1.0026, norm:0.3259, tok/sec: 100658.33, flops:105.65, batch-reuse:1
@ 594 train 7.7660 , allloss: 7.8009, dt: 1292.71ms, fracRes: 0.2064, norm(attn): 0.1768, norm(output): 0.7656, norm(x): 0.8290, norm(y): 1.0026, norm:0.5674, tok/sec: 101393.57, flops:106.43, batch-reuse:1
@ 595 train 7.6518 , allloss: 7.6739, dt: 1304.08ms, fracRes: 0.2072, norm(attn): 0.1768, norm(output): 0.7656, norm(x): 0.8285, norm(y): 1.0026, norm:0.3263, tok/sec: 100509.34, flops:105.50, batch-reuse:1
@ 596 train 7.6379 , allloss: 7.6641, dt: 1297.32ms, fracRes: 0.2080, norm(attn): 0.1768, norm(output): 0.7695, norm(x): 0.8290, norm(y): 1.0026, norm:0.3167, tok/sec: 101033.24, flops:106.05, batch-reuse:1
@ 597 train 7.6147 , allloss: 7.6392, dt: 1313.79ms, fracRes: 0.2088, norm(attn): 0.1768, norm(output): 0.7695, norm(x): 0.8293, norm(y): 1.0026, norm:0.3772, tok/sec: 99766.01, flops:104.72, batch-reuse:1
@ 598 train 7.7228 , allloss: 7.7470, dt: 1326.39ms, fracRes: 0.2089, norm(attn): 0.1768, norm(output): 0.7734, norm(x): 0.8308, norm(y): 1.0026, norm:0.3544, tok/sec: 98818.35, flops:103.72, batch-reuse:1
@ 599 train 7.7558 , allloss: 7.7789, dt: 1312.24ms, fracRes: 0.2096, norm(attn): 0.1768, norm(output): 0.7695, norm(x): 0.8313, norm(y): 1.0026, norm:0.4714, tok/sec: 99884.12, flops:104.84, batch-reuse:1
@ 600 train 7.6622 , allloss: 7.6856, dt: 1345.66ms, fracRes: 0.2103, norm(attn): 0.1768, norm(output): 0.7734, norm(x): 0.8319, norm(y): 1.0026, norm:0.2365, tok/sec: 97403.33, flops:102.24, batch-reuse:1
@ 601 train 7.7135 , allloss: 7.7337, dt: 1336.00ms, fracRes: 0.2109, norm(attn): 0.1768, norm(output): 0.7734, norm(x): 0.8331, norm(y): 1.0026, norm:0.3951, tok/sec: 98107.47, flops:102.98, batch-reuse:1
@ 602 train 7.7030 , allloss: 7.7255, dt: 1314.09ms, fracRes: 0.2112, norm(attn): 0.1768, norm(output): 0.7930, norm(x): 0.8336, norm(y): 1.0026, norm:0.3293, tok/sec: 99743.89, flops:104.69, batch-reuse:1
@ 603 train 7.6714 , allloss: 7.6916, dt: 1307.07ms, fracRes: 0.2116, norm(attn): 0.1768, norm(output): 0.7930, norm(x): 0.8356, norm(y): 1.0026, norm:0.3628, tok/sec: 100279.10, flops:105.26, batch-reuse:1
@ 604 train 7.6140 , allloss: 7.6366, dt: 1318.14ms, fracRes: 0.2121, norm(attn): 0.1768, norm(output): 0.7891, norm(x): 0.8367, norm(y): 1.0026, norm:0.3034, tok/sec: 99436.72, flops:104.37, batch-reuse:1
@ 605 train 7.6641 , allloss: 7.6863, dt: 1287.33ms, fracRes: 0.2128, norm(attn): 0.1768, norm(output): 0.7930, norm(x): 0.8375, norm(y): 1.0026, norm:0.3745, tok/sec: 101816.68, flops:106.87, batch-reuse:1
@ 606 train 7.6641 , allloss: 7.6820, dt: 1329.92ms, fracRes: 0.2132, norm(attn): 0.1768, norm(output): 0.7930, norm(x): 0.8385, norm(y): 1.0026, norm:0.3390, tok/sec: 98556.65, flops:103.45, batch-reuse:1
@ 607 train 7.6569 , allloss: 7.6766, dt: 1338.27ms, fracRes: 0.2139, norm(attn): 0.1768, norm(output): 0.7969, norm(x): 0.8391, norm(y): 1.0026, norm:0.3137, tok/sec: 97941.64, flops:102.80, batch-reuse:1
@ 608 train 7.5932 , allloss: 7.6146, dt: 1323.69ms, fracRes: 0.2147, norm(attn): 0.1768, norm(output): 0.7969, norm(x): 0.8382, norm(y): 1.0026, norm:0.3001, tok/sec: 99020.36, flops:103.93, batch-reuse:1
@ 609 train 7.6152 , allloss: 7.6378, dt: 1308.08ms, fracRes: 0.2152, norm(attn): 0.1748, norm(output): 0.7930, norm(x): 0.8375, norm(y): 1.0026, norm:0.2890, tok/sec: 100201.73, flops:105.17, batch-reuse:1
@ 610 train 7.7621 , allloss: 7.7855, dt: 1302.79ms, fracRes: 0.2152, norm(attn): 0.1748, norm(output): 0.7930, norm(x): 0.8405, norm(y): 1.0026, norm:0.3845, tok/sec: 100608.83, flops:105.60, batch-reuse:1
@ 611 train 7.6889 , allloss: 7.7146, dt: 1314.32ms, fracRes: 0.2155, norm(attn): 0.1738, norm(output): 0.7969, norm(x): 0.8408, norm(y): 1.0026, norm:0.3449, tok/sec: 99726.40, flops:104.68, batch-reuse:1
@ 612 train 7.7483 , allloss: 7.7753, dt: 1311.75ms, fracRes: 0.2153, norm(attn): 0.1738, norm(output): 0.8008, norm(x): 0.8437, norm(y): 1.0026, norm:0.3157, tok/sec: 99921.30, flops:104.88, batch-reuse:1
@ 613 train 7.7950 , allloss: 7.8203, dt: 1296.73ms, fracRes: 0.2153, norm(attn): 0.1758, norm(output): 0.8086, norm(x): 0.8482, norm(y): 1.0026, norm:0.4313, tok/sec: 101078.73, flops:106.10, batch-reuse:1
@ 614 train 7.7158 , allloss: 7.7429, dt: 1303.14ms, fracRes: 0.2160, norm(attn): 0.1758, norm(output): 0.8086, norm(x): 0.8482, norm(y): 1.0026, norm:0.3490, tok/sec: 100582.01, flops:105.57, batch-reuse:1
@ 615 train 7.6779 , allloss: 7.7052, dt: 1303.89ms, fracRes: 0.2167, norm(attn): 0.1748, norm(output): 0.8086, norm(x): 0.8490, norm(y): 1.0026, norm:0.4076, tok/sec: 100524.11, flops:105.51, batch-reuse:1
@ 616 train 7.7147 , allloss: 7.7409, dt: 1302.64ms, fracRes: 0.2170, norm(attn): 0.1768, norm(output): 0.8086, norm(x): 0.8499, norm(y): 1.0026, norm:0.3242, tok/sec: 100620.13, flops:105.61, batch-reuse:1
@ 617 train 7.5678 , allloss: 7.5896, dt: 1304.97ms, fracRes: 0.2181, norm(attn): 0.1758, norm(output): 0.8086, norm(x): 0.8494, norm(y): 1.0026, norm:0.3250, tok/sec: 100440.79, flops:105.43, batch-reuse:1
@ 618 train 7.6518 , allloss: 7.6744, dt: 1309.23ms, fracRes: 0.2192, norm(attn): 0.1748, norm(output): 0.8086, norm(x): 0.8501, norm(y): 1.0026, norm:0.4317, tok/sec: 100113.64, flops:105.08, batch-reuse:1
@ 619 train 7.6666 , allloss: 7.6864, dt: 1336.99ms, fracRes: 0.2209, norm(attn): 0.1738, norm(output): 0.8086, norm(x): 0.8486, norm(y): 1.0026, norm:0.3213, tok/sec: 98035.27, flops:102.90, batch-reuse:1
@ 620 train 7.6481 , allloss: 7.6683, dt: 1337.13ms, fracRes: 0.2227, norm(attn): 0.1758, norm(output): 0.8086, norm(x): 0.8482, norm(y): 1.0026, norm:0.3305, tok/sec: 98024.94, flops:102.89, batch-reuse:1
@ 621 train 7.6494 , allloss: 7.6718, dt: 1281.52ms, fracRes: 0.2242, norm(attn): 0.1748, norm(output): 0.8086, norm(x): 0.8499, norm(y): 1.0026, norm:0.4551, tok/sec: 102278.74, flops:107.36, batch-reuse:1
@ 622 train 7.5915 , allloss: 7.6140, dt: 1309.61ms, fracRes: 0.2250, norm(attn): 0.1768, norm(output): 0.8086, norm(x): 0.8524, norm(y): 1.0026, norm:0.3807, tok/sec: 100084.49, flops:105.05, batch-reuse:1
@ 623 train 7.6308 , allloss: 7.6573, dt: 1323.53ms, fracRes: 0.2259, norm(attn): 0.1758, norm(output): 0.8086, norm(x): 0.8568, norm(y): 1.0026, norm:0.3076, tok/sec: 99032.17, flops:103.95, batch-reuse:1
@ 624 train 7.7111 , allloss: 7.7381, dt: 1334.98ms, fracRes: 0.2264, norm(attn): 0.1768, norm(output): 0.8125, norm(x): 0.8599, norm(y): 1.0026, norm:0.3793, tok/sec: 98182.92, flops:103.06, batch-reuse:1
@ 625 train 7.7644 , allloss: 7.7932, dt: 1328.88ms, fracRes: 0.2275, norm(attn): 0.1768, norm(output): 0.8125, norm(x): 0.8639, norm(y): 1.0026, norm:0.3649, tok/sec: 98633.70, flops:103.53, batch-reuse:1
@ 626 train 7.6634 , allloss: 7.6896, dt: 1347.00ms, fracRes: 0.2295, norm(attn): 0.1768, norm(output): 0.8125, norm(x): 0.8626, norm(y): 1.0026, norm:0.3060, tok/sec: 97306.86, flops:102.14, batch-reuse:1
@ 627 train 7.6958 , allloss: 7.7261, dt: 1345.90ms, fracRes: 0.2327, norm(attn): 0.1768, norm(output): 0.8164, norm(x): 0.8642, norm(y): 1.0026, norm:0.5024, tok/sec: 97386.05, flops:102.22, batch-reuse:1
@ 628 train 7.6879 , allloss: 7.7152, dt: 1332.70ms, fracRes: 0.2384, norm(attn): 0.1758, norm(output): 0.8086, norm(x): 0.8567, norm(y): 1.0026, norm:0.4030, tok/sec: 98350.42, flops:103.23, batch-reuse:1
@ 629 train 7.7209 , allloss: 7.7468, dt: 1296.75ms, fracRes: 0.2446, norm(attn): 0.1729, norm(output): 0.8047, norm(x): 0.8545, norm(y): 1.0026, norm:0.3099, tok/sec: 101077.49, flops:106.09, batch-reuse:1
@ 630 train 7.8123 , allloss: 7.8410, dt: 1287.91ms, fracRes: 0.2506, norm(attn): 0.1729, norm(output): 0.8008, norm(x): 0.8547, norm(y): 1.0026, norm:0.4469, tok/sec: 101770.81, flops:106.82, batch-reuse:1
@ 631 train 7.7010 , allloss: 7.7227, dt: 1294.99ms, fracRes: 0.2558, norm(attn): 0.1719, norm(output): 0.7930, norm(x): 0.8524, norm(y): 1.0026, norm:0.2729, tok/sec: 101214.94, flops:106.24, batch-reuse:1
@ 632 train 7.8039 , allloss: 7.8272, dt: 1318.21ms, fracRes: 0.2588, norm(attn): 0.1719, norm(output): 0.7891, norm(x): 0.8554, norm(y): 1.0026, norm:0.4984, tok/sec: 99432.17, flops:104.37, batch-reuse:1
@ 633 train 7.7625 , allloss: 7.7828, dt: 1299.73ms, fracRes: 0.2608, norm(attn): 0.1719, norm(output): 0.7734, norm(x): 0.8529, norm(y): 1.0026, norm:0.4169, tok/sec: 100845.78, flops:105.85, batch-reuse:1
@ 634 train 7.5745 , allloss: 7.5963, dt: 1317.58ms, fracRes: 0.2615, norm(attn): 0.1719, norm(output): 0.7656, norm(x): 0.8516, norm(y): 1.0026, norm:0.4336, tok/sec: 99479.62, flops:104.42, batch-reuse:1
@ 635 train 7.7430 , allloss: 7.7662, dt: 1321.25ms, fracRes: 0.2618, norm(attn): 0.1719, norm(output): 0.7578, norm(x): 0.8546, norm(y): 1.0026, norm:0.3470, tok/sec: 99203.26, flops:104.13, batch-reuse:1
@ 636 train 7.7438 , allloss: 7.7692, dt: 1312.51ms, fracRes: 0.2618, norm(attn): 0.1719, norm(output): 0.7539, norm(x): 0.8583, norm(y): 1.0026, norm:0.3001, tok/sec: 99863.82, flops:104.82, batch-reuse:1
@ 637 train 7.6163 , allloss: 7.6373, dt: 1344.49ms, fracRes: 0.2617, norm(attn): 0.1719, norm(output): 0.7539, norm(x): 0.8589, norm(y): 1.0026, norm:0.3512, tok/sec: 97487.92, flops:102.33, batch-reuse:1
@ 638 train 7.6190 , allloss: 7.6376, dt: 1322.39ms, fracRes: 0.2615, norm(attn): 0.1719, norm(output): 0.7539, norm(x): 0.8626, norm(y): 1.0026, norm:0.3460, tok/sec: 99117.79, flops:104.04, batch-reuse:1
@ 639 train 7.7089 , allloss: 7.7324, dt: 1303.92ms, fracRes: 0.2616, norm(attn): 0.1729, norm(output): 0.7617, norm(x): 0.8716, norm(y): 1.0026, norm:0.4127, tok/sec: 100521.21, flops:105.51, batch-reuse:1
@ 640 train 7.6457 , allloss: 7.6660, dt: 1310.32ms, fracRes: 0.2613, norm(attn): 0.1729, norm(output): 0.7578, norm(x): 0.8727, norm(y): 1.0027, norm:0.3178, tok/sec: 100030.73, flops:105.00, batch-reuse:1
@ 641 train 7.7314 , allloss: 7.7534, dt: 1314.37ms, fracRes: 0.2614, norm(attn): 0.1729, norm(output): 0.7656, norm(x): 0.8805, norm(y): 1.0027, norm:0.4287, tok/sec: 99722.52, flops:104.67, batch-reuse:1
@ 642 train 7.5932 , allloss: 7.6128, dt: 1291.82ms, fracRes: 0.2613, norm(attn): 0.1729, norm(output): 0.7617, norm(x): 0.8810, norm(y): 1.0027, norm:0.5106, tok/sec: 101463.20, flops:106.50, batch-reuse:1
@ 643 train 7.6144 , allloss: 7.6363, dt: 1309.94ms, fracRes: 0.2612, norm(attn): 0.1729, norm(output): 0.7617, norm(x): 0.8808, norm(y): 1.0027, norm:0.5070, tok/sec: 100059.52, flops:105.03, batch-reuse:1
@ 644 train 7.7801 , allloss: 7.8043, dt: 1311.06ms, fracRes: 0.2614, norm(attn): 0.1729, norm(output): 0.7617, norm(x): 0.8825, norm(y): 1.0027, norm:0.4044, tok/sec: 99973.93, flops:104.94, batch-reuse:1
@ 645 train 7.7213 , allloss: 7.7419, dt: 1313.49ms, fracRes: 0.2615, norm(attn): 0.1729, norm(output): 0.7617, norm(x): 0.8790, norm(y): 1.0027, norm:0.3342, tok/sec: 99788.81, flops:104.74, batch-reuse:1
@ 646 train 7.6176 , allloss: 7.6366, dt: 1296.86ms, fracRes: 0.2619, norm(attn): 0.1729, norm(output): 0.7656, norm(x): 0.8788, norm(y): 1.0027, norm:0.3113, tok/sec: 101068.96, flops:106.09, batch-reuse:1
@ 647 train 7.6581 , allloss: 7.6817, dt: 1322.12ms, fracRes: 0.2622, norm(attn): 0.1729, norm(output): 0.7617, norm(x): 0.8778, norm(y): 1.0027, norm:0.3482, tok/sec: 99137.81, flops:104.06, batch-reuse:1
@ 648 train 7.5652 , allloss: 7.5876, dt: 1328.08ms, fracRes: 0.2625, norm(attn): 0.1729, norm(output): 0.7578, norm(x): 0.8786, norm(y): 1.0027, norm:0.3907, tok/sec: 98693.21, flops:103.59, batch-reuse:1
@ 649 train 7.6880 , allloss: 7.7155, dt: 1347.26ms, fracRes: 0.2629, norm(attn): 0.1729, norm(output): 0.7656, norm(x): 0.8859, norm(y): 1.0027, norm:0.3707, tok/sec: 97288.14, flops:102.12, batch-reuse:1
@ 650 train 7.5992 , allloss: 7.6233, dt: 1339.10ms, fracRes: 0.2631, norm(attn): 0.1738, norm(output): 0.7656, norm(x): 0.8858, norm(y): 1.0027, norm:0.4157, tok/sec: 97880.83, flops:102.74, batch-reuse:1
@ 651 train 7.6499 , allloss: 7.6787, dt: 1338.04ms, fracRes: 0.2636, norm(attn): 0.1729, norm(output): 0.7852, norm(x): 0.8944, norm(y): 1.0027, norm:0.3491, tok/sec: 97958.18, flops:102.82, batch-reuse:1
@ 652 train 7.5577 , allloss: 7.5861, dt: 1311.46ms, fracRes: 0.2642, norm(attn): 0.1729, norm(output): 0.7891, norm(x): 0.8948, norm(y): 1.0027, norm:0.3371, tok/sec: 99943.57, flops:104.90, batch-reuse:1
@ 653 train 7.5921 , allloss: 7.6207, dt: 1322.04ms, fracRes: 0.2645, norm(attn): 0.1738, norm(output): 0.7930, norm(x): 0.9006, norm(y): 1.0027, norm:0.4115, tok/sec: 99144.12, flops:104.06, batch-reuse:1
@ 654 train 7.6447 , allloss: 7.6754, dt: 1295.44ms, fracRes: 0.2650, norm(attn): 0.1738, norm(output): 0.8008, norm(x): 0.9073, norm(y): 1.0028, norm:0.3979, tok/sec: 101179.54, flops:106.20, batch-reuse:1
@ 655 train 7.6414 , allloss: 7.6718, dt: 1306.66ms, fracRes: 0.2664, norm(attn): 0.1758, norm(output): 0.8008, norm(x): 0.9085, norm(y): 1.0028, norm:0.4121, tok/sec: 100310.96, flops:105.29, batch-reuse:1
@ 656 train 7.6333 , allloss: 7.6649, dt: 1318.63ms, fracRes: 0.2668, norm(attn): 0.1738, norm(output): 0.8086, norm(x): 0.9076, norm(y): 1.0028, norm:0.4831, tok/sec: 99400.48, flops:104.33, batch-reuse:1
@ 657 train 7.6259 , allloss: 7.6554, dt: 1333.95ms, fracRes: 0.2671, norm(attn): 0.1768, norm(output): 0.8125, norm(x): 0.9160, norm(y): 1.0028, norm:0.3793, tok/sec: 98258.66, flops:103.14, batch-reuse:1
@ 658 train 7.7087 , allloss: 7.7400, dt: 1314.32ms, fracRes: 0.2673, norm(attn): 0.1768, norm(output): 0.8125, norm(x): 0.9236, norm(y): 1.0028, norm:0.3507, tok/sec: 99726.21, flops:104.68, batch-reuse:1
@ 659 train 7.6393 , allloss: 7.6684, dt: 1320.21ms, fracRes: 0.2669, norm(attn): 0.1768, norm(output): 0.8125, norm(x): 0.9235, norm(y): 1.0028, norm:0.3351, tok/sec: 99281.21, flops:104.21, batch-reuse:1
@ 660 train 7.6993 , allloss: 7.7267, dt: 1326.90ms, fracRes: 0.2674, norm(attn): 0.1777, norm(output): 0.8164, norm(x): 0.9297, norm(y): 1.0028, norm:0.3415, tok/sec: 98780.58, flops:103.68, batch-reuse:1
@ 661 train 7.6559 , allloss: 7.6829, dt: 1315.77ms, fracRes: 0.2695, norm(attn): 0.1768, norm(output): 0.8164, norm(x): 0.9271, norm(y): 1.0028, norm:0.2937, tok/sec: 99615.86, flops:104.56, batch-reuse:1
@ 662 train 7.6874 , allloss: 7.7164, dt: 1287.16ms, fracRes: 0.2705, norm(attn): 0.1768, norm(output): 0.8203, norm(x): 0.9264, norm(y): 1.0028, norm:0.3168, tok/sec: 101830.56, flops:106.88, batch-reuse:1
@ 663 train 7.6651 , allloss: 7.6929, dt: 1299.62ms, fracRes: 0.2709, norm(attn): 0.1768, norm(output): 0.8164, norm(x): 0.9238, norm(y): 1.0028, norm:0.2989, tok/sec: 100854.27, flops:105.86, batch-reuse:1
@ 664 train 7.6063 , allloss: 7.6333, dt: 1298.22ms, fracRes: 0.2717, norm(attn): 0.1768, norm(output): 0.8125, norm(x): 0.9227, norm(y): 1.0028, norm:0.3431, tok/sec: 100963.23, flops:105.97, batch-reuse:1
@ 665 train 7.6426 , allloss: 7.6732, dt: 1314.94ms, fracRes: 0.2724, norm(attn): 0.1777, norm(output): 0.8281, norm(x): 0.9332, norm(y): 1.0029, norm:0.4116, tok/sec: 99678.88, flops:104.63, batch-reuse:1
@ 666 train 7.5142 , allloss: 7.5443, dt: 1340.16ms, fracRes: 0.2727, norm(attn): 0.1807, norm(output): 0.8281, norm(x): 0.9340, norm(y): 1.0029, norm:0.8059, tok/sec: 97803.48, flops:102.66, batch-reuse:1
@ 667 train 7.5194 , allloss: 7.5472, dt: 1285.72ms, fracRes: 0.2741, norm(attn): 0.1816, norm(output): 0.8398, norm(x): 0.9431, norm(y): 1.0029, norm:0.7442, tok/sec: 101944.18, flops:107.00, batch-reuse:1
@ 668 train 7.6386 , allloss: 7.6692, dt: 1319.55ms, fracRes: 0.2751, norm(attn): 0.1816, norm(output): 0.8633, norm(x): 0.9554, norm(y): 1.0029, norm:0.4513, tok/sec: 99330.74, flops:104.26, batch-reuse:1
@ 669 train 7.6103 , allloss: 7.6426, dt: 1341.69ms, fracRes: 0.2769, norm(attn): 0.1816, norm(output): 0.8750, norm(x): 0.9674, norm(y): 1.0029, norm:0.4403, tok/sec: 97691.71, flops:102.54, batch-reuse:1
@ 670 train 7.7001 , allloss: 7.7315, dt: 1324.74ms, fracRes: 0.2792, norm(attn): 0.1797, norm(output): 0.8789, norm(x): 0.9739, norm(y): 1.0029, norm:0.4525, tok/sec: 98941.56, flops:103.85, batch-reuse:1
@ 671 train 7.5781 , allloss: 7.6101, dt: 1323.09ms, fracRes: 0.2828, norm(attn): 0.1768, norm(output): 0.8750, norm(x): 0.9736, norm(y): 1.0029, norm:0.4104, tok/sec: 99065.40, flops:103.98, batch-reuse:1
@ 672 train 7.6221 , allloss: 7.6544, dt: 1315.24ms, fracRes: 0.2852, norm(attn): 0.1768, norm(output): 0.8789, norm(x): 0.9772, norm(y): 1.0029, norm:0.3555, tok/sec: 99656.29, flops:104.60, batch-reuse:1
@ 673 train 7.6070 , allloss: 7.6377, dt: 1326.76ms, fracRes: 0.2895, norm(attn): 0.1758, norm(output): 0.8828, norm(x): 0.9768, norm(y): 1.0029, norm:0.4762, tok/sec: 98791.16, flops:103.69, batch-reuse:1
@ 674 train 7.6561 , allloss: 7.6865, dt: 1341.91ms, fracRes: 0.2970, norm(attn): 0.1729, norm(output): 0.8789, norm(x): 0.9661, norm(y): 1.0029, norm:0.3591, tok/sec: 97675.74, flops:102.52, batch-reuse:1
@ 675 train 7.5202 , allloss: 7.5509, dt: 1332.81ms, fracRes: 0.3088, norm(attn): 0.1709, norm(output): 0.8789, norm(x): 0.9597, norm(y): 1.0030, norm:0.3529, tok/sec: 98342.64, flops:103.22, batch-reuse:1
@ 676 train 7.6546 , allloss: 7.6844, dt: 1293.95ms, fracRes: 0.3230, norm(attn): 0.1660, norm(output): 0.8789, norm(x): 0.9369, norm(y): 1.0030, norm:0.3643, tok/sec: 101295.65, flops:106.32, batch-reuse:1
@ 677 train 7.7684 , allloss: 7.7995, dt: 1317.07ms, fracRes: 0.3318, norm(attn): 0.1611, norm(output): 0.8828, norm(x): 0.9225, norm(y): 1.0030, norm:0.5272, tok/sec: 99517.58, flops:104.46, batch-reuse:1
@ 678 train 7.5678 , allloss: 7.5970, dt: 1320.86ms, fracRes: 0.3370, norm(attn): 0.1582, norm(output): 0.8711, norm(x): 0.9038, norm(y): 1.0030, norm:0.3504, tok/sec: 99232.36, flops:104.16, batch-reuse:1
@ 679 train 7.6507 , allloss: 7.6779, dt: 1296.68ms, fracRes: 0.3392, norm(attn): 0.1572, norm(output): 0.8594, norm(x): 0.8893, norm(y): 1.0030, norm:0.4166, tok/sec: 101083.01, flops:106.10, batch-reuse:1
@ 680 train 7.6252 , allloss: 7.6529, dt: 1307.22ms, fracRes: 0.3391, norm(attn): 0.1562, norm(output): 0.8242, norm(x): 0.8593, norm(y): 1.0030, norm:0.4071, tok/sec: 100268.02, flops:105.24, batch-reuse:1
@ 681 train 7.6283 , allloss: 7.6556, dt: 1326.73ms, fracRes: 0.3290, norm(attn): 0.1514, norm(output): 0.8047, norm(x): 0.8182, norm(y): 1.0030, norm:0.3385, tok/sec: 98793.43, flops:103.70, batch-reuse:1
@ 682 train 7.6611 , allloss: 7.7335, dt: 1330.84ms, fracRes: 0.3226, norm(attn): 0.1465, norm(output): 0.7734, norm(x): 0.8030, norm(y): 1.0030, norm:0.9948, tok/sec: 98488.29, flops:103.38, batch-reuse:1
@ 683 train 12.5517 , allloss: 16.0353, dt: 1329.48ms, fracRes: 0.2587, norm(attn): 0.1050, norm(output): 0.5273, norm(x): 0.5827, norm(y): 1.0025, norm:7767.3408, tok/sec: 98589.28, flops:103.48, batch-reuse:1
@ 684 train 7.5914 , allloss: 7.7015, dt: 1317.33ms, fracRes: 0.3381, norm(attn): 0.1611, norm(output): 0.7461, norm(x): 0.8467, norm(y): 1.0029, norm:1.1994, tok/sec: 99498.07, flops:104.44, batch-reuse:1
@ 685 train 7.6519 , allloss: 7.8843, dt: 1325.90ms, fracRes: 0.3366, norm(attn): 0.1709, norm(output): 0.7500, norm(x): 0.8622, norm(y): 1.0028, norm:2.1285, tok/sec: 98854.81, flops:103.76, batch-reuse:1
@ 686 train 7.7189 , allloss: 7.8747, dt: 1321.32ms, fracRes: 0.3384, norm(attn): 0.1729, norm(output): 0.7539, norm(x): 0.8846, norm(y): 1.0029, norm:1.6429, tok/sec: 99197.93, flops:104.12, batch-reuse:1
@ 687 train 7.6379 , allloss: 7.7433, dt: 1315.38ms, fracRes: 0.3390, norm(attn): 0.1816, norm(output): 0.7578, norm(x): 0.9062, norm(y): 1.0029, norm:1.0856, tok/sec: 99645.72, flops:104.59, batch-reuse:1
@ 688 train 7.6778 , allloss: 7.7603, dt: 1303.77ms, fracRes: 0.3393, norm(attn): 0.1855, norm(output): 0.7695, norm(x): 0.9211, norm(y): 1.0030, norm:0.7422, tok/sec: 100533.45, flops:105.52, batch-reuse:1
@ 689 train 7.6258 , allloss: 7.7063, dt: 1287.44ms, fracRes: 0.3396, norm(attn): 0.1865, norm(output): 0.7734, norm(x): 0.9342, norm(y): 1.0030, norm:0.7462, tok/sec: 101808.08, flops:106.86, batch-reuse:1
@ 690 train 7.6635 , allloss: 7.7403, dt: 1298.38ms, fracRes: 0.3403, norm(attn): 0.1885, norm(output): 0.7969, norm(x): 0.9489, norm(y): 1.0031, norm:0.5920, tok/sec: 100950.27, flops:105.96, batch-reuse:1
@ 691 train 7.6438 , allloss: 7.7099, dt: 1319.68ms, fracRes: 0.3417, norm(attn): 0.1895, norm(output): 0.8047, norm(x): 0.9571, norm(y): 1.0032, norm:0.4459, tok/sec: 99321.03, flops:104.25, batch-reuse:1
@ 692 train 7.5760 , allloss: 7.6302, dt: 1294.87ms, fracRes: 0.3453, norm(attn): 0.1924, norm(output): 0.8125, norm(x): 0.9680, norm(y): 1.0033, norm:0.4627, tok/sec: 101224.35, flops:106.25, batch-reuse:1
@ 693 train 7.6271 , allloss: 7.6777, dt: 1288.16ms, fracRes: 0.3483, norm(attn): 0.1973, norm(output): 0.8164, norm(x): 0.9747, norm(y): 1.0034, norm:0.4077, tok/sec: 101751.14, flops:106.80, batch-reuse:1
@ 694 train 7.5749 , allloss: 7.6222, dt: 1314.02ms, fracRes: 0.3527, norm(attn): 0.1992, norm(output): 0.8164, norm(x): 0.9796, norm(y): 1.0034, norm:0.4347, tok/sec: 99748.65, flops:104.70, batch-reuse:1
@ 695 train 7.6469 , allloss: 7.6923, dt: 1307.15ms, fracRes: 0.3557, norm(attn): 0.2012, norm(output): 0.8320, norm(x): 0.9906, norm(y): 1.0034, norm:0.3854, tok/sec: 100273.30, flops:105.25, batch-reuse:1
@ 696 train 7.5504 , allloss: 7.5902, dt: 1288.38ms, fracRes: 0.3605, norm(attn): 0.2021, norm(output): 0.8594, norm(x): 0.9968, norm(y): 1.0035, norm:0.3694, tok/sec: 101733.91, flops:106.78, batch-reuse:1
@ 697 train 7.5838 , allloss: 7.6223, dt: 1290.74ms, fracRes: 0.3628, norm(attn): 0.2021, norm(output): 0.8633, norm(x): 1.0009, norm(y): 1.0035, norm:0.3807, tok/sec: 101547.99, flops:106.59, batch-reuse:1
@ 698 train 7.6499 , allloss: 7.6856, dt: 1306.37ms, fracRes: 0.3641, norm(attn): 0.2021, norm(output): 0.8750, norm(x): 1.0164, norm(y): 1.0035, norm:0.3279, tok/sec: 100333.28, flops:105.31, batch-reuse:1
@ 699 train 7.6820 , allloss: 7.7174, dt: 1331.86ms, fracRes: 0.3662, norm(attn): 0.2031, norm(output): 0.8828, norm(x): 1.0271, norm(y): 1.0035, norm:0.3746, tok/sec: 98412.53, flops:103.30, batch-reuse:1
@ 700 train 7.6327 , allloss: 7.6677, dt: 1310.80ms, fracRes: 0.3682, norm(attn): 0.2031, norm(output): 0.8984, norm(x): 1.0395, norm(y): 1.0035, norm:0.3400, tok/sec: 99993.78, flops:104.96, batch-reuse:1
@ 701 train 7.7295 , allloss: 7.7637, dt: 1348.60ms, fracRes: 0.3682, norm(attn): 0.2031, norm(output): 0.9219, norm(x): 1.0547, norm(y): 1.0035, norm:0.3987, tok/sec: 97191.41, flops:102.02, batch-reuse:1
@ 702 train 7.7094 , allloss: 7.7407, dt: 1351.63ms, fracRes: 0.3685, norm(attn): 0.2031, norm(output): 0.9336, norm(x): 1.0677, norm(y): 1.0035, norm:0.3965, tok/sec: 96973.35, flops:101.79, batch-reuse:1
@ 703 train 7.6470 , allloss: 7.6752, dt: 1349.39ms, fracRes: 0.3691, norm(attn): 0.2031, norm(output): 0.9375, norm(x): 1.0784, norm(y): 1.0035, norm:0.3034, tok/sec: 97133.92, flops:101.95, batch-reuse:1
@ 704 train 7.5830 , allloss: 7.6078, dt: 1345.59ms, fracRes: 0.3696, norm(attn): 0.2031, norm(output): 0.9414, norm(x): 1.0899, norm(y): 1.0035, norm:0.3023, tok/sec: 97408.25, flops:102.24, batch-reuse:1
@ 705 train 7.5973 , allloss: 7.6222, dt: 1345.96ms, fracRes: 0.3705, norm(attn): 0.2041, norm(output): 0.9531, norm(x): 1.1026, norm(y): 1.0035, norm:0.3290, tok/sec: 97381.65, flops:102.21, batch-reuse:1
@ 706 train 7.6419 , allloss: 7.6670, dt: 1295.55ms, fracRes: 0.3719, norm(attn): 0.2031, norm(output): 0.9844, norm(x): 1.1114, norm(y): 1.0035, norm:0.3124, tok/sec: 101170.92, flops:106.19, batch-reuse:1
@ 707 train 7.6536 , allloss: 7.6783, dt: 1307.62ms, fracRes: 0.3726, norm(attn): 0.2041, norm(output): 0.9961, norm(x): 1.1208, norm(y): 1.0035, norm:0.2834, tok/sec: 100236.94, flops:105.21, batch-reuse:1
@ 708 train 7.6253 , allloss: 7.6494, dt: 1308.37ms, fracRes: 0.3736, norm(attn): 0.2041, norm(output): 0.9961, norm(x): 1.1269, norm(y): 1.0035, norm:0.3070, tok/sec: 100179.60, flops:105.15, batch-reuse:1
@ 709 train 7.6143 , allloss: 7.6377, dt: 1305.37ms, fracRes: 0.3750, norm(attn): 0.2041, norm(output): 1.0000, norm(x): 1.1316, norm(y): 1.0035, norm:0.2898, tok/sec: 100409.65, flops:105.39, batch-reuse:1
@ 710 train 7.6782 , allloss: 7.7015, dt: 1306.02ms, fracRes: 0.3752, norm(attn): 0.2041, norm(output): 1.0078, norm(x): 1.1351, norm(y): 1.0035, norm:0.4806, tok/sec: 100359.63, flops:105.34, batch-reuse:1
@ 711 train 7.6853 , allloss: 7.7091, dt: 1312.42ms, fracRes: 0.3765, norm(attn): 0.2041, norm(output): 1.0078, norm(x): 1.1354, norm(y): 1.0035, norm:0.2833, tok/sec: 99870.84, flops:104.83, batch-reuse:1
@ 712 train 7.5800 , allloss: 7.6020, dt: 1310.49ms, fracRes: 0.3755, norm(attn): 0.2041, norm(output): 1.0078, norm(x): 1.1385, norm(y): 1.0035, norm:0.3010, tok/sec: 100017.50, flops:104.98, batch-reuse:1
@ 713 train 7.6898 , allloss: 7.7140, dt: 1289.31ms, fracRes: 0.3751, norm(attn): 0.2041, norm(output): 1.0078, norm(x): 1.1416, norm(y): 1.0035, norm:0.3244, tok/sec: 101660.71, flops:106.71, batch-reuse:1
@ 714 train 7.5680 , allloss: 7.5909, dt: 1294.12ms, fracRes: 0.3753, norm(attn): 0.2051, norm(output): 1.0078, norm(x): 1.1418, norm(y): 1.0035, norm:0.3354, tok/sec: 101282.81, flops:106.31, batch-reuse:1
@ 715 train 7.5795 , allloss: 7.6018, dt: 1299.44ms, fracRes: 0.3751, norm(attn): 0.2070, norm(output): 1.0078, norm(x): 1.1435, norm(y): 1.0035, norm:0.3309, tok/sec: 100868.31, flops:105.87, batch-reuse:1
@ 716 train 7.6174 , allloss: 7.6397, dt: 1315.58ms, fracRes: 0.3757, norm(attn): 0.2070, norm(output): 1.0078, norm(x): 1.1459, norm(y): 1.0035, norm:0.2764, tok/sec: 99630.82, flops:104.58, batch-reuse:1
@ 717 train 7.5096 , allloss: 7.5318, dt: 1297.53ms, fracRes: 0.3757, norm(attn): 0.2080, norm(output): 1.0156, norm(x): 1.1488, norm(y): 1.0035, norm:0.4290, tok/sec: 101016.29, flops:106.03, batch-reuse:1
@ 718 train 7.6482 , allloss: 7.6690, dt: 1315.70ms, fracRes: 0.3769, norm(attn): 0.2080, norm(output): 1.0156, norm(x): 1.1492, norm(y): 1.0035, norm:0.3393, tok/sec: 99621.71, flops:104.57, batch-reuse:1
@ 719 train 7.5847 , allloss: 7.6047, dt: 1322.19ms, fracRes: 0.3774, norm(attn): 0.2090, norm(output): 1.0234, norm(x): 1.1512, norm(y): 1.0035, norm:0.2730, tok/sec: 99132.26, flops:104.05, batch-reuse:1
@ 720 train 7.5716 , allloss: 7.5911, dt: 1320.63ms, fracRes: 0.3771, norm(attn): 0.2100, norm(output): 1.0469, norm(x): 1.1553, norm(y): 1.0035, norm:0.2680, tok/sec: 99249.94, flops:104.18, batch-reuse:1
@ 721 train 7.5419 , allloss: 7.5610, dt: 1345.64ms, fracRes: 0.3768, norm(attn): 0.2119, norm(output): 1.0391, norm(x): 1.1581, norm(y): 1.0035, norm:0.4487, tok/sec: 97405.22, flops:102.24, batch-reuse:1
@ 722 train 7.6235 , allloss: 7.6424, dt: 1316.83ms, fracRes: 0.3770, norm(attn): 0.2129, norm(output): 1.0547, norm(x): 1.1615, norm(y): 1.0035, norm:0.3102, tok/sec: 99535.80, flops:104.48, batch-reuse:1
@ 723 train 7.6210 , allloss: 7.6386, dt: 1286.35ms, fracRes: 0.3776, norm(attn): 0.2148, norm(output): 1.0469, norm(x): 1.1633, norm(y): 1.0035, norm:0.3592, tok/sec: 101894.15, flops:106.95, batch-reuse:1
@ 724 train 7.6211 , allloss: 7.6384, dt: 1314.37ms, fracRes: 0.3787, norm(attn): 0.2148, norm(output): 1.0547, norm(x): 1.1635, norm(y): 1.0035, norm:0.2829, tok/sec: 99722.23, flops:104.67, batch-reuse:1
@ 725 train 7.6050 , allloss: 7.6222, dt: 1307.53ms, fracRes: 0.3797, norm(attn): 0.2148, norm(output): 1.0469, norm(x): 1.1645, norm(y): 1.0035, norm:0.3140, tok/sec: 100243.76, flops:105.22, batch-reuse:1
@ 726 train 7.6424 , allloss: 7.6607, dt: 1299.05ms, fracRes: 0.3786, norm(attn): 0.2148, norm(output): 1.0547, norm(x): 1.1686, norm(y): 1.0035, norm:0.3903, tok/sec: 100898.32, flops:105.91, batch-reuse:1
@ 727 train 7.6418 , allloss: 7.6608, dt: 1315.37ms, fracRes: 0.3786, norm(attn): 0.2148, norm(output): 1.0547, norm(x): 1.1695, norm(y): 1.0035, norm:0.2852, tok/sec: 99646.61, flops:104.59, batch-reuse:1
@ 728 train 7.6425 , allloss: 7.6628, dt: 1322.65ms, fracRes: 0.3785, norm(attn): 0.2158, norm(output): 1.0547, norm(x): 1.1706, norm(y): 1.0035, norm:0.3488, tok/sec: 99097.69, flops:104.02, batch-reuse:1
@ 729 train 7.5964 , allloss: 7.6166, dt: 1327.35ms, fracRes: 0.3796, norm(attn): 0.2139, norm(output): 1.0547, norm(x): 1.1676, norm(y): 1.0035, norm:0.3150, tok/sec: 98747.37, flops:103.65, batch-reuse:1
@ 730 train 7.5967 , allloss: 7.6171, dt: 1289.51ms, fracRes: 0.3795, norm(attn): 0.2158, norm(output): 1.0547, norm(x): 1.1673, norm(y): 1.0035, norm:0.4160, tok/sec: 101644.98, flops:106.69, batch-reuse:1
@ 731 train 7.6496 , allloss: 7.6699, dt: 1305.80ms, fracRes: 0.3800, norm(attn): 0.2168, norm(output): 1.0547, norm(x): 1.1663, norm(y): 1.0035, norm:0.3266, tok/sec: 100376.51, flops:105.36, batch-reuse:1
@ 732 train 7.6087 , allloss: 7.6273, dt: 1314.48ms, fracRes: 0.3801, norm(attn): 0.2158, norm(output): 1.0547, norm(x): 1.1656, norm(y): 1.0035, norm:0.3705, tok/sec: 99714.20, flops:104.66, batch-reuse:1
@ 733 train 7.6287 , allloss: 7.6473, dt: 1290.49ms, fracRes: 0.3826, norm(attn): 0.2148, norm(output): 1.0547, norm(x): 1.1623, norm(y): 1.0035, norm:0.3312, tok/sec: 101567.29, flops:106.61, batch-reuse:1
@ 734 train 7.6325 , allloss: 7.6492, dt: 1304.00ms, fracRes: 0.3810, norm(attn): 0.2148, norm(output): 1.0625, norm(x): 1.1683, norm(y): 1.0035, norm:0.2737, tok/sec: 100515.38, flops:105.50, batch-reuse:1
@ 735 train 7.6129 , allloss: 7.6300, dt: 1314.73ms, fracRes: 0.3818, norm(attn): 0.2168, norm(output): 1.0625, norm(x): 1.1703, norm(y): 1.0035, norm:0.3261, tok/sec: 99695.02, flops:104.64, batch-reuse:1
@ 736 train 7.6793 , allloss: 7.6985, dt: 1304.51ms, fracRes: 0.3814, norm(attn): 0.2148, norm(output): 1.0625, norm(x): 1.1756, norm(y): 1.0035, norm:0.2530, tok/sec: 100476.14, flops:105.46, batch-reuse:1
@ 737 train 7.5855 , allloss: 7.6049, dt: 1291.39ms, fracRes: 0.3813, norm(attn): 0.2168, norm(output): 1.0703, norm(x): 1.1785, norm(y): 1.0035, norm:0.3250, tok/sec: 101497.05, flops:106.53, batch-reuse:1
@ 738 train 7.6359 , allloss: 7.6562, dt: 1297.78ms, fracRes: 0.3816, norm(attn): 0.2168, norm(output): 1.0703, norm(x): 1.1816, norm(y): 1.0035, norm:0.2985, tok/sec: 100996.90, flops:106.01, batch-reuse:1
@ 739 train 7.6481 , allloss: 7.6683, dt: 1314.56ms, fracRes: 0.3804, norm(attn): 0.2178, norm(output): 1.0703, norm(x): 1.1873, norm(y): 1.0035, norm:0.3115, tok/sec: 99707.77, flops:104.66, batch-reuse:1
@ 740 train 7.5472 , allloss: 7.5663, dt: 1322.01ms, fracRes: 0.3803, norm(attn): 0.2178, norm(output): 1.0703, norm(x): 1.1888, norm(y): 1.0035, norm:0.3966, tok/sec: 99145.67, flops:104.07, batch-reuse:1
@ 741 train 7.6449 , allloss: 7.6640, dt: 1341.94ms, fracRes: 0.3806, norm(attn): 0.2178, norm(output): 1.0703, norm(x): 1.1897, norm(y): 1.0035, norm:0.3732, tok/sec: 97673.85, flops:102.52, batch-reuse:1
@ 742 train 7.7221 , allloss: 7.7422, dt: 1342.15ms, fracRes: 0.3794, norm(attn): 0.2188, norm(output): 1.0781, norm(x): 1.1914, norm(y): 1.0036, norm:0.3298, tok/sec: 97658.24, flops:102.51, batch-reuse:1
@ 743 train 7.7015 , allloss: 7.7223, dt: 1316.91ms, fracRes: 0.3801, norm(attn): 0.2188, norm(output): 1.0781, norm(x): 1.1875, norm(y): 1.0036, norm:0.6097, tok/sec: 99530.16, flops:104.47, batch-reuse:1
@ 744 train 7.6976 , allloss: 7.7196, dt: 1317.51ms, fracRes: 0.3803, norm(attn): 0.2188, norm(output): 1.0781, norm(x): 1.1878, norm(y): 1.0036, norm:0.3825, tok/sec: 99484.35, flops:104.42, batch-reuse:1
@ 745 train 7.6343 , allloss: 7.6554, dt: 1324.13ms, fracRes: 0.3819, norm(attn): 0.2178, norm(output): 1.0781, norm(x): 1.1834, norm(y): 1.0035, norm:0.3991, tok/sec: 98987.06, flops:103.90, batch-reuse:1
@ 746 train 7.6819 , allloss: 7.7029, dt: 1297.71ms, fracRes: 0.3805, norm(attn): 0.2188, norm(output): 1.0703, norm(x): 1.1857, norm(y): 1.0036, norm:0.3109, tok/sec: 101002.69, flops:106.02, batch-reuse:1
@ 747 train 7.6691 , allloss: 7.6898, dt: 1323.41ms, fracRes: 0.3810, norm(attn): 0.2188, norm(output): 1.0703, norm(x): 1.1839, norm(y): 1.0036, norm:0.2834, tok/sec: 99040.84, flops:103.96, batch-reuse:1
@ 748 train 7.6918 , allloss: 7.7125, dt: 1310.98ms, fracRes: 0.3813, norm(attn): 0.2188, norm(output): 1.0703, norm(x): 1.1858, norm(y): 1.0036, norm:0.2751, tok/sec: 99980.31, flops:104.94, batch-reuse:1
@ 749 train 7.8115 , allloss: 7.8322, dt: 1313.69ms, fracRes: 0.3806, norm(attn): 0.2178, norm(output): 1.0781, norm(x): 1.1890, norm(y): 1.0036, norm:0.4342, tok/sec: 99774.23, flops:104.73, batch-reuse:1
@ 750 train 7.6917 , allloss: 7.7112, dt: 1312.47ms, fracRes: 0.3797, norm(attn): 0.2188, norm(output): 1.0781, norm(x): 1.1926, norm(y): 1.0036, norm:0.2821, tok/sec: 99866.87, flops:104.82, batch-reuse:1
@ 751 train 7.6717 , allloss: 7.6930, dt: 1320.54ms, fracRes: 0.3784, norm(attn): 0.2188, norm(output): 1.0781, norm(x): 1.1953, norm(y): 1.0036, norm:0.3650, tok/sec: 99256.69, flops:104.18, batch-reuse:1
@ 752 train 7.6908 , allloss: 7.7134, dt: 1322.60ms, fracRes: 0.3780, norm(attn): 0.2188, norm(output): 1.0938, norm(x): 1.2017, norm(y): 1.0036, norm:0.2645, tok/sec: 99102.06, flops:104.02, batch-reuse:1
@ 753 train 7.6782 , allloss: 7.7041, dt: 1316.85ms, fracRes: 0.3777, norm(attn): 0.2188, norm(output): 1.1094, norm(x): 1.2048, norm(y): 1.0036, norm:0.3067, tok/sec: 99534.73, flops:104.47, batch-reuse:1
@ 754 train 7.6458 , allloss: 7.6713, dt: 1319.83ms, fracRes: 0.3783, norm(attn): 0.2188, norm(output): 1.1094, norm(x): 1.2072, norm(y): 1.0036, norm:0.3654, tok/sec: 99310.05, flops:104.24, batch-reuse:1
@ 755 train 7.7233 , allloss: 7.7488, dt: 1316.83ms, fracRes: 0.3780, norm(attn): 0.2188, norm(output): 1.1094, norm(x): 1.2127, norm(y): 1.0036, norm:0.3635, tok/sec: 99536.27, flops:104.48, batch-reuse:1
@ 756 train 7.6405 , allloss: 7.6617, dt: 1314.72ms, fracRes: 0.3774, norm(attn): 0.2188, norm(output): 1.1172, norm(x): 1.2160, norm(y): 1.0036, norm:0.3166, tok/sec: 99695.81, flops:104.64, batch-reuse:1
@ 757 train 7.6984 , allloss: 7.7195, dt: 1315.03ms, fracRes: 0.3781, norm(attn): 0.2197, norm(output): 1.1172, norm(x): 1.2179, norm(y): 1.0036, norm:0.3323, tok/sec: 99672.57, flops:104.62, batch-reuse:1
@ 758 train 7.6088 , allloss: 7.6305, dt: 1293.36ms, fracRes: 0.3788, norm(attn): 0.2197, norm(output): 1.1172, norm(x): 1.2239, norm(y): 1.0036, norm:0.4288, tok/sec: 101342.28, flops:106.37, batch-reuse:1
@ 759 train 7.6933 , allloss: 7.7171, dt: 1297.70ms, fracRes: 0.3819, norm(attn): 0.2188, norm(output): 1.1250, norm(x): 1.2229, norm(y): 1.0036, norm:0.3927, tok/sec: 101003.58, flops:106.02, batch-reuse:1
@ 760 train 7.6417 , allloss: 7.6630, dt: 1303.37ms, fracRes: 0.3797, norm(attn): 0.2197, norm(output): 1.1250, norm(x): 1.2312, norm(y): 1.0036, norm:0.3118, tok/sec: 100563.67, flops:105.55, batch-reuse:1
@ 761 train 7.6842 , allloss: 7.7043, dt: 1325.35ms, fracRes: 0.3802, norm(attn): 0.2197, norm(output): 1.1250, norm(x): 1.2353, norm(y): 1.0036, norm:0.2884, tok/sec: 98896.33, flops:103.80, batch-reuse:1
@ 762 train 7.6950 , allloss: 7.7165, dt: 1567.92ms, fracRes: 0.3808, norm(attn): 0.2197, norm(output): 1.1250, norm(x): 1.2349, norm(y): 1.0036, norm:0.3914, tok/sec: 83595.96, flops:87.74, batch-reuse:1
@ 763 train 7.6986 , allloss: 7.7208, dt: 1327.73ms, fracRes: 0.3808, norm(attn): 0.2197, norm(output): 1.1250, norm(x): 1.2345, norm(y): 1.0036, norm:0.3822, tok/sec: 98719.03, flops:103.62, batch-reuse:1
@ 764 train 7.6879 , allloss: 7.7087, dt: 1348.75ms, fracRes: 0.3810, norm(attn): 0.2207, norm(output): 1.1328, norm(x): 1.2373, norm(y): 1.0036, norm:0.3171, tok/sec: 97180.53, flops:102.00, batch-reuse:1
@ 765 train 7.6357 , allloss: 7.6563, dt: 1349.59ms, fracRes: 0.3823, norm(attn): 0.2197, norm(output): 1.1250, norm(x): 1.2343, norm(y): 1.0036, norm:0.4219, tok/sec: 97119.96, flops:101.94, batch-reuse:1
@ 766 train 7.6229 , allloss: 7.6458, dt: 1313.09ms, fracRes: 0.3830, norm(attn): 0.2197, norm(output): 1.1250, norm(x): 1.2336, norm(y): 1.0035, norm:0.3104, tok/sec: 99819.76, flops:104.77, batch-reuse:1
@ 767 train 7.6703 , allloss: 7.6950, dt: 1316.79ms, fracRes: 0.3863, norm(attn): 0.2197, norm(output): 1.1328, norm(x): 1.2316, norm(y): 1.0035, norm:0.2908, tok/sec: 99538.81, flops:104.48, batch-reuse:1
@ 768 train 7.7344 , allloss: 7.7619, dt: 1292.46ms, fracRes: 0.3886, norm(attn): 0.2188, norm(output): 1.1172, norm(x): 1.2224, norm(y): 1.0035, norm:0.3041, tok/sec: 101412.49, flops:106.45, batch-reuse:1
@ 769 train 7.6326 , allloss: 7.6615, dt: 1297.84ms, fracRes: 0.3922, norm(attn): 0.2178, norm(output): 1.1172, norm(x): 1.2143, norm(y): 1.0035, norm:0.3998, tok/sec: 100992.58, flops:106.01, batch-reuse:1
@ 770 train 7.6447 , allloss: 7.6748, dt: 1299.80ms, fracRes: 0.3921, norm(attn): 0.2178, norm(output): 1.1172, norm(x): 1.2134, norm(y): 1.0035, norm:0.3539, tok/sec: 100840.06, flops:105.84, batch-reuse:1
@ 771 train 7.5937 , allloss: 7.6252, dt: 1327.15ms, fracRes: 0.3948, norm(attn): 0.2168, norm(output): 1.1172, norm(x): 1.2026, norm(y): 1.0035, norm:0.3202, tok/sec: 98762.07, flops:103.66, batch-reuse:1
@ 772 train 7.6330 , allloss: 7.6631, dt: 1315.14ms, fracRes: 0.3930, norm(attn): 0.2178, norm(output): 1.1172, norm(x): 1.2089, norm(y): 1.0035, norm:0.3205, tok/sec: 99663.79, flops:104.61, batch-reuse:1
@ 773 train 7.7414 , allloss: 7.7718, dt: 1302.02ms, fracRes: 0.3961, norm(attn): 0.2148, norm(output): 1.0938, norm(x): 1.1897, norm(y): 1.0035, norm:0.3420, tok/sec: 100667.95, flops:105.66, batch-reuse:1
@ 774 train 7.6930 , allloss: 7.7204, dt: 1317.42ms, fracRes: 0.3945, norm(attn): 0.2168, norm(output): 1.1016, norm(x): 1.1966, norm(y): 1.0035, norm:0.4524, tok/sec: 99491.52, flops:104.43, batch-reuse:1
@ 775 train 7.7543 , allloss: 7.7820, dt: 1299.60ms, fracRes: 0.3936, norm(attn): 0.2158, norm(output): 1.0938, norm(x): 1.1911, norm(y): 1.0035, norm:0.3378, tok/sec: 100856.01, flops:105.86, batch-reuse:1
@ 776 train 7.5740 , allloss: 7.6014, dt: 1311.21ms, fracRes: 0.3941, norm(attn): 0.2168, norm(output): 1.0781, norm(x): 1.1822, norm(y): 1.0035, norm:0.4110, tok/sec: 99962.38, flops:104.92, batch-reuse:1
@ 777 train 7.6373 , allloss: 7.6624, dt: 1338.95ms, fracRes: 0.3933, norm(attn): 0.2178, norm(output): 1.0781, norm(x): 1.1922, norm(y): 1.0035, norm:0.3823, tok/sec: 97891.27, flops:102.75, batch-reuse:1
@ 778 train 7.6375 , allloss: 7.6615, dt: 1328.13ms, fracRes: 0.3944, norm(attn): 0.2178, norm(output): 1.0859, norm(x): 1.1877, norm(y): 1.0035, norm:0.2905, tok/sec: 98689.47, flops:103.59, batch-reuse:1
@ 779 train 7.6698 , allloss: 7.6945, dt: 1345.73ms, fracRes: 0.3971, norm(attn): 0.2168, norm(output): 1.0781, norm(x): 1.1846, norm(y): 1.0035, norm:0.3814, tok/sec: 97398.47, flops:102.23, batch-reuse:1
@ 780 train 7.6210 , allloss: 7.6433, dt: 1303.11ms, fracRes: 0.3975, norm(attn): 0.2178, norm(output): 1.0781, norm(x): 1.1907, norm(y): 1.0036, norm:0.4625, tok/sec: 100583.67, flops:105.58, batch-reuse:1
@ 781 train 7.6242 , allloss: 7.6458, dt: 1294.60ms, fracRes: 0.3998, norm(attn): 0.2178, norm(output): 1.0781, norm(x): 1.1907, norm(y): 1.0036, norm:0.2815, tok/sec: 101245.34, flops:106.27, batch-reuse:1
@ 782 train 7.6302 , allloss: 7.6530, dt: 1314.67ms, fracRes: 0.4011, norm(attn): 0.2168, norm(output): 1.0781, norm(x): 1.1838, norm(y): 1.0036, norm:0.4212, tok/sec: 99699.86, flops:104.65, batch-reuse:1
@ 783 train 7.6114 , allloss: 7.6325, dt: 1325.86ms, fracRes: 0.4001, norm(attn): 0.2178, norm(output): 1.1016, norm(x): 1.2014, norm(y): 1.0036, norm:0.3410, tok/sec: 98858.22, flops:103.76, batch-reuse:1
@ 784 train 7.6201 , allloss: 7.6421, dt: 1309.07ms, fracRes: 0.4013, norm(attn): 0.2178, norm(output): 1.1016, norm(x): 1.2032, norm(y): 1.0036, norm:0.4054, tok/sec: 100125.78, flops:105.10, batch-reuse:1
@ 785 train 7.6477 , allloss: 7.6707, dt: 1344.30ms, fracRes: 0.4013, norm(attn): 0.2178, norm(output): 1.0859, norm(x): 1.1949, norm(y): 1.0036, norm:0.3902, tok/sec: 97502.01, flops:102.34, batch-reuse:1
@ 786 train 7.6418 , allloss: 7.6638, dt: 1298.30ms, fracRes: 0.4005, norm(attn): 0.2188, norm(output): 1.1094, norm(x): 1.2080, norm(y): 1.0036, norm:0.3551, tok/sec: 100956.36, flops:105.97, batch-reuse:1
@ 787 train 7.6465 , allloss: 7.6689, dt: 1296.27ms, fracRes: 0.4013, norm(attn): 0.2188, norm(output): 1.1094, norm(x): 1.2081, norm(y): 1.0036, norm:0.3068, tok/sec: 101114.52, flops:106.13, batch-reuse:1
@ 788 train 7.6742 , allloss: 7.6963, dt: 1283.95ms, fracRes: 0.4030, norm(attn): 0.2178, norm(output): 1.0938, norm(x): 1.1993, norm(y): 1.0036, norm:0.3707, tok/sec: 102085.15, flops:107.15, batch-reuse:1
@ 789 train 7.6019 , allloss: 7.6224, dt: 1294.34ms, fracRes: 0.4027, norm(attn): 0.2188, norm(output): 1.1016, norm(x): 1.2064, norm(y): 1.0036, norm:0.3213, tok/sec: 101265.63, flops:106.29, batch-reuse:1
@ 790 train 7.6260 , allloss: 7.6446, dt: 1292.80ms, fracRes: 0.4026, norm(attn): 0.2188, norm(output): 1.0938, norm(x): 1.2078, norm(y): 1.0036, norm:0.3068, tok/sec: 101386.11, flops:106.42, batch-reuse:1
@ 791 train 7.7354 , allloss: 7.7549, dt: 1303.11ms, fracRes: 0.4030, norm(attn): 0.2188, norm(output): 1.1016, norm(x): 1.2064, norm(y): 1.0036, norm:0.3306, tok/sec: 100584.33, flops:105.58, batch-reuse:1
@ 792 train 7.6940 , allloss: 7.7126, dt: 1309.26ms, fracRes: 0.4011, norm(attn): 0.2197, norm(output): 1.1094, norm(x): 1.2069, norm(y): 1.0036, norm:0.2701, tok/sec: 100111.18, flops:105.08, batch-reuse:1
@ 793 train 7.6909 , allloss: 7.7099, dt: 1309.56ms, fracRes: 0.3994, norm(attn): 0.2197, norm(output): 1.1094, norm(x): 1.2128, norm(y): 1.0036, norm:0.2821, tok/sec: 100088.57, flops:105.06, batch-reuse:1
@ 794 train 7.7896 , allloss: 7.8088, dt: 1308.96ms, fracRes: 0.4000, norm(attn): 0.2197, norm(output): 1.1172, norm(x): 1.2141, norm(y): 1.0036, norm:0.3530, tok/sec: 100134.77, flops:105.10, batch-reuse:1
@ 795 train 7.6266 , allloss: 7.6471, dt: 1313.01ms, fracRes: 0.3991, norm(attn): 0.2197, norm(output): 1.1016, norm(x): 1.2049, norm(y): 1.0037, norm:0.2711, tok/sec: 99825.68, flops:104.78, batch-reuse:1
@ 796 train 7.6156 , allloss: 7.6339, dt: 1298.19ms, fracRes: 0.3983, norm(attn): 0.2207, norm(output): 1.1172, norm(x): 1.2188, norm(y): 1.0037, norm:0.2719, tok/sec: 100965.22, flops:105.98, batch-reuse:1
@ 797 train 7.6825 , allloss: 7.7023, dt: 1303.93ms, fracRes: 0.3980, norm(attn): 0.2217, norm(output): 1.0938, norm(x): 1.2080, norm(y): 1.0037, norm:0.2531, tok/sec: 100520.69, flops:105.51, batch-reuse:1
@ 798 train 7.6954 , allloss: 7.7167, dt: 1313.55ms, fracRes: 0.3985, norm(attn): 0.2227, norm(output): 1.1016, norm(x): 1.2040, norm(y): 1.0037, norm:0.2891, tok/sec: 99784.79, flops:104.74, batch-reuse:1
@ 799 train 7.6783 , allloss: 7.6985, dt: 1300.37ms, fracRes: 0.3987, norm(attn): 0.2227, norm(output): 1.1094, norm(x): 1.2082, norm(y): 1.0037, norm:0.2862, tok/sec: 100795.86, flops:105.80, batch-reuse:1
@ 800 train 7.6106 , allloss: 7.6297, dt: 1312.26ms, fracRes: 0.3985, norm(attn): 0.2227, norm(output): 1.1172, norm(x): 1.2100, norm(y): 1.0037, norm:0.2873, tok/sec: 99882.92, flops:104.84, batch-reuse:1
@ 801 train 7.6314 , allloss: 7.6507, dt: 1335.84ms, fracRes: 0.3980, norm(attn): 0.2227, norm(output): 1.0938, norm(x): 1.2017, norm(y): 1.0037, norm:0.2916, tok/sec: 98119.52, flops:102.99, batch-reuse:1
@ 802 train 7.6855 , allloss: 7.7037, dt: 1328.95ms, fracRes: 0.3959, norm(attn): 0.2285, norm(output): 1.1172, norm(x): 1.2159, norm(y): 1.0037, norm:0.2409, tok/sec: 98627.89, flops:103.52, batch-reuse:1
@ 803 train 7.7105 , allloss: 7.7280, dt: 1293.92ms, fracRes: 0.3939, norm(attn): 0.2334, norm(output): 1.1172, norm(x): 1.2240, norm(y): 1.0038, norm:0.2953, tok/sec: 101298.45, flops:106.33, batch-reuse:1
@ 804 train 7.6052 , allloss: 7.6227, dt: 1315.30ms, fracRes: 0.3917, norm(attn): 0.2344, norm(output): 1.1172, norm(x): 1.2167, norm(y): 1.0038, norm:0.3091, tok/sec: 99651.50, flops:104.60, batch-reuse:1
@ 805 train 7.6895 , allloss: 7.7056, dt: 1309.67ms, fracRes: 0.3885, norm(attn): 0.2354, norm(output): 1.1328, norm(x): 1.2346, norm(y): 1.0038, norm:0.3591, tok/sec: 100079.97, flops:105.05, batch-reuse:1
@ 806 train 7.5769 , allloss: 7.5925, dt: 1310.85ms, fracRes: 0.3859, norm(attn): 0.2363, norm(output): 1.1250, norm(x): 1.2286, norm(y): 1.0038, norm:0.3568, tok/sec: 99990.33, flops:104.95, batch-reuse:1
@ 807 train 7.6384 , allloss: 7.6537, dt: 1323.84ms, fracRes: 0.3841, norm(attn): 0.2363, norm(output): 1.1250, norm(x): 1.2294, norm(y): 1.0038, norm:0.3097, tok/sec: 99008.93, flops:103.92, batch-reuse:1
@ 808 train 7.6078 , allloss: 7.6220, dt: 1327.51ms, fracRes: 0.3838, norm(attn): 0.2383, norm(output): 1.1250, norm(x): 1.2282, norm(y): 1.0039, norm:0.2783, tok/sec: 98734.95, flops:103.64, batch-reuse:1
@ 809 train 7.6297 , allloss: 7.6428, dt: 1324.57ms, fracRes: 0.3804, norm(attn): 0.2432, norm(output): 1.1328, norm(x): 1.2396, norm(y): 1.0039, norm:0.3075, tok/sec: 98954.51, flops:103.87, batch-reuse:1
@ 810 train 7.6811 , allloss: 7.6943, dt: 1313.55ms, fracRes: 0.3801, norm(attn): 0.2422, norm(output): 1.1250, norm(x): 1.2292, norm(y): 1.0039, norm:0.2814, tok/sec: 99784.81, flops:104.74, batch-reuse:1
@ 811 train 7.6851 , allloss: 7.6975, dt: 1297.96ms, fracRes: 0.3798, norm(attn): 0.2461, norm(output): 1.1250, norm(x): 1.2266, norm(y): 1.0039, norm:0.2822, tok/sec: 100983.13, flops:106.00, batch-reuse:1
@ 812 train 7.5505 , allloss: 7.5610, dt: 1282.37ms, fracRes: 0.3783, norm(attn): 0.2471, norm(output): 1.1328, norm(x): 1.2409, norm(y): 1.0039, norm:0.3240, tok/sec: 102211.14, flops:107.28, batch-reuse:1
@ 813 train 7.7915 , allloss: 7.8024, dt: 1310.35ms, fracRes: 0.3754, norm(attn): 0.2480, norm(output): 1.1328, norm(x): 1.2488, norm(y): 1.0039, norm:0.3680, tok/sec: 100028.57, flops:104.99, batch-reuse:1
@ 814 train 7.7215 , allloss: 7.7324, dt: 1324.84ms, fracRes: 0.3754, norm(attn): 0.2480, norm(output): 1.1328, norm(x): 1.2441, norm(y): 1.0039, norm:0.4158, tok/sec: 98934.01, flops:103.84, batch-reuse:1
@ 815 train 7.6061 , allloss: 7.6172, dt: 1297.02ms, fracRes: 0.3762, norm(attn): 0.2480, norm(output): 1.1328, norm(x): 1.2353, norm(y): 1.0039, norm:0.3272, tok/sec: 101055.90, flops:106.07, batch-reuse:1
@ 816 train 7.6366 , allloss: 7.6468, dt: 1294.85ms, fracRes: 0.3736, norm(attn): 0.2490, norm(output): 1.1328, norm(x): 1.2492, norm(y): 1.0039, norm:0.2724, tok/sec: 101225.67, flops:106.25, batch-reuse:1
@ 817 train 7.6081 , allloss: 7.6177, dt: 1316.97ms, fracRes: 0.3758, norm(attn): 0.2490, norm(output): 1.1250, norm(x): 1.2414, norm(y): 1.0039, norm:0.4338, tok/sec: 99525.80, flops:104.47, batch-reuse:1
@ 818 train 7.6111 , allloss: 7.6212, dt: 1313.48ms, fracRes: 0.3753, norm(attn): 0.2490, norm(output): 1.1328, norm(x): 1.2458, norm(y): 1.0039, norm:0.3474, tok/sec: 99790.17, flops:104.74, batch-reuse:1
@ 819 train 7.7197 , allloss: 7.7302, dt: 1316.28ms, fracRes: 0.3750, norm(attn): 0.2490, norm(output): 1.1328, norm(x): 1.2500, norm(y): 1.0039, norm:0.3706, tok/sec: 99577.68, flops:104.52, batch-reuse:1
@ 820 train 7.7688 , allloss: 7.7793, dt: 1321.42ms, fracRes: 0.3752, norm(attn): 0.2500, norm(output): 1.1250, norm(x): 1.2535, norm(y): 1.0040, norm:0.3589, tok/sec: 99190.43, flops:104.11, batch-reuse:1
@ 821 train 7.7003 , allloss: 7.7109, dt: 1303.31ms, fracRes: 0.3748, norm(attn): 0.2500, norm(output): 1.1250, norm(x): 1.2528, norm(y): 1.0040, norm:0.2870, tok/sec: 100568.69, flops:105.56, batch-reuse:1
@ 822 train 7.8468 , allloss: 7.8578, dt: 1306.46ms, fracRes: 0.3772, norm(attn): 0.2500, norm(output): 1.1250, norm(x): 1.2466, norm(y): 1.0040, norm:0.4879, tok/sec: 100326.32, flops:105.31, batch-reuse:1
@ 823 train 7.6226 , allloss: 7.6321, dt: 1299.51ms, fracRes: 0.3780, norm(attn): 0.2490, norm(output): 1.1250, norm(x): 1.2469, norm(y): 1.0040, norm:0.5183, tok/sec: 100862.89, flops:105.87, batch-reuse:1
@ 824 train 7.8183 , allloss: 7.8283, dt: 1300.38ms, fracRes: 0.3810, norm(attn): 0.2490, norm(output): 1.1250, norm(x): 1.2433, norm(y): 1.0040, norm:0.4915, tok/sec: 100794.84, flops:105.80, batch-reuse:1
@ 825 train 7.6559 , allloss: 7.6653, dt: 1320.10ms, fracRes: 0.3847, norm(attn): 0.2500, norm(output): 1.1328, norm(x): 1.2360, norm(y): 1.0040, norm:0.3545, tok/sec: 99289.73, flops:104.22, batch-reuse:1
@ 826 train 7.6141 , allloss: 7.6223, dt: 1318.90ms, fracRes: 0.3822, norm(attn): 0.2500, norm(output): 1.1328, norm(x): 1.2498, norm(y): 1.0040, norm:0.3170, tok/sec: 99380.05, flops:104.31, batch-reuse:1
@ 827 train 7.7487 , allloss: 7.7567, dt: 1300.43ms, fracRes: 0.3829, norm(attn): 0.2500, norm(output): 1.1406, norm(x): 1.2567, norm(y): 1.0040, norm:0.6362, tok/sec: 100791.25, flops:105.79, batch-reuse:1
@ 828 train 7.6335 , allloss: 7.6414, dt: 1315.00ms, fracRes: 0.3858, norm(attn): 0.2500, norm(output): 1.1406, norm(x): 1.2543, norm(y): 1.0040, norm:0.3032, tok/sec: 99674.38, flops:104.62, batch-reuse:1
@ 829 train 7.6679 , allloss: 7.6757, dt: 1320.77ms, fracRes: 0.3896, norm(attn): 0.2500, norm(output): 1.1328, norm(x): 1.2498, norm(y): 1.0040, norm:0.3471, tok/sec: 99239.08, flops:104.16, batch-reuse:1
@ 830 train 7.6551 , allloss: 7.6620, dt: 1302.34ms, fracRes: 0.3916, norm(attn): 0.2490, norm(output): 1.1328, norm(x): 1.2551, norm(y): 1.0040, norm:0.3447, tok/sec: 100643.42, flops:105.64, batch-reuse:1
@ 831 train 7.6973 , allloss: 7.7039, dt: 1317.78ms, fracRes: 0.3974, norm(attn): 0.2490, norm(output): 1.1328, norm(x): 1.2452, norm(y): 1.0040, norm:0.3329, tok/sec: 99464.25, flops:104.40, batch-reuse:1
@ 832 train 7.6821 , allloss: 7.6894, dt: 1322.14ms, fracRes: 0.3993, norm(attn): 0.2490, norm(output): 1.1484, norm(x): 1.2493, norm(y): 1.0040, norm:0.2851, tok/sec: 99136.45, flops:104.06, batch-reuse:1
@ 833 train 7.6112 , allloss: 7.6188, dt: 1314.97ms, fracRes: 0.4040, norm(attn): 0.2471, norm(output): 1.1484, norm(x): 1.2450, norm(y): 1.0039, norm:0.3210, tok/sec: 99676.58, flops:104.62, batch-reuse:1
@ 834 train 7.6210 , allloss: 7.6291, dt: 1322.84ms, fracRes: 0.4069, norm(attn): 0.2461, norm(output): 1.1406, norm(x): 1.2420, norm(y): 1.0039, norm:0.3883, tok/sec: 99083.77, flops:104.00, batch-reuse:1
@ 835 train 7.5872 , allloss: 7.5954, dt: 1312.16ms, fracRes: 0.4056, norm(attn): 0.2412, norm(output): 1.1484, norm(x): 1.2412, norm(y): 1.0039, norm:0.3062, tok/sec: 99890.13, flops:104.85, batch-reuse:1
@ 836 train 7.6312 , allloss: 7.6403, dt: 1298.93ms, fracRes: 0.3923, norm(attn): 0.2393, norm(output): 1.1328, norm(x): 1.2298, norm(y): 1.0038, norm:0.2788, tok/sec: 100907.36, flops:105.92, batch-reuse:1
@ 837 train 7.6713 , allloss: 7.6853, dt: 1288.59ms, fracRes: 0.3943, norm(attn): 0.2354, norm(output): 1.1328, norm(x): 1.2295, norm(y): 1.0038, norm:0.3953, tok/sec: 101717.42, flops:106.77, batch-reuse:1
@ 838 train 7.6052 , allloss: 7.7027, dt: 1310.07ms, fracRes: 0.4167, norm(attn): 0.2227, norm(output): 1.1250, norm(x): 1.1864, norm(y): 1.0037, norm:2.9159, tok/sec: 100050.00, flops:105.02, batch-reuse:1
@ 839 train 7.5065 , allloss: 7.5162, dt: 1297.14ms, fracRes: 0.4388, norm(attn): 0.2178, norm(output): 1.1250, norm(x): 1.1921, norm(y): 1.0037, norm:0.3974, tok/sec: 101046.63, flops:106.06, batch-reuse:1
@ 840 train 7.6099 , allloss: 7.6178, dt: 1336.61ms, fracRes: 0.4535, norm(attn): 0.2051, norm(output): 1.1250, norm(x): 1.2026, norm(y): 1.0037, norm:0.3280, tok/sec: 98062.76, flops:102.93, batch-reuse:1
@ 841 train 7.5193 , allloss: 7.5267, dt: 1304.77ms, fracRes: 0.4763, norm(attn): 0.1953, norm(output): 1.0781, norm(x): 1.1713, norm(y): 1.0036, norm:0.2348, tok/sec: 100455.71, flops:105.44, batch-reuse:1
@ 842 train 7.6409 , allloss: 7.6489, dt: 1306.38ms, fracRes: 0.4870, norm(attn): 0.1875, norm(output): 1.0625, norm(x): 1.1589, norm(y): 1.0035, norm:0.3148, tok/sec: 100332.45, flops:105.31, batch-reuse:1
@ 843 train 7.6825 , allloss: 7.6893, dt: 1305.64ms, fracRes: 0.4929, norm(attn): 0.1855, norm(output): 1.0469, norm(x): 1.1639, norm(y): 1.0035, norm:0.3277, tok/sec: 100389.23, flops:105.37, batch-reuse:1
@ 844 train 7.6686 , allloss: 7.6762, dt: 1320.09ms, fracRes: 0.5001, norm(attn): 0.1826, norm(output): 1.0078, norm(x): 1.1598, norm(y): 1.0035, norm:0.3268, tok/sec: 99290.39, flops:104.22, batch-reuse:1
@ 845 train 7.6295 , allloss: 7.6382, dt: 1327.65ms, fracRes: 0.5042, norm(attn): 0.1836, norm(output): 0.9844, norm(x): 1.1463, norm(y): 1.0035, norm:0.3674, tok/sec: 98724.81, flops:103.62, batch-reuse:1
@ 846 train 7.6335 , allloss: 7.6402, dt: 1283.27ms, fracRes: 0.5051, norm(attn): 0.1846, norm(output): 0.9922, norm(x): 1.1654, norm(y): 1.0035, norm:0.3200, tok/sec: 102139.04, flops:107.21, batch-reuse:1
@ 847 train 7.6959 , allloss: 7.7039, dt: 1297.75ms, fracRes: 0.5057, norm(attn): 0.1855, norm(output): 0.9844, norm(x): 1.1527, norm(y): 1.0036, norm:0.2714, tok/sec: 100999.26, flops:106.01, batch-reuse:1
@ 848 train 7.6863 , allloss: 7.6952, dt: 1320.04ms, fracRes: 0.5056, norm(attn): 0.1865, norm(output): 0.9648, norm(x): 1.1434, norm(y): 1.0036, norm:0.3140, tok/sec: 99293.94, flops:104.22, batch-reuse:1
@ 849 train 7.6253 , allloss: 7.6307, dt: 1342.70ms, fracRes: 0.5055, norm(attn): 0.1865, norm(output): 0.9961, norm(x): 1.1595, norm(y): 1.0036, norm:0.3288, tok/sec: 97618.06, flops:102.46, batch-reuse:1
@ 850 train 7.6157 , allloss: 7.6206, dt: 1297.01ms, fracRes: 0.5055, norm(attn): 0.1875, norm(output): 0.9961, norm(x): 1.1574, norm(y): 1.0036, norm:0.3429, tok/sec: 101057.01, flops:106.07, batch-reuse:1
@ 851 train 7.8221 , allloss: 7.8276, dt: 1315.98ms, fracRes: 0.5052, norm(attn): 0.1875, norm(output): 0.9961, norm(x): 1.1508, norm(y): 1.0036, norm:0.6133, tok/sec: 99599.92, flops:104.54, batch-reuse:1
@ 852 train 7.7204 , allloss: 7.7274, dt: 1315.95ms, fracRes: 0.5051, norm(attn): 0.1885, norm(output): 0.9844, norm(x): 1.1277, norm(y): 1.0036, norm:0.2755, tok/sec: 99602.72, flops:104.55, batch-reuse:1
@ 853 train 7.6146 , allloss: 7.6202, dt: 1317.19ms, fracRes: 0.5049, norm(attn): 0.1885, norm(output): 0.9844, norm(x): 1.1182, norm(y): 1.0037, norm:0.2444, tok/sec: 99508.95, flops:104.45, batch-reuse:1
@ 854 train 7.6813 , allloss: 7.6862, dt: 1306.49ms, fracRes: 0.5042, norm(attn): 0.1895, norm(output): 0.9922, norm(x): 1.1214, norm(y): 1.0037, norm:0.3286, tok/sec: 100323.48, flops:105.30, batch-reuse:1
@ 855 train 7.7158 , allloss: 7.7273, dt: 1301.11ms, fracRes: 0.5009, norm(attn): 0.1914, norm(output): 1.0000, norm(x): 1.1159, norm(y): 1.0037, norm:0.2643, tok/sec: 100738.34, flops:105.74, batch-reuse:1
@ 856 train 7.6635 , allloss: 7.6685, dt: 1318.03ms, fracRes: 0.5034, norm(attn): 0.1914, norm(output): 1.0000, norm(x): 1.1277, norm(y): 1.0037, norm:0.2418, tok/sec: 99445.14, flops:104.38, batch-reuse:1
@ 857 train 7.6850 , allloss: 7.6906, dt: 1320.19ms, fracRes: 0.5029, norm(attn): 0.1924, norm(output): 0.9922, norm(x): 1.1262, norm(y): 1.0037, norm:0.2524, tok/sec: 99282.45, flops:104.21, batch-reuse:1
@ 858 train 7.6972 , allloss: 7.7044, dt: 1310.72ms, fracRes: 0.5019, norm(attn): 0.1924, norm(output): 0.9922, norm(x): 1.1216, norm(y): 1.0037, norm:0.3449, tok/sec: 99999.97, flops:104.96, batch-reuse:1
@ 859 train 7.6326 , allloss: 7.6394, dt: 1296.27ms, fracRes: 0.4998, norm(attn): 0.1934, norm(output): 0.9961, norm(x): 1.1334, norm(y): 1.0037, norm:0.2919, tok/sec: 101114.86, flops:106.13, batch-reuse:1
@ 860 train 7.6837 , allloss: 7.6897, dt: 1306.20ms, fracRes: 0.4957, norm(attn): 0.1953, norm(output): 1.0000, norm(x): 1.1505, norm(y): 1.0037, norm:0.2979, tok/sec: 100346.17, flops:105.33, batch-reuse:1
@ 861 train 7.6609 , allloss: 7.6672, dt: 1320.96ms, fracRes: 0.4942, norm(attn): 0.2002, norm(output): 1.0000, norm(x): 1.1583, norm(y): 1.0038, norm:0.2462, tok/sec: 99224.91, flops:104.15, batch-reuse:1
@ 862 train 7.7374 , allloss: 7.7450, dt: 1320.46ms, fracRes: 0.4872, norm(attn): 0.2031, norm(output): 1.0078, norm(x): 1.1472, norm(y): 1.0038, norm:0.3158, tok/sec: 99262.59, flops:104.19, batch-reuse:1
@ 863 train 7.6959 , allloss: 7.7081, dt: 1306.22ms, fracRes: 0.4576, norm(attn): 0.2041, norm(output): 1.0000, norm(x): 1.0706, norm(y): 1.0037, norm:0.2479, tok/sec: 100344.41, flops:105.32, batch-reuse:1
@ 864 train 7.6951 , allloss: 7.7101, dt: 1305.97ms, fracRes: 0.4444, norm(attn): 0.2070, norm(output): 1.0000, norm(x): 1.0497, norm(y): 1.0037, norm:0.3003, tok/sec: 100363.96, flops:105.35, batch-reuse:1
@ 865 train 7.6057 , allloss: 7.6460, dt: 1299.01ms, fracRes: 0.4250, norm(attn): 0.2051, norm(output): 0.9922, norm(x): 1.0135, norm(y): 1.0036, norm:0.9714, tok/sec: 100901.30, flops:105.91, batch-reuse:1
@ 866 train 7.5721 , allloss: 7.6400, dt: 1311.13ms, fracRes: 0.4189, norm(attn): 0.2031, norm(output): 0.9609, norm(x): 0.9982, norm(y): 1.0035, norm:1.1649, tok/sec: 99969.05, flops:104.93, batch-reuse:1
@ 867 train 7.6831 , allloss: 7.8288, dt: 1316.36ms, fracRes: 0.3762, norm(attn): 0.2061, norm(output): 0.9844, norm(x): 0.9969, norm(y): 1.0035, norm:2.2472, tok/sec: 99571.47, flops:104.51, batch-reuse:1
@ 868 train 7.6052 , allloss: 7.7176, dt: 1295.49ms, fracRes: 0.3246, norm(attn): 0.2178, norm(output): 0.9883, norm(x): 0.9854, norm(y): 1.0035, norm:2.1415, tok/sec: 101175.82, flops:106.20, batch-reuse:1
@ 869 train 7.6432 , allloss: 7.7093, dt: 1312.97ms, fracRes: 0.3163, norm(attn): 0.2207, norm(output): 1.0000, norm(x): 1.0276, norm(y): 1.0034, norm:1.1956, tok/sec: 99828.64, flops:104.78, batch-reuse:1
@ 870 train 7.5913 , allloss: 7.6319, dt: 1283.29ms, fracRes: 0.3334, norm(attn): 0.2197, norm(output): 0.9961, norm(x): 1.0292, norm(y): 1.0035, norm:1.0340, tok/sec: 102137.39, flops:107.21, batch-reuse:1
@ 871 train 7.6577 , allloss: 7.6829, dt: 1303.80ms, fracRes: 0.3445, norm(attn): 0.2227, norm(output): 0.9961, norm(x): 1.0331, norm(y): 1.0035, norm:0.6137, tok/sec: 100531.10, flops:105.52, batch-reuse:1
@ 872 train 7.6192 , allloss: 7.6392, dt: 1318.42ms, fracRes: 0.3565, norm(attn): 0.2246, norm(output): 0.9961, norm(x): 1.0245, norm(y): 1.0036, norm:0.4510, tok/sec: 99415.60, flops:104.35, batch-reuse:1
@ 873 train 7.6837 , allloss: 7.7030, dt: 1318.63ms, fracRes: 0.3717, norm(attn): 0.2227, norm(output): 1.0000, norm(x): 1.0254, norm(y): 1.0036, norm:0.4949, tok/sec: 99400.30, flops:104.33, batch-reuse:1
@ 874 train 7.5947 , allloss: 7.6101, dt: 1314.97ms, fracRes: 0.3792, norm(attn): 0.2227, norm(output): 1.0000, norm(x): 1.0410, norm(y): 1.0036, norm:0.4434, tok/sec: 99677.07, flops:104.62, batch-reuse:1
@ 875 train 7.6119 , allloss: 7.6256, dt: 1330.46ms, fracRes: 0.3871, norm(attn): 0.2217, norm(output): 1.0078, norm(x): 1.0513, norm(y): 1.0036, norm:0.3846, tok/sec: 98515.96, flops:103.41, batch-reuse:1
@ 876 train 7.6230 , allloss: 7.6356, dt: 1277.89ms, fracRes: 0.3972, norm(attn): 0.2188, norm(output): 1.0000, norm(x): 1.0625, norm(y): 1.0037, norm:0.3335, tok/sec: 102568.81, flops:107.66, batch-reuse:1
@ 877 train 7.6370 , allloss: 7.6470, dt: 1302.86ms, fracRes: 0.4065, norm(attn): 0.2178, norm(output): 1.0000, norm(x): 1.0722, norm(y): 1.0037, norm:0.3049, tok/sec: 100603.62, flops:105.60, batch-reuse:1
@ 878 train 7.5943 , allloss: 7.6013, dt: 1291.49ms, fracRes: 0.4135, norm(attn): 0.2178, norm(output): 0.9961, norm(x): 1.0810, norm(y): 1.0037, norm:0.3524, tok/sec: 101488.93, flops:106.53, batch-reuse:1
@ 879 train 7.6154 , allloss: 7.6204, dt: 1316.99ms, fracRes: 0.4195, norm(attn): 0.2158, norm(output): 0.9883, norm(x): 1.0895, norm(y): 1.0038, norm:0.4118, tok/sec: 99524.28, flops:104.46, batch-reuse:1
@ 880 train 7.6814 , allloss: 7.6856, dt: 1307.80ms, fracRes: 0.4249, norm(attn): 0.2129, norm(output): 0.9844, norm(x): 1.0985, norm(y): 1.0038, norm:0.3352, tok/sec: 100223.13, flops:105.20, batch-reuse:1
@ 881 train 7.6167 , allloss: 7.6197, dt: 1298.06ms, fracRes: 0.4319, norm(attn): 0.2129, norm(output): 0.9922, norm(x): 1.1069, norm(y): 1.0038, norm:0.2424, tok/sec: 100975.03, flops:105.99, batch-reuse:1
@ 882 train 7.6097 , allloss: 7.6117, dt: 1310.39ms, fracRes: 0.4354, norm(attn): 0.2148, norm(output): 0.9961, norm(x): 1.1127, norm(y): 1.0038, norm:0.2783, tok/sec: 100024.87, flops:104.99, batch-reuse:1
@ 883 train 7.5719 , allloss: 7.5733, dt: 1286.81ms, fracRes: 0.4380, norm(attn): 0.2148, norm(output): 1.0000, norm(x): 1.1179, norm(y): 1.0039, norm:0.3664, tok/sec: 101858.37, flops:106.91, batch-reuse:1
@ 884 train 7.5661 , allloss: 7.5675, dt: 1316.15ms, fracRes: 0.4403, norm(attn): 0.2148, norm(output): 1.0000, norm(x): 1.1168, norm(y): 1.0039, norm:0.3231, tok/sec: 99587.64, flops:104.53, batch-reuse:1
@ 885 train 7.6033 , allloss: 7.6054, dt: 1309.31ms, fracRes: 0.4437, norm(attn): 0.2148, norm(output): 1.0000, norm(x): 1.1120, norm(y): 1.0039, norm:0.2503, tok/sec: 100107.80, flops:105.08, batch-reuse:1
@ 886 train 7.6499 , allloss: 7.6519, dt: 1325.38ms, fracRes: 0.4489, norm(attn): 0.2129, norm(output): 1.0078, norm(x): 1.0996, norm(y): 1.0040, norm:0.2760, tok/sec: 98894.23, flops:103.80, batch-reuse:1
@ 887 train 7.5944 , allloss: 7.5974, dt: 1316.28ms, fracRes: 0.4510, norm(attn): 0.2100, norm(output): 1.0078, norm(x): 1.0782, norm(y): 1.0040, norm:0.2325, tok/sec: 99577.89, flops:104.52, batch-reuse:1
@ 888 train 7.6230 , allloss: 7.6253, dt: 1303.87ms, fracRes: 0.4512, norm(attn): 0.2178, norm(output): 1.0078, norm(x): 1.0923, norm(y): 1.0040, norm:0.2619, tok/sec: 100525.05, flops:105.51, batch-reuse:1
@ 889 train 7.6322 , allloss: 7.6358, dt: 1290.46ms, fracRes: 0.4553, norm(attn): 0.2158, norm(output): 1.0078, norm(x): 1.0855, norm(y): 1.0040, norm:0.2271, tok/sec: 101570.37, flops:106.61, batch-reuse:1
@ 890 train 7.7162 , allloss: 7.7654, dt: 1281.20ms, fracRes: 0.4506, norm(attn): 0.2080, norm(output): 1.0078, norm(x): 1.0149, norm(y): 1.0040, norm:1.2424, tok/sec: 102304.32, flops:107.38, batch-reuse:1
@ 891 train 7.6469 , allloss: 7.6531, dt: 1296.64ms, fracRes: 0.4687, norm(attn): 0.2031, norm(output): 1.0078, norm(x): 1.0085, norm(y): 1.0041, norm:0.2718, tok/sec: 101085.54, flops:106.10, batch-reuse:1
@ 892 train 7.5729 , allloss: 7.5777, dt: 1282.54ms, fracRes: 0.4829, norm(attn): 0.2031, norm(output): 1.0078, norm(x): 1.0260, norm(y): 1.0041, norm:0.2621, tok/sec: 102197.12, flops:107.27, batch-reuse:1
@ 893 train 7.5254 , allloss: 7.5292, dt: 1291.57ms, fracRes: 0.4868, norm(attn): 0.2021, norm(output): 1.0156, norm(x): 1.0301, norm(y): 1.0041, norm:0.3282, tok/sec: 101482.32, flops:106.52, batch-reuse:1
@ 894 train 7.6386 , allloss: 7.6446, dt: 1276.41ms, fracRes: 0.4886, norm(attn): 0.2041, norm(output): 1.0234, norm(x): 1.0268, norm(y): 1.0041, norm:0.2914, tok/sec: 102687.73, flops:107.78, batch-reuse:1
@ 895 train 7.6828 , allloss: 7.6890, dt: 1302.50ms, fracRes: 0.4909, norm(attn): 0.2158, norm(output): 1.0547, norm(x): 1.0092, norm(y): 1.0042, norm:0.3070, tok/sec: 100631.19, flops:105.63, batch-reuse:1
@ 896 train 7.5142 , allloss: 7.5206, dt: 1284.15ms, fracRes: 0.4888, norm(attn): 0.2227, norm(output): 1.0625, norm(x): 1.0039, norm(y): 1.0043, norm:0.2782, tok/sec: 102069.31, flops:107.14, batch-reuse:1
@ 897 train 7.6111 , allloss: 7.6241, dt: 1299.93ms, fracRes: 0.4996, norm(attn): 0.2227, norm(output): 1.0625, norm(x): 1.0153, norm(y): 1.0043, norm:0.3157, tok/sec: 100830.20, flops:105.83, batch-reuse:1
@ 898 train 7.6604 , allloss: 7.6769, dt: 1288.47ms, fracRes: 0.5050, norm(attn): 0.2295, norm(output): 1.0469, norm(x): 1.0192, norm(y): 1.0044, norm:0.3580, tok/sec: 101727.06, flops:106.78, batch-reuse:1
@ 899 train 7.5911 , allloss: 7.6219, dt: 1290.40ms, fracRes: 0.5046, norm(attn): 0.2305, norm(output): 1.0391, norm(x): 1.0249, norm(y): 1.0044, norm:0.6348, tok/sec: 101574.50, flops:106.62, batch-reuse:1
@ 900 train 7.6561 , allloss: 7.6746, dt: 1309.56ms, fracRes: 0.5062, norm(attn): 0.2344, norm(output): 1.0156, norm(x): 1.0381, norm(y): 1.0045, norm:0.5081, tok/sec: 100088.21, flops:105.06, batch-reuse:1
@ 901 train 7.5551 , allloss: 7.5684, dt: 1284.11ms, fracRes: 0.5062, norm(attn): 0.2354, norm(output): 1.0156, norm(x): 1.0442, norm(y): 1.0045, norm:0.3654, tok/sec: 102072.59, flops:107.14, batch-reuse:1
@ 902 train 7.5543 , allloss: 7.5776, dt: 1296.35ms, fracRes: 0.5058, norm(attn): 0.2373, norm(output): 1.0312, norm(x): 1.0479, norm(y): 1.0046, norm:0.5703, tok/sec: 101108.16, flops:106.13, batch-reuse:1
@ 903 train 7.5746 , allloss: 7.5913, dt: 1323.51ms, fracRes: 0.5067, norm(attn): 0.2383, norm(output): 1.0156, norm(x): 1.0564, norm(y): 1.0046, norm:0.3964, tok/sec: 99033.69, flops:103.95, batch-reuse:1
@ 904 train 7.5804 , allloss: 7.5901, dt: 1310.41ms, fracRes: 0.5072, norm(attn): 0.2471, norm(output): 1.0156, norm(x): 1.0628, norm(y): 1.0046, norm:0.3527, tok/sec: 100023.78, flops:104.99, batch-reuse:1
@ 905 train 7.6747 , allloss: 7.6823, dt: 1312.63ms, fracRes: 0.5074, norm(attn): 0.2490, norm(output): 1.0234, norm(x): 1.0681, norm(y): 1.0046, norm:0.3218, tok/sec: 99854.31, flops:104.81, batch-reuse:1
@ 906 train 7.5802 , allloss: 7.5847, dt: 1290.71ms, fracRes: 0.5074, norm(attn): 0.2490, norm(output): 1.0156, norm(x): 1.0707, norm(y): 1.0046, norm:0.2649, tok/sec: 101550.37, flops:106.59, batch-reuse:1
@ 907 train 7.5236 , allloss: 7.5257, dt: 1300.45ms, fracRes: 0.5076, norm(attn): 0.2490, norm(output): 1.0156, norm(x): 1.0725, norm(y): 1.0046, norm:0.4020, tok/sec: 100789.96, flops:105.79, batch-reuse:1
@ 908 train 7.5696 , allloss: 7.5727, dt: 1300.26ms, fracRes: 0.5074, norm(attn): 0.2490, norm(output): 1.0234, norm(x): 1.0777, norm(y): 1.0047, norm:0.4157, tok/sec: 100804.25, flops:105.81, batch-reuse:1
@ 909 train 7.7977 , allloss: 7.8027, dt: 1290.81ms, fracRes: 0.5065, norm(attn): 0.2490, norm(output): 1.0234, norm(x): 1.0879, norm(y): 1.0046, norm:0.7369, tok/sec: 101542.36, flops:106.58, batch-reuse:1
@ 910 train 7.6070 , allloss: 7.6078, dt: 1322.90ms, fracRes: 0.5074, norm(attn): 0.2500, norm(output): 1.0391, norm(x): 1.0884, norm(y): 1.0047, norm:0.2646, tok/sec: 99079.01, flops:104.00, batch-reuse:1
@ 911 train 7.6995 , allloss: 7.7014, dt: 1334.16ms, fracRes: 0.5075, norm(attn): 0.2500, norm(output): 1.0469, norm(x): 1.0869, norm(y): 1.0047, norm:0.4769, tok/sec: 98242.87, flops:103.12, batch-reuse:1
@ 912 train 7.6186 , allloss: 7.6196, dt: 1325.78ms, fracRes: 0.5078, norm(attn): 0.2500, norm(output): 1.0547, norm(x): 1.0803, norm(y): 1.0047, norm:0.6297, tok/sec: 98864.25, flops:103.77, batch-reuse:1
@ 913 train 7.6193 , allloss: 7.6304, dt: 1316.07ms, fracRes: 0.5075, norm(attn): 0.2500, norm(output): 1.0547, norm(x): 1.0777, norm(y): 1.0047, norm:0.3960, tok/sec: 99593.35, flops:104.54, batch-reuse:1
@ 914 train 7.6199 , allloss: 7.6216, dt: 1279.16ms, fracRes: 0.5081, norm(attn): 0.2500, norm(output): 1.0625, norm(x): 1.0746, norm(y): 1.0046, norm:0.2659, tok/sec: 102467.30, flops:107.55, batch-reuse:1
@ 915 train 7.6185 , allloss: 7.6196, dt: 1299.10ms, fracRes: 0.5083, norm(attn): 0.2490, norm(output): 1.0703, norm(x): 1.0734, norm(y): 1.0045, norm:0.3999, tok/sec: 100894.25, flops:105.90, batch-reuse:1
@ 916 train 7.5677 , allloss: 7.5703, dt: 1323.14ms, fracRes: 0.5074, norm(attn): 0.2490, norm(output): 1.0781, norm(x): 1.0764, norm(y): 1.0045, norm:0.4045, tok/sec: 99061.55, flops:103.98, batch-reuse:1
@ 917 train 7.6252 , allloss: 7.6264, dt: 1291.96ms, fracRes: 0.5029, norm(attn): 0.2490, norm(output): 1.1016, norm(x): 1.0786, norm(y): 1.0044, norm:0.2992, tok/sec: 101451.93, flops:106.49, batch-reuse:1
@ 918 train 7.6576 , allloss: 7.6590, dt: 1305.86ms, fracRes: 0.4882, norm(attn): 0.2500, norm(output): 1.1172, norm(x): 1.0838, norm(y): 1.0044, norm:0.2626, tok/sec: 100372.07, flops:105.35, batch-reuse:1
@ 919 train 7.6067 , allloss: 7.6136, dt: 1293.82ms, fracRes: 0.4829, norm(attn): 0.2480, norm(output): 1.1094, norm(x): 1.0748, norm(y): 1.0043, norm:0.3102, tok/sec: 101305.99, flops:106.33, batch-reuse:1
@ 920 train 7.6476 , allloss: 7.6489, dt: 1312.97ms, fracRes: 0.5038, norm(attn): 0.2285, norm(output): 1.0625, norm(x): 1.0564, norm(y): 1.0042, norm:0.3213, tok/sec: 99828.75, flops:104.78, batch-reuse:1
@ 921 train 7.6046 , allloss: 7.6539, dt: 1315.18ms, fracRes: 0.5025, norm(attn): 0.2197, norm(output): 1.0625, norm(x): 1.0975, norm(y): 1.0041, norm:1.2084, tok/sec: 99660.79, flops:104.61, batch-reuse:1
@ 922 train 7.7489 , allloss: 7.8354, dt: 1300.23ms, fracRes: 0.5000, norm(attn): 0.2207, norm(output): 1.0547, norm(x): 1.1613, norm(y): 1.0040, norm:0.3476, tok/sec: 100806.80, flops:105.81, batch-reuse:1
@ 923 train 7.9888 , allloss: 8.1311, dt: 1298.84ms, fracRes: 0.5031, norm(attn): 0.2178, norm(output): 1.0312, norm(x): 1.1007, norm(y): 1.0041, norm:9.2367, tok/sec: 100914.60, flops:105.92, batch-reuse:1
@ 924 train 8.6902 , allloss: 10.1350, dt: 1318.70ms, fracRes: 0.2757, norm(attn): 0.2598, norm(output): 1.4609, norm(x): 1.6053, norm(y): 1.0037, norm:32.1503, tok/sec: 99394.64, flops:104.33, batch-reuse:1
@ 925 train 7.6224 , allloss: 8.3118, dt: 1323.28ms, fracRes: 0.2908, norm(attn): 0.2793, norm(output): 1.4766, norm(x): 1.6482, norm(y): 1.0039, norm:3.5769, tok/sec: 99050.68, flops:103.97, batch-reuse:1
@ 926 train 7.5788 , allloss: 7.9506, dt: 1323.23ms, fracRes: 0.2968, norm(attn): 0.2773, norm(output): 1.3516, norm(x): 1.4984, norm(y): 1.0041, norm:1.4639, tok/sec: 99054.53, flops:103.97, batch-reuse:1
@ 927 train 7.5916 , allloss: 7.8536, dt: 1327.61ms, fracRes: 0.2994, norm(attn): 0.2812, norm(output): 1.2812, norm(x): 1.4105, norm(y): 1.0043, norm:1.4860, tok/sec: 98727.84, flops:103.63, batch-reuse:1
@ 928 train 7.6721 , allloss: 7.8665, dt: 1274.70ms, fracRes: 0.2961, norm(attn): 0.2891, norm(output): 1.2656, norm(x): 1.3514, norm(y): 1.0044, norm:1.1192, tok/sec: 102826.02, flops:107.93, batch-reuse:1
@ 929 train 7.7654 , allloss: 7.9414, dt: 1298.73ms, fracRes: 0.3085, norm(attn): 0.2930, norm(output): 1.2500, norm(x): 1.3212, norm(y): 1.0046, norm:1.3341, tok/sec: 100923.46, flops:105.93, batch-reuse:1
@ 930 train 7.6441 , allloss: 7.7715, dt: 1322.74ms, fracRes: 0.3096, norm(attn): 0.2969, norm(output): 1.2344, norm(x): 1.3175, norm(y): 1.0046, norm:0.8255, tok/sec: 99091.54, flops:104.01, batch-reuse:1
@ 931 train 7.7908 , allloss: 7.8863, dt: 1308.94ms, fracRes: 0.2957, norm(attn): 0.3047, norm(output): 1.2344, norm(x): 1.3058, norm(y): 1.0046, norm:0.7698, tok/sec: 100135.61, flops:105.11, batch-reuse:1
@ 932 train 7.7118 , allloss: 7.7984, dt: 1298.76ms, fracRes: 0.2899, norm(attn): 0.3047, norm(output): 1.2344, norm(x): 1.3266, norm(y): 1.0045, norm:0.5705, tok/sec: 100920.62, flops:105.93, batch-reuse:1
@ 933 train 7.6818 , allloss: 7.7595, dt: 1305.98ms, fracRes: 0.2435, norm(attn): 0.3145, norm(output): 1.2656, norm(x): 1.3842, norm(y): 1.0043, norm:0.5251, tok/sec: 100362.62, flops:105.34, batch-reuse:1
@ 934 train 7.7110 , allloss: 7.7969, dt: 1288.73ms, fracRes: 0.2346, norm(attn): 0.3145, norm(output): 1.2656, norm(x): 1.3935, norm(y): 1.0042, norm:0.4917, tok/sec: 101706.71, flops:106.75, batch-reuse:1
@ 935 train 7.6894 , allloss: 7.7618, dt: 1269.85ms, fracRes: 0.2411, norm(attn): 0.3145, norm(output): 1.2500, norm(x): 1.3928, norm(y): 1.0043, norm:0.4624, tok/sec: 103218.70, flops:108.34, batch-reuse:1
@ 936 train 7.7039 , allloss: 7.7985, dt: 1299.16ms, fracRes: 0.2356, norm(attn): 0.3164, norm(output): 1.2422, norm(x): 1.3815, norm(y): 1.0043, norm:2.9301, tok/sec: 100889.58, flops:105.90, batch-reuse:1
@ 937 train 7.7135 , allloss: 7.7995, dt: 1284.19ms, fracRes: 0.2470, norm(attn): 0.3105, norm(output): 1.2891, norm(x): 1.4423, norm(y): 1.0041, norm:0.6220, tok/sec: 102066.22, flops:107.13, batch-reuse:1
@ 938 train 7.6637 , allloss: 7.7293, dt: 1297.28ms, fracRes: 0.2829, norm(attn): 0.2969, norm(output): 1.2812, norm(x): 1.4594, norm(y): 1.0040, norm:0.5600, tok/sec: 101035.93, flops:106.05, batch-reuse:1
@ 939 train 7.6932 , allloss: 7.7419, dt: 1298.78ms, fracRes: 0.3085, norm(attn): 0.2930, norm(output): 1.2656, norm(x): 1.4815, norm(y): 1.0040, norm:0.4390, tok/sec: 100919.20, flops:105.93, batch-reuse:1
@ 940 train 7.6894 , allloss: 7.7503, dt: 1305.27ms, fracRes: 0.3245, norm(attn): 0.2891, norm(output): 1.2891, norm(x): 1.5075, norm(y): 1.0040, norm:0.4151, tok/sec: 100417.74, flops:105.40, batch-reuse:1
@ 941 train 7.7155 , allloss: 7.7694, dt: 1331.70ms, fracRes: 0.3218, norm(attn): 0.2871, norm(output): 1.2812, norm(x): 1.5168, norm(y): 1.0040, norm:0.4406, tok/sec: 98424.70, flops:103.31, batch-reuse:1
@ 942 train 7.6777 , allloss: 7.7383, dt: 1329.23ms, fracRes: 0.3249, norm(attn): 0.2852, norm(output): 1.3203, norm(x): 1.5502, norm(y): 1.0041, norm:0.3780, tok/sec: 98607.78, flops:103.50, batch-reuse:1
@ 943 train 7.7007 , allloss: 7.7491, dt: 1309.86ms, fracRes: 0.3279, norm(attn): 0.2852, norm(output): 1.3281, norm(x): 1.5479, norm(y): 1.0041, norm:0.5066, tok/sec: 100065.60, flops:105.03, batch-reuse:1
@ 944 train 7.6713 , allloss: 7.7071, dt: 1305.88ms, fracRes: 0.3345, norm(attn): 0.2910, norm(output): 1.3125, norm(x): 1.5194, norm(y): 1.0042, norm:0.3674, tok/sec: 100370.77, flops:105.35, batch-reuse:1
@ 945 train 7.7879 , allloss: 7.8170, dt: 1328.28ms, fracRes: 0.3398, norm(attn): 0.2891, norm(output): 1.3516, norm(x): 1.5508, norm(y): 1.0042, norm:0.5117, tok/sec: 98678.35, flops:103.58, batch-reuse:1
@ 946 train 7.7149 , allloss: 7.7388, dt: 1296.60ms, fracRes: 0.3499, norm(attn): 0.2852, norm(output): 1.3594, norm(x): 1.5614, norm(y): 1.0041, norm:0.2731, tok/sec: 101089.11, flops:106.11, batch-reuse:1
@ 947 train 7.6834 , allloss: 7.7096, dt: 1310.70ms, fracRes: 0.3613, norm(attn): 0.2832, norm(output): 1.3828, norm(x): 1.5983, norm(y): 1.0041, norm:0.4284, tok/sec: 100001.40, flops:104.96, batch-reuse:1
@ 948 train 7.6684 , allloss: 7.6911, dt: 1328.97ms, fracRes: 0.3604, norm(attn): 0.2852, norm(output): 1.4062, norm(x): 1.6178, norm(y): 1.0040, norm:0.5661, tok/sec: 98626.78, flops:103.52, batch-reuse:1
@ 949 train 7.7315 , allloss: 7.7533, dt: 1339.56ms, fracRes: 0.3621, norm(attn): 0.2910, norm(output): 1.3906, norm(x): 1.6258, norm(y): 1.0040, norm:0.3923, tok/sec: 97846.81, flops:102.70, batch-reuse:1
@ 950 train 7.6735 , allloss: 7.6950, dt: 1331.20ms, fracRes: 0.3656, norm(attn): 0.2891, norm(output): 1.4141, norm(x): 1.6495, norm(y): 1.0040, norm:0.2831, tok/sec: 98461.81, flops:103.35, batch-reuse:1
@ 951 train 7.7468 , allloss: 7.7696, dt: 1331.03ms, fracRes: 0.3724, norm(attn): 0.2910, norm(output): 1.4688, norm(x): 1.6987, norm(y): 1.0040, norm:0.2687, tok/sec: 98473.98, flops:103.36, batch-reuse:1
@ 952 train 7.7059 , allloss: 7.7260, dt: 1295.61ms, fracRes: 0.3721, norm(attn): 0.2930, norm(output): 1.4844, norm(x): 1.7135, norm(y): 1.0040, norm:0.4187, tok/sec: 101166.55, flops:106.19, batch-reuse:1
@ 953 train 7.6715 , allloss: 7.6898, dt: 1305.91ms, fracRes: 0.3776, norm(attn): 0.2930, norm(output): 1.4844, norm(x): 1.7174, norm(y): 1.0040, norm:0.2803, tok/sec: 100368.61, flops:105.35, batch-reuse:1
@ 954 train 7.6217 , allloss: 7.6433, dt: 1320.98ms, fracRes: 0.3834, norm(attn): 0.2930, norm(output): 1.5078, norm(x): 1.7562, norm(y): 1.0040, norm:0.2924, tok/sec: 99223.41, flops:104.15, batch-reuse:1
@ 955 train 7.6739 , allloss: 7.6964, dt: 1316.03ms, fracRes: 0.3860, norm(attn): 0.2949, norm(output): 1.5625, norm(x): 1.7907, norm(y): 1.0040, norm:0.3327, tok/sec: 99596.67, flops:104.54, batch-reuse:1
@ 956 train 7.6374 , allloss: 7.6644, dt: 1324.45ms, fracRes: 0.3945, norm(attn): 0.2949, norm(output): 1.5859, norm(x): 1.8202, norm(y): 1.0040, norm:0.3791, tok/sec: 98963.32, flops:103.88, batch-reuse:1
@ 957 train 7.6671 , allloss: 7.7123, dt: 1291.67ms, fracRes: 0.3921, norm(attn): 0.2930, norm(output): 1.6172, norm(x): 1.8583, norm(y): 1.0040, norm:0.5929, tok/sec: 101474.85, flops:106.51, batch-reuse:1
@ 958 train 7.6945 , allloss: 7.7800, dt: 1304.52ms, fracRes: 0.3911, norm(attn): 0.2949, norm(output): 1.7109, norm(x): 1.9336, norm(y): 1.0040, norm:1.1579, tok/sec: 100475.50, flops:105.46, batch-reuse:1
@ 959 train 7.6287 , allloss: 7.6736, dt: 1290.09ms, fracRes: 0.3815, norm(attn): 0.3008, norm(output): 1.6406, norm(x): 1.8922, norm(y): 1.0040, norm:0.6817, tok/sec: 101598.81, flops:106.64, batch-reuse:1
@ 960 train 7.7363 , allloss: 7.7799, dt: 1311.32ms, fracRes: 0.3840, norm(attn): 0.2988, norm(output): 1.8125, norm(x): 2.0449, norm(y): 1.0040, norm:0.7327, tok/sec: 99954.46, flops:104.92, batch-reuse:1
@ 961 train 7.6727 , allloss: 7.6956, dt: 1338.63ms, fracRes: 0.3938, norm(attn): 0.2969, norm(output): 1.7656, norm(x): 2.0035, norm(y): 1.0040, norm:0.3830, tok/sec: 97915.02, flops:102.77, batch-reuse:1
@ 962 train 7.6568 , allloss: 7.6750, dt: 1337.88ms, fracRes: 0.4031, norm(attn): 0.2930, norm(output): 1.7656, norm(x): 2.0067, norm(y): 1.0040, norm:0.3962, tok/sec: 97970.21, flops:102.83, batch-reuse:1
@ 963 train 7.7400 , allloss: 7.7597, dt: 1317.25ms, fracRes: 0.4103, norm(attn): 0.2949, norm(output): 1.8828, norm(x): 2.1114, norm(y): 1.0040, norm:0.5813, tok/sec: 99504.04, flops:104.44, batch-reuse:1
@ 964 train 7.6860 , allloss: 7.7029, dt: 1289.86ms, fracRes: 0.4160, norm(attn): 0.2930, norm(output): 1.8672, norm(x): 2.1090, norm(y): 1.0040, norm:0.2658, tok/sec: 101617.02, flops:106.66, batch-reuse:1
@ 965 train 7.6686 , allloss: 7.6841, dt: 1302.30ms, fracRes: 0.4192, norm(attn): 0.2930, norm(output): 1.8750, norm(x): 2.1127, norm(y): 1.0041, norm:0.3309, tok/sec: 100646.42, flops:105.64, batch-reuse:1
@ 966 train 7.6642 , allloss: 7.6831, dt: 1306.10ms, fracRes: 0.4222, norm(attn): 0.2969, norm(output): 1.9922, norm(x): 2.2117, norm(y): 1.0041, norm:0.4665, tok/sec: 100353.53, flops:105.33, batch-reuse:1
@ 967 train 7.7345 , allloss: 7.7551, dt: 1298.68ms, fracRes: 0.4241, norm(attn): 0.2988, norm(output): 2.0469, norm(x): 2.2915, norm(y): 1.0041, norm:0.9704, tok/sec: 100927.05, flops:105.94, batch-reuse:1
@ 968 train 7.6820 , allloss: 7.6976, dt: 1310.45ms, fracRes: 0.4254, norm(attn): 0.2969, norm(output): 2.0156, norm(x): 2.2748, norm(y): 1.0041, norm:0.3436, tok/sec: 100020.52, flops:104.98, batch-reuse:1
@ 969 train 7.6382 , allloss: 7.6569, dt: 1302.29ms, fracRes: 0.4271, norm(attn): 0.3027, norm(output): 2.1094, norm(x): 2.3444, norm(y): 1.0041, norm:0.5502, tok/sec: 100647.43, flops:105.64, batch-reuse:1
@ 970 train 7.6690 , allloss: 7.6983, dt: 1293.77ms, fracRes: 0.4290, norm(attn): 0.3105, norm(output): 2.1875, norm(x): 2.4114, norm(y): 1.0041, norm:0.5045, tok/sec: 101309.93, flops:106.34, batch-reuse:1
@ 971 train 7.6544 , allloss: 7.6786, dt: 1288.30ms, fracRes: 0.4309, norm(attn): 0.3105, norm(output): 2.1875, norm(x): 2.4093, norm(y): 1.0041, norm:0.6666, tok/sec: 101740.67, flops:106.79, batch-reuse:1
@ 972 train 7.6820 , allloss: 7.7067, dt: 1284.75ms, fracRes: 0.4308, norm(attn): 0.3105, norm(output): 2.1562, norm(x): 2.3649, norm(y): 1.0041, norm:0.6847, tok/sec: 102021.14, flops:107.08, batch-reuse:1
@ 973 train 7.6814 , allloss: 7.7056, dt: 1295.93ms, fracRes: 0.4325, norm(attn): 0.3105, norm(output): 2.2188, norm(x): 2.4048, norm(y): 1.0041, norm:0.4740, tok/sec: 101141.18, flops:106.16, batch-reuse:1
@ 974 train 7.7432 , allloss: 7.7732, dt: 1311.71ms, fracRes: 0.4371, norm(attn): 0.3125, norm(output): 2.2500, norm(x): 2.4051, norm(y): 1.0041, norm:0.6669, tok/sec: 99924.66, flops:104.88, batch-reuse:1
@ 975 train 7.7258 , allloss: 7.7480, dt: 1329.86ms, fracRes: 0.4399, norm(attn): 0.3125, norm(output): 2.2656, norm(x): 2.3969, norm(y): 1.0041, norm:0.6702, tok/sec: 98560.75, flops:103.45, batch-reuse:1
@ 976 train 7.6298 , allloss: 7.6510, dt: 1298.77ms, fracRes: 0.4360, norm(attn): 0.3125, norm(output): 2.2344, norm(x): 2.4004, norm(y): 1.0042, norm:0.5139, tok/sec: 100920.16, flops:105.93, batch-reuse:1
@ 977 train 7.6390 , allloss: 7.6607, dt: 1320.15ms, fracRes: 0.4352, norm(attn): 0.3125, norm(output): 2.2344, norm(x): 2.4302, norm(y): 1.0042, norm:0.5064, tok/sec: 99285.48, flops:104.21, batch-reuse:1
@ 978 train 7.6616 , allloss: 7.6823, dt: 1304.39ms, fracRes: 0.4358, norm(attn): 0.3145, norm(output): 2.2656, norm(x): 2.4620, norm(y): 1.0042, norm:0.4360, tok/sec: 100485.12, flops:105.47, batch-reuse:1
@ 979 train 7.6585 , allloss: 7.6796, dt: 1315.62ms, fracRes: 0.4361, norm(attn): 0.3145, norm(output): 2.2656, norm(x): 2.4566, norm(y): 1.0042, norm:0.5437, tok/sec: 99627.66, flops:104.57, batch-reuse:1
@ 980 train 7.5771 , allloss: 7.5977, dt: 1347.00ms, fracRes: 0.4343, norm(attn): 0.3145, norm(output): 2.2656, norm(x): 2.4753, norm(y): 1.0042, norm:0.4278, tok/sec: 97306.37, flops:102.14, batch-reuse:1
@ 981 train 7.6414 , allloss: 7.6625, dt: 1298.30ms, fracRes: 0.4322, norm(attn): 0.3145, norm(output): 2.2812, norm(x): 2.5309, norm(y): 1.0043, norm:0.4951, tok/sec: 100956.86, flops:105.97, batch-reuse:1
@ 982 train 7.6139 , allloss: 7.6343, dt: 1306.45ms, fracRes: 0.4313, norm(attn): 0.3145, norm(output): 2.2969, norm(x): 2.5442, norm(y): 1.0043, norm:0.3316, tok/sec: 100327.03, flops:105.31, batch-reuse:1
@ 983 train 7.7154 , allloss: 7.7335, dt: 1306.03ms, fracRes: 0.4313, norm(attn): 0.3125, norm(output): 2.3125, norm(x): 2.5379, norm(y): 1.0043, norm:0.5728, tok/sec: 100359.19, flops:105.34, batch-reuse:1
@ 984 train 7.6434 , allloss: 7.6603, dt: 1307.52ms, fracRes: 0.4300, norm(attn): 0.3125, norm(output): 2.2656, norm(x): 2.5328, norm(y): 1.0043, norm:0.3702, tok/sec: 100244.89, flops:105.22, batch-reuse:1
@ 985 train 7.6232 , allloss: 7.6395, dt: 1288.04ms, fracRes: 0.4301, norm(attn): 0.3125, norm(output): 2.2812, norm(x): 2.5262, norm(y): 1.0043, norm:0.4414, tok/sec: 101760.82, flops:106.81, batch-reuse:1
@ 986 train 7.7069 , allloss: 7.7230, dt: 1309.70ms, fracRes: 0.4299, norm(attn): 0.3125, norm(output): 2.2656, norm(x): 2.5157, norm(y): 1.0043, norm:0.4444, tok/sec: 100078.17, flops:105.05, batch-reuse:1
@ 987 train 7.6434 , allloss: 7.6578, dt: 1304.15ms, fracRes: 0.4294, norm(attn): 0.3125, norm(output): 2.2344, norm(x): 2.4560, norm(y): 1.0043, norm:0.3328, tok/sec: 100503.49, flops:105.49, batch-reuse:1
@ 988 train 7.7067 , allloss: 7.7223, dt: 1323.25ms, fracRes: 0.4296, norm(attn): 0.3125, norm(output): 2.1562, norm(x): 2.3900, norm(y): 1.0044, norm:0.3517, tok/sec: 99053.32, flops:103.97, batch-reuse:1
@ 989 train 7.7949 , allloss: 7.8128, dt: 1331.33ms, fracRes: 0.4292, norm(attn): 0.3125, norm(output): 2.0625, norm(x): 2.3021, norm(y): 1.0044, norm:0.4497, tok/sec: 98451.74, flops:103.34, batch-reuse:1
@ 990 train 7.6185 , allloss: 7.6359, dt: 1320.50ms, fracRes: 0.4302, norm(attn): 0.3125, norm(output): 1.9453, norm(x): 2.1887, norm(y): 1.0044, norm:0.3540, tok/sec: 99259.45, flops:104.19, batch-reuse:1
@ 991 train 7.6913 , allloss: 7.7105, dt: 1308.08ms, fracRes: 0.4320, norm(attn): 0.3105, norm(output): 1.7891, norm(x): 2.0336, norm(y): 1.0045, norm:0.2668, tok/sec: 100202.14, flops:105.18, batch-reuse:1
@ 992 train 7.7337 , allloss: 7.7514, dt: 1322.17ms, fracRes: 0.4328, norm(attn): 0.3105, norm(output): 1.6953, norm(x): 1.9409, norm(y): 1.0045, norm:0.2960, tok/sec: 99134.27, flops:104.05, batch-reuse:1
@ 993 train 7.6307 , allloss: 7.6472, dt: 1276.45ms, fracRes: 0.4334, norm(attn): 0.3125, norm(output): 1.6406, norm(x): 1.8952, norm(y): 1.0045, norm:0.2870, tok/sec: 102684.45, flops:107.78, batch-reuse:1
@ 994 train 7.7393 , allloss: 7.7540, dt: 1300.12ms, fracRes: 0.4334, norm(attn): 0.3125, norm(output): 1.6016, norm(x): 1.8575, norm(y): 1.0045, norm:0.2510, tok/sec: 100815.08, flops:105.82, batch-reuse:1
@ 995 train 7.6739 , allloss: 7.6879, dt: 1314.12ms, fracRes: 0.4330, norm(attn): 0.3125, norm(output): 1.5781, norm(x): 1.8268, norm(y): 1.0045, norm:0.2488, tok/sec: 99741.32, flops:104.69, batch-reuse:1
@ 996 train 7.6400 , allloss: 7.6540, dt: 1316.37ms, fracRes: 0.4332, norm(attn): 0.3125, norm(output): 1.5703, norm(x): 1.8058, norm(y): 1.0045, norm:0.4518, tok/sec: 99570.95, flops:104.51, batch-reuse:1
@ 997 train 7.6114 , allloss: 7.6269, dt: 1312.28ms, fracRes: 0.4338, norm(attn): 0.3125, norm(output): 1.5781, norm(x): 1.8139, norm(y): 1.0045, norm:0.2750, tok/sec: 99881.05, flops:104.84, batch-reuse:1
@ 998 train 7.7610 , allloss: 7.7776, dt: 1323.26ms, fracRes: 0.4350, norm(attn): 0.3125, norm(output): 1.5781, norm(x): 1.8260, norm(y): 1.0045, norm:0.3396, tok/sec: 99052.14, flops:103.97, batch-reuse:1
@ 999 train 7.6230 , allloss: 7.6416, dt: 1325.42ms, fracRes: 0.4358, norm(attn): 0.3145, norm(output): 1.5469, norm(x): 1.7988, norm(y): 1.0045, norm:0.2641, tok/sec: 98891.00, flops:103.80, batch-reuse:1
@ 1000 train 7.7697 , allloss: 7.7879, dt: 1306.97ms, fracRes: 0.4349, norm(attn): 0.3145, norm(output): 1.6250, norm(x): 1.8609, norm(y): 1.0045, norm:0.3341, tok/sec: 100286.75, flops:105.26, batch-reuse:1
@ 1001 train 7.6624 , allloss: 7.6801, dt: 1342.74ms, fracRes: 0.4328, norm(attn): 0.3145, norm(output): 1.6719, norm(x): 1.9161, norm(y): 1.0044, norm:0.3826, tok/sec: 97615.11, flops:102.46, batch-reuse:1
@ 1002 train 7.6203 , allloss: 7.6365, dt: 1314.96ms, fracRes: 0.4302, norm(attn): 0.3145, norm(output): 1.7500, norm(x): 1.9851, norm(y): 1.0044, norm:0.4423, tok/sec: 99677.85, flops:104.63, batch-reuse:1
@ 1003 train 7.7177 , allloss: 7.7317, dt: 1313.39ms, fracRes: 0.4295, norm(attn): 0.3164, norm(output): 1.8672, norm(x): 2.1073, norm(y): 1.0044, norm:0.2702, tok/sec: 99796.98, flops:104.75, batch-reuse:1
@ 1004 train 7.6211 , allloss: 7.6353, dt: 1314.95ms, fracRes: 0.4289, norm(attn): 0.3184, norm(output): 1.8906, norm(x): 2.1217, norm(y): 1.0044, norm:0.3103, tok/sec: 99678.04, flops:104.63, batch-reuse:1
@ 1005 train 7.6784 , allloss: 7.6928, dt: 1294.19ms, fracRes: 0.4290, norm(attn): 0.3164, norm(output): 1.9688, norm(x): 2.2058, norm(y): 1.0044, norm:0.3647, tok/sec: 101276.86, flops:106.30, batch-reuse:1
@ 1006 train 7.6778 , allloss: 7.6933, dt: 1314.38ms, fracRes: 0.4282, norm(attn): 0.3242, norm(output): 2.0312, norm(x): 2.2568, norm(y): 1.0044, norm:0.2577, tok/sec: 99721.67, flops:104.67, batch-reuse:1
@ 1007 train 7.6157 , allloss: 7.6319, dt: 1280.45ms, fracRes: 0.4288, norm(attn): 0.3223, norm(output): 1.9609, norm(x): 2.1818, norm(y): 1.0044, norm:0.2513, tok/sec: 102363.87, flops:107.44, batch-reuse:1
@ 1008 train 7.6813 , allloss: 7.6962, dt: 1298.85ms, fracRes: 0.4285, norm(attn): 0.3242, norm(output): 2.0781, norm(x): 2.3182, norm(y): 1.0044, norm:0.3306, tok/sec: 100913.97, flops:105.92, batch-reuse:1
@ 1009 train 7.8313 , allloss: 7.8478, dt: 1316.14ms, fracRes: 0.4282, norm(attn): 0.3242, norm(output): 2.0625, norm(x): 2.2845, norm(y): 1.0044, norm:0.4738, tok/sec: 99588.45, flops:104.53, batch-reuse:1
@ 1010 train 7.7468 , allloss: 7.7617, dt: 1333.28ms, fracRes: 0.4273, norm(attn): 0.3242, norm(output): 2.2031, norm(x): 2.4234, norm(y): 1.0044, norm:0.3655, tok/sec: 98308.12, flops:103.19, batch-reuse:1
@ 1011 train 7.6398 , allloss: 7.6558, dt: 1329.50ms, fracRes: 0.4267, norm(attn): 0.3281, norm(output): 2.1250, norm(x): 2.3795, norm(y): 1.0044, norm:0.4390, tok/sec: 98587.25, flops:103.48, batch-reuse:1
@ 1012 train 7.7316 , allloss: 7.7459, dt: 1303.64ms, fracRes: 0.4277, norm(attn): 0.3320, norm(output): 2.2500, norm(x): 2.4856, norm(y): 1.0044, norm:0.4283, tok/sec: 100543.43, flops:105.53, batch-reuse:1
@ 1013 train 7.6744 , allloss: 7.6867, dt: 1331.36ms, fracRes: 0.4274, norm(attn): 0.3320, norm(output): 2.2188, norm(x): 2.4524, norm(y): 1.0044, norm:0.3130, tok/sec: 98449.50, flops:103.34, batch-reuse:1
@ 1014 train 7.5742 , allloss: 7.5871, dt: 1315.91ms, fracRes: 0.4268, norm(attn): 0.3301, norm(output): 2.1562, norm(x): 2.3904, norm(y): 1.0044, norm:0.4232, tok/sec: 99605.97, flops:104.55, batch-reuse:1
@ 1015 train 7.6620 , allloss: 7.6728, dt: 1299.38ms, fracRes: 0.4264, norm(attn): 0.3340, norm(output): 2.2500, norm(x): 2.4796, norm(y): 1.0044, norm:0.3112, tok/sec: 100872.61, flops:105.88, batch-reuse:1
@ 1016 train 7.6879 , allloss: 7.6961, dt: 1294.73ms, fracRes: 0.4263, norm(attn): 0.3379, norm(output): 2.2812, norm(x): 2.5026, norm(y): 1.0044, norm:0.4269, tok/sec: 101234.66, flops:106.26, batch-reuse:1
@ 1017 train 7.6125 , allloss: 7.6201, dt: 1326.80ms, fracRes: 0.4266, norm(attn): 0.3359, norm(output): 2.1875, norm(x): 2.4052, norm(y): 1.0045, norm:0.4062, tok/sec: 98787.98, flops:103.69, batch-reuse:1
@ 1018 train 7.7152 , allloss: 7.7241, dt: 1322.81ms, fracRes: 0.4286, norm(attn): 0.3320, norm(output): 2.0781, norm(x): 2.2861, norm(y): 1.0045, norm:0.3227, tok/sec: 99086.11, flops:104.00, batch-reuse:1
@ 1019 train 7.7005 , allloss: 7.7078, dt: 1320.00ms, fracRes: 0.4282, norm(attn): 0.3340, norm(output): 2.0156, norm(x): 2.2454, norm(y): 1.0045, norm:0.2890, tok/sec: 99297.14, flops:104.23, batch-reuse:1
@ 1020 train 7.6666 , allloss: 7.6737, dt: 1313.78ms, fracRes: 0.4318, norm(attn): 0.3281, norm(output): 2.0000, norm(x): 2.2115, norm(y): 1.0045, norm:0.3344, tok/sec: 99767.21, flops:104.72, batch-reuse:1
@ 1021 train 7.6777 , allloss: 7.6852, dt: 1318.54ms, fracRes: 0.4340, norm(attn): 0.3281, norm(output): 1.9375, norm(x): 2.1417, norm(y): 1.0046, norm:0.4028, tok/sec: 99407.25, flops:104.34, batch-reuse:1
@ 1022 train 7.6091 , allloss: 7.6176, dt: 1340.07ms, fracRes: 0.4382, norm(attn): 0.3242, norm(output): 1.8281, norm(x): 2.0280, norm(y): 1.0046, norm:0.3381, tok/sec: 97809.69, flops:102.66, batch-reuse:1
@ 1023 train 7.6613 , allloss: 7.6702, dt: 1310.39ms, fracRes: 0.4455, norm(attn): 0.3242, norm(output): 1.7188, norm(x): 1.9132, norm(y): 1.0047, norm:0.2978, tok/sec: 100025.00, flops:104.99, batch-reuse:1
@ 1024 train 7.5928 , allloss: 7.6004, dt: 1333.07ms, fracRes: 0.4472, norm(attn): 0.3242, norm(output): 1.6719, norm(x): 1.8560, norm(y): 1.0048, norm:0.3484, tok/sec: 98323.52, flops:103.20, batch-reuse:1
@ 1025 train 7.6594 , allloss: 7.6666, dt: 1330.73ms, fracRes: 0.4441, norm(attn): 0.3242, norm(output): 1.6562, norm(x): 1.8429, norm(y): 1.0048, norm:0.3096, tok/sec: 98496.28, flops:103.38, batch-reuse:1
@ 1026 train 7.7142 , allloss: 7.7210, dt: 1294.33ms, fracRes: 0.4454, norm(attn): 0.3242, norm(output): 1.6719, norm(x): 1.8455, norm(y): 1.0048, norm:0.3263, tok/sec: 101266.34, flops:106.29, batch-reuse:1
@ 1027 train 7.7523 , allloss: 7.7589, dt: 1282.60ms, fracRes: 0.4483, norm(attn): 0.3242, norm(output): 1.6719, norm(x): 1.8599, norm(y): 1.0048, norm:0.3404, tok/sec: 102192.43, flops:107.26, batch-reuse:1
@ 1028 train 7.6134 , allloss: 7.6189, dt: 1293.46ms, fracRes: 0.4480, norm(attn): 0.3262, norm(output): 1.6797, norm(x): 1.8566, norm(y): 1.0048, norm:0.2825, tok/sec: 101334.34, flops:106.36, batch-reuse:1
@ 1029 train 7.6344 , allloss: 7.6395, dt: 1323.91ms, fracRes: 0.4466, norm(attn): 0.3242, norm(output): 1.7031, norm(x): 1.8766, norm(y): 1.0048, norm:0.3426, tok/sec: 99003.41, flops:103.92, batch-reuse:1
@ 1030 train 7.7213 , allloss: 7.7264, dt: 1328.79ms, fracRes: 0.4471, norm(attn): 0.3281, norm(output): 1.7266, norm(x): 1.9047, norm(y): 1.0048, norm:0.5245, tok/sec: 98640.30, flops:103.54, batch-reuse:1
@ 1031 train 7.7036 , allloss: 7.7088, dt: 1352.16ms, fracRes: 0.4464, norm(attn): 0.3281, norm(output): 1.7578, norm(x): 1.9294, norm(y): 1.0048, norm:0.2468, tok/sec: 96935.55, flops:101.75, batch-reuse:1
@ 1032 train 7.6281 , allloss: 7.6337, dt: 1349.76ms, fracRes: 0.4459, norm(attn): 0.3301, norm(output): 1.7734, norm(x): 1.9526, norm(y): 1.0048, norm:0.3203, tok/sec: 97107.66, flops:101.93, batch-reuse:1
@ 1033 train 7.6193 , allloss: 7.6242, dt: 1321.11ms, fracRes: 0.4466, norm(attn): 0.3281, norm(output): 1.7812, norm(x): 1.9612, norm(y): 1.0048, norm:0.3164, tok/sec: 99213.84, flops:104.14, batch-reuse:1
@ 1034 train 7.6237 , allloss: 7.6287, dt: 1279.98ms, fracRes: 0.4430, norm(attn): 0.3320, norm(output): 1.8359, norm(x): 2.0195, norm(y): 1.0047, norm:0.4420, tok/sec: 102401.78, flops:107.48, batch-reuse:1
@ 1035 train 7.6333 , allloss: 7.6379, dt: 1293.06ms, fracRes: 0.4434, norm(attn): 0.3379, norm(output): 1.8750, norm(x): 2.0480, norm(y): 1.0047, norm:0.3745, tok/sec: 101366.08, flops:106.40, batch-reuse:1
@ 1036 train 7.6962 , allloss: 7.7007, dt: 1297.00ms, fracRes: 0.4407, norm(attn): 0.3379, norm(output): 1.9062, norm(x): 2.0942, norm(y): 1.0047, norm:0.2911, tok/sec: 101057.70, flops:106.07, batch-reuse:1
@ 1037 train 7.6798 , allloss: 7.6842, dt: 1312.35ms, fracRes: 0.4416, norm(attn): 0.3359, norm(output): 1.9766, norm(x): 2.1574, norm(y): 1.0046, norm:0.3724, tok/sec: 99875.83, flops:104.83, batch-reuse:1
@ 1038 train 7.6438 , allloss: 7.6479, dt: 1310.78ms, fracRes: 0.4395, norm(attn): 0.3418, norm(output): 2.0469, norm(x): 2.2348, norm(y): 1.0046, norm:0.3145, tok/sec: 99995.06, flops:104.96, batch-reuse:1
@ 1039 train 7.6039 , allloss: 7.6080, dt: 1318.01ms, fracRes: 0.4409, norm(attn): 0.3398, norm(output): 2.1094, norm(x): 2.3032, norm(y): 1.0046, norm:0.3728, tok/sec: 99446.80, flops:104.38, batch-reuse:1
@ 1040 train 7.4854 , allloss: 7.4891, dt: 1299.01ms, fracRes: 0.4375, norm(attn): 0.3418, norm(output): 2.1719, norm(x): 2.3801, norm(y): 1.0045, norm:0.5621, tok/sec: 100901.19, flops:105.91, batch-reuse:1
@ 1041 train 7.5631 , allloss: 7.5669, dt: 1326.00ms, fracRes: 0.4375, norm(attn): 0.3418, norm(output): 2.2656, norm(x): 2.4659, norm(y): 1.0045, norm:0.3842, tok/sec: 98847.74, flops:103.75, batch-reuse:1
@ 1042 train 7.6026 , allloss: 7.6062, dt: 1307.42ms, fracRes: 0.4383, norm(attn): 0.3418, norm(output): 2.3594, norm(x): 2.5271, norm(y): 1.0045, norm:0.2553, tok/sec: 100252.15, flops:105.23, batch-reuse:1
@ 1043 train 7.6404 , allloss: 7.6439, dt: 1298.33ms, fracRes: 0.4391, norm(attn): 0.3438, norm(output): 2.3906, norm(x): 2.5725, norm(y): 1.0045, norm:0.3034, tok/sec: 100954.30, flops:105.96, batch-reuse:1
@ 1044 train 7.6907 , allloss: 7.6945, dt: 1299.07ms, fracRes: 0.4410, norm(attn): 0.3438, norm(output): 2.4844, norm(x): 2.6225, norm(y): 1.0045, norm:0.4255, tok/sec: 100896.66, flops:105.90, batch-reuse:1
@ 1045 train 7.6726 , allloss: 7.6767, dt: 1313.49ms, fracRes: 0.4477, norm(attn): 0.3438, norm(output): 2.5000, norm(x): 2.6718, norm(y): 1.0045, norm:0.2549, tok/sec: 99788.92, flops:104.74, batch-reuse:1
@ 1046 train 7.6107 , allloss: 7.6156, dt: 1329.22ms, fracRes: 0.4561, norm(attn): 0.3418, norm(output): 2.5156, norm(x): 2.6759, norm(y): 1.0045, norm:0.2941, tok/sec: 98608.03, flops:103.50, batch-reuse:1
@ 1047 train 7.6149 , allloss: 7.6205, dt: 1334.01ms, fracRes: 0.4661, norm(attn): 0.3398, norm(output): 2.5156, norm(x): 2.6958, norm(y): 1.0045, norm:0.3081, tok/sec: 98254.21, flops:103.13, batch-reuse:1
@ 1048 train 7.6082 , allloss: 7.6171, dt: 1332.99ms, fracRes: 0.4791, norm(attn): 0.3320, norm(output): 2.5156, norm(x): 2.6947, norm(y): 1.0044, norm:0.3856, tok/sec: 98329.24, flops:103.21, batch-reuse:1
@ 1049 train 7.6055 , allloss: 7.6150, dt: 1294.93ms, fracRes: 0.4857, norm(attn): 0.3320, norm(output): 2.5000, norm(x): 2.6693, norm(y): 1.0044, norm:0.3505, tok/sec: 101219.35, flops:106.24, batch-reuse:1
tensor([[    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.8867,     0.1152,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.4238,     0.2295,     0.3457,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.2773,     0.1318,     0.4570,     0.1328,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.2617,     0.0391,     0.1768,     0.4336,     0.0879,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.4531,     0.0435,     0.2637,     0.1924,     0.0444,     0.0017,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.2061,     0.1309,     0.1787,     0.1709,     0.0623,     0.0840,     0.1670,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.1816,     0.1309,     0.2012,     0.1445,     0.0352,     0.0060,     0.0674,     0.2324,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.2871,     0.0081,     0.1523,     0.2910,     0.0089,     0.0003,     0.0107,     0.2412,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.1250,     0.0388,     0.2070,     0.1768,     0.0505,     0.0278,     0.0327,     0.2021,     0.0596,     0.0806,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.2793,     0.0143,     0.1387,     0.1836,     0.0452,     0.0018,     0.0259,     0.2441,     0.0006,     0.0623,     0.0036,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.1338,     0.0515,     0.2090,     0.0986,     0.0413,     0.0082,     0.0283,     0.1729,     0.0033,     0.0654,     0.0116,     0.1748,     0.0000,     0.0000,     0.0000],
        [    0.0209,     0.0659,     0.0231,     0.0388,     0.0581,     0.2461,     0.0447,     0.0312,     0.2480,     0.0991,     0.0786,     0.0339,     0.0109,     0.0000,     0.0000],
        [    0.1191,     0.0219,     0.1011,     0.1543,     0.0481,     0.0139,     0.0299,     0.1182,     0.0060,     0.0430,     0.0109,     0.1187,     0.2061,     0.0096,     0.0000],
        [    0.1011,     0.0864,     0.0962,     0.0742,     0.0659,     0.0188,     0.0361,     0.1279,     0.0120,     0.0522,     0.0122,     0.1050,     0.1777,     0.0222,     0.0125]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[     0.0026,     -0.0020,     -0.0309,  ...,     -0.0141,      0.0227,     -0.0178],
        [    -0.0239,     -0.0198,      0.0152,  ...,      0.0123,     -0.0042,      0.0307],
        [     0.0298,      0.0518,      0.0504,  ...,     -0.0077,      0.0046,      0.0002],
        ...,
        [     0.0277,      0.0415,     -0.0258,  ...,      0.0188,     -0.0192,     -0.0196],
        [     0.0451,     -0.0025,     -0.0251,  ...,     -0.0040,     -0.0214,      0.0411],
        [    -0.0478,      0.0001,      0.0181,  ...,      0.0028,     -0.0033,     -0.0013]], device='cuda:0', requires_grad=True)
K: tensor([-0.8438, -1.1719, -0.4746, -1.3750,  0.2930,  0.4844,  0.1865, -1.0859,  1.0000,  0.0391,  0.7227,  0.9141, -1.7188, -1.3047, -0.8672, -0.2441,  0.9805, -1.1875, -0.4199, -0.1157, -0.3496,  0.5352, -1.7188,  0.9727,  0.4980, -0.2393,  0.3418,  0.0136, -0.1660,  1.0391,  0.6953, -1.4219,
        -0.5703, -0.2930, -0.8438,  1.3984,  0.7031, -1.1562,  0.1729, -0.5352,  0.5156, -0.5195,  0.0684,  0.6797,  0.4160, -0.6641,  0.4023, -0.3359,  0.5352, -1.5156, -0.1157,  0.8438,  0.1748, -0.1973,  1.3984,  1.0391, -0.6719,  1.5781,  0.7500, -0.5664,  0.5547,  0.2852,  0.2656,  0.0151],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[-0.0648, -0.0100,  0.0287,  ...,  0.0177,  0.0150,  0.0282],
        [-0.0308, -0.0005,  0.0151,  ...,  0.0164,  0.0051, -0.0129],
        [ 0.0670, -0.0267, -0.0274,  ..., -0.0442, -0.0043,  0.0092],
        ...,
        [-0.0163,  0.0370,  0.0026,  ...,  0.0091, -0.0341, -0.0128],
        [-0.0325,  0.0223,  0.0112,  ..., -0.0195, -0.0207, -0.0018],
        [ 0.0082, -0.0207,  0.0051,  ...,  0.0109,  0.0130,  0.0337]], device='cuda:0', requires_grad=True)
Q: tensor([ 0.3359,  0.2334,  0.8828,  0.9570,  0.2422, -0.9648,  0.8477,  0.4277, -0.1895,  0.6094, -0.7930, -0.5938,  0.9805, -0.6328, -0.3691, -0.3477, -0.9531,  1.0156, -0.0251,  0.1729,  0.0036, -0.3438, -0.3691, -0.2852,  0.1138,  0.0469, -0.3906,  0.3848,  0.2891, -0.5273, -0.0077, -0.0036,
        -0.4727, -0.0811,  0.1177, -0.1855,  0.0540,  1.3125, -0.5078,  0.9609, -0.6758,  1.6562,  0.1758, -0.6445,  0.0737,  0.6836, -1.0859,  0.8047, -0.3906,  0.5039, -0.4668, -0.2773, -0.6758,  0.4375, -0.2598, -0.1177, -0.2363, -0.9648, -0.9141,  0.7383,  0.1602, -0.2334, -0.5312, -0.2070],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[     0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000],
        [     0.0000,     -2.0312,     -0.3125,     -0.4512,     -2.0000,     -2.8125,     -1.6797,     -0.0347,     -4.4062,     -0.9375,     -3.0938,      0.7891,      0.9102,     -3.3281,     -1.8984],
        [     0.0000,     -0.6133,     -0.2031,     -0.6250,     -0.1533,     -0.0962,      0.0069,      0.6250,     -0.3320,     -0.4180,     -0.3848,      0.6914,      0.4297,      0.2988,     -0.2158],
        [     0.0000,     -0.7500,      0.4961,     -0.7383,     -0.6680,     -2.1875,     -0.4395,     -0.0923,     -2.3125,     -0.8555,     -1.7656,     -0.2832,      0.7383,     -0.9844,     -0.9570],
        [     0.0000,     -1.9062,     -0.3945,      0.5039,     -1.0938,     -2.2031,     -0.8867,     -0.1553,     -2.0312,     -0.8906,     -0.8047,     -0.0153,      0.8672,     -1.3438,     -1.4844],
        [     0.0000,     -2.3438,     -0.5391,     -0.8594,     -2.3281,     -5.5625,     -2.0156,     -0.7227,     -6.9375,     -1.8125,     -4.4688,      0.4980,      0.8086,     -5.5938,     -3.7969],
        [     0.0000,     -0.4551,     -0.1426,     -0.1875,     -1.1953,     -0.8984,     -0.2109,     -0.4180,     -1.7578,     -0.1797,     -1.4062,      0.2246,      0.1143,     -0.9688,     -0.5938],
        [     0.0000,     -0.3281,      0.1001,     -0.2334,     -1.6406,     -3.4062,     -0.9883,      0.2461,     -3.3281,     -0.7656,     -2.6250,      0.4707,      0.5820,     -3.1406,     -1.9766],
        [     0.0000,     -3.5625,     -0.6367,      0.0149,     -3.4844,     -6.9375,     -3.2969,     -0.1758,     -9.3750,     -2.4219,     -6.8125,      0.8125,      1.2188,     -7.4375,     -5.0938],
        [     0.0000,     -1.1641,      0.5078,      0.3477,     -0.9023,     -1.5000,     -1.3359,      0.4805,     -0.7383,     -0.4375,     -1.1328,      0.6719,     -0.0552,     -1.0781,     -1.2969],
        [     0.0000,     -2.9688,     -0.6992,     -0.4199,     -1.8203,     -5.0312,     -2.3750,     -0.1328,     -6.0938,     -1.5000,     -4.3438,     -0.4590,      0.7852,     -4.6875,     -3.2969],
        [     0.0000,     -0.9531,      0.4453,     -0.3086,     -1.1797,     -2.7969,     -1.5547,      0.2559,     -3.7031,     -0.7188,     -2.4531,      0.2676,      0.8516,     -3.0469,     -2.2188],
        [     0.0000,      1.1484,      0.0977,      0.6172,      1.0234,      2.4688,      0.7617,      0.4043,      2.4688,      1.5547,      1.3281,      0.4844,     -0.6562,      1.7266,      0.6094],
        [     0.0000,     -1.6953,     -0.1621,      0.2598,     -0.9062,     -2.1562,     -1.3750,     -0.0068,     -2.9844,     -1.0156,     -2.3906,     -0.0017,      0.5469,     -2.5156,     -1.9531],
        [     0.0000,     -0.1582,     -0.0513,     -0.3105,     -0.4277,     -1.6875,     -1.0312,      0.2305,     -2.1406,     -0.6602,     -2.1094,      0.0339,      0.5586,     -1.5156,     -2.0938]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.9320],
        [0.3199],
        [0.3488],
        [0.2618],
        [0.3670],
        [0.1671],
        [0.1871],
        [0.2169],
        [0.1367],
        [0.1912],
        [0.1683],
        [0.0451],
        [0.0891],
        [0.1022]], device='cuda:0')
tensor([[    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.4863,     0.5117,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.1807,     0.7344,     0.0835,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0659,     0.7383,     0.1943,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.1235,     0.7148,     0.1602,     0.0001,     0.0024,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0498,     0.6055,     0.3457,     0.0000,     0.0001,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0952,     0.5000,     0.4043,     0.0000,     0.0007,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.2227,     0.5117,     0.1465,     0.0137,     0.0420,     0.0096,     0.0209,     0.0332,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.1621,     0.4609,     0.3379,     0.0006,     0.0066,     0.0004,     0.0006,     0.0251,     0.0065,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0432,     0.4102,     0.5469,     0.0000,     0.0001,     0.0000,     0.0000,     0.0017,     0.0001,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0884,     0.6250,     0.2773,     0.0000,     0.0007,     0.0000,     0.0000,     0.0084,     0.0008,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0640,     0.6211,     0.3125,     0.0000,     0.0002,     0.0000,     0.0000,     0.0015,     0.0003,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.1680,     0.3047,     0.2207,     0.0129,     0.0439,     0.0157,     0.0128,     0.0752,     0.0693,     0.0048,     0.0220,     0.0039,     0.0457,     0.0000,     0.0000],
        [    0.0339,     0.4766,     0.4883,     0.0000,     0.0000,     0.0000,     0.0000,     0.0004,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0378,     0.1885,     0.7695,     0.0000,     0.0001,     0.0000,     0.0000,     0.0028,     0.0001,     0.0000,     0.0000,     0.0000,     0.0001,     0.0000,     0.0000]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[-0.0221,  0.0007,  0.0032,  ..., -0.0186, -0.0045, -0.0004],
        [ 0.0288, -0.0125,  0.0035,  ..., -0.0068, -0.0249,  0.0046],
        [ 0.0111, -0.0025, -0.0247,  ...,  0.0039, -0.0397,  0.0266],
        ...,
        [ 0.0005, -0.0012, -0.0251,  ...,  0.0049,  0.0230, -0.0224],
        [-0.0187, -0.0344, -0.0325,  ..., -0.0215,  0.0452, -0.0232],
        [-0.0299, -0.0026, -0.0038,  ...,  0.0270,  0.0537, -0.0012]], device='cuda:0', requires_grad=True)
K: tensor([-1.1406, -2.5625,  0.5547,  1.5703,  3.0000, -2.4844,  0.5352, -2.3594, -0.0918,  1.9688,  0.5898,  1.0703, -3.6562,  1.0938,  0.7852,  1.5625,  1.9375, -0.7656,  0.9727,  2.3125,  1.0781, -0.9688,  1.8281,  1.4297,  2.3594,  0.6758, -2.5469, -1.4453, -0.7656,  2.1875, -0.3398,  2.5312,
         1.7891,  1.0312,  2.0781, -2.1094,  1.5781,  0.2812, -0.3594,  0.8320, -0.1182,  0.8789, -2.0469,  0.5898, -0.0566,  2.0156, -0.9141, -1.4062,  0.0220,  1.5938,  2.2812, -0.3086,  2.1562,  1.7266, -1.7422,  1.8750,  0.8516,  1.3203, -1.7344,  0.9414,  2.5625, -0.3926,  1.7266,  1.6875],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[ 0.0093, -0.0073,  0.0103,  ...,  0.0250,  0.0104, -0.0317],
        [-0.0264,  0.0221,  0.0043,  ...,  0.0066,  0.0269,  0.0129],
        [ 0.0080,  0.0156, -0.0313,  ..., -0.0310,  0.0015,  0.0066],
        ...,
        [ 0.0105, -0.0261, -0.0090,  ...,  0.0088, -0.0059,  0.0049],
        [ 0.0285, -0.0130, -0.0152,  ...,  0.0039, -0.0157,  0.0128],
        [-0.0152,  0.0026, -0.0447,  ...,  0.0078, -0.0271,  0.0030]], device='cuda:0', requires_grad=True)
Q: tensor([     0.9258,      2.4375,      0.0835,     -1.3672,     -2.6094,      2.5781,     -2.2188,      1.8438,      0.6367,     -2.3125,      0.3848,     -0.5977,      3.6719,     -0.1328,     -0.2988,     -1.7188,     -1.1406,      0.0018,      0.6055,     -1.9766,     -0.6289,      2.2500,
            -1.6406,     -2.3750,     -1.8672,      1.9141,      1.9766,     -0.0515,      0.8477,     -3.3906,     -0.3965,     -2.5156,     -1.1172,     -0.7266,     -2.0469,      2.1562,     -2.2031,     -0.6523,      0.9297,     -0.3555,      0.5312,     -1.6250,      2.3594,     -0.8789,
            -0.0884,     -0.8906,      1.5469,      2.8125,      1.3203,     -2.0625,     -1.6797,     -0.7852,     -2.0469,     -1.5938,      2.0625,     -2.6406,      0.2539,     -1.8516,      1.4297,     -1.2109,     -1.1406,      0.7930,     -1.7500,     -3.0781], device='cuda:0',
       dtype=torch.bfloat16)
RAWVALUES
tensor([[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
        [  0.0000,   0.0525,   0.6680,  -1.2969,  -0.5938,  -1.5859,  -1.3828,  -0.1621,  -0.9531,  -2.7500,  -1.0312,  -2.1406,  -0.9961,  -3.0156,  -2.7344],
        [  0.0000,   1.4062,  -0.7695,  -6.1250,  -3.8750,  -6.7188,  -5.3438,  -2.8594,  -3.2344,  -6.4062,  -5.3438,  -5.6562,  -1.9375,  -9.0625,  -4.4062],
        [  0.0000,   2.4219,   1.0781, -11.7500,  -6.5312, -12.1875, -11.3750,  -4.5000,  -6.3438, -16.3750, -10.8125, -14.3750,  -5.3438, -19.8750, -15.2500],
        [  0.0000,   1.7578,   0.2578,  -7.0625,  -3.9531,  -6.7188,  -6.0938,  -2.7344,  -3.4688,  -9.1250,  -5.7812,  -8.1875,  -3.0156, -11.0000,  -8.1875],
        [  0.0000,   2.5000,   1.9375, -11.4375,  -6.6250, -11.9375, -11.0000,  -4.2812,  -6.3125, -17.1250, -10.6250, -14.5000,  -5.1875, -20.3750, -15.8750],
        [  0.0000,   1.6641,   1.4453,  -8.1250,  -4.8750,  -8.6250,  -8.8125,  -2.7031,  -4.3125, -13.4375,  -7.6562, -11.3750,  -4.3750, -15.0625, -12.8750],
        [  0.0000,   0.8320,  -0.4180,  -2.7812,  -1.6719,  -3.1406,  -2.3594,  -1.8984,  -1.9531,  -3.5156,  -2.6250,  -2.3125,  -0.9844,  -3.7500,  -2.5781],
        [  0.0000,   1.0391,   0.7344,  -5.5938,  -3.2031,  -6.1250,  -5.6250,  -1.8594,  -3.2188,  -8.8750,  -5.2500,  -7.3438,  -2.6875, -10.3750,  -8.6875],
        [  0.0000,   2.2500,   2.5312, -11.9375,  -6.4062, -12.3750, -11.9375,  -3.2500,  -6.2812, -19.2500, -11.4375, -16.3750,  -5.7812, -22.0000, -19.2500],
        [  0.0000,   1.9531,   1.1484,  -8.2500,  -4.8750,  -9.0000,  -8.1875,  -2.3438,  -4.7500, -12.5000,  -8.0625, -10.3750,  -3.8281, -14.9375, -12.2500],
        [  0.0000,   2.2812,   1.5859, -10.3125,  -5.8750, -10.6875, -10.4375,  -3.7812,  -5.3750, -15.8750,  -9.5625, -14.0000,  -5.4062, -18.1250, -15.3125],
        [  0.0000,   0.5977,   0.2715,  -2.5625,  -1.3438,  -2.3750,  -2.5781,  -0.8047,  -0.8906,  -3.5625,  -2.0312,  -3.7500,  -1.3047,  -3.6719,  -3.9219],
        [  0.0000,   2.6406,   2.6719, -14.3750,  -8.1875, -15.1875, -14.1250,  -4.5312,  -7.4375, -21.8750, -13.8125, -18.7500,  -6.5312, -25.8750, -21.3750],
        [  0.0000,   1.6094,   3.0156, -10.8125,  -5.7500, -11.6875, -11.8125,  -2.5938,  -6.0312, -18.7500, -10.5625, -16.3750,  -5.9062, -20.8750, -19.7500]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.6418],
        [0.2576],
        [0.1760],
        [0.2067],
        [0.1720],
        [0.1893],
        [0.2149],
        [0.1938],
        [0.1370],
        [0.1606],
        [0.1628],
        [0.1544],
        [0.1326],
        [0.1242]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3242, 0.6758, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5000, 0.0762, 0.4238, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2598, 0.0601, 0.2480, 0.4336, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1855, 0.0410, 0.1787, 0.3203, 0.2754, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1426, 0.0327, 0.1377, 0.2402, 0.2080, 0.2393, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1133, 0.0270, 0.1118, 0.1914, 0.1670, 0.1904, 0.1992, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0952, 0.0225, 0.0952, 0.1631, 0.1416, 0.1621, 0.1699, 0.1494, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0830, 0.0201, 0.0820, 0.1406, 0.1221, 0.1396, 0.1455, 0.1289, 0.1387, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0728, 0.0176, 0.0708, 0.1211, 0.1055, 0.1206, 0.1260, 0.1113, 0.1201, 0.1348, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0640, 0.0152, 0.0630, 0.1084, 0.0938, 0.1074, 0.1123, 0.0991, 0.1069, 0.1201, 0.1094, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0579, 0.0139, 0.0564, 0.0967, 0.0840, 0.0962, 0.1001, 0.0884, 0.0957, 0.1069, 0.0972, 0.1069, 0.0000, 0.0000, 0.0000],
        [0.0520, 0.0129, 0.0520, 0.0874, 0.0762, 0.0869, 0.0908, 0.0806, 0.0864, 0.0967, 0.0884, 0.0967, 0.0933, 0.0000, 0.0000],
        [0.0476, 0.0113, 0.0466, 0.0801, 0.0698, 0.0796, 0.0830, 0.0732, 0.0791, 0.0889, 0.0811, 0.0894, 0.0854, 0.0845, 0.0000],
        [0.0442, 0.0112, 0.0437, 0.0728, 0.0640, 0.0728, 0.0757, 0.0674, 0.0723, 0.0806, 0.0737, 0.0806, 0.0776, 0.0767, 0.0874]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[     0.0087,     -0.0133,      0.0075,  ...,      0.0216,     -0.0291,      0.0099],
        [     0.0169,     -0.0151,      0.0283,  ...,     -0.0145,     -0.0117,      0.0100],
        [    -0.0073,      0.0001,      0.0120,  ...,      0.0359,     -0.0061,     -0.0054],
        ...,
        [     0.0091,      0.0128,     -0.0335,  ...,      0.0074,     -0.0217,      0.0294],
        [    -0.0093,     -0.0072,     -0.0276,  ...,     -0.0059,     -0.0049,      0.0211],
        [     0.0214,      0.0222,      0.0319,  ...,      0.0271,     -0.0000,     -0.0123]], device='cuda:0', requires_grad=True)
K: tensor([     0.4219,     -0.9922,      0.6172,      0.3848,      1.1094,     -0.1416,      0.2236,      1.2891,     -0.2412,     -0.6328,     -0.7656,     -0.6367,     -0.9609,      0.9141,      0.7500,      0.5508,     -0.1865,     -0.6367,      0.4023,      0.1621,     -0.1533,     -0.5703,
            -1.3438,     -0.0486,      0.9570,     -0.8516,      1.2266,      1.1719,     -0.1455,     -1.4375,      0.1797,     -0.1074,      0.2324,     -0.5273,      1.3516,      0.2754,     -0.2422,      0.0012,      0.5117,     -0.8320,     -0.0332,      0.0369,     -0.2373,     -0.2852,
             0.3574,      0.0684,     -0.0786,      0.8320,      0.0258,     -0.1021,      1.2188,     -0.5000,      0.9531,      1.4219,     -0.7305,      0.7031,      0.6289,      0.5117,      0.4883,     -0.1079,      1.0391,     -0.5898,      0.2148,     -0.7734], device='cuda:0',
       dtype=torch.bfloat16)
Qweights
tensor([[ 0.0046,  0.0024,  0.0094,  ...,  0.0078,  0.0339, -0.0145],
        [-0.0255,  0.0332, -0.0395,  ...,  0.0134,  0.0561, -0.0022],
        [ 0.0025, -0.0163, -0.0069,  ..., -0.0228, -0.0078, -0.0055],
        ...,
        [ 0.0231,  0.0110, -0.0039,  ..., -0.0273, -0.0405,  0.0348],
        [ 0.0403,  0.0094, -0.0193,  ...,  0.0360,  0.0026,  0.0161],
        [ 0.0167, -0.0165,  0.0089,  ...,  0.0191,  0.0053,  0.0066]], device='cuda:0', requires_grad=True)
Q: tensor([-2.2031, -0.6602,  0.4902,  1.3516, -0.1709,  0.9219,  1.0234,  0.5430, -1.2969,  0.3418, -0.2432,  0.2275, -1.0859,  0.3125,  0.8086,  0.5508, -1.0469, -1.0703, -0.3984,  0.3223, -0.4492,  0.8086,  0.0815, -0.4727, -0.1240,  1.2422, -0.5664, -0.1206,  0.2344, -0.2773, -1.4531,  0.0840,
        -1.4219, -1.1172, -0.1152,  0.2285,  1.4219,  0.6172, -0.6055, -0.3887,  0.7031,  0.5664,  0.0420, -1.1094, -0.1572, -0.0289,  1.8672,  0.5625, -1.0391, -0.6367, -0.4824, -1.0938,  1.4453,  0.8047,  0.8086,  0.6875,  1.5547, -0.7891, -0.3887,  0.0938,  0.5273, -0.4355, -0.9844,  0.3086],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[     0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000,      0.0000],
        [     0.0000,      0.7383,     -0.1226,     -0.3379,     -0.3105,     -0.3359,     -0.3535,     -0.3457,     -0.3516,     -0.3652,     -0.3516,     -0.3652,     -0.3711,     -0.3535,     -0.3828],
        [     0.0000,     -1.8828,     -0.1611,      0.6094,      0.4141,      0.6016,      0.6562,      0.4844,      0.5898,      0.7500,      0.6172,      0.7539,      0.6953,      0.6758,      0.8633],
        [     0.0000,     -1.4609,     -0.0439,      0.5117,      0.3691,      0.5078,      0.5508,      0.4238,      0.5039,      0.6172,      0.5234,      0.6211,      0.5781,      0.5625,      0.7031],
        [     0.0000,     -1.5078,     -0.0366,      0.5430,      0.3906,      0.5352,      0.5820,      0.4492,      0.5312,      0.6523,      0.5508,      0.6523,      0.6094,      0.5938,      0.7383],
        [     0.0000,     -1.4688,     -0.0337,      0.5273,      0.3789,      0.5195,      0.5625,      0.4355,      0.5156,      0.6328,      0.5352,      0.6328,      0.5938,      0.5781,      0.7188],
        [     0.0000,     -1.4375,     -0.0136,      0.5234,      0.3848,      0.5195,      0.5625,      0.4375,      0.5156,      0.6289,      0.5352,      0.6289,      0.5898,      0.5742,      0.7109],
        [     0.0000,     -1.4453,     -0.0030,      0.5391,      0.3984,      0.5352,      0.5781,      0.4512,      0.5273,      0.6445,      0.5469,      0.6445,      0.6055,      0.5898,      0.7266],
        [     0.0000,     -1.4219,     -0.0133,      0.5234,      0.3828,      0.5156,      0.5586,      0.4355,      0.5117,      0.6250,      0.5312,      0.6250,      0.5859,      0.5742,      0.7070],
        [     0.0000,     -1.4219,     -0.0258,      0.5078,      0.3691,      0.5039,      0.5469,      0.4219,      0.4980,      0.6133,      0.5195,      0.6133,      0.5742,      0.5586,      0.6953],
        [     0.0000,     -1.4375,     -0.0161,      0.5273,      0.3848,      0.5195,      0.5625,      0.4395,      0.5156,      0.6289,      0.5352,      0.6328,      0.5898,      0.5781,      0.7109],
        [     0.0000,     -1.4297,     -0.0247,      0.5117,      0.3711,      0.5078,      0.5469,      0.4258,      0.5000,      0.6133,      0.5195,      0.6172,      0.5781,      0.5625,      0.6953],
        [     0.0000,     -1.3906,      0.0012,      0.5195,      0.3828,      0.5156,      0.5547,      0.4355,      0.5078,      0.6211,      0.5273,      0.6211,      0.5820,      0.5703,      0.6992],
        [     0.0000,     -1.4375,     -0.0204,      0.5234,      0.3809,      0.5195,      0.5625,      0.4355,      0.5117,      0.6289,      0.5312,      0.6289,      0.5898,      0.5742,      0.7109],
        [     0.0000,     -1.3750,     -0.0080,      0.5039,      0.3691,      0.4980,      0.5391,      0.4199,      0.4922,      0.6016,      0.5117,      0.6055,      0.5664,      0.5508,      0.6797]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.5454],
        [0.4180],
        [0.2084],
        [0.1406],
        [0.1081],
        [0.0883],
        [0.0738],
        [0.0637],
        [0.0554],
        [0.0487],
        [0.0445],
        [0.0409],
        [0.0358],
        [0.0345]], device='cuda:0')
tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5469, 0.4551, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3594, 0.2344, 0.4062, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2598, 0.1699, 0.2754, 0.2969, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1934, 0.1235, 0.2178, 0.2334, 0.2314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1562, 0.1001, 0.1777, 0.1895, 0.1885, 0.1885, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1299, 0.0825, 0.1514, 0.1592, 0.1592, 0.1592, 0.1582, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.1094, 0.0698, 0.1318, 0.1377, 0.1387, 0.1387, 0.1387, 0.1357, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0972, 0.0620, 0.1162, 0.1211, 0.1221, 0.1221, 0.1216, 0.1187, 0.1191, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0864, 0.0552, 0.1040, 0.1084, 0.1094, 0.1094, 0.1089, 0.1060, 0.1064, 0.1060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0771, 0.0496, 0.0942, 0.0972, 0.0986, 0.0991, 0.0986, 0.0967, 0.0967, 0.0967, 0.0952, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0708, 0.0454, 0.0859, 0.0889, 0.0903, 0.0903, 0.0903, 0.0884, 0.0884, 0.0884, 0.0869, 0.0864, 0.0000, 0.0000, 0.0000],
        [0.0649, 0.0415, 0.0791, 0.0815, 0.0830, 0.0830, 0.0830, 0.0815, 0.0815, 0.0815, 0.0801, 0.0796, 0.0796, 0.0000, 0.0000],
        [0.0603, 0.0386, 0.0732, 0.0757, 0.0767, 0.0771, 0.0771, 0.0757, 0.0757, 0.0752, 0.0742, 0.0737, 0.0737, 0.0732, 0.0000],
        [0.0564, 0.0361, 0.0684, 0.0708, 0.0718, 0.0718, 0.0718, 0.0703, 0.0703, 0.0703, 0.0688, 0.0684, 0.0684, 0.0684, 0.0688]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[-0.0233,  0.0128, -0.0111,  ...,  0.0211, -0.0296, -0.0387],
        [ 0.0087, -0.0206,  0.0238,  ...,  0.0281, -0.0181, -0.0068],
        [ 0.0183,  0.0056,  0.0220,  ...,  0.0001,  0.0245,  0.0224],
        ...,
        [-0.0067,  0.0157,  0.0194,  ...,  0.0063, -0.0235, -0.0101],
        [ 0.0043, -0.0279,  0.0095,  ...,  0.0092, -0.0124, -0.0037],
        [-0.0123, -0.0185,  0.0170,  ...,  0.0049,  0.0273, -0.0281]], device='cuda:0', requires_grad=True)
K: tensor([-0.8359,  0.1289,  0.3535,  0.8203, -0.5039, -0.3184, -0.4160, -0.2051, -0.4492, -0.0933, -0.7852, -0.2852, -0.5938, -0.0918,  0.4238, -0.3320, -0.8477,  0.3398,  0.4355,  0.5312, -0.5117,  0.3105, -0.4453,  0.1660,  0.4824,  1.0938,  0.7812, -1.0234,  0.6211, -0.5117, -0.2832, -0.2197,
         0.0908,  0.5078,  0.3086, -0.0732, -0.7930,  0.4941, -0.6797, -0.7500,  1.1328, -0.3418,  0.9297, -1.0547,  0.3223,  0.6562,  0.0918,  0.8594,  0.3672,  0.5391,  0.0579,  0.4414,  0.2393,  0.7695,  0.1582, -0.5781,  0.1904, -0.4512, -0.3789, -0.1504, -0.6328,  0.4199, -0.1934, -0.8125],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[-0.0026,  0.0236, -0.0111,  ..., -0.0124,  0.0023, -0.0149],
        [ 0.0002, -0.0096,  0.0015,  ..., -0.0069, -0.0155,  0.0125],
        [-0.0230,  0.0241, -0.0219,  ..., -0.0188,  0.0009,  0.0031],
        ...,
        [-0.0355,  0.0233, -0.0227,  ..., -0.0098,  0.0383,  0.0233],
        [-0.0106,  0.0077, -0.0450,  ...,  0.0177,  0.0071,  0.0125],
        [ 0.0112, -0.0152,  0.0109,  ..., -0.0387,  0.0018, -0.0209]], device='cuda:0', requires_grad=True)
Q: tensor([    -0.1504,      0.5781,     -0.4922,     -0.9219,      0.2188,      0.8203,      0.3867,      0.0071,     -0.2080,      0.0229,      0.1865,     -0.1953,     -0.8516,     -0.5156,      0.6719,      0.1230,     -0.3164,      0.8359,     -0.2354,      0.4473,     -0.1494,     -0.0640,
            -0.3789,     -0.5039,     -0.1924,      0.3574,      0.0317,     -0.2637,     -1.0703,     -0.7266,      0.4023,      0.1768,     -0.6484,     -0.1602,     -0.6641,      0.1387,     -0.2129,      0.5469,      0.3027,     -0.3457,      0.2988,     -0.0359,     -0.1494,     -0.1543,
            -0.0008,     -0.2500,     -0.2158,     -0.3438,     -0.5938,      0.3320,      0.1270,      0.0554,      1.2656,      0.0077,     -0.2793,     -0.4766,     -0.3301,     -0.0244,     -0.4062,      0.0032,     -0.4219,     -0.1396,      0.3828,     -0.3047], device='cuda:0',
       dtype=torch.bfloat16)
RAWVALUES
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000, -0.1826,  0.0332,  0.1035,  0.0977,  0.1079,  0.1099,  0.0933,  0.1001,  0.1016,  0.0806,  0.0776,  0.0718,  0.0732,  0.0830],
        [ 0.0000, -0.4316,  0.1187,  0.1807,  0.1846,  0.1875,  0.1846,  0.1611,  0.1631,  0.1631,  0.1426,  0.1396,  0.1367,  0.1348,  0.1426],
        [ 0.0000, -0.4258,  0.0557,  0.1328,  0.1123,  0.1094,  0.0938,  0.0588,  0.0615,  0.0603,  0.0361,  0.0332,  0.0283,  0.0276,  0.0366],
        [ 0.0000, -0.4492,  0.1196,  0.1855,  0.1797,  0.1787,  0.1689,  0.1387,  0.1406,  0.1396,  0.1167,  0.1133,  0.1089,  0.1074,  0.1162],
        [ 0.0000, -0.4473,  0.1289,  0.1934,  0.1865,  0.1855,  0.1748,  0.1445,  0.1465,  0.1445,  0.1221,  0.1187,  0.1138,  0.1123,  0.1211],
        [ 0.0000, -0.4531,  0.1514,  0.2070,  0.2061,  0.2061,  0.1973,  0.1699,  0.1719,  0.1699,  0.1484,  0.1455,  0.1406,  0.1387,  0.1475],
        [ 0.0000, -0.4512,  0.1846,  0.2246,  0.2354,  0.2373,  0.2334,  0.2119,  0.2129,  0.2119,  0.1934,  0.1895,  0.1855,  0.1836,  0.1904],
        [ 0.0000, -0.4492,  0.1787,  0.2227,  0.2295,  0.2314,  0.2256,  0.2021,  0.2031,  0.2021,  0.1826,  0.1787,  0.1748,  0.1729,  0.1797],
        [ 0.0000, -0.4492,  0.1826,  0.2256,  0.2334,  0.2344,  0.2285,  0.2051,  0.2061,  0.2051,  0.1846,  0.1816,  0.1768,  0.1748,  0.1826],
        [ 0.0000, -0.4453,  0.1973,  0.2295,  0.2441,  0.2461,  0.2441,  0.2246,  0.2256,  0.2236,  0.2061,  0.2021,  0.1982,  0.1963,  0.2031],
        [ 0.0000, -0.4453,  0.1953,  0.2266,  0.2422,  0.2441,  0.2422,  0.2227,  0.2236,  0.2227,  0.2041,  0.2012,  0.1963,  0.1953,  0.2012],
        [ 0.0000, -0.4473,  0.1982,  0.2256,  0.2422,  0.2451,  0.2441,  0.2266,  0.2266,  0.2256,  0.2080,  0.2051,  0.2002,  0.1982,  0.2041],
        [ 0.0000, -0.4453,  0.1973,  0.2266,  0.2422,  0.2451,  0.2432,  0.2236,  0.2246,  0.2236,  0.2051,  0.2021,  0.1973,  0.1963,  0.2021],
        [ 0.0000, -0.4473,  0.1934,  0.2256,  0.2383,  0.2402,  0.2383,  0.2178,  0.2178,  0.2168,  0.1982,  0.1943,  0.1904,  0.1885,  0.1943]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[1.0000],
        [0.6468],
        [0.3957],
        [0.3045],
        [0.2354],
        [0.1941],
        [0.1618],
        [0.1369],
        [0.1220],
        [0.1093],
        [0.0975],
        [0.0891],
        [0.0817],
        [0.0761],
        [0.0715]], device='cuda:0')
tensor([[    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0067,     0.9922,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0036,     0.5312,     0.4668,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0025,     0.3594,     0.3184,     0.3184,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0019,     0.2715,     0.2402,     0.2402,     0.2461,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0016,     0.2168,     0.1924,     0.1924,     0.1973,     0.1982,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0013,     0.1807,     0.1611,     0.1602,     0.1650,     0.1650,     0.1660,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0012,     0.1553,     0.1377,     0.1377,     0.1406,     0.1416,     0.1426,     0.1436,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0010,     0.1357,     0.1206,     0.1201,     0.1235,     0.1240,     0.1245,     0.1250,     0.1260,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0009,     0.1206,     0.1069,     0.1069,     0.1094,     0.1104,     0.1108,     0.1113,     0.1118,     0.1113,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0008,     0.1084,     0.0962,     0.0962,     0.0986,     0.0991,     0.0996,     0.1001,     0.1006,     0.1001,     0.1006,     0.0000,     0.0000,     0.0000,     0.0000],
        [    0.0007,     0.0981,     0.0874,     0.0874,     0.0894,     0.0898,     0.0903,     0.0908,     0.0913,     0.0913,     0.0913,     0.0918,     0.0000,     0.0000,     0.0000],
        [    0.0007,     0.0903,     0.0801,     0.0801,     0.0820,     0.0825,     0.0830,     0.0830,     0.0835,     0.0835,     0.0840,     0.0840,     0.0840,     0.0000,     0.0000],
        [    0.0006,     0.0830,     0.0737,     0.0737,     0.0757,     0.0762,     0.0762,     0.0767,     0.0771,     0.0771,     0.0771,     0.0776,     0.0771,     0.0771,     0.0000],
        [    0.0006,     0.0771,     0.0688,     0.0684,     0.0703,     0.0708,     0.0708,     0.0713,     0.0718,     0.0713,     0.0718,     0.0718,     0.0718,     0.0718,     0.0718]], device='cuda:0', dtype=torch.bfloat16)
Kweights
tensor([[ 0.0321,  0.0336, -0.0257,  ...,  0.0048, -0.0082, -0.0050],
        [-0.0137,  0.0240, -0.0027,  ..., -0.0304,  0.0156, -0.0340],
        [ 0.0058,  0.0258,  0.0242,  ..., -0.0024, -0.0174,  0.0138],
        ...,
        [ 0.0171,  0.0124, -0.0100,  ...,  0.0202, -0.0151, -0.0023],
        [-0.0257, -0.0087, -0.0141,  ..., -0.0136,  0.0051, -0.0309],
        [-0.0120, -0.0146, -0.0260,  ..., -0.0058, -0.0158, -0.0066]], device='cuda:0', requires_grad=True)
K: tensor([-0.6641, -0.2021, -0.3730, -0.6328,  0.2441, -1.5391, -0.2832, -2.2188, -2.2812, -0.6445,  0.9141,  0.0425, -0.7656, -2.3281,  0.1924, -0.1719, -0.1504, -0.3418, -0.8906,  0.6445,  0.5625,  0.9531,  0.1895, -0.1621,  0.6719, -0.0635,  0.2002,  0.0923,  1.9062, -0.6641,  0.3125,  0.0449,
        -1.8203,  1.5859, -1.5000, -0.8047, -0.6836,  0.4238, -0.5742, -0.1406,  0.2852,  1.6328, -1.6641, -0.2793,  0.3203,  1.2812, -0.1011, -0.1348,  0.5234,  0.3281, -0.0254, -2.3906, -0.0610, -0.3652,  0.2988, -0.0282, -1.2734,  1.0312, -0.1211,  1.2344,  0.3672, -0.2266, -0.0786, -2.0000],
       device='cuda:0', dtype=torch.bfloat16)
Qweights
tensor([[ 0.0162, -0.0266,  0.0001,  ..., -0.0058, -0.0381, -0.0018],
        [ 0.0315,  0.0053, -0.0009,  ...,  0.0207,  0.0084,  0.0269],
        [ 0.0129, -0.0190, -0.0167,  ...,  0.0163,  0.0215, -0.0312],
        ...,
        [-0.0052, -0.0255,  0.0057,  ...,  0.0127,  0.0368,  0.0110],
        [-0.0076, -0.0333,  0.0433,  ..., -0.0039, -0.0040, -0.0268],
        [-0.0319, -0.0009, -0.0506,  ...,  0.0142,  0.0030, -0.0028]], device='cuda:0', requires_grad=True)
Q: tensor([-0.1484, -0.1445, -1.0703, -0.7031,  0.3906, -0.8008, -0.0154, -1.2734, -1.7266,  0.4766,  2.1719, -0.4297, -1.1484, -0.6992, -0.2207, -0.2383, -0.4160, -0.7852, -0.3945,  0.5352,  0.4004,  0.9219,  0.2002, -0.1357,  0.5078, -0.0282,  0.7422, -0.0049,  0.6953, -1.5938, -0.0986, -0.3125,
        -1.0078,  0.8945, -1.1641, -1.8203,  0.6875,  0.0227, -0.7227, -0.1914,  0.0332,  0.7734, -1.1094, -0.9883,  0.8945,  0.1270, -0.3730,  0.0537,  0.4824,  0.7500,  0.3711, -0.6797,  0.8125, -0.4219,  0.1230, -0.2852, -2.1250,  0.7539, -0.1992,  0.7734,  0.2559, -0.4062,  0.0630, -1.5000],
       device='cuda:0', dtype=torch.bfloat16)
RAWVALUES
tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 5.0000, 4.8750, 4.8750, 4.9062, 4.9062, 4.9062, 4.9062, 4.9062, 4.9062, 4.9062, 4.9375, 4.9062, 4.9062, 4.9062],
        [0.0000, 5.0000, 4.8750, 4.8750, 4.9062, 4.9062, 4.9062, 4.9375, 4.9375, 4.9375, 4.9375, 4.9375, 4.9375, 4.9375, 4.9375],
        [0.0000, 4.9688, 4.8438, 4.8438, 4.8750, 4.8750, 4.8750, 4.8750, 4.8750, 4.8750, 4.9062, 4.9062, 4.9062, 4.9062, 4.9062],
        [0.0000, 4.9375, 4.8125, 4.8125, 4.8438, 4.8438, 4.8438, 4.8750, 4.8750, 4.8750, 4.8750, 4.8750, 4.8750, 4.8750, 4.8750],
        [0.0000, 4.9375, 4.8125, 4.8125, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438],
        [0.0000, 4.9062, 4.7812, 4.7812, 4.8125, 4.8125, 4.8125, 4.8125, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438],
        [0.0000, 4.9062, 4.7812, 4.7812, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8438, 4.8438, 4.8438, 4.8438, 4.8438],
        [0.0000, 4.9062, 4.7812, 4.7812, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125],
        [0.0000, 4.9062, 4.7812, 4.7812, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125],
        [0.0000, 4.9062, 4.7812, 4.7812, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125],
        [0.0000, 4.8750, 4.7500, 4.7500, 4.7812, 4.7812, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125],
        [0.0000, 4.8750, 4.7812, 4.7812, 4.7812, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125],
        [0.0000, 4.8750, 4.7812, 4.7500, 4.7812, 4.7812, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125],
        [0.0000, 4.8750, 4.7500, 4.7500, 4.7812, 4.7812, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125, 4.8125]], device='cuda:0', dtype=torch.bfloat16)
========
RESW: tensor([[    1.0000],
        [    0.0058],
        [    0.0032],
        [    0.0022],
        [    0.0017],
        [    0.0014],
        [    0.0011],
        [    0.0010],
        [    0.0009],
        [    0.0008],
        [    0.0007],
        [    0.0006],
        [    0.0006],
        [    0.0005],
        [    0.0005]], device='cuda:0')
rank 0 sample 0: A Poem for you! Roses are red, Potatoes are 
------
		( the:0.0405 the:0.0405 the:0.0405 the:0.0405 the:0.0405 the:0.0405 the:0.0405 the:0.0405)
 the
------
		( the:0.0405 the:0.0405 the:0.0405 the:0.0405 the:0.0405 the:0.0405 the:0.0405 the:0.0405)
 the the the the the the the the the the the the the the the
@ 1050 train 7.6220 , allloss: 7.6399, dt: 1685.27ms, fracRes: 0.4843, norm(attn): 0.3340, norm(output): 2.5156, norm(x): 2.6903, norm(y): 1.0045, norm:0.5521, tok/sec: 77775.20, flops:81.64, batch-reuse:1
@ 1051 train 7.6016 , allloss: 7.6100, dt: 1314.12ms, fracRes: 0.4787, norm(attn): 0.3379, norm(output): 2.4688, norm(x): 2.6220, norm(y): 1.0046, norm:0.3419, tok/sec: 99741.38, flops:104.69, batch-reuse:1
@ 1052 train 7.5631 , allloss: 7.5693, dt: 1293.97ms, fracRes: 0.4851, norm(attn): 0.3379, norm(output): 2.4375, norm(x): 2.6103, norm(y): 1.0046, norm:0.3466, tok/sec: 101294.20, flops:106.32, batch-reuse:1
@ 1053 train 7.6262 , allloss: 7.6339, dt: 1286.50ms, fracRes: 0.4874, norm(attn): 0.3379, norm(output): 2.4844, norm(x): 2.6490, norm(y): 1.0046, norm:0.4618, tok/sec: 101882.29, flops:106.94, batch-reuse:1
@ 1054 train 7.6070 , allloss: 7.6208, dt: 1301.56ms, fracRes: 0.4895, norm(attn): 0.3359, norm(output): 2.5000, norm(x): 2.6830, norm(y): 1.0046, norm:0.3686, tok/sec: 100703.67, flops:105.70, batch-reuse:1
@ 1055 train 7.6105 , allloss: 7.6368, dt: 1292.58ms, fracRes: 0.4920, norm(attn): 0.3340, norm(output): 2.5000, norm(x): 2.6867, norm(y): 1.0046, norm:0.5233, tok/sec: 101403.70, flops:106.44, batch-reuse:1
@ 1056 train 7.6117 , allloss: 7.8827, dt: 1318.39ms, fracRes: 0.4947, norm(attn): 0.3340, norm(output): 2.4844, norm(x): 2.6748, norm(y): 1.0046, norm:2.7639, tok/sec: 99418.60, flops:104.35, batch-reuse:1
@ 1057 train 7.6748 , allloss: 7.8850, dt: 1336.60ms, fracRes: 0.4950, norm(attn): 0.3418, norm(output): 2.4688, norm(x): 2.6279, norm(y): 1.0047, norm:1.9871, tok/sec: 98063.53, flops:102.93, batch-reuse:1
@ 1058 train 7.6406 , allloss: 7.7998, dt: 1314.88ms, fracRes: 0.4960, norm(attn): 0.3398, norm(output): 2.3906, norm(x): 2.5616, norm(y): 1.0048, norm:0.8368, tok/sec: 99683.83, flops:104.63, batch-reuse:1
@ 1059 train 7.6278 , allloss: 7.7581, dt: 1349.58ms, fracRes: 0.4973, norm(attn): 0.3320, norm(output): 2.3438, norm(x): 2.5335, norm(y): 1.0048, norm:0.7423, tok/sec: 97120.70, flops:101.94, batch-reuse:1
@ 1060 train 7.6111 , allloss: 7.7741, dt: 1340.21ms, fracRes: 0.4977, norm(attn): 0.3242, norm(output): 2.2969, norm(x): 2.4871, norm(y): 1.0048, norm:0.6947, tok/sec: 97799.86, flops:102.65, batch-reuse:1
@ 1061 train 7.6659 , allloss: 7.8049, dt: 1325.39ms, fracRes: 0.4980, norm(attn): 0.3301, norm(output): 2.1875, norm(x): 2.3845, norm(y): 1.0048, norm:0.5946, tok/sec: 98892.85, flops:103.80, batch-reuse:1
@ 1062 train 7.6370 , allloss: 7.7805, dt: 1304.51ms, fracRes: 0.4950, norm(attn): 0.3379, norm(output): 2.0000, norm(x): 2.1712, norm(y): 1.0050, norm:0.5469, tok/sec: 100475.70, flops:105.46, batch-reuse:1
@ 1063 train 7.7107 , allloss: 7.8512, dt: 1301.74ms, fracRes: 0.4932, norm(attn): 0.3438, norm(output): 1.8984, norm(x): 2.0515, norm(y): 1.0052, norm:0.5793, tok/sec: 100689.80, flops:105.69, batch-reuse:1
@ 1064 train 7.6326 , allloss: 7.7884, dt: 1300.09ms, fracRes: 0.4917, norm(attn): 0.3477, norm(output): 1.8594, norm(x): 1.9980, norm(y): 1.0053, norm:0.4987, tok/sec: 100817.32, flops:105.82, batch-reuse:1
@ 1065 train 7.6608 , allloss: 7.8135, dt: 1330.97ms, fracRes: 0.4891, norm(attn): 0.3594, norm(output): 1.8594, norm(x): 1.9633, norm(y): 1.0056, norm:0.4493, tok/sec: 98478.88, flops:103.37, batch-reuse:1
@ 1066 train 7.6993 , allloss: 7.8684, dt: 1303.08ms, fracRes: 0.4864, norm(attn): 0.3652, norm(output): 1.8203, norm(x): 1.9370, norm(y): 1.0057, norm:0.7168, tok/sec: 100586.28, flops:105.58, batch-reuse:1
@ 1067 train 7.7233 , allloss: 7.9097, dt: 1291.60ms, fracRes: 0.4852, norm(attn): 0.3711, norm(output): 1.8047, norm(x): 1.9221, norm(y): 1.0058, norm:0.6975, tok/sec: 101480.45, flops:106.52, batch-reuse:1
@ 1068 train 7.6405 , allloss: 7.7969, dt: 1296.38ms, fracRes: 0.4847, norm(attn): 0.3730, norm(output): 1.8203, norm(x): 1.9436, norm(y): 1.0059, norm:0.6131, tok/sec: 101105.87, flops:106.12, batch-reuse:1
@ 1069 train 7.5946 , allloss: 7.7165, dt: 1303.44ms, fracRes: 0.4846, norm(attn): 0.3750, norm(output): 1.8359, norm(x): 1.9396, norm(y): 1.0059, norm:0.6642, tok/sec: 100558.20, flops:105.55, batch-reuse:1
@ 1070 train 7.6361 , allloss: 7.7253, dt: 1313.85ms, fracRes: 0.4890, norm(attn): 0.3750, norm(output): 1.8281, norm(x): 1.9417, norm(y): 1.0059, norm:0.5171, tok/sec: 99762.05, flops:104.71, batch-reuse:1
@ 1071 train 7.5709 , allloss: 7.6525, dt: 1319.84ms, fracRes: 0.4943, norm(attn): 0.3750, norm(output): 1.7969, norm(x): 1.9157, norm(y): 1.0059, norm:0.4471, tok/sec: 99308.92, flops:104.24, batch-reuse:1
@ 1072 train 7.6503 , allloss: 7.7379, dt: 1320.29ms, fracRes: 0.4979, norm(attn): 0.3750, norm(output): 1.8047, norm(x): 1.9503, norm(y): 1.0059, norm:0.4683, tok/sec: 99274.87, flops:104.20, batch-reuse:1
@ 1073 train 7.5965 , allloss: 7.6814, dt: 1306.19ms, fracRes: 0.5002, norm(attn): 0.3730, norm(output): 1.8359, norm(x): 2.0003, norm(y): 1.0058, norm:0.4673, tok/sec: 100346.53, flops:105.33, batch-reuse:1
@ 1074 train 7.6126 , allloss: 7.6861, dt: 1284.26ms, fracRes: 0.5029, norm(attn): 0.3711, norm(output): 1.8047, norm(x): 2.0080, norm(y): 1.0057, norm:0.5038, tok/sec: 102060.18, flops:107.13, batch-reuse:1
@ 1075 train 7.6283 , allloss: 7.6883, dt: 1303.44ms, fracRes: 0.5049, norm(attn): 0.3652, norm(output): 1.7578, norm(x): 2.0054, norm(y): 1.0057, norm:0.4428, tok/sec: 100558.20, flops:105.55, batch-reuse:1
@ 1076 train 7.6792 , allloss: 7.7313, dt: 1306.75ms, fracRes: 0.5057, norm(attn): 0.3633, norm(output): 1.7500, norm(x): 1.9949, norm(y): 1.0057, norm:0.4124, tok/sec: 100303.58, flops:105.28, batch-reuse:1
@ 1077 train 7.6016 , allloss: 7.6427, dt: 1305.67ms, fracRes: 0.5065, norm(attn): 0.3613, norm(output): 1.7188, norm(x): 1.9510, norm(y): 1.0058, norm:0.3758, tok/sec: 100386.57, flops:105.37, batch-reuse:1
