Threshold: 0.1
Enable layer loss: False
MAX LEARNING RATE: 0.0006
Experiment name: 14-mlpmatrix
MLPSCALE: 4
Experiment description: Transformer, max LR 6e-4
Setting:
========
y = self.ln_1(x)
attn = self.attn(y)
mlp, bias = self.fatmlp(y)
M = self.matrixfromparams(mlp)
x = M @ attn + bias + x
======== 
VALUEMATRIX=True
REUSE_WEIGHTS=False
MLP_SCALE=4
DELETE_SELF_CONTRIBUTION=False
NEW_ALL_LAYER_LOSS=False
MATRIX_NUM_PARAMS_MULTIPLIER=3
MLPMAT_INNER_SIZE=48

Warmup steps: 100
total desired batch size: 131072
Mini-batch size: 8*1024
=> calculated gradient accumulation steps: 16
=> calculated gradient accumulation steps: 16
Training max steps: 300001Num GPUs: 1{'block_size': 1024, 'vocab_size': 50304, 'n_layer': 12, 'n_head': 12, 'n_embd': 768}
num decayed parameter tensors: 74, with 210,173,952 parameters
num non-decayed parameter tensors: 98, with 148,992 parameters
@ 0 train 11.0101 , allloss: 11.0101, norm:8.4430, dt: 1813.02ms, tok/sec: 72294.97, flops:101.46, batch-reuse:1
rank 0 sample 0: A Poem for you! Roses are red, Potatoes are 
------
		( Greatest:0.0002 licens:0.0002 Coke:0.0002 CLS:0.0002 markedly:0.0002defense:0.0002 Cookie:0.0002 bullshit:0.0002)
 bullshit
------
		( licens:0.0002 Coke:0.0002 CLS:0.0002 markedly:0.0002defense:0.0002 Cookie:0.0002 bullshit:0.0002 write:0.0002)
 write write Yelpinterpretelectionelectionunt behavingBasic touchscreenaffer economist Hi Hiancock
@ 1 train 10.8109 , allloss: 10.8109, norm:8.5558, dt: 922.40ms, tok/sec: 142098.87, flops:199.42, batch-reuse:1
@ 2 train 10.4771 , allloss: 10.4771, norm:7.0144, dt: 576.58ms, tok/sec: 227327.20, flops:319.02, batch-reuse:1
@ 3 train 10.1493 , allloss: 10.1493, norm:5.2457, dt: 575.25ms, tok/sec: 227853.03, flops:319.76, batch-reuse:1
@ 4 train 9.9089 , allloss: 9.9089, norm:3.7470, dt: 570.05ms, tok/sec: 229929.36, flops:322.67, batch-reuse:1
@ 5 train 9.7914 , allloss: 9.7914, norm:2.7824, dt: 573.05ms, tok/sec: 228726.88, flops:320.99, batch-reuse:1
@ 6 train 9.6114 , allloss: 9.6114, norm:2.5865, dt: 575.27ms, tok/sec: 227843.87, flops:319.75, batch-reuse:1
@ 7 train 9.5390 , allloss: 9.5390, norm:2.3125, dt: 573.73ms, tok/sec: 228456.75, flops:320.61, batch-reuse:1
@ 8 train 9.4985 , allloss: 9.4985, norm:2.2410, dt: 573.50ms, tok/sec: 228546.12, flops:320.73, batch-reuse:1
@ 9 train 9.4189 , allloss: 9.4189, norm:2.2512, dt: 574.97ms, tok/sec: 227963.67, flops:319.91, batch-reuse:1
@ 10 train 9.3563 , allloss: 9.3563, norm:2.0482, dt: 575.06ms, tok/sec: 227926.05, flops:319.86, batch-reuse:1
@ 11 train 9.3428 , allloss: 9.3428, norm:1.8727, dt: 577.60ms, tok/sec: 226925.21, flops:318.46, batch-reuse:1
@ 12 train 9.2372 , allloss: 9.2372, norm:1.9397, dt: 580.98ms, tok/sec: 225603.14, flops:316.60, batch-reuse:1
@ 13 train 9.1677 , allloss: 9.1677, norm:2.0314, dt: 577.41ms, tok/sec: 226998.85, flops:318.56, batch-reuse:1
@ 14 train 9.0662 , allloss: 9.0662, norm:1.8034, dt: 576.45ms, tok/sec: 227378.81, flops:319.09, batch-reuse:1
@ 15 train 9.0059 , allloss: 9.0059, norm:1.7875, dt: 579.09ms, tok/sec: 226341.56, flops:317.64, batch-reuse:1
@ 16 train 8.9088 , allloss: 8.9088, norm:1.6984, dt: 575.96ms, tok/sec: 227572.43, flops:319.37, batch-reuse:1
@ 17 train 8.8475 , allloss: 8.8475, norm:1.7927, dt: 574.08ms, tok/sec: 228318.13, flops:320.41, batch-reuse:1
@ 18 train 8.7627 , allloss: 8.7627, norm:1.6296, dt: 575.30ms, tok/sec: 227830.56, flops:319.73, batch-reuse:1
@ 19 train 8.6260 , allloss: 8.6260, norm:1.6605, dt: 573.88ms, tok/sec: 228396.01, flops:320.52, batch-reuse:1
@ 20 train 8.5761 , allloss: 8.5761, norm:1.6212, dt: 575.83ms, tok/sec: 227623.97, flops:319.44, batch-reuse:1
@ 21 train 8.4856 , allloss: 8.4856, norm:1.5711, dt: 579.02ms, tok/sec: 226367.19, flops:317.67, batch-reuse:1
@ 22 train 8.4089 , allloss: 8.4089, norm:1.5305, dt: 576.10ms, tok/sec: 227517.14, flops:319.29, batch-reuse:1
@ 23 train 8.4188 , allloss: 8.4188, norm:1.2780, dt: 578.37ms, tok/sec: 226622.50, flops:318.03, batch-reuse:1
@ 24 train 8.3705 , allloss: 8.3705, norm:1.2644, dt: 577.15ms, tok/sec: 227103.88, flops:318.71, batch-reuse:1
@ 25 train 8.0970 , allloss: 8.0970, norm:1.4493, dt: 577.12ms, tok/sec: 227113.64, flops:318.72, batch-reuse:1
@ 26 train 8.1002 , allloss: 8.1002, norm:1.3359, dt: 576.46ms, tok/sec: 227373.45, flops:319.09, batch-reuse:1
@ 27 train 8.0083 , allloss: 8.0083, norm:1.0741, dt: 576.44ms, tok/sec: 227383.61, flops:319.10, batch-reuse:1
@ 28 train 7.9405 , allloss: 7.9405, norm:1.1133, dt: 577.34ms, tok/sec: 227028.95, flops:318.60, batch-reuse:1
@ 29 train 7.9362 , allloss: 7.9362, norm:1.0342, dt: 576.55ms, tok/sec: 227338.48, flops:319.04, batch-reuse:1
@ 30 train 7.7590 , allloss: 7.7590, norm:1.0767, dt: 577.02ms, tok/sec: 227154.55, flops:318.78, batch-reuse:1
@ 31 train 7.7472 , allloss: 7.7472, norm:0.8281, dt: 574.82ms, tok/sec: 228024.56, flops:320.00, batch-reuse:1
@ 32 train 7.6778 , allloss: 7.6778, norm:0.7220, dt: 576.72ms, tok/sec: 227269.96, flops:318.94, batch-reuse:1
@ 33 train 7.5729 , allloss: 7.5729, norm:0.7761, dt: 575.50ms, tok/sec: 227751.65, flops:319.62, batch-reuse:1
@ 34 train 7.5516 , allloss: 7.5516, norm:0.6207, dt: 578.58ms, tok/sec: 226541.16, flops:317.92, batch-reuse:1
@ 35 train 7.5036 , allloss: 7.5036, norm:0.6998, dt: 579.09ms, tok/sec: 226342.12, flops:317.64, batch-reuse:1
@ 36 train 7.3927 , allloss: 7.3927, norm:0.6584, dt: 574.08ms, tok/sec: 228315.57, flops:320.41, batch-reuse:1
@ 37 train 7.4034 , allloss: 7.4034, norm:0.5389, dt: 575.98ms, tok/sec: 227564.51, flops:319.35, batch-reuse:1
@ 38 train 7.3360 , allloss: 7.3360, norm:0.7920, dt: 577.15ms, tok/sec: 227102.00, flops:318.71, batch-reuse:1
@ 39 train 7.3516 , allloss: 7.3516, norm:0.6023, dt: 576.25ms, tok/sec: 227457.37, flops:319.20, batch-reuse:1
@ 40 train 7.3581 , allloss: 7.3581, norm:0.8027, dt: 575.94ms, tok/sec: 227581.19, flops:319.38, batch-reuse:1
@ 41 train 7.3007 , allloss: 7.3007, norm:0.8718, dt: 575.59ms, tok/sec: 227716.27, flops:319.57, batch-reuse:1
@ 42 train 7.2659 , allloss: 7.2659, norm:1.0104, dt: 573.93ms, tok/sec: 228378.17, flops:320.50, batch-reuse:1
@ 43 train 7.2531 , allloss: 7.2531, norm:1.0038, dt: 572.72ms, tok/sec: 228860.57, flops:321.17, batch-reuse:1
@ 44 train 7.2572 , allloss: 7.2572, norm:1.0355, dt: 573.83ms, tok/sec: 228417.07, flops:320.55, batch-reuse:1
@ 45 train 7.1553 , allloss: 7.1553, norm:0.7807, dt: 576.62ms, tok/sec: 227309.24, flops:319.00, batch-reuse:1
@ 46 train 7.1729 , allloss: 7.1729, norm:0.6650, dt: 578.18ms, tok/sec: 226697.73, flops:318.14, batch-reuse:1
@ 47 train 7.1036 , allloss: 7.1036, norm:0.5985, dt: 576.82ms, tok/sec: 227231.73, flops:318.89, batch-reuse:1
@ 48 train 7.0906 , allloss: 7.0906, norm:0.5930, dt: 579.32ms, tok/sec: 226250.74, flops:317.51, batch-reuse:1
@ 49 train 7.0949 , allloss: 7.0949, norm:0.7411, dt: 577.04ms, tok/sec: 227144.32, flops:318.76, batch-reuse:1
rank 0 sample 0: A Poem for you! Roses are red, Potatoes are 
------
		(,:0.0747 a:0.0364,:0.0654 and:0.0913,:0.0815,:0.0713 not:0.0386
:0.2656)


------
		( a:0.0364,:0.0654 and:0.0913,:0.0815,:0.0713 not:0.0386
:0.2656-:0.1235)
-
-
-
-
-
-
-
-
@ 50 train 7.1881 , allloss: 7.1881, norm:0.5806, dt: 709.82ms, tok/sec: 184654.82, flops:259.14, batch-reuse:1
@ 51 train 7.2502 , allloss: 7.2502, norm:0.9295, dt: 576.48ms, tok/sec: 227365.65, flops:319.08, batch-reuse:1
@ 52 train 7.0518 , allloss: 7.0518, norm:0.7142, dt: 577.77ms, tok/sec: 226858.44, flops:318.36, batch-reuse:1
@ 53 train 6.9925 , allloss: 6.9925, norm:0.8040, dt: 576.82ms, tok/sec: 227231.07, flops:318.89, batch-reuse:1
@ 54 train 7.1030 , allloss: 7.1030, norm:0.6183, dt: 575.35ms, tok/sec: 227814.32, flops:319.70, batch-reuse:1
@ 55 train 7.1692 , allloss: 7.1692, norm:0.7721, dt: 573.53ms, tok/sec: 228533.96, flops:320.71, batch-reuse:1
@ 56 train 6.9488 , allloss: 6.9488, norm:0.8045, dt: 575.64ms, tok/sec: 227696.66, flops:319.54, batch-reuse:1
@ 57 train 6.8706 , allloss: 6.8706, norm:0.7872, dt: 574.43ms, tok/sec: 228176.74, flops:320.21, batch-reuse:1
@ 58 train 6.9182 , allloss: 6.9182, norm:0.6398, dt: 575.99ms, tok/sec: 227559.33, flops:319.35, batch-reuse:1
@ 59 train 6.7118 , allloss: 6.7118, norm:0.5373, dt: 574.93ms, tok/sec: 227980.02, flops:319.94, batch-reuse:1
@ 60 train 6.9072 , allloss: 6.9072, norm:0.8650, dt: 574.79ms, tok/sec: 228034.40, flops:320.01, batch-reuse:1
@ 61 train 6.8411 , allloss: 6.8411, norm:0.7609, dt: 574.99ms, tok/sec: 227955.35, flops:319.90, batch-reuse:1
@ 62 train 6.9032 , allloss: 6.9032, norm:1.1677, dt: 575.23ms, tok/sec: 227862.00, flops:319.77, batch-reuse:1
@ 63 train 6.8566 , allloss: 6.8566, norm:0.7119, dt: 574.54ms, tok/sec: 228133.57, flops:320.15, batch-reuse:1
@ 64 train 6.8294 , allloss: 6.8294, norm:0.8085, dt: 576.90ms, tok/sec: 227201.96, flops:318.85, batch-reuse:1
@ 65 train 6.9076 , allloss: 6.9076, norm:0.6866, dt: 574.54ms, tok/sec: 228132.34, flops:320.15, batch-reuse:1
@ 66 train 6.9469 , allloss: 6.9469, norm:0.5560, dt: 574.62ms, tok/sec: 228102.71, flops:320.11, batch-reuse:1
@ 67 train 6.8299 , allloss: 6.8299, norm:0.5573, dt: 573.61ms, tok/sec: 228502.71, flops:320.67, batch-reuse:1
@ 68 train 6.8722 , allloss: 6.8722, norm:0.6274, dt: 575.66ms, tok/sec: 227688.64, flops:319.53, batch-reuse:1
@ 69 train 6.7500 , allloss: 6.7500, norm:0.7842, dt: 578.86ms, tok/sec: 226431.62, flops:317.76, batch-reuse:1
@ 70 train 6.7593 , allloss: 6.7593, norm:0.7007, dt: 571.85ms, tok/sec: 229208.46, flops:321.66, batch-reuse:1
@ 71 train 6.7123 , allloss: 6.7123, norm:0.5946, dt: 572.23ms, tok/sec: 229055.28, flops:321.45, batch-reuse:1
@ 72 train 6.7579 , allloss: 6.7579, norm:0.4549, dt: 573.49ms, tok/sec: 228551.73, flops:320.74, batch-reuse:1
@ 73 train 6.8680 , allloss: 6.8680, norm:0.6209, dt: 575.77ms, tok/sec: 227645.27, flops:319.47, batch-reuse:1
@ 74 train 6.7724 , allloss: 6.7724, norm:0.4866, dt: 578.91ms, tok/sec: 226411.75, flops:317.74, batch-reuse:1
@ 75 train 7.4214 , allloss: 7.4214, norm:0.7902, dt: 577.02ms, tok/sec: 227151.92, flops:318.78, batch-reuse:1
@ 76 train 6.7398 , allloss: 6.7398, norm:0.7984, dt: 577.61ms, tok/sec: 226922.87, flops:318.45, batch-reuse:1
@ 77 train 7.5690 , allloss: 7.5690, norm:1.7765, dt: 579.55ms, tok/sec: 226162.13, flops:317.39, batch-reuse:1
@ 78 train 7.0115 , allloss: 7.0115, norm:1.0940, dt: 578.00ms, tok/sec: 226769.26, flops:318.24, batch-reuse:1
@ 79 train 6.6827 , allloss: 6.6827, norm:0.7211, dt: 574.80ms, tok/sec: 228029.86, flops:320.01, batch-reuse:1
@ 80 train 6.7795 , allloss: 6.7795, norm:1.1282, dt: 576.81ms, tok/sec: 227236.43, flops:318.89, batch-reuse:1
@ 81 train 6.7440 , allloss: 6.7440, norm:0.6597, dt: 578.98ms, tok/sec: 226385.83, flops:317.70, batch-reuse:1
@ 82 train 6.7260 , allloss: 6.7260, norm:0.7199, dt: 577.78ms, tok/sec: 226853.57, flops:318.36, batch-reuse:1
@ 83 train 6.7013 , allloss: 6.7013, norm:0.6292, dt: 579.31ms, tok/sec: 226254.65, flops:317.52, batch-reuse:1
@ 84 train 6.7352 , allloss: 6.7352, norm:0.7633, dt: 576.38ms, tok/sec: 227406.47, flops:319.13, batch-reuse:1
@ 85 train 6.6668 , allloss: 6.6668, norm:0.8001, dt: 578.84ms, tok/sec: 226440.38, flops:317.78, batch-reuse:1
@ 86 train 6.6270 , allloss: 6.6270, norm:0.8222, dt: 580.24ms, tok/sec: 225893.47, flops:317.01, batch-reuse:1
@ 87 train 6.6817 , allloss: 6.6817, norm:0.7266, dt: 584.43ms, tok/sec: 224274.97, flops:314.74, batch-reuse:1
@ 88 train 6.6486 , allloss: 6.6486, norm:0.5536, dt: 582.74ms, tok/sec: 224923.33, flops:315.65, batch-reuse:1
@ 89 train 6.5940 , allloss: 6.5940, norm:0.5232, dt: 581.75ms, tok/sec: 225307.73, flops:316.19, batch-reuse:1
@ 90 train 6.6128 , allloss: 6.6128, norm:0.5434, dt: 580.78ms, tok/sec: 225682.60, flops:316.71, batch-reuse:1
@ 91 train 6.5759 , allloss: 6.5759, norm:0.5479, dt: 581.58ms, tok/sec: 225370.63, flops:316.28, batch-reuse:1
@ 92 train 6.5551 , allloss: 6.5551, norm:0.6563, dt: 577.31ms, tok/sec: 227038.51, flops:318.62, batch-reuse:1
@ 93 train 6.5408 , allloss: 6.5408, norm:0.4338, dt: 577.99ms, tok/sec: 226773.28, flops:318.24, batch-reuse:1
@ 94 train 6.8057 , allloss: 6.8057, norm:0.8531, dt: 576.37ms, tok/sec: 227411.26, flops:319.14, batch-reuse:1
@ 95 train 6.5842 , allloss: 6.5842, norm:0.7677, dt: 577.63ms, tok/sec: 226912.84, flops:318.44, batch-reuse:1
@ 96 train 6.4580 , allloss: 6.4580, norm:0.6679, dt: 574.48ms, tok/sec: 228156.76, flops:320.19, batch-reuse:1
@ 97 train 6.5106 , allloss: 6.5106, norm:0.5510, dt: 573.50ms, tok/sec: 228546.12, flops:320.73, batch-reuse:1
@ 98 train 6.5791 , allloss: 6.5791, norm:0.5012, dt: 576.72ms, tok/sec: 227272.41, flops:318.94, batch-reuse:1
@ 99 train 6.4752 , allloss: 6.4752, norm:0.6146, dt: 576.09ms, tok/sec: 227520.34, flops:319.29, batch-reuse:1
@ 100 train 6.5056 , allloss: 6.5056, norm:0.5201, dt: 577.34ms, tok/sec: 227025.48, flops:318.60, batch-reuse:1
