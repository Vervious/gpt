1: sample 0: Hello, I'm a language model,
------
		( Rebellion:0.0001 chord:0.0002Jacob:0.0001 Police:0.0002walk:0.0002Call:0.0002Beer:0.0002weed:0.0001)
		(specified:0.0002 Reno:0.0002 wider:0.0002 Authentication:0.0001insula:0.0002File:0.0001 file:0.0001 Mumbai:0.0001)
		( McInt:0.0002WARN:0.0002 produce:0.0001speaking:0.0001ivers:0.0002Rs:0.0001 Guatem:0.0001 partName:0.0001)
		(wich:0.0003 Certain:0.0001 Chamberlain:0.0002 describing:0.0001503:0.000170:0.0001 slogans:0.0000 Friend:0.0000)
		(Hal:0.0002 pastor:0.0002 Container:0.0002 DevOnline:0.0001 Union:0.0000 intric:0.0000.:0.0000 ingest:0.0000)
		( enhancement:0.0002dll:0.0002Sk:0.0001our:0.0001 waiver:0.0000 millennia:0.0000 the:0.0000.:0.0000)
		( xen:0.0001 addictive:0.0001 entail:0.0001 cuts:0.0000 Dharma:0.0000.:0.0000.:0.0000.:0.0000)
		(urated:0.0001umbnails:0.0002====:0.0001 troopers:0.0000.:0.0000,:0.0000.:0.0000.:0.0000)
		( hurdles:0.0001 Bolt:0.0002 print:0.0001 the:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
		( salvation:0.0002 Mor:0.0002rupt:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
		( discriminated:0.0002undown:0.0002asures:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
		( grants:0.0002 accumulating:0.0002 modern:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
		( grants:0.0002 accumulating:0.0002 modern:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
.
------
		( chord:0.0002Jacob:0.0001 Police:0.0002walk:0.0002Call:0.0002Beer:0.0002weed:0.0001710:0.0002)
		( Reno:0.0002 wider:0.0002 Authentication:0.0001insula:0.0002File:0.0001 file:0.0001 Mumbai:0.0001 Career:0.0001)
		(WARN:0.0002 produce:0.0001speaking:0.0001ivers:0.0002Rs:0.0001 Guatem:0.0001 partName:0.0001 ARE:0.0001)
		( Certain:0.0001 Chamberlain:0.0002 describing:0.0001503:0.000170:0.0001 slogans:0.0000 Friend:0.0000bes:0.0000)
		( pastor:0.0002 Container:0.0002 DevOnline:0.0001 Union:0.0000 intric:0.0000.:0.0000 ingest:0.0000 Sark:0.0000)
		(dll:0.0002Sk:0.0001our:0.0001 waiver:0.0000 millennia:0.0000 the:0.0000.:0.0000 the:0.0000)
		( addictive:0.0001 entail:0.0001 cuts:0.0000 Dharma:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
		(umbnails:0.0002====:0.0001 troopers:0.0000.:0.0000,:0.0000.:0.0000.:0.0000.:0.0000)
		( Bolt:0.0002 print:0.0001 the:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
		( Mor:0.0002rupt:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
		(undown:0.0002asures:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
		( accumulating:0.0002 modern:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
		( accumulating:0.0002 modern:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000.:0.0000)
...........
50: sample 0: Hello, I'm a language model,
------
		(
:0.0840 and:0.0801 the:0.0479
:0.0583
:0.0479,:0.0588,:0.0654 the:0.0732)
		(
:0.0742 the:0.0835 the:0.0591.:0.0698
:0.0189,:0.0757,:0.0806 the:0.1055)
		( the:0.0374 the:0.0569 the:0.0869,:0.0535�:0.0281,:0.0708,:0.0728 the:0.0732)
		( the:0.0420,:0.0562 the:0.0801,:0.0566
:0.0581,:0.0757,:0.0762,:0.0493)
		(
:0.0435,:0.0635 the:0.0659,:0.0601
:0.1475,:0.0698,:0.0703,:0.0608)
		(
:0.0479,:0.0640 the:0.0532,:0.0593
:0.1738,:0.0742,:0.0742,:0.0669)
		(
:0.1797,:0.0679,:0.0591,:0.0659
:0.1865,:0.0693,:0.0688,:0.0669)
		(
:0.2100,:0.0757,:0.0664,:0.0703
:0.1660,:0.0752,:0.0752,:0.0732)
		(
:0.2148,:0.0688,:0.0669,:0.0688
:0.1719,:0.0698,:0.0698,:0.0693)
		(
:0.2178,:0.0786,:0.0742,:0.0767
:0.1572,:0.0762,:0.0757,:0.0737)
		(
:0.2158,:0.0728,:0.0708,:0.0723
:0.1641,:0.0698,:0.0698,:0.0713)
		(
:0.2188,:0.0791,:0.0767,:0.0767
:0.1494,:0.0742,:0.0742,:0.0737)
		(
:0.2188,:0.0791,:0.0767,:0.0767
:0.1494,:0.0742,:0.0742,:0.0737)
,
------
		( and:0.0801 the:0.0479
:0.0583
:0.0479,:0.0588,:0.0654 the:0.0732 and:0.0796)
		( the:0.0835 the:0.0591.:0.0698
:0.0189,:0.0757,:0.0806 the:0.1055 the:0.0811)
		( the:0.0569 the:0.0869,:0.0535�:0.0281,:0.0708,:0.0728 the:0.0732 the:0.0535)
		(,:0.0562 the:0.0801,:0.0566
:0.0581,:0.0757,:0.0762,:0.0493,:0.0620)
		(,:0.0635 the:0.0659,:0.0601
:0.1475,:0.0698,:0.0703,:0.0608,:0.0659)
		(,:0.0640 the:0.0532,:0.0593
:0.1738,:0.0742,:0.0742,:0.0669,:0.0703)
		(,:0.0679,:0.0591,:0.0659
:0.1865,:0.0693,:0.0688,:0.0669,:0.0688)
		(,:0.0757,:0.0664,:0.0703
:0.1660,:0.0752,:0.0752,:0.0732,:0.0732)
		(,:0.0688,:0.0669,:0.0688
:0.1719,:0.0698,:0.0698,:0.0693,:0.0693)
		(,:0.0786,:0.0742,:0.0767
:0.1572,:0.0762,:0.0757,:0.0737,:0.0757)
		(,:0.0728,:0.0708,:0.0723
:0.1641,:0.0698,:0.0698,:0.0713,:0.0713)
		(,:0.0791,:0.0767,:0.0767
:0.1494,:0.0742,:0.0742,:0.0737,:0.0762)
		(,:0.0791,:0.0767,:0.0767
:0.1494,:0.0742,:0.0742,:0.0737,:0.0762)
,,,,,,,,,,,
200: sample 0: Hello, I'm a language model,
------
		(,:0.1147 and:0.0845 have:0.0286 a:0.0598 new:0.0171 of:0.0942 of:0.1006 and:0.1270)
		(,:0.1387 and:0.0898�:0.0302 a:0.0825 new:0.0153,:0.0952 of:0.1084 and:0.1187)
		(,:0.1338 and:0.1074�:0.0330 a:0.0928 few:0.0159,:0.1108,:0.1123 and:0.1309)
		(,:0.1309 and:0.1045�:0.0317 a:0.0903 few:0.0159,:0.1118,:0.1108 and:0.1299)
		(,:0.1191 and:0.1006�:0.0366 a:0.0952 few:0.0161,:0.1118,:0.1143 and:0.1328)
		(,:0.1167 and:0.0957�:0.0432 a:0.0986 few:0.0165,:0.1108,:0.1177 and:0.1289)
		(,:0.1050 and:0.0903�:0.0542 a:0.0947 few:0.0170,:0.1113,:0.1201 and:0.1245)
		(,:0.1001 and:0.0820�:0.0664 a:0.1016 few:0.0176,:0.1113,:0.1147 and:0.1201)
		(,:0.0923 and:0.0742�:0.0791 a:0.1011 few:0.0182,:0.1108,:0.1157 and:0.1191)
		(,:0.0845 and:0.0674�:0.0942 a:0.1060�:0.0194,:0.1055,:0.1162 and:0.1123)
		(,:0.0776 and:0.0588�:0.1157 a:0.1035�:0.0258,:0.1045,:0.1162 and:0.1060)
		(,:0.0732 and:0.0496�:0.1318 a:0.1060�:0.0354,:0.1035,:0.1157 and:0.1006)
		(,:0.0732 and:0.0496�:0.1318 a:0.1060�:0.0354,:0.1035,:0.1157 and:0.1006)
 and
------
		( and:0.0845 have:0.0286 a:0.0598 new:0.0171 of:0.0942 of:0.1006 and:0.1270 the:0.0669)
		( and:0.0898�:0.0302 a:0.0825 new:0.0153,:0.0952 of:0.1084 and:0.1187 the:0.0728)
		( and:0.1074�:0.0330 a:0.0928 few:0.0159,:0.1108,:0.1123 and:0.1309 the:0.0830)
		( and:0.1045�:0.0317 a:0.0903 few:0.0159,:0.1118,:0.1108 and:0.1299 the:0.0801)
		( and:0.1006�:0.0366 a:0.0952 few:0.0161,:0.1118,:0.1143 and:0.1328 the:0.0771)
		( and:0.0957�:0.0432 a:0.0986 few:0.0165,:0.1108,:0.1177 and:0.1289 the:0.0723)
		( and:0.0903�:0.0542 a:0.0947 few:0.0170,:0.1113,:0.1201 and:0.1245 the:0.0698)
		( and:0.0820�:0.0664 a:0.1016 few:0.0176,:0.1113,:0.1147 and:0.1201 the:0.0654)
		( and:0.0742�:0.0791 a:0.1011 few:0.0182,:0.1108,:0.1157 and:0.1191 the:0.0613)
		( and:0.0674�:0.0942 a:0.1060�:0.0194,:0.1055,:0.1162 and:0.1123 the:0.0574)
		( and:0.0588�:0.1157 a:0.1035�:0.0258,:0.1045,:0.1162 and:0.1060 the:0.0554)
		( and:0.0496�:0.1318 a:0.1060�:0.0354,:0.1035,:0.1157 and:0.1006 the:0.0503)
		( and:0.0496�:0.1318 a:0.1060�:0.0354,:0.1035,:0.1157 and:0.1006 the:0.0503)
 the same time, and the same time, and the
350: sample 0: Hello, I'm a language model,
------
		(,:0.2734 and:0.1299�:0.1245 not:0.0664 lot:0.0173,:0.1348 of:0.1289 and:0.1426)
		(,:0.3086 and:0.1582�:0.0684 not:0.0835 good:0.0172,:0.1436,:0.1201 and:0.1553)
		(,:0.3203 and:0.1445�:0.1006 not:0.0811 good:0.0187,:0.1318.:0.1289 and:0.1602)
		(,:0.3027 and:0.1348�:0.0840 not:0.0693 good:0.0184.:0.1357.:0.1211 and:0.1650)
		(,:0.2617 and:0.1250�:0.0981 not:0.0713 good:0.0200.:0.1348,:0.1128 and:0.1670)
		(,:0.2334 and:0.1191�:0.0981 not:0.0659 good:0.0212,:0.1299,:0.1152 and:0.1709)
		(,:0.2188 and:0.1138�:0.0952 not:0.0640 good:0.0221.:0.1338,:0.1094 and:0.1670)
		(,:0.2041 and:0.1133�:0.0859 not:0.0598 good:0.0226.:0.1338,:0.1099 and:0.1631)
		(,:0.1865 and:0.1113�:0.0830 not:0.0562 good:0.0234.:0.1396,:0.1040 and:0.1533)
		(,:0.1699 and:0.1099�:0.0767 not:0.0530 good:0.0239.:0.1348,:0.0981 and:0.1436)
		(,:0.1553 and:0.1099�:0.0679 not:0.0498 good:0.0239.:0.1367,:0.0933 and:0.1357)
		(,:0.1426 and:0.1074�:0.0645 not:0.0466 good:0.0242.:0.1318,:0.0889 and:0.1299)
		(,:0.1426 and:0.1074�:0.0645 not:0.0466 good:0.0242.:0.1318,:0.0889 and:0.1299)
 and
------
		( and:0.1299�:0.1245 not:0.0664 lot:0.0173,:0.1348 of:0.1289 and:0.1426 the:0.0635)
		( and:0.1582�:0.0684 not:0.0835 good:0.0172,:0.1436,:0.1201 and:0.1553 the:0.0352)
		( and:0.1445�:0.1006 not:0.0811 good:0.0187,:0.1318.:0.1289 and:0.1602 the:0.0383)
		( and:0.1348�:0.0840 not:0.0693 good:0.0184.:0.1357.:0.1211 and:0.1650 the:0.0420)
		( and:0.1250�:0.0981 not:0.0713 good:0.0200.:0.1348,:0.1128 and:0.1670 the:0.0491)
		( and:0.1191�:0.0981 not:0.0659 good:0.0212,:0.1299,:0.1152 and:0.1709 the:0.0532)
		( and:0.1138�:0.0952 not:0.0640 good:0.0221.:0.1338,:0.1094 and:0.1670 the:0.0549)
		( and:0.1133�:0.0859 not:0.0598 good:0.0226.:0.1338,:0.1099 and:0.1631 the:0.0559)
		( and:0.1113�:0.0830 not:0.0562 good:0.0234.:0.1396,:0.1040 and:0.1533 the:0.0554)
		( and:0.1099�:0.0767 not:0.0530 good:0.0239.:0.1348,:0.0981 and:0.1436 the:0.0542)
		( and:0.1099�:0.0679 not:0.0498 good:0.0239.:0.1367,:0.0933 and:0.1357 the:0.0518)
		( and:0.1074�:0.0645 not:0.0466 good:0.0242.:0.1318,:0.0889 and:0.1299 the:0.0486)
		( and:0.1074�:0.0645 not:0.0466 good:0.0242.:0.1318,:0.0889 and:0.1299 the:0.0486)
 the first.
The first of the first of the
500: sample 0: Hello, I'm a language model,
------
		(,:0.2266 and:0.0874�:0.0771 not:0.0457 good:0.0119,:0.1309 of:0.1206 and:0.0674)
		(,:0.1836 and:0.0796�:0.0544 not:0.0557 few:0.0200,:0.1436,:0.1104 I:0.1436)
		(,:0.1963 and:0.0723�:0.0801 not:0.0654 few:0.0267,:0.1426.:0.1289 and:0.1035)
		(,:0.1836 the:0.0869�:0.0747 not:0.0703 few:0.0325.:0.1719.:0.1445 and:0.1172)
		(,:0.1768 the:0.1006�:0.0796 not:0.0742 few:0.0398.:0.2012.:0.1494 and:0.1182)
		(,:0.1699 the:0.1118�:0.0806 not:0.0718 few:0.0488.:0.2061.:0.1494 and:0.1162)
		(,:0.1689 the:0.1206�:0.0830 not:0.0684 few:0.0562.:0.2041.:0.1396 and:0.1108)
		(,:0.1631 the:0.1260�:0.0801 not:0.0659 few:0.0608.:0.1973,:0.1328 and:0.1021)
		(,:0.1592 the:0.1299�:0.0801 not:0.0623 few:0.0654.:0.1904,:0.1377 and:0.1016)
		(,:0.1484 the:0.1299 can:0.0820 not:0.0613 few:0.0674.:0.1875,:0.1357 and:0.1025)
		(,:0.1387 the:0.1279 can:0.0864 not:0.0588 few:0.0664.:0.1826,:0.1416 and:0.0981)
		(,:0.1279 the:0.1211 can:0.0869 not:0.0581 few:0.0630.:0.1807,:0.1387 and:0.1001)
		(,:0.1279 the:0.1211 can:0.0869 not:0.0581 few:0.0630.:0.1807,:0.1387 and:0.1001)
 and
------
		( and:0.0874�:0.0771 not:0.0457 good:0.0119,:0.1309 of:0.1206 and:0.0674 the:0.0405)
		( and:0.0796�:0.0544 not:0.0557 few:0.0200,:0.1436,:0.1104 I:0.1436 I:0.1084)
		( and:0.0723�:0.0801 not:0.0654 few:0.0267,:0.1426.:0.1289 and:0.1035 I:0.0723)
		( the:0.0869�:0.0747 not:0.0703 few:0.0325.:0.1719.:0.1445 and:0.1172 I:0.0520)
		( the:0.1006�:0.0796 not:0.0742 few:0.0398.:0.2012.:0.1494 and:0.1182 the:0.0530)
		( the:0.1118�:0.0806 not:0.0718 few:0.0488.:0.2061.:0.1494 and:0.1162 the:0.0576)
		( the:0.1206�:0.0830 not:0.0684 few:0.0562.:0.2041.:0.1396 and:0.1108 the:0.0610)
		( the:0.1260�:0.0801 not:0.0659 few:0.0608.:0.1973,:0.1328 and:0.1021 the:0.0640)
		( the:0.1299�:0.0801 not:0.0623 few:0.0654.:0.1904,:0.1377 and:0.1016 the:0.0654)
		( the:0.1299 can:0.0820 not:0.0613 few:0.0674.:0.1875,:0.1357 and:0.1025 the:0.0659)
		( the:0.1279 can:0.0864 not:0.0588 few:0.0664.:0.1826,:0.1416 and:0.0981 the:0.0645)
		( the:0.1211 can:0.0869 not:0.0581 few:0.0630.:0.1807,:0.1387 and:0.1001 the:0.0640)
		( the:0.1211 can:0.0869 not:0.0581 few:0.0630.:0.1807,:0.1387 and:0.1001 the:0.0640)
 the same way of the same way of the same way
650: sample 0: Hello, I'm a language model,
------
		(,:0.2637 and:0.1377�:0.0537 not:0.0454 �:0.0100,:0.1328 of:0.1138 and:0.0806)
		(,:0.1279 and:0.0835 am:0.0376 not:0.0469 few:0.0140,:0.0918.:0.0801 I:0.0972)
		(,:0.1226 and:0.0684 am:0.0588 not:0.0479 few:0.0205.:0.0854.:0.0972 and:0.1348)
		(,:0.1191 the:0.0762 am:0.0640 going:0.0564 few:0.0293.:0.1035.:0.1167 and:0.1504)
		(,:0.1250 the:0.0874 am:0.0640 going:0.0620 few:0.0381.:0.1108.:0.1279 and:0.1641)
		(,:0.1328 the:0.0918 am:0.0596 going:0.0623 few:0.0444.:0.1152.:0.1309 and:0.1748)
		(,:0.1436 the:0.0952 can:0.0540 going:0.0596 few:0.0483.:0.1201.:0.1279 but:0.1826)
		(,:0.1523 the:0.0957 can:0.0525 going:0.0525 few:0.0500.:0.1260.:0.1245 and:0.1777)
		(,:0.1553 the:0.0928 can:0.0483 going:0.0459 few:0.0483.:0.1270.:0.1211 and:0.1807)
		(,:0.1562 the:0.0869 can:0.0417 going:0.0388 few:0.0464.:0.1348.:0.1152 and:0.1777)
		(,:0.1562 the:0.0786 can:0.0320 going:0.0330 few:0.0442.:0.1367.:0.1113 and:0.1797)
		(,:0.1445 the:0.0679 can:0.0220 going:0.0288 few:0.0400.:0.1387.:0.1050 and:0.1748)
		(,:0.1445 the:0.0679 can:0.0220 going:0.0288 few:0.0400.:0.1387.:0.1050 and:0.1748)
 and
------
		( and:0.1377�:0.0537 not:0.0454 �:0.0100,:0.1328 of:0.1138 and:0.0806 the:0.0229)
		( and:0.0835 am:0.0376 not:0.0469 few:0.0140,:0.0918.:0.0801 I:0.0972 I:0.0698)
		( and:0.0684 am:0.0588 not:0.0479 few:0.0205.:0.0854.:0.0972 and:0.1348 I:0.0669)
		( the:0.0762 am:0.0640 going:0.0564 few:0.0293.:0.1035.:0.1167 and:0.1504 I:0.0986)
		( the:0.0874 am:0.0640 going:0.0620 few:0.0381.:0.1108.:0.1279 and:0.1641 I:0.1182)
		( the:0.0918 am:0.0596 going:0.0623 few:0.0444.:0.1152.:0.1309 and:0.1748 I:0.1318)
		( the:0.0952 can:0.0540 going:0.0596 few:0.0483.:0.1201.:0.1279 but:0.1826 I:0.1318)
		( the:0.0957 can:0.0525 going:0.0525 few:0.0500.:0.1260.:0.1245 and:0.1777 I:0.1216)
		( the:0.0928 can:0.0483 going:0.0459 few:0.0483.:0.1270.:0.1211 and:0.1807 I:0.1152)
		( the:0.0869 can:0.0417 going:0.0388 few:0.0464.:0.1348.:0.1152 and:0.1777 I:0.1050)
		( the:0.0786 can:0.0320 going:0.0330 few:0.0442.:0.1367.:0.1113 and:0.1797 I:0.0918)
		( the:0.0679 can:0.0220 going:0.0288 few:0.0400.:0.1387.:0.1050 and:0.1748 I:0.0806)
		( the:0.0679 can:0.0220 going:0.0288 few:0.0400.:0.1387.:0.1050 and:0.1748 I:0.0806)
 I can be able to be able to be able to
800: sample 0: Hello, I'm a language model,
------
		(,:0.2080 and:0.0884�:0.0613 not:0.0688 �:0.0120,:0.1543 of:0.1709 and:0.0332)
		(,:0.1367 and:0.0444 have:0.0508 not:0.1040 few:0.0168,:0.1328 of:0.1172 I:0.1045)
		(,:0.1387 I:0.0593 have:0.0505 not:0.0923 great:0.0330,:0.1328 that:0.0967 but:0.0767)
		(,:0.1377 I:0.0796 have:0.0464 not:0.1055 great:0.0532 that:0.1035 that:0.1094 but:0.1348)
		(,:0.1494 I:0.0923 have:0.0483 not:0.1108 great:0.0542,:0.1021 for:0.1196 but:0.1533)
		(,:0.1621 I:0.1040 am:0.0525 not:0.1260 great:0.0469,:0.1147 for:0.1187 but:0.1611)
		(,:0.1738 I:0.1118 am:0.0535 not:0.1250 great:0.0413,:0.1270 for:0.1099 but:0.1572)
		(,:0.1816 I:0.1191 am:0.0513 not:0.1201 great:0.0361,:0.1377 for:0.1035 but:0.1455)
		(,:0.1846 I:0.1167 am:0.0452 not:0.1064 great:0.0311,:0.1523,:0.1011 but:0.1235)
		(,:0.1807 I:0.1084 am:0.0371 not:0.0903 great:0.0267,:0.1611,:0.1025 but:0.1074)
		(,:0.1709 I:0.0967 am:0.0289 not:0.0757 great:0.0211,:0.1650,:0.1074 but:0.0894)
		(,:0.1553 I:0.0825'm:0.0226 not:0.0603 great:0.0170,:0.1611,:0.1074 but:0.0728)
		(,:0.1553 I:0.0825'm:0.0226 not:0.0603 great:0.0170,:0.1611,:0.1074 but:0.0728)
 but
------
		( and:0.0884�:0.0613 not:0.0688 �:0.0120,:0.1543 of:0.1709 and:0.0332 the:0.0781)
		( and:0.0444 have:0.0508 not:0.1040 few:0.0168,:0.1328 of:0.1172 I:0.1045 I:0.2217)
		( I:0.0593 have:0.0505 not:0.0923 great:0.0330,:0.1328 that:0.0967 but:0.0767 I:0.2432)
		( I:0.0796 have:0.0464 not:0.1055 great:0.0532 that:0.1035 that:0.1094 but:0.1348 I:0.2695)
		( I:0.0923 have:0.0483 not:0.1108 great:0.0542,:0.1021 for:0.1196 but:0.1533 I:0.2891)
		( I:0.1040 am:0.0525 not:0.1260 great:0.0469,:0.1147 for:0.1187 but:0.1611 I:0.2930)
		( I:0.1118 am:0.0535 not:0.1250 great:0.0413,:0.1270 for:0.1099 but:0.1572 I:0.2969)
		( I:0.1191 am:0.0513 not:0.1201 great:0.0361,:0.1377 for:0.1035 but:0.1455 I:0.2891)
		( I:0.1167 am:0.0452 not:0.1064 great:0.0311,:0.1523,:0.1011 but:0.1235 I:0.2754)
		( I:0.1084 am:0.0371 not:0.0903 great:0.0267,:0.1611,:0.1025 but:0.1074 I:0.2559)
		( I:0.0967 am:0.0289 not:0.0757 great:0.0211,:0.1650,:0.1074 but:0.0894 I:0.2275)
		( I:0.0825'm:0.0226 not:0.0603 great:0.0170,:0.1611,:0.1074 but:0.0728 I:0.1934)
		( I:0.0825'm:0.0226 not:0.0603 great:0.0170,:0.1611,:0.1074 but:0.0728 I:0.1934)
 I'm not sure that I'm not sure that I
950: sample 0: Hello, I'm a language model,
------
		(,:0.1309 and:0.1040 have:0.0569 not:0.0889 ":0.0104,:0.1709 of:0.1475 and:0.0796)
		(,:0.1270 and:0.0649 have:0.0708 not:0.1250 few:0.0140,:0.1396 of:0.2393 and:0.1025)
		(,:0.1201 and:0.0879 have:0.0679 not:0.1426 great:0.0305,:0.1680 of:0.1719 and:0.1299)
		(,:0.1113 and:0.0850 have:0.0684 not:0.1631 great:0.0444,:0.1602 of:0.1426 and:0.1309)
		(,:0.1260 and:0.0835 have:0.0708 not:0.1748 great:0.0422,:0.1533 of:0.1699 but:0.1504)
		(,:0.1396 and:0.0796 have:0.0698 not:0.1768 little:0.0398,:0.1592 of:0.1865 but:0.1562)
		(,:0.1445 and:0.0776 have:0.0630 not:0.1709 little:0.0369,:0.1797 of:0.1758 but:0.1445)
		(,:0.1475 and:0.0728 have:0.0544 not:0.1592 little:0.0322,:0.1846 of:0.1680 and:0.1475)
		(,:0.1445 and:0.0664 have:0.0444 not:0.1514 little:0.0271,:0.2041,:0.1611 and:0.1543)
		(,:0.1348 I:0.0581 have:0.0366 not:0.1377 few:0.0216,:0.2041,:0.1660 and:0.1631)
		(,:0.1191 I:0.0518've:0.0342 not:0.1250 new:0.0194,:0.2070,:0.1709 and:0.1631)
		(,:0.1025 I:0.0449've:0.0330 not:0.1152 new:0.0182,:0.2002,:0.1777 and:0.1738)
		(,:0.1025 I:0.0449've:0.0330 not:0.1152 new:0.0182,:0.2002,:0.1777 and:0.1738)
 and
------
		( and:0.1040 have:0.0569 not:0.0889 ":0.0104,:0.1709 of:0.1475 and:0.0796 the:0.0361)
		( and:0.0649 have:0.0708 not:0.1250 few:0.0140,:0.1396 of:0.2393 and:0.1025 the:0.0574)
		( and:0.0879 have:0.0679 not:0.1426 great:0.0305,:0.1680 of:0.1719 and:0.1299 I:0.0596)
		( and:0.0850 have:0.0684 not:0.1631 great:0.0444,:0.1602 of:0.1426 and:0.1309 I:0.0791)
		( and:0.0835 have:0.0708 not:0.1748 great:0.0422,:0.1533 of:0.1699 but:0.1504 I:0.0933)
		( and:0.0796 have:0.0698 not:0.1768 little:0.0398,:0.1592 of:0.1865 but:0.1562 I:0.0967)
		( and:0.0776 have:0.0630 not:0.1709 little:0.0369,:0.1797 of:0.1758 but:0.1445 I:0.1006)
		( and:0.0728 have:0.0544 not:0.1592 little:0.0322,:0.1846 of:0.1680 and:0.1475 I:0.1016)
		( and:0.0664 have:0.0444 not:0.1514 little:0.0271,:0.2041,:0.1611 and:0.1543 I:0.0991)
		( I:0.0581 have:0.0366 not:0.1377 few:0.0216,:0.2041,:0.1660 and:0.1631 I:0.0952)
		( I:0.0518've:0.0342 not:0.1250 new:0.0194,:0.2070,:0.1709 and:0.1631 I:0.0898)
		( I:0.0449've:0.0330 not:0.1152 new:0.0182,:0.2002,:0.1777 and:0.1738 I:0.0820)
		( I:0.0449've:0.0330 not:0.1152 new:0.0182,:0.2002,:0.1777 and:0.1738 I:0.0820)
 I've got to the same way of the book.
1100: sample 0: Hello, I'm a language model,
------
		(,:0.1270 and:0.0952�:0.0811 not:0.0708 �:0.0170,:0.1670 of:0.1260 and:0.0635)
		(,:0.0991 I:0.0530 am:0.0579 not:0.1064 lot:0.0157 that:0.1279 of:0.1260 I:0.0879)
		(,:0.0688 I:0.0938 am:0.0693 not:0.1074 lot:0.0374 that:0.1465 that:0.1357 I:0.0771)
		(,:0.0762 I:0.1187 am:0.0645 not:0.1216 lot:0.0435 that:0.1396 that:0.1396 but:0.0874)
		(,:0.0918 I:0.1172 am:0.0752 not:0.1494 lot:0.0393 that:0.1338 that:0.1338 but:0.1069)
		(,:0.1016 I:0.1216 am:0.0791 not:0.1572 good:0.0366 that:0.1270 that:0.1128 but:0.1084)
		(,:0.0986 I:0.1226 am:0.0732 not:0.1514 great:0.0364 that:0.1289 that:0.1074 but:0.1064)
		(,:0.0952 I:0.1201 am:0.0698 not:0.1426 great:0.0356 that:0.1309 that:0.1021 but:0.1030)
		(,:0.0845 I:0.1123 am:0.0669 not:0.1436 great:0.0349 that:0.1338,:0.0996 and:0.1006)
		(,:0.0752 I:0.1079 am:0.0640 not:0.1377 great:0.0334 that:0.1328,:0.1025 and:0.1104)
		(,:0.0649 I:0.1006 am:0.0605 not:0.1260 great:0.0320 that:0.1367,:0.1011 and:0.1182)
		(,:0.0552 I:0.0923 am:0.0576 not:0.1211 great:0.0297 that:0.1328,:0.1025 and:0.1270)
		(,:0.0552 I:0.0923 am:0.0576 not:0.1211 great:0.0297 that:0.1328,:0.1025 and:0.1270)
 and
------
		( and:0.0952�:0.0811 not:0.0708 �:0.0170,:0.1670 of:0.1260 and:0.0635 the:0.0488)
		( I:0.0530 am:0.0579 not:0.1064 lot:0.0157 that:0.1279 of:0.1260 I:0.0879 the:0.0605)
		( I:0.0938 am:0.0693 not:0.1074 lot:0.0374 that:0.1465 that:0.1357 I:0.0771 the:0.0598)
		( I:0.1187 am:0.0645 not:0.1216 lot:0.0435 that:0.1396 that:0.1396 but:0.0874 I:0.0649)
		( I:0.1172 am:0.0752 not:0.1494 lot:0.0393 that:0.1338 that:0.1338 but:0.1069 I:0.0879)
		( I:0.1216 am:0.0791 not:0.1572 good:0.0366 that:0.1270 that:0.1128 but:0.1084 I:0.0903)
		( I:0.1226 am:0.0732 not:0.1514 great:0.0364 that:0.1289 that:0.1074 but:0.1064 I:0.0903)
		( I:0.1201 am:0.0698 not:0.1426 great:0.0356 that:0.1309 that:0.1021 but:0.1030 I:0.0898)
		( I:0.1123 am:0.0669 not:0.1436 great:0.0349 that:0.1338,:0.0996 and:0.1006 I:0.0879)
		( I:0.1079 am:0.0640 not:0.1377 great:0.0334 that:0.1328,:0.1025 and:0.1104 I:0.0840)
		( I:0.1006 am:0.0605 not:0.1260 great:0.0320 that:0.1367,:0.1011 and:0.1182 I:0.0806)
		( I:0.0923 am:0.0576 not:0.1211 great:0.0297 that:0.1328,:0.1025 and:0.1270 I:0.0771)
		( I:0.0923 am:0.0576 not:0.1211 great:0.0297 that:0.1328,:0.1025 and:0.1270 I:0.0771)
 I'm not sure that I'm not sure that I
1250: sample 0: Hello, I'm a language model,
------
		(,:0.0728 and:0.0698�:0.0869 not:0.0742 new:0.0116.:0.1338.:0.1021 and:0.0854)
		(,:0.0840 I:0.0530�:0.0605 not:0.0938 great:0.0203,:0.0981 of:0.1030 and:0.0962)
		(.:0.0693 I:0.1504�:0.0649 not:0.0889 great:0.0337 that:0.0898 that:0.0938 and:0.0986)
		(.:0.0889 I:0.1816�:0.0674 not:0.1187 great:0.0508,:0.0884,:0.0947 and:0.1289)
		(.:0.1245 I:0.2002�:0.0781 not:0.1162 great:0.0481 that:0.0962,:0.1094 and:0.1367)
		(.:0.1138 I:0.1943�:0.0820 not:0.1157 great:0.0474 that:0.0952,:0.1133 and:0.1387)
		(.:0.0981 I:0.1846�:0.0801 not:0.1206 great:0.0459 that:0.0942,:0.1133 and:0.1445)
		(.:0.0825 I:0.1777�:0.0830 not:0.1206 great:0.0449 that:0.0962,:0.1138 and:0.1523)
		(.:0.0688 I:0.1699�:0.0767 not:0.1201 great:0.0452 that:0.0957,:0.1133 and:0.1562)
		(.:0.0571 I:0.1621�:0.0757 not:0.1211 great:0.0439 that:0.0981,:0.1138 and:0.1611)
		(.:0.0486 I:0.1504�:0.0742 not:0.1211 great:0.0430 that:0.0977,:0.1133 and:0.1611)
		(.:0.0398 I:0.1436�:0.0688 not:0.1147 great:0.0405 that:0.0981,:0.1108 and:0.1611)
		(.:0.0398 I:0.1436�:0.0688 not:0.1147 great:0.0405 that:0.0981,:0.1108 and:0.1611)
 and
------
		( and:0.0698�:0.0869 not:0.0742 new:0.0116.:0.1338.:0.1021 and:0.0854 the:0.0510)
		( I:0.0530�:0.0605 not:0.0938 great:0.0203,:0.0981 of:0.1030 and:0.0962 the:0.0732)
		( I:0.1504�:0.0649 not:0.0889 great:0.0337 that:0.0898 that:0.0938 and:0.0986 I:0.1387)
		( I:0.1816�:0.0674 not:0.1187 great:0.0508,:0.0884,:0.0947 and:0.1289 I:0.1138)
		( I:0.2002�:0.0781 not:0.1162 great:0.0481 that:0.0962,:0.1094 and:0.1367 I:0.1221)
		( I:0.1943�:0.0820 not:0.1157 great:0.0474 that:0.0952,:0.1133 and:0.1387 I:0.1147)
		( I:0.1846�:0.0801 not:0.1206 great:0.0459 that:0.0942,:0.1133 and:0.1445 I:0.1128)
		( I:0.1777�:0.0830 not:0.1206 great:0.0449 that:0.0962,:0.1138 and:0.1523 I:0.1089)
		( I:0.1699�:0.0767 not:0.1201 great:0.0452 that:0.0957,:0.1133 and:0.1562 I:0.1025)
		( I:0.1621�:0.0757 not:0.1211 great:0.0439 that:0.0981,:0.1138 and:0.1611 I:0.0991)
		( I:0.1504�:0.0742 not:0.1211 great:0.0430 that:0.0977,:0.1133 and:0.1611 I:0.0957)
		( I:0.1436�:0.0688 not:0.1147 great:0.0405 that:0.0981,:0.1108 and:0.1611 I:0.0923)
		( I:0.1436�:0.0688 not:0.1147 great:0.0405 that:0.0981,:0.1108 and:0.1611 I:0.0923)
 I've got to be a great way to learn.
1400: sample 0: Hello, I'm a language model,
------
		(,:0.0864 and:0.0879�:0.0728 not:0.0898 few:0.0110,:0.1611,:0.1621 and:0.1196)
		(,:0.0713 we:0.0630�:0.0588 not:0.0674 bit:0.0231,:0.0981 of:0.1367 and:0.0811)
		(,:0.0605 I:0.1172 have:0.0664 not:0.0874 bit:0.0325,:0.1504,:0.1206 and:0.0884)
		(,:0.0664 I:0.1172�:0.0679 going:0.1206 little:0.0461,:0.1582,:0.1494 and:0.1328)
		(,:0.0923 we:0.1426�:0.0801 going:0.1416 little:0.0430,:0.1582,:0.1514 and:0.1455)
		(,:0.0869 we:0.1455�:0.0850 going:0.1406 little:0.0388,:0.1484,:0.1484 and:0.1465)
		(,:0.0830 we:0.1455�:0.0840 going:0.1367 little:0.0364,:0.1465,:0.1553 and:0.1455)
		(,:0.0776 we:0.1455�:0.0835 going:0.1279 bit:0.0349,:0.1426,:0.1572 and:0.1455)
		(,:0.0723 we:0.1416�:0.0830 going:0.1191 bit:0.0327,:0.1406,:0.1631 and:0.1445)
		(,:0.0674 we:0.1367�:0.0825 going:0.1172 great:0.0305,:0.1406,:0.1719 and:0.1436)
		(,:0.0645 we:0.1357�:0.0820 not:0.1094 great:0.0311,:0.1357,:0.1738 and:0.1396)
		(,:0.0596 we:0.1299�:0.0815 not:0.1079 great:0.0306,:0.1318,:0.1787 and:0.1396)
		(,:0.0596 we:0.1299�:0.0815 not:0.1079 great:0.0306,:0.1318,:0.1787 and:0.1396)
 and
------
		( and:0.0879�:0.0728 not:0.0898 few:0.0110,:0.1611,:0.1621 and:0.1196 the:0.0408)
		( we:0.0630�:0.0588 not:0.0674 bit:0.0231,:0.0981 of:0.1367 and:0.0811 the:0.0835)
		( I:0.1172 have:0.0664 not:0.0874 bit:0.0325,:0.1504,:0.1206 and:0.0884 I:0.1426)
		( I:0.1172�:0.0679 going:0.1206 little:0.0461,:0.1582,:0.1494 and:0.1328 I:0.1113)
		( we:0.1426�:0.0801 going:0.1416 little:0.0430,:0.1582,:0.1514 and:0.1455 I:0.1270)
		( we:0.1455�:0.0850 going:0.1406 little:0.0388,:0.1484,:0.1484 and:0.1465 I:0.1206)
		( we:0.1455�:0.0840 going:0.1367 little:0.0364,:0.1465,:0.1553 and:0.1455 I:0.1172)
		( we:0.1455�:0.0835 going:0.1279 bit:0.0349,:0.1426,:0.1572 and:0.1455 I:0.1157)
		( we:0.1416�:0.0830 going:0.1191 bit:0.0327,:0.1406,:0.1631 and:0.1445 I:0.1143)
		( we:0.1367�:0.0825 going:0.1172 great:0.0305,:0.1406,:0.1719 and:0.1436 I:0.1099)
		( we:0.1357�:0.0820 not:0.1094 great:0.0311,:0.1357,:0.1738 and:0.1396 I:0.1084)
		( we:0.1299�:0.0815 not:0.1079 great:0.0306,:0.1318,:0.1787 and:0.1396 I:0.1084)
		( we:0.1299�:0.0815 not:0.1079 great:0.0306,:0.1318,:0.1787 and:0.1396 I:0.1084)
 I'm going to be a language that I want to
1550: sample 0: Hello, I'm a language model,
------
		(,:0.0854 and:0.1060�:0.0630 not:0.0820 �:0.0145,:0.1650.:0.1289 and:0.0703)
		(,:0.0859 the:0.0449 am:0.0564 going:0.0693 lot:0.0150 that:0.1074 of:0.1768 but:0.0913)
		(,:0.0583 I:0.1055 have:0.0520 sure:0.0957 lot:0.0299 that:0.1084 of:0.1133 but:0.1484)
		(,:0.0562 I:0.1240 have:0.0591 sure:0.1177 little:0.0432 that:0.1089,:0.1021 but:0.2021)
		(.:0.0967 I:0.1543 have:0.0664 sure:0.1270 little:0.0464 that:0.1226.:0.1387 but:0.2441)
		(.:0.1060 I:0.1602 have:0.0718 sure:0.1260 little:0.0413 that:0.1260.:0.1582 but:0.2354)
		(.:0.0962 I:0.1562 have:0.0698 sure:0.1250 little:0.0371 that:0.1250.:0.1562 I:0.2188)
		(.:0.0879 I:0.1484 have:0.0693 sure:0.1187 little:0.0347 that:0.1250.:0.1514 I:0.2236)
		(.:0.0811 I:0.1455 have:0.0684 sure:0.1128 little:0.0325 that:0.1211.:0.1504 I:0.2285)
		(.:0.0757 I:0.1406 have:0.0679 sure:0.1069 little:0.0312 that:0.1211.:0.1445 I:0.2324)
		(.:0.0693 I:0.1367 have:0.0669 sure:0.1011 little:0.0292,:0.1177,:0.1426 I:0.2354)
		(.:0.0649 I:0.1289 have:0.0625 sure:0.0898 little:0.0278,:0.1147,:0.1426 I:0.2383)
		(.:0.0649 I:0.1289 have:0.0625 sure:0.0898 little:0.0278,:0.1147,:0.1426 I:0.2383)
 I
------
		( and:0.1060�:0.0630 not:0.0820 �:0.0145,:0.1650.:0.1289 and:0.0703 have:0.0679)
		( the:0.0449 am:0.0564 going:0.0693 lot:0.0150 that:0.1074 of:0.1768 but:0.0913 can:0.0615)
		( I:0.1055 have:0.0520 sure:0.0957 lot:0.0299 that:0.1084 of:0.1133 but:0.1484 can:0.0698)
		( I:0.1240 have:0.0591 sure:0.1177 little:0.0432 that:0.1089,:0.1021 but:0.2021'm:0.0659)
		( I:0.1543 have:0.0664 sure:0.1270 little:0.0464 that:0.1226.:0.1387 but:0.2441'm:0.0708)
		( I:0.1602 have:0.0718 sure:0.1260 little:0.0413 that:0.1260.:0.1582 but:0.2354'm:0.0713)
		( I:0.1562 have:0.0698 sure:0.1250 little:0.0371 that:0.1250.:0.1562 I:0.2188'm:0.0728)
		( I:0.1484 have:0.0693 sure:0.1187 little:0.0347 that:0.1250.:0.1514 I:0.2236'm:0.0718)
		( I:0.1455 have:0.0684 sure:0.1128 little:0.0325 that:0.1211.:0.1504 I:0.2285'm:0.0708)
		( I:0.1406 have:0.0679 sure:0.1069 little:0.0312 that:0.1211.:0.1445 I:0.2324'm:0.0708)
		( I:0.1367 have:0.0669 sure:0.1011 little:0.0292,:0.1177,:0.1426 I:0.2354'm:0.0708)
		( I:0.1289 have:0.0625 sure:0.0898 little:0.0278,:0.1147,:0.1426 I:0.2383'm:0.0703)
		( I:0.1289 have:0.0625 sure:0.0898 little:0.0278,:0.1147,:0.1426 I:0.2383'm:0.0703)
'm going to be a teacher, but I've got
1700: sample 0: Hello, I'm a language model,
------
		(,:0.0566 and:0.0962 was:0.0544 not:0.1089 ":0.0117,:0.1465,:0.1162 and:0.0693)
		(.:0.0732 I:0.0596 am:0.0547 not:0.0879 lot:0.0261 that:0.0972 of:0.1807 I:0.0806)
		(,:0.0471 I:0.1553'm:0.0549 not:0.1045 lot:0.0369,:0.1069 of:0.1328 I:0.1455)
		(,:0.0500 I:0.1621'm:0.0942 not:0.1426 little:0.0491,:0.1050.:0.1152 I:0.1660)
		(,:0.0649 I:0.1592'm:0.1040 not:0.1455 little:0.0483 that:0.1196.:0.1309 I:0.1748)
		(,:0.0586 I:0.1475'm:0.1025 not:0.1543 little:0.0452 that:0.1187.:0.1309 I:0.1709)
		(,:0.0525 I:0.1348'm:0.0981 not:0.1592 little:0.0437 that:0.1133.:0.1270 I:0.1777)
		(,:0.0483 I:0.1260'm:0.0947 not:0.1562 little:0.0425 that:0.1118,:0.1270 I:0.1738)
		(,:0.0447 I:0.1172'm:0.0908 not:0.1621 little:0.0422 that:0.1104,:0.1289 I:0.1807)
		(
:0.0449 I:0.1084'm:0.0928 not:0.1592 little:0.0417 that:0.1050,:0.1309 I:0.1846)
		(
:0.0439 I:0.1030'm:0.0894 not:0.1562 little:0.0410 that:0.1035,:0.1338 I:0.1885)
		(
:0.0427 I:0.0947'm:0.0864 not:0.1533 little:0.0400,:0.1021,:0.1357 I:0.1934)
		(
:0.0427 I:0.0947'm:0.0864 not:0.1533 little:0.0400,:0.1021,:0.1357 I:0.1934)
 I
------
		( and:0.0962 was:0.0544 not:0.1089 ":0.0117,:0.1465,:0.1162 and:0.0693 have:0.0461)
		( I:0.0596 am:0.0547 not:0.0879 lot:0.0261 that:0.0972 of:0.1807 I:0.0806'm:0.0762)
		( I:0.1553'm:0.0549 not:0.1045 lot:0.0369,:0.1069 of:0.1328 I:0.1455'm:0.1523)
		( I:0.1621'm:0.0942 not:0.1426 little:0.0491,:0.1050.:0.1152 I:0.1660'm:0.2334)
		( I:0.1592'm:0.1040 not:0.1455 little:0.0483 that:0.1196.:0.1309 I:0.1748'm:0.2637)
		( I:0.1475'm:0.1025 not:0.1543 little:0.0452 that:0.1187.:0.1309 I:0.1709'm:0.2715)
		( I:0.1348'm:0.0981 not:0.1592 little:0.0437 that:0.1133.:0.1270 I:0.1777'm:0.2715)
		( I:0.1260'm:0.0947 not:0.1562 little:0.0425 that:0.1118,:0.1270 I:0.1738'm:0.2734)
		( I:0.1172'm:0.0908 not:0.1621 little:0.0422 that:0.1104,:0.1289 I:0.1807'm:0.2793)
		( I:0.1084'm:0.0928 not:0.1592 little:0.0417 that:0.1050,:0.1309 I:0.1846'm:0.2695)
		( I:0.1030'm:0.0894 not:0.1562 little:0.0410 that:0.1035,:0.1338 I:0.1885'm:0.2754)
		( I:0.0947'm:0.0864 not:0.1533 little:0.0400,:0.1021,:0.1357 I:0.1934'm:0.2695)
		( I:0.0947'm:0.0864 not:0.1533 little:0.0400,:0.1021,:0.1357 I:0.1934'm:0.2695)
'm not sure that I'm not sure that I've
1850: sample 0: Hello, I'm a language model,
------
		(,:0.0571 and:0.0684�:0.0913 not:0.1050 �:0.0141,:0.1270,:0.1118 I:0.0544)
		(.:0.0796 I:0.0708�:0.1084 not:0.1094 great:0.0203 that:0.1338 of:0.1992 I:0.1025)
		(,:0.0693 I:0.1494�:0.0981 not:0.1216 lot:0.0300 that:0.1235 of:0.1484 I:0.1387)
		(,:0.0747 I:0.1338�:0.0996 not:0.1455 lot:0.0447 that:0.1582 that:0.1523 and:0.0986)
		(.:0.0820 I:0.1226�:0.1030 not:0.1455 lot:0.0435 that:0.1816 that:0.1660 but:0.1064)
		(.:0.0762 I:0.1104�:0.1035 not:0.1445 lot:0.0439 that:0.1807 that:0.1660 but:0.1025)
		(.:0.0693 I:0.0996�:0.1006 not:0.1387 lot:0.0439 that:0.1836 that:0.1650 but:0.1001)
		(.:0.0635 I:0.0923�:0.0986 not:0.1406 lot:0.0454 that:0.1826 that:0.1680 but:0.0947)
		(.:0.0583 I:0.0825�:0.0962 not:0.1357 lot:0.0457 that:0.1865 that:0.1660 but:0.0947)
		(.:0.0530 I:0.0737�:0.0947 not:0.1309 lot:0.0471 that:0.1855 that:0.1631 but:0.0913)
		(,:0.0481 you:0.0674�:0.0933 not:0.1270 lot:0.0474 that:0.1855 that:0.1650 but:0.0913)
		(,:0.0449 you:0.0654�:0.0864 not:0.1226 lot:0.0491 that:0.1846 that:0.1631 but:0.0908)
		(,:0.0449 you:0.0654�:0.0864 not:0.1226 lot:0.0491 that:0.1846 that:0.1631 but:0.0908)
 but
------
		( and:0.0684�:0.0913 not:0.1050 �:0.0141,:0.1270,:0.1118 I:0.0544 the:0.1113)
		( I:0.0708�:0.1084 not:0.1094 great:0.0203 that:0.1338 of:0.1992 I:0.1025 I:0.2383)
		( I:0.1494�:0.0981 not:0.1216 lot:0.0300 that:0.1235 of:0.1484 I:0.1387 I:0.2578)
		( I:0.1338�:0.0996 not:0.1455 lot:0.0447 that:0.1582 that:0.1523 and:0.0986 I:0.2500)
		( I:0.1226�:0.1030 not:0.1455 lot:0.0435 that:0.1816 that:0.1660 but:0.1064 I:0.2412)
		( I:0.1104�:0.1035 not:0.1445 lot:0.0439 that:0.1807 that:0.1660 but:0.1025 I:0.2344)
		( I:0.0996�:0.1006 not:0.1387 lot:0.0439 that:0.1836 that:0.1650 but:0.1001 I:0.2412)
		( I:0.0923�:0.0986 not:0.1406 lot:0.0454 that:0.1826 that:0.1680 but:0.0947 I:0.2471)
		( I:0.0825�:0.0962 not:0.1357 lot:0.0457 that:0.1865 that:0.1660 but:0.0947 I:0.2412)
		( I:0.0737�:0.0947 not:0.1309 lot:0.0471 that:0.1855 that:0.1631 but:0.0913 I:0.2461)
		( you:0.0674�:0.0933 not:0.1270 lot:0.0474 that:0.1855 that:0.1650 but:0.0913 I:0.2402)
		( you:0.0654�:0.0864 not:0.1226 lot:0.0491 that:0.1846 that:0.1631 but:0.0908 I:0.2461)
		( you:0.0654�:0.0864 not:0.1226 lot:0.0491 that:0.1846 that:0.1631 but:0.0908 I:0.2461)
 I'm not sure that I'm going to be a
2000: sample 0: Hello, I'm a language model,
------
		(.:0.0635 and:0.0520�:0.0825 not:0.1279 few:0.0100,:0.1328,:0.1133 I:0.0454)
		(.:0.0869 I:0.0928�:0.0918 not:0.1001 great:0.0255 that:0.0981 of:0.2090 I:0.1553)
		(,:0.0649 I:0.1484�:0.0874 not:0.1572 little:0.0291 that:0.1152 of:0.1719 I:0.1816)
		(.:0.0625 I:0.1377�:0.0923 not:0.2158 little:0.0425 that:0.1318 that:0.1387 I:0.1807)
		(.:0.0718 I:0.1270�:0.0903 not:0.2158 little:0.0403 that:0.1387 that:0.1523 I:0.1787)
		(.:0.0654 I:0.1206�:0.0898 not:0.2178 little:0.0383 that:0.1396 that:0.1523 I:0.1729)
		(.:0.0610 I:0.1118�:0.0879 not:0.2217 little:0.0359 that:0.1416 that:0.1475 I:0.1738)
		(.:0.0571 I:0.1035�:0.0854 not:0.2168 little:0.0344 that:0.1416 that:0.1416 I:0.1748)
		(.:0.0544 I:0.0972�:0.0835 not:0.2217 little:0.0330 that:0.1406 that:0.1396 I:0.1787)
		(,:0.0505 I:0.0884�:0.0811 not:0.2168 little:0.0325 that:0.1396 that:0.1338 I:0.1787)
		(,:0.0496 I:0.0796�:0.0786 not:0.2119 little:0.0317 that:0.1387 that:0.1318 I:0.1768)
		(,:0.0483 I:0.0713�:0.0762 not:0.2168 little:0.0309 that:0.1348 of:0.1270 I:0.1797)
		(,:0.0483 I:0.0713�:0.0762 not:0.2168 little:0.0309 that:0.1348 of:0.1270 I:0.1797)
 I
------
		( and:0.0520�:0.0825 not:0.1279 few:0.0100,:0.1328,:0.1133 I:0.0454�:0.0635)
		( I:0.0928�:0.0918 not:0.1001 great:0.0255 that:0.0981 of:0.2090 I:0.1553'm:0.1084)
		( I:0.1484�:0.0874 not:0.1572 little:0.0291 that:0.1152 of:0.1719 I:0.1816'm:0.1895)
		( I:0.1377�:0.0923 not:0.2158 little:0.0425 that:0.1318 that:0.1387 I:0.1807'm:0.2461)
		( I:0.1270�:0.0903 not:0.2158 little:0.0403 that:0.1387 that:0.1523 I:0.1787'm:0.2695)
		( I:0.1206�:0.0898 not:0.2178 little:0.0383 that:0.1396 that:0.1523 I:0.1729'm:0.2812)
		( I:0.1118�:0.0879 not:0.2217 little:0.0359 that:0.1416 that:0.1475 I:0.1738'm:0.2871)
		( I:0.1035�:0.0854 not:0.2168 little:0.0344 that:0.1416 that:0.1416 I:0.1748'm:0.3066)
		( I:0.0972�:0.0835 not:0.2217 little:0.0330 that:0.1406 that:0.1396 I:0.1787'm:0.3164)
		( I:0.0884�:0.0811 not:0.2168 little:0.0325 that:0.1396 that:0.1338 I:0.1787'm:0.3242)
		( I:0.0796�:0.0786 not:0.2119 little:0.0317 that:0.1387 that:0.1318 I:0.1768'm:0.3301)
		( I:0.0713�:0.0762 not:0.2168 little:0.0309 that:0.1348 of:0.1270 I:0.1797'm:0.3242)
		( I:0.0713�:0.0762 not:0.2168 little:0.0309 that:0.1348 of:0.1270 I:0.1797'm:0.3242)
'm not a language. I'm not a language.
2150: sample 0: Hello, I'm a language model,
------
		(.:0.0586 and:0.0659 have:0.0608 not:0.1709 ":0.0157,:0.1299 of:0.1475 and:0.0496)
		(.:0.0688 I:0.1113�:0.0820 not:0.1543 good:0.0231 of:0.1206 of:0.2246 but:0.1191)
		(.:0.0603 I:0.1729 am:0.0811 not:0.1533 good:0.0282 that:0.1367 of:0.1885 but:0.1221)
		(.:0.0586 I:0.1533 am:0.0942 not:0.1699 good:0.0349 that:0.1602 of:0.1738 but:0.1582)
		(.:0.0598 I:0.1328 am:0.0933 not:0.1758 good:0.0339 that:0.1699 of:0.1699 but:0.1562)
		(.:0.0557 I:0.1211 am:0.0913 not:0.1807 good:0.0344 that:0.1699 of:0.1689 but:0.1465)
		(,:0.0537 I:0.1113�:0.0859 not:0.1885 good:0.0342 that:0.1719 of:0.1680 but:0.1367)
		(,:0.0522 I:0.0991�:0.0903 not:0.1953 good:0.0347 that:0.1738 of:0.1709 but:0.1250)
		(,:0.0520 I:0.0903�:0.0898 not:0.2041 good:0.0354 that:0.1758 of:0.1719 but:0.1187)
		(,:0.0503 I:0.0820�:0.0947 not:0.2119 good:0.0347 that:0.1777 of:0.1689 I:0.1157)
		(,:0.0498 you:0.0767�:0.0947 not:0.2188 good:0.0349 that:0.1748 of:0.1709 I:0.1167)
		(,:0.0491 you:0.0732�:0.0996 not:0.2168 good:0.0352 that:0.1758 of:0.1680 I:0.1143)
		(,:0.0491 you:0.0732�:0.0996 not:0.2168 good:0.0352 that:0.1758 of:0.1680 I:0.1143)
 I
------
		( and:0.0659 have:0.0608 not:0.1709 ":0.0157,:0.1299 of:0.1475 and:0.0496�:0.0605)
		( I:0.1113�:0.0820 not:0.1543 good:0.0231 of:0.1206 of:0.2246 but:0.1191'm:0.0869)
		( I:0.1729 am:0.0811 not:0.1533 good:0.0282 that:0.1367 of:0.1885 but:0.1221'm:0.1436)
		( I:0.1533 am:0.0942 not:0.1699 good:0.0349 that:0.1602 of:0.1738 but:0.1582'm:0.1973)
		( I:0.1328 am:0.0933 not:0.1758 good:0.0339 that:0.1699 of:0.1699 but:0.1562'm:0.2109)
		( I:0.1211 am:0.0913 not:0.1807 good:0.0344 that:0.1699 of:0.1689 but:0.1465'm:0.2041)
		( I:0.1113�:0.0859 not:0.1885 good:0.0342 that:0.1719 of:0.1680 but:0.1367'm:0.2100)
		( I:0.0991�:0.0903 not:0.1953 good:0.0347 that:0.1738 of:0.1709 but:0.1250'm:0.2080)
		( I:0.0903�:0.0898 not:0.2041 good:0.0354 that:0.1758 of:0.1719 but:0.1187'm:0.2041)
		( I:0.0820�:0.0947 not:0.2119 good:0.0347 that:0.1777 of:0.1689 I:0.1157'm:0.2109)
		( you:0.0767�:0.0947 not:0.2188 good:0.0349 that:0.1748 of:0.1709 I:0.1167'm:0.2080)
		( you:0.0732�:0.0996 not:0.2168 good:0.0352 that:0.1758 of:0.1680 I:0.1143'm:0.2041)
		( you:0.0732�:0.0996 not:0.2168 good:0.0352 that:0.1758 of:0.1680 I:0.1143'm:0.2041)
'm a good idea.
I'm a good idea
2300: sample 0: Hello, I'm a language model,
------
		(,:0.0535 I:0.0530 am:0.0518 not:0.1709 lot:0.0222 of:0.1069,:0.1226 and:0.0869)
		(.:0.0457 I:0.1270 am:0.0757 not:0.1270 good:0.0315 of:0.1357 of:0.2129 I:0.1406)
		(,:0.0500 I:0.1445 am:0.0859 not:0.1660 good:0.0283 that:0.1318 of:0.1973 and:0.1504)
		(,:0.0437 I:0.1309 am:0.1035 not:0.1729 good:0.0334 that:0.1299 of:0.1855 and:0.1709)
		(,:0.0427 I:0.1191 am:0.1016 not:0.1680 very:0.0325 that:0.1299 of:0.1816 and:0.1621)
		(,:0.0393 I:0.1089 am:0.1025 not:0.1689 very:0.0337 that:0.1328 of:0.1768 and:0.1533)
		(,:0.0371 I:0.0981 am:0.0947 not:0.1641 very:0.0347 that:0.1309 of:0.1738 and:0.1465)
		(,:0.0359 I:0.0874 am:0.0923 not:0.1611 very:0.0356 that:0.1318 of:0.1768 and:0.1406)
		(,:0.0347 I:0.0801 am:0.0908 not:0.1650 very:0.0366 that:0.1328 of:0.1729 and:0.1338)
		(,:0.0334 I:0.0693�:0.0884 not:0.1621 very:0.0376 that:0.1309 of:0.1748 and:0.1235)
		(,:0.0317 I:0.0613�:0.0864 not:0.1680 very:0.0386 that:0.1328 of:0.1719 and:0.1177)
		(,:0.0302 I:0.0540 am:0.0854 not:0.1641 very:0.0393 that:0.1299 of:0.1689 and:0.1118)
		(,:0.0302 I:0.0540 am:0.0854 not:0.1641 very:0.0393 that:0.1299 of:0.1689 and:0.1118)
 and
------
		( I:0.0530 am:0.0518 not:0.1709 lot:0.0222 of:0.1069,:0.1226 and:0.0869 the:0.0669)
		( I:0.1270 am:0.0757 not:0.1270 good:0.0315 of:0.1357 of:0.2129 I:0.1406 I:0.2891)
		( I:0.1445 am:0.0859 not:0.1660 good:0.0283 that:0.1318 of:0.1973 and:0.1504 I:0.2910)
		( I:0.1309 am:0.1035 not:0.1729 good:0.0334 that:0.1299 of:0.1855 and:0.1709 I:0.3496)
		( I:0.1191 am:0.1016 not:0.1680 very:0.0325 that:0.1299 of:0.1816 and:0.1621 I:0.3379)
		( I:0.1089 am:0.1025 not:0.1689 very:0.0337 that:0.1328 of:0.1768 and:0.1533 I:0.3301)
		( I:0.0981 am:0.0947 not:0.1641 very:0.0347 that:0.1309 of:0.1738 and:0.1465 I:0.3262)
		( I:0.0874 am:0.0923 not:0.1611 very:0.0356 that:0.1318 of:0.1768 and:0.1406 I:0.3379)
		( I:0.0801 am:0.0908 not:0.1650 very:0.0366 that:0.1328 of:0.1729 and:0.1338 I:0.3340)
		( I:0.0693�:0.0884 not:0.1621 very:0.0376 that:0.1309 of:0.1748 and:0.1235 I:0.3301)
		( I:0.0613�:0.0864 not:0.1680 very:0.0386 that:0.1328 of:0.1719 and:0.1177 I:0.3262)
		( I:0.0540 am:0.0854 not:0.1641 very:0.0393 that:0.1299 of:0.1689 and:0.1118 I:0.3223)
		( I:0.0540 am:0.0854 not:0.1641 very:0.0393 that:0.1299 of:0.1689 and:0.1118 I:0.3223)
 I'm not a language. I'm not a language
2450: sample 0: Hello, I'm a language model,
------
		(,:0.0645 I:0.0527 am:0.0623 not:0.1484 ":0.0199 of:0.1396,:0.1260 the:0.0620)
		(.:0.0547 I:0.1128 am:0.0781 not:0.1523 good:0.0272 that:0.1011.:0.1040 and:0.1094)
		(.:0.0464 I:0.1240 am:0.0752 not:0.2314 little:0.0227 that:0.0977 for:0.1523 and:0.1631)
		(,:0.0427 I:0.1079 have:0.0879 not:0.2559 good:0.0262 that:0.0913 for:0.1719 and:0.2021)
		(,:0.0400 I:0.0977 have:0.0879 not:0.2402 good:0.0275 that:0.0913 for:0.1621 and:0.2002)
		(,:0.0374 I:0.0918 have:0.0894 not:0.2402 good:0.0278 that:0.0908 for:0.1572 and:0.1992)
		(,:0.0366 I:0.0845 have:0.0913 not:0.2354 good:0.0276 that:0.0889 for:0.1543 and:0.2002)
		(,:0.0344 I:0.0771 have:0.0942 not:0.2285 good:0.0282 that:0.0898 for:0.1514 and:0.1992)
		(,:0.0332 I:0.0684 have:0.0918 not:0.2119 good:0.0281 that:0.0908 for:0.1484 and:0.1982)
		(,:0.0298 I:0.0620 have:0.0942 not:0.2080 good:0.0287 that:0.0918 for:0.1445 and:0.1973)
		(,:0.0273 I:0.0544 have:0.0918 not:0.2041 good:0.0292 that:0.0898 that:0.1406 and:0.1953)
		(,:0.0249 I:0.0474 have:0.0942 not:0.2012 good:0.0288 that:0.0903 that:0.1416 and:0.1934)
		(,:0.0249 I:0.0474 have:0.0942 not:0.2012 good:0.0288 that:0.0903 that:0.1416 and:0.1934)
 and
------
		( I:0.0527 am:0.0623 not:0.1484 ":0.0199 of:0.1396,:0.1260 the:0.0620 the:0.1040)
		( I:0.1128 am:0.0781 not:0.1523 good:0.0272 that:0.1011.:0.1040 and:0.1094 I:0.2412)
		( I:0.1240 am:0.0752 not:0.2314 little:0.0227 that:0.0977 for:0.1523 and:0.1631 I:0.2461)
		( I:0.1079 have:0.0879 not:0.2559 good:0.0262 that:0.0913 for:0.1719 and:0.2021 I:0.2949)
		( I:0.0977 have:0.0879 not:0.2402 good:0.0275 that:0.0913 for:0.1621 and:0.2002 I:0.2969)
		( I:0.0918 have:0.0894 not:0.2402 good:0.0278 that:0.0908 for:0.1572 and:0.1992 I:0.2891)
		( I:0.0845 have:0.0913 not:0.2354 good:0.0276 that:0.0889 for:0.1543 and:0.2002 I:0.2852)
		( I:0.0771 have:0.0942 not:0.2285 good:0.0282 that:0.0898 for:0.1514 and:0.1992 I:0.2793)
		( I:0.0684 have:0.0918 not:0.2119 good:0.0281 that:0.0908 for:0.1484 and:0.1982 I:0.2754)
		( I:0.0620 have:0.0942 not:0.2080 good:0.0287 that:0.0918 for:0.1445 and:0.1973 I:0.2793)
		( I:0.0544 have:0.0918 not:0.2041 good:0.0292 that:0.0898 that:0.1406 and:0.1953 I:0.2715)
		( I:0.0474 have:0.0942 not:0.2012 good:0.0288 that:0.0903 that:0.1416 and:0.1934 I:0.2656)
		( I:0.0474 have:0.0942 not:0.2012 good:0.0288 that:0.0903 that:0.1416 and:0.1934 I:0.2656)
 I'm not a language.
The first thing I
2600: sample 0: Hello, I'm a language model,
------
		(,:0.0481 you:0.0840�:0.0815 not:0.1226 lot:0.0287,:0.0923.:0.1885 and:0.1060)
		(.:0.0522 I:0.1660 am:0.0938 not:0.1108 little:0.0332 that:0.1396.:0.2148 and:0.1396)
		(.:0.0444 you:0.1211 am:0.1035 not:0.1475 little:0.0339 that:0.1484.:0.2070 and:0.1777)
		(.:0.0413 you:0.1367�:0.1074 not:0.1523 little:0.0322 that:0.1553.:0.2139 and:0.1748)
		(.:0.0391 you:0.1357�:0.1113 not:0.1533 little:0.0305 that:0.1602.:0.2139 and:0.1699)
		(.:0.0422 you:0.1299�:0.1152 not:0.1465 little:0.0297 that:0.1611.:0.2148 and:0.1650)
		(.:0.0444 you:0.1270�:0.1138 not:0.1494 little:0.0299 that:0.1621.:0.2168 and:0.1621)
		(.:0.0452 you:0.1206�:0.1196 not:0.1455 bit:0.0304 that:0.1641.:0.2197 and:0.1582)
		(.:0.0442 you:0.1138�:0.1191 not:0.1416 bit:0.0308 that:0.1611.:0.2217 and:0.1504)
		(.:0.0430 you:0.1060�:0.1260 not:0.1377 bit:0.0311 that:0.1621.:0.2236 and:0.1465)
		(,:0.0391 you:0.0981�:0.1260 not:0.1426 bit:0.0315 that:0.1602.:0.2266 and:0.1436)
		(,:0.0374 you:0.0903�:0.1270 not:0.1396 bit:0.0320 that:0.1611.:0.2285 and:0.1387)
		(,:0.0374 you:0.0903�:0.1270 not:0.1396 bit:0.0320 that:0.1611.:0.2285 and:0.1387)
 and
------
		( you:0.0840�:0.0815 not:0.1226 lot:0.0287,:0.0923.:0.1885 and:0.1060 the:0.1006)
		( I:0.1660 am:0.0938 not:0.1108 little:0.0332 that:0.1396.:0.2148 and:0.1396 I:0.3105)
		( you:0.1211 am:0.1035 not:0.1475 little:0.0339 that:0.1484.:0.2070 and:0.1777 I:0.3750)
		( you:0.1367�:0.1074 not:0.1523 little:0.0322 that:0.1553.:0.2139 and:0.1748 I:0.4805)
		( you:0.1357�:0.1113 not:0.1533 little:0.0305 that:0.1602.:0.2139 and:0.1699 I:0.4707)
		( you:0.1299�:0.1152 not:0.1465 little:0.0297 that:0.1611.:0.2148 and:0.1650 I:0.4590)
		( you:0.1270�:0.1138 not:0.1494 little:0.0299 that:0.1621.:0.2168 and:0.1621 I:0.4668)
		( you:0.1206�:0.1196 not:0.1455 bit:0.0304 that:0.1641.:0.2197 and:0.1582 I:0.4551)
		( you:0.1138�:0.1191 not:0.1416 bit:0.0308 that:0.1611.:0.2217 and:0.1504 I:0.4609)
		( you:0.1060�:0.1260 not:0.1377 bit:0.0311 that:0.1621.:0.2236 and:0.1465 I:0.4512)
		( you:0.0981�:0.1260 not:0.1426 bit:0.0315 that:0.1602.:0.2266 and:0.1436 I:0.4531)
		( you:0.0903�:0.1270 not:0.1396 bit:0.0320 that:0.1611.:0.2285 and:0.1387 I:0.4434)
		( you:0.0903�:0.1270 not:0.1396 bit:0.0320 that:0.1611.:0.2285 and:0.1387 I:0.4434)
 I'm a language model. I'm a language model
2750: sample 0: Hello, I'm a language model,
------
		(,:0.0566 you:0.0957 am:0.0669 not:0.1816 lot:0.0352,:0.1191.:0.2090 we:0.0679)
		(.:0.0386 I:0.1514 am:0.0796 not:0.1699 little:0.0415 that:0.1157.:0.2070 but:0.1406)
		(,:0.0330 you:0.1270 am:0.0879 not:0.1895 little:0.0435 that:0.0986.:0.1797 but:0.1650)
		(,:0.0339 you:0.1387 am:0.1035 not:0.1934 good:0.0461 that:0.1060.:0.1885 but:0.1973)
		(,:0.0310 you:0.1348 am:0.1016 not:0.1895 good:0.0476 that:0.1045.:0.1836 but:0.1973)
		(,:0.0317 you:0.1260 am:0.0981 not:0.1914 good:0.0476 that:0.1040.:0.1807 but:0.1924)
		(,:0.0322 you:0.1201 am:0.0898 not:0.1855 good:0.0481 that:0.1045.:0.1787 but:0.1875)
		(,:0.0317 you:0.1123 have:0.0879 not:0.1914 good:0.0483 that:0.1021.:0.1758 but:0.1787)
		(,:0.0306 you:0.1011 have:0.0864 not:0.1875 good:0.0486 that:0.1001.:0.1729 but:0.1748)
		(,:0.0295 you:0.0933 have:0.0894 not:0.1826 good:0.0474 that:0.0977.:0.1709 and:0.1699)
		(,:0.0280 you:0.0830 have:0.0884 not:0.1797 good:0.0479 that:0.0957.:0.1689 and:0.1660)
		(,:0.0272 you:0.0742 have:0.0918 not:0.1777 good:0.0479 that:0.0938.:0.1670 and:0.1631)
		(,:0.0272 you:0.0742 have:0.0918 not:0.1777 good:0.0479 that:0.0938.:0.1670 and:0.1631)
 and
------
		( you:0.0957 am:0.0669 not:0.1816 lot:0.0352,:0.1191.:0.2090 we:0.0679 the:0.0820)
		( I:0.1514 am:0.0796 not:0.1699 little:0.0415 that:0.1157.:0.2070 but:0.1406 I:0.3691)
		( you:0.1270 am:0.0879 not:0.1895 little:0.0435 that:0.0986.:0.1797 but:0.1650 I:0.4238)
		( you:0.1387 am:0.1035 not:0.1934 good:0.0461 that:0.1060.:0.1885 but:0.1973 I:0.4824)
		( you:0.1348 am:0.1016 not:0.1895 good:0.0476 that:0.1045.:0.1836 but:0.1973 I:0.4570)
		( you:0.1260 am:0.0981 not:0.1914 good:0.0476 that:0.1040.:0.1807 but:0.1924 I:0.4668)
		( you:0.1201 am:0.0898 not:0.1855 good:0.0481 that:0.1045.:0.1787 but:0.1875 I:0.4590)
		( you:0.1123 have:0.0879 not:0.1914 good:0.0483 that:0.1021.:0.1758 but:0.1787 I:0.4531)
		( you:0.1011 have:0.0864 not:0.1875 good:0.0486 that:0.1001.:0.1729 but:0.1748 I:0.4453)
		( you:0.0933 have:0.0894 not:0.1826 good:0.0474 that:0.0977.:0.1709 and:0.1699 I:0.4355)
		( you:0.0830 have:0.0884 not:0.1797 good:0.0479 that:0.0957.:0.1689 and:0.1660 I:0.4434)
		( you:0.0742 have:0.0918 not:0.1777 good:0.0479 that:0.0938.:0.1670 and:0.1631 I:0.4355)
		( you:0.0742 have:0.0918 not:0.1777 good:0.0479 that:0.0938.:0.1670 and:0.1631 I:0.4355)
 I'm a good teacher. I'm a good teacher
2900: sample 0: Hello, I'm a language model,
------
		(,:0.0613 I:0.0918 am:0.0518 not:0.1196 lot:0.0262 of:0.1523.:0.2949 and:0.0679)
		(.:0.0420 I:0.1455 am:0.0732 going:0.1006 little:0.0334 of:0.1035.:0.2236 and:0.1196)
		(.:0.0422 I:0.1680 have:0.0752 going:0.1650 little:0.0344,:0.0908.:0.1738 and:0.1416)
		(,:0.0452 I:0.1650 have:0.0835 going:0.2178 little:0.0309 that:0.0923.:0.1533 and:0.1523)
		(.:0.0405 I:0.1533 have:0.0869 going:0.2207 little:0.0300 that:0.0952.:0.1523 and:0.1455)
		(.:0.0437 I:0.1475 have:0.0840 going:0.2246 little:0.0300 that:0.0981.:0.1504 and:0.1396)
		(.:0.0447 I:0.1387 have:0.0869 going:0.2275 little:0.0302 that:0.1016.:0.1484 and:0.1387)
		(.:0.0452 I:0.1299 have:0.0898 going:0.2197 little:0.0298 that:0.1030.:0.1514 and:0.1367)
		(.:0.0439 you:0.1279 have:0.0884 going:0.2236 little:0.0300 that:0.1040.:0.1494 and:0.1357)
		(.:0.0422 you:0.1260 have:0.0864 going:0.2178 good:0.0303 that:0.1050.:0.1484 and:0.1338)
		(.:0.0388 you:0.1201 have:0.0898 going:0.2227 good:0.0305 that:0.1060.:0.1504 and:0.1309)
		(.:0.0366 you:0.1138 have:0.0879 going:0.2178 good:0.0317 that:0.1074.:0.1484 and:0.1299)
		(.:0.0366 you:0.1138 have:0.0879 going:0.2178 good:0.0317 that:0.1074.:0.1484 and:0.1299)
 and
------
		( I:0.0918 am:0.0518 not:0.1196 lot:0.0262 of:0.1523.:0.2949 and:0.0679 the:0.0952)
		( I:0.1455 am:0.0732 going:0.1006 little:0.0334 of:0.1035.:0.2236 and:0.1196 I:0.3594)
		( I:0.1680 have:0.0752 going:0.1650 little:0.0344,:0.0908.:0.1738 and:0.1416 I:0.5430)
		( I:0.1650 have:0.0835 going:0.2178 little:0.0309 that:0.0923.:0.1533 and:0.1523 I:0.5859)
		( I:0.1533 have:0.0869 going:0.2207 little:0.0300 that:0.0952.:0.1523 and:0.1455 I:0.5742)
		( I:0.1475 have:0.0840 going:0.2246 little:0.0300 that:0.0981.:0.1504 and:0.1396 I:0.5781)
		( I:0.1387 have:0.0869 going:0.2275 little:0.0302 that:0.1016.:0.1484 and:0.1387 I:0.5820)
		( I:0.1299 have:0.0898 going:0.2197 little:0.0298 that:0.1030.:0.1514 and:0.1367 I:0.5703)
		( you:0.1279 have:0.0884 going:0.2236 little:0.0300 that:0.1040.:0.1494 and:0.1357 I:0.5742)
		( you:0.1260 have:0.0864 going:0.2178 good:0.0303 that:0.1050.:0.1484 and:0.1338 I:0.5781)
		( you:0.1201 have:0.0898 going:0.2227 good:0.0305 that:0.1060.:0.1504 and:0.1309 I:0.5781)
		( you:0.1138 have:0.0879 going:0.2178 good:0.0317 that:0.1074.:0.1484 and:0.1299 I:0.5820)
		( you:0.1138 have:0.0879 going:0.2178 good:0.0317 that:0.1074.:0.1484 and:0.1299 I:0.5820)
 I'm a good teacher. I'm a good teacher
3050: sample 0: Hello, I'm a language model,
------
		(,:0.0781 I:0.0952 have:0.0515 not:0.1025 great:0.0228 of:0.2129.:0.2412 and:0.1328)
		(.:0.0430 I:0.1118 am:0.0598 not:0.0986 little:0.0256 of:0.1777.:0.2148 and:0.1729)
		(.:0.0396 I:0.1328 have:0.0669 not:0.1001 little:0.0342 of:0.1543.:0.1592 and:0.1670)
		(,:0.0654 I:0.1157 have:0.0762 going:0.1299 little:0.0366 of:0.1553.:0.1572 and:0.1768)
		(,:0.0588 I:0.1069 have:0.0786 going:0.1299 little:0.0354 of:0.1543.:0.1582 and:0.1738)
		(,:0.0557 I:0.0977 have:0.0767 going:0.1309 little:0.0344 of:0.1523.:0.1660 and:0.1689)
		(.:0.0547 I:0.0918 have:0.0806 going:0.1318 little:0.0339 of:0.1523.:0.1680 and:0.1650)
		(.:0.0549 I:0.0835 have:0.0801 going:0.1270 little:0.0337 of:0.1572.:0.1699 and:0.1611)
		(.:0.0532 I:0.0776 have:0.0796 going:0.1289 little:0.0334 of:0.1533.:0.1777 and:0.1602)
		(.:0.0527 I:0.0718 have:0.0791 going:0.1318 little:0.0332 of:0.1533.:0.1807 and:0.1553)
		(.:0.0498 I:0.0645 have:0.0791 going:0.1270 little:0.0330 of:0.1533.:0.1826 and:0.1533)
		(.:0.0469 I:0.0574 have:0.0786 going:0.1299 little:0.0327 of:0.1504.:0.1836 and:0.1484)
		(.:0.0469 I:0.0574 have:0.0786 going:0.1299 little:0.0327 of:0.1504.:0.1836 and:0.1484)
 and
------
		( I:0.0952 have:0.0515 not:0.1025 great:0.0228 of:0.2129.:0.2412 and:0.1328 the:0.1025)
		( I:0.1118 am:0.0598 not:0.0986 little:0.0256 of:0.1777.:0.2148 and:0.1729 I:0.2451)
		( I:0.1328 have:0.0669 not:0.1001 little:0.0342 of:0.1543.:0.1592 and:0.1670 I:0.3906)
		( I:0.1157 have:0.0762 going:0.1299 little:0.0366 of:0.1553.:0.1572 and:0.1768 I:0.4238)
		( I:0.1069 have:0.0786 going:0.1299 little:0.0354 of:0.1543.:0.1582 and:0.1738 I:0.4082)
		( I:0.0977 have:0.0767 going:0.1309 little:0.0344 of:0.1523.:0.1660 and:0.1689 I:0.4004)
		( I:0.0918 have:0.0806 going:0.1318 little:0.0339 of:0.1523.:0.1680 and:0.1650 I:0.4062)
		( I:0.0835 have:0.0801 going:0.1270 little:0.0337 of:0.1572.:0.1699 and:0.1611 I:0.3984)
		( I:0.0776 have:0.0796 going:0.1289 little:0.0334 of:0.1533.:0.1777 and:0.1602 I:0.3906)
		( I:0.0718 have:0.0791 going:0.1318 little:0.0332 of:0.1533.:0.1807 and:0.1553 I:0.3828)
		( I:0.0645 have:0.0791 going:0.1270 little:0.0330 of:0.1533.:0.1826 and:0.1533 I:0.3867)
		( I:0.0574 have:0.0786 going:0.1299 little:0.0327 of:0.1504.:0.1836 and:0.1484 I:0.3770)
		( I:0.0574 have:0.0786 going:0.1299 little:0.0327 of:0.1504.:0.1836 and:0.1484 I:0.3770)
 I'm a good example.
I'm a good
3200: sample 0: Hello, I'm a language model,
------
		(,:0.0684 I:0.0747 was:0.0679 not:0.1250 great:0.0247 of:0.1475,:0.2598 and:0.0806)
		(.:0.0396 I:0.1641'm:0.0781 not:0.1338 little:0.0266 of:0.0981.:0.1631 I:0.2236)
		(,:0.0293 I:0.2227'm:0.0864 not:0.1611 little:0.0247 that:0.0593.:0.1523 and:0.1592)
		(,:0.0356 I:0.1953 am:0.0801 not:0.1611 good:0.0250 teacher:0.0635.:0.1484 and:0.1826)
		(.:0.0349 I:0.1826 am:0.0806 not:0.1543 member:0.0258 teacher:0.0679.:0.1504 and:0.1738)
		(.:0.0383 I:0.1699 am:0.0796 not:0.1543 member:0.0272 teacher:0.0684.:0.1494 and:0.1680)
		(.:0.0408 I:0.1523 am:0.0752 not:0.1465 member:0.0271 teacher:0.0674.:0.1504 and:0.1631)
		(.:0.0415 I:0.1396 am:0.0713 not:0.1396 member:0.0280 teacher:0.0645.:0.1523 and:0.1572)
		(.:0.0405 I:0.1240 am:0.0679 not:0.1406 member:0.0282,:0.0640.:0.1523 and:0.1504)
		(.:0.0381 I:0.1084 am:0.0649 not:0.1348 lot:0.0294,:0.0669.:0.1523 and:0.1484)
		(.:0.0352 I:0.0967 am:0.0610 going:0.1309 lot:0.0317,:0.0703.:0.1543 and:0.1426)
		(,:0.0315 I:0.0835 have:0.0591 going:0.1328 lot:0.0330,:0.0742.:0.1582 and:0.1367)
		(,:0.0315 I:0.0835 have:0.0591 going:0.1328 lot:0.0330,:0.0742.:0.1582 and:0.1367)
 and
------
		( I:0.0747 was:0.0679 not:0.1250 great:0.0247 of:0.1475,:0.2598 and:0.0806 the:0.1074)
		( I:0.1641'm:0.0781 not:0.1338 little:0.0266 of:0.0981.:0.1631 I:0.2236 I:0.4961)
		( I:0.2227'm:0.0864 not:0.1611 little:0.0247 that:0.0593.:0.1523 and:0.1592 I:0.4512)
		( I:0.1953 am:0.0801 not:0.1611 good:0.0250 teacher:0.0635.:0.1484 and:0.1826 I:0.4883)
		( I:0.1826 am:0.0806 not:0.1543 member:0.0258 teacher:0.0679.:0.1504 and:0.1738 I:0.4805)
		( I:0.1699 am:0.0796 not:0.1543 member:0.0272 teacher:0.0684.:0.1494 and:0.1680 I:0.4707)
		( I:0.1523 am:0.0752 not:0.1465 member:0.0271 teacher:0.0674.:0.1504 and:0.1631 I:0.4766)
		( I:0.1396 am:0.0713 not:0.1396 member:0.0280 teacher:0.0645.:0.1523 and:0.1572 I:0.4668)
		( I:0.1240 am:0.0679 not:0.1406 member:0.0282,:0.0640.:0.1523 and:0.1504 I:0.4746)
		( I:0.1084 am:0.0649 not:0.1348 lot:0.0294,:0.0669.:0.1523 and:0.1484 I:0.4648)
		( I:0.0967 am:0.0610 going:0.1309 lot:0.0317,:0.0703.:0.1543 and:0.1426 I:0.4707)
		( I:0.0835 have:0.0591 going:0.1328 lot:0.0330,:0.0742.:0.1582 and:0.1367 I:0.4746)
		( I:0.0835 have:0.0591 going:0.1328 lot:0.0330,:0.0742.:0.1582 and:0.1367 I:0.4746)
 I'm a teacher. I'm a teacher. I
3350: sample 0: Hello, I'm a language model,
------
		(,:0.0693 I:0.1299 have:0.0762 a:0.1079 lot:0.0237 of:0.1250,:0.2559 and:0.0840)
		(.:0.0347 I:0.1235 am:0.0649 going:0.0981 little:0.0311 that:0.1152.:0.1875 but:0.1787)
		(.:0.0276 you:0.1328 have:0.0820 going:0.1167 little:0.0400 that:0.1011.:0.1846 and:0.1729)
		(,:0.0291 you:0.1348 have:0.0942 going:0.1406 little:0.0442 that:0.1001.:0.1904 and:0.1855)
		(,:0.0261 you:0.1328 have:0.0942 going:0.1387 little:0.0439 that:0.0977.:0.1875 and:0.1836)
		(,:0.0273 you:0.1309 have:0.0918 going:0.1338 little:0.0432 that:0.0977.:0.1885 and:0.1836)
		(,:0.0286 you:0.1245 have:0.0898 going:0.1367 little:0.0444 that:0.0981.:0.1855 and:0.1826)
		(,:0.0304 you:0.1226 have:0.0884 going:0.1357 little:0.0442 that:0.0991.:0.1865 and:0.1816)
		(,:0.0310 you:0.1167 have:0.0918 going:0.1348 little:0.0444 that:0.0996.:0.1826 and:0.1807)
		(,:0.0312 you:0.1108 have:0.0903 going:0.1357 little:0.0444 that:0.1006.:0.1797 and:0.1787)
		(,:0.0322 you:0.1055 have:0.0845 going:0.1348 little:0.0447 that:0.1016.:0.1816 and:0.1787)
		(,:0.0317 you:0.0996 have:0.0835 going:0.1357 little:0.0449 that:0.1025.:0.1787 and:0.1768)
		(,:0.0317 you:0.0996 have:0.0835 going:0.1357 little:0.0449 that:0.1025.:0.1787 and:0.1768)
 and
------
		( I:0.1299 have:0.0762 a:0.1079 lot:0.0237 of:0.1250,:0.2559 and:0.0840 the:0.0913)
		( I:0.1235 am:0.0649 going:0.0981 little:0.0311 that:0.1152.:0.1875 but:0.1787 I:0.4688)
		( you:0.1328 have:0.0820 going:0.1167 little:0.0400 that:0.1011.:0.1846 and:0.1729 I:0.3730)
		( you:0.1348 have:0.0942 going:0.1406 little:0.0442 that:0.1001.:0.1904 and:0.1855 I:0.4180)
		( you:0.1328 have:0.0942 going:0.1387 little:0.0439 that:0.0977.:0.1875 and:0.1836 I:0.3965)
		( you:0.1309 have:0.0918 going:0.1338 little:0.0432 that:0.0977.:0.1885 and:0.1836 I:0.3906)
		( you:0.1245 have:0.0898 going:0.1367 little:0.0444 that:0.0981.:0.1855 and:0.1826 I:0.3848)
		( you:0.1226 have:0.0884 going:0.1357 little:0.0442 that:0.0991.:0.1865 and:0.1816 I:0.3770)
		( you:0.1167 have:0.0918 going:0.1348 little:0.0444 that:0.0996.:0.1826 and:0.1807 I:0.3711)
		( you:0.1108 have:0.0903 going:0.1357 little:0.0444 that:0.1006.:0.1797 and:0.1787 I:0.3613)
		( you:0.1055 have:0.0845 going:0.1348 little:0.0447 that:0.1016.:0.1816 and:0.1787 I:0.3555)
		( you:0.0996 have:0.0835 going:0.1357 little:0.0449 that:0.1025.:0.1787 and:0.1768 I:0.3496)
		( you:0.0996 have:0.0835 going:0.1357 little:0.0449 that:0.1025.:0.1787 and:0.1768 I:0.3496)
 I'm a language model. I'm a language model
3500: sample 0: Hello, I'm a language model,
------
		(,:0.0583 I:0.1689 am:0.0559 not:0.1050 lot:0.0206 of:0.1816,:0.3008 we:0.0981)
		(.:0.0334 I:0.1875�:0.0708 not:0.1270 little:0.0547 of:0.1602 that:0.1245 I:0.1328)
		(.:0.0284 I:0.2217�:0.0996 not:0.1270 little:0.0500 of:0.1074.:0.1455 and:0.1172)
		(.:0.0325 I:0.2090�:0.1118 not:0.1260 little:0.0476 of:0.0903.:0.1426 but:0.1289)
		(.:0.0280 I:0.1953�:0.1060 not:0.1235 little:0.0466 of:0.0854 that:0.1504 but:0.1270)
		(.:0.0298 I:0.1797�:0.1099 not:0.1177 little:0.0457 of:0.0854 that:0.1533 but:0.1216)
		(.:0.0310 I:0.1699�:0.1084 not:0.1196 little:0.0447 of:0.0859 that:0.1543 and:0.1187)
		(.:0.0320 I:0.1562�:0.1143 not:0.1157 little:0.0454 of:0.0894 that:0.1592 and:0.1206)
		(-:0.0325 I:0.1475�:0.1133 not:0.1143 little:0.0435 of:0.0874 that:0.1582 and:0.1216)
		(-:0.0327 I:0.1348�:0.1196 not:0.1143 little:0.0430 of:0.0879 that:0.1621 and:0.1226)
		(-:0.0327 I:0.1260�:0.1196 not:0.1138 little:0.0422 of:0.0884 that:0.1621 and:0.1235)
		(-:0.0322 I:0.1147�:0.1191 not:0.1104 little:0.0405 of:0.0869 that:0.1660 and:0.1235)
		(-:0.0322 I:0.1147�:0.1191 not:0.1104 little:0.0405 of:0.0869 that:0.1660 and:0.1235)
 and
------
		( I:0.1689 am:0.0559 not:0.1050 lot:0.0206 of:0.1816,:0.3008 we:0.0981 the:0.0972)
		( I:0.1875�:0.0708 not:0.1270 little:0.0547 of:0.1602 that:0.1245 I:0.1328 I:0.4199)
		( I:0.2217�:0.0996 not:0.1270 little:0.0500 of:0.1074.:0.1455 and:0.1172 I:0.4785)
		( I:0.2090�:0.1118 not:0.1260 little:0.0476 of:0.0903.:0.1426 but:0.1289 I:0.4238)
		( I:0.1953�:0.1060 not:0.1235 little:0.0466 of:0.0854 that:0.1504 but:0.1270 I:0.4004)
		( I:0.1797�:0.1099 not:0.1177 little:0.0457 of:0.0854 that:0.1533 but:0.1216 I:0.3906)
		( I:0.1699�:0.1084 not:0.1196 little:0.0447 of:0.0859 that:0.1543 and:0.1187 I:0.3945)
		( I:0.1562�:0.1143 not:0.1157 little:0.0454 of:0.0894 that:0.1592 and:0.1206 I:0.3848)
		( I:0.1475�:0.1133 not:0.1143 little:0.0435 of:0.0874 that:0.1582 and:0.1216 I:0.3730)
		( I:0.1348�:0.1196 not:0.1143 little:0.0430 of:0.0879 that:0.1621 and:0.1226 I:0.3613)
		( I:0.1260�:0.1196 not:0.1138 little:0.0422 of:0.0884 that:0.1621 and:0.1235 I:0.3633)
		( I:0.1147�:0.1191 not:0.1104 little:0.0405 of:0.0869 that:0.1660 and:0.1235 I:0.3516)
		( I:0.1147�:0.1191 not:0.1104 little:0.0405 of:0.0869 that:0.1660 and:0.1235 I:0.3516)
 I'm a language model. I'm a language model
3650: sample 0: Hello, I'm a language model,
------
		(,:0.0625 you:0.0535 have:0.0679 not:0.0933 great:0.0160 of:0.2451,:0.2734 and:0.0913)
		(.:0.0344 the:0.0820�:0.0801 going:0.1250 little:0.0315 of:0.1953.:0.1455 and:0.1660)
		(,:0.0386 I:0.0923�:0.0938 going:0.1670 little:0.0439 of:0.1118.:0.1924 and:0.1416)
		(,:0.0645 I:0.0967�:0.1089 going:0.2129 little:0.0508 of:0.0898.:0.2061 and:0.1426)
		(,:0.0583 I:0.0947�:0.1050 going:0.2080 little:0.0508 teacher:0.0923.:0.2070 and:0.1338)
		(,:0.0579 I:0.0913�:0.1060 going:0.2100 little:0.0510 teacher:0.0942.:0.2080 and:0.1289)
		(,:0.0576 you:0.0908�:0.1079 going:0.2139 little:0.0515 teacher:0.0918.:0.2041 and:0.1240)
		(,:0.0569 you:0.0933�:0.1099 going:0.2070 little:0.0510 teacher:0.0898.:0.2061 and:0.1162)
		(,:0.0576 you:0.0928�:0.1123 going:0.2109 little:0.0505 teacher:0.0879.:0.2070 and:0.1143)
		(,:0.0559 you:0.0947�:0.1216 going:0.2061 little:0.0503 teacher:0.0859.:0.2080 and:0.1089)
		(,:0.0557 you:0.0938�:0.1250 going:0.2021 little:0.0498 that:0.0840.:0.2090 and:0.1040)
		(,:0.0547 you:0.0962�:0.1279 going:0.2061 little:0.0508 that:0.0854.:0.2109 and:0.1016)
		(,:0.0547 you:0.0962�:0.1279 going:0.2061 little:0.0508 that:0.0854.:0.2109 and:0.1016)
 and
------
		( you:0.0535 have:0.0679 not:0.0933 great:0.0160 of:0.2451,:0.2734 and:0.0913 the:0.0791)
		( the:0.0820�:0.0801 going:0.1250 little:0.0315 of:0.1953.:0.1455 and:0.1660 I:0.2812)
		( I:0.0923�:0.0938 going:0.1670 little:0.0439 of:0.1118.:0.1924 and:0.1416 I:0.3809)
		( I:0.0967�:0.1089 going:0.2129 little:0.0508 of:0.0898.:0.2061 and:0.1426 I:0.3770)
		( I:0.0947�:0.1050 going:0.2080 little:0.0508 teacher:0.0923.:0.2070 and:0.1338 I:0.3574)
		( I:0.0913�:0.1060 going:0.2100 little:0.0510 teacher:0.0942.:0.2080 and:0.1289 I:0.3477)
		( you:0.0908�:0.1079 going:0.2139 little:0.0515 teacher:0.0918.:0.2041 and:0.1240 I:0.3379)
		( you:0.0933�:0.1099 going:0.2070 little:0.0510 teacher:0.0898.:0.2061 and:0.1162 I:0.3418)
		( you:0.0928�:0.1123 going:0.2109 little:0.0505 teacher:0.0879.:0.2070 and:0.1143 I:0.3301)
		( you:0.0947�:0.1216 going:0.2061 little:0.0503 teacher:0.0859.:0.2080 and:0.1089 I:0.3320)
		( you:0.0938�:0.1250 going:0.2021 little:0.0498 that:0.0840.:0.2090 and:0.1040 I:0.3203)
		( you:0.0962�:0.1279 going:0.2061 little:0.0508 that:0.0854.:0.2109 and:0.1016 I:0.3242)
		( you:0.0962�:0.1279 going:0.2061 little:0.0508 that:0.0854.:0.2109 and:0.1016 I:0.3242)
 I'm a language model.
I'm a language
3800: sample 0: Hello, I'm a language model,
------
		(,:0.0496 I:0.0718 have:0.0679 going:0.0771 great:0.0166 of:0.1074,:0.2832 we:0.0718)
		(.:0.0320 I:0.1211 am:0.0684 going:0.1064 little:0.0327 of:0.0894.:0.1719 but:0.1611)
		(.:0.0339 I:0.1465 have:0.0603 going:0.1226 little:0.0374.:0.1035.:0.2139 and:0.1689)
		(.:0.0500 I:0.1279 have:0.0664 going:0.1445 little:0.0410 teacher:0.0918.:0.2158 and:0.1797)
		(.:0.0459 I:0.1235 have:0.0664 going:0.1494 little:0.0410 teacher:0.0977.:0.2119 and:0.1787)
		(.:0.0471 I:0.1187�:0.0688 going:0.1514 little:0.0410 teacher:0.0981.:0.2148 and:0.1777)
		(.:0.0491 I:0.1118�:0.0728 going:0.1543 little:0.0422 teacher:0.0962.:0.2158 and:0.1768)
		(,:0.0505 I:0.1074�:0.0811 going:0.1572 little:0.0427 teacher:0.0918.:0.2188 and:0.1787)
		(,:0.0530 I:0.1030�:0.0854 going:0.1611 little:0.0430 teacher:0.0898.:0.2188 and:0.1807)
		(,:0.0535 I:0.0986�:0.0908 going:0.1660 little:0.0437.:0.0908.:0.2285 and:0.1826)
		(,:0.0566 I:0.0938�:0.0967 going:0.1611 little:0.0439.:0.0947.:0.2256 and:0.1787)
		(,:0.0579 I:0.0869�:0.1025 going:0.1660 little:0.0454.:0.0962.:0.2256 and:0.1807)
		(,:0.0579 I:0.0869�:0.1025 going:0.1660 little:0.0454.:0.0962.:0.2256 and:0.1807)
 and
------
		( I:0.0718 have:0.0679 going:0.0771 great:0.0166 of:0.1074,:0.2832 we:0.0718 the:0.0771)
		( I:0.1211 am:0.0684 going:0.1064 little:0.0327 of:0.0894.:0.1719 but:0.1611 I:0.4258)
		( I:0.1465 have:0.0603 going:0.1226 little:0.0374.:0.1035.:0.2139 and:0.1689 I:0.4844)
		( I:0.1279 have:0.0664 going:0.1445 little:0.0410 teacher:0.0918.:0.2158 and:0.1797 I:0.4922)
		( I:0.1235 have:0.0664 going:0.1494 little:0.0410 teacher:0.0977.:0.2119 and:0.1787 I:0.4707)
		( I:0.1187�:0.0688 going:0.1514 little:0.0410 teacher:0.0981.:0.2148 and:0.1777 I:0.4629)
		( I:0.1118�:0.0728 going:0.1543 little:0.0422 teacher:0.0962.:0.2158 and:0.1768 I:0.4512)
		( I:0.1074�:0.0811 going:0.1572 little:0.0427 teacher:0.0918.:0.2188 and:0.1787 I:0.4570)
		( I:0.1030�:0.0854 going:0.1611 little:0.0430 teacher:0.0898.:0.2188 and:0.1807 I:0.4453)
		( I:0.0986�:0.0908 going:0.1660 little:0.0437.:0.0908.:0.2285 and:0.1826 I:0.4492)
		( I:0.0938�:0.0967 going:0.1611 little:0.0439.:0.0947.:0.2256 and:0.1787 I:0.4375)
		( I:0.0869�:0.1025 going:0.1660 little:0.0454.:0.0962.:0.2256 and:0.1807 I:0.4414)
		( I:0.0869�:0.1025 going:0.1660 little:0.0454.:0.0962.:0.2256 and:0.1807 I:0.4414)
 I'm a language model. I'm a language model
3950: sample 0: Hello, I'm a language model,
------
		(,:0.0564 I:0.0962 have:0.0757 not:0.0825 great:0.0131 of:0.1084,:0.2656 we:0.0767)
		(.:0.0266 I:0.0894 am:0.0703 not:0.1045 very:0.0178 of:0.1143.:0.1328 but:0.1543)
		(,:0.0277 I:0.0952 will:0.0593 going:0.1318 fan:0.0356.:0.0972.:0.1953 but:0.1709)
		(,:0.0327 I:0.0918 am:0.0786 going:0.1670 fan:0.0327.:0.0884.:0.2061 and:0.1650)
		(,:0.0334 I:0.0879 am:0.0781 going:0.1650 fan:0.0315.:0.0850.:0.1973 but:0.1641)
		(.:0.0356 I:0.0859 am:0.0762 going:0.1758 fan:0.0309.:0.0835.:0.1934 and:0.1582)
		(.:0.0376 I:0.0845 am:0.0747 going:0.1787 fan:0.0297.:0.0825.:0.1904 and:0.1592)
		(.:0.0386 I:0.0801 am:0.0752 going:0.1816 fan:0.0295.:0.0811.:0.1875 and:0.1572)
		(.:0.0393 I:0.0781 am:0.0737 going:0.1836 fan:0.0293.:0.0825.:0.1846 and:0.1543)
		(,:0.0383 I:0.0737 am:0.0723 going:0.1973 fan:0.0288.:0.0811.:0.1807 and:0.1543)
		(,:0.0383 I:0.0718 am:0.0688 going:0.2012 fan:0.0278.:0.0830.:0.1768 and:0.1504)
		(,:0.0376 I:0.0674 am:0.0674 going:0.2041 fan:0.0282,:0.0815.:0.1729 and:0.1514)
		(,:0.0376 I:0.0674 am:0.0674 going:0.2041 fan:0.0282,:0.0815.:0.1729 and:0.1514)
 and
------
		( I:0.0962 have:0.0757 not:0.0825 great:0.0131 of:0.1084,:0.2656 we:0.0767 the:0.1108)
		( I:0.0894 am:0.0703 not:0.1045 very:0.0178 of:0.1143.:0.1328 but:0.1543 I:0.4707)
		( I:0.0952 will:0.0593 going:0.1318 fan:0.0356.:0.0972.:0.1953 but:0.1709 I:0.5000)
		( I:0.0918 am:0.0786 going:0.1670 fan:0.0327.:0.0884.:0.2061 and:0.1650 I:0.4434)
		( I:0.0879 am:0.0781 going:0.1650 fan:0.0315.:0.0850.:0.1973 but:0.1641 I:0.4219)
		( I:0.0859 am:0.0762 going:0.1758 fan:0.0309.:0.0835.:0.1934 and:0.1582 I:0.4141)
		( I:0.0845 am:0.0747 going:0.1787 fan:0.0297.:0.0825.:0.1904 and:0.1592 I:0.4180)
		( I:0.0801 am:0.0752 going:0.1816 fan:0.0295.:0.0811.:0.1875 and:0.1572 I:0.4062)
		( I:0.0781 am:0.0737 going:0.1836 fan:0.0293.:0.0825.:0.1846 and:0.1543 I:0.4102)
		( I:0.0737 am:0.0723 going:0.1973 fan:0.0288.:0.0811.:0.1807 and:0.1543 I:0.4141)
		( I:0.0718 am:0.0688 going:0.2012 fan:0.0278.:0.0830.:0.1768 and:0.1504 I:0.4004)
		( I:0.0674 am:0.0674 going:0.2041 fan:0.0282,:0.0815.:0.1729 and:0.1514 I:0.4004)
		( I:0.0674 am:0.0674 going:0.2041 fan:0.0282,:0.0815.:0.1729 and:0.1514 I:0.4004)
 I'm a language. I'm a language. I
