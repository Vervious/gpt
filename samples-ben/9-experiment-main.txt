1: sample 0: Hello, I'm a language model,
------
		( circulating:0.0002 Portugal:0.0002 align:0.0002 Amen:0.0002assembled:0.0002 CAL:0.0002Analy:0.0002Enabled:0.0002)
		(anted:0.0002arm:0.0002 dashed:0.0002 weary:0.0002 Site:0.0001 Cognitive:0.0002ci:0.0001Adapter:0.0002)
		( sparing:0.0002success:0.0002 Bullet:0.0002elect:0.0002 Songs:0.0001 apologies:0.0001Begin:0.0001 Hardware:0.0001)
		( dangers:0.0002selage:0.0002 estab:0.0001 Awesome:0.0001map:0.0001 bearded:0.0001hey:0.0001astern:0.0001)
		( Construction:0.0002wrong:0.0002such:0.0001 Emmy:0.0001 consult:0.0001 deregulation:0.0000 Presidents:0.0000urate:0.0000)
		(ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ:0.0002 Anglic:0.0002Lat:0.0001 radical:0.0001berg:0.0000 Inst:0.0000Myth:0.0000 the:0.0000)
		( trailer:0.0002 dependence:0.0002 Columb:0.0001 Territory:0.0000 ASIC:0.0000,:0.0000,:0.0000,:0.0000)
		( crooked:0.0002 Geneva:0.0002 dismissed:0.0001 dragons:0.0000 the:0.0000,:0.0000,:0.0000,:0.0000)
		( haul:0.0002 technicians:0.0002----------:0.0000rared:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		(Orange:0.0002 Reserved:0.0001 tracks:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( Welsh:0.0002 somet:0.0002Planet:0.0000 the:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( Castro:0.0002resolution:0.0001,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( Castro:0.0002resolution:0.0001,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
,
------
		( Portugal:0.0002 align:0.0002 Amen:0.0002assembled:0.0002 CAL:0.0002Analy:0.0002Enabled:0.0002 dated:0.0002)
		(arm:0.0002 dashed:0.0002 weary:0.0002 Site:0.0001 Cognitive:0.0002ci:0.0001Adapter:0.0002 feminine:0.0002)
		(success:0.0002 Bullet:0.0002elect:0.0002 Songs:0.0001 apologies:0.0001Begin:0.0001 Hardware:0.0001itizens:0.0001)
		(selage:0.0002 estab:0.0001 Awesome:0.0001map:0.0001 bearded:0.0001hey:0.0001astern:0.0001 bore:0.0001)
		(wrong:0.0002such:0.0001 Emmy:0.0001 consult:0.0001 deregulation:0.0000 Presidents:0.0000urate:0.0000 professors:0.0000)
		( Anglic:0.0002Lat:0.0001 radical:0.0001berg:0.0000 Inst:0.0000Myth:0.0000 the:0.0000,:0.0000)
		( dependence:0.0002 Columb:0.0001 Territory:0.0000 ASIC:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( Geneva:0.0002 dismissed:0.0001 dragons:0.0000 the:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( technicians:0.0002----------:0.0000rared:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( Reserved:0.0001 tracks:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( somet:0.0002Planet:0.0000 the:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		(resolution:0.0001,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		(resolution:0.0001,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
,,,,,,,,,,,
50: sample 0: Hello, I'm a language model,
------
		(,:0.0342 the:0.0859 the:0.0591.:0.0811
:0.0322.:0.0417.:0.0635 and:0.0564)
		(,:0.0674 the:0.1611 the:0.1494,:0.0547
:0.0408,:0.0598,:0.0752 the:0.1729)
		( the:0.0535 the:0.1582 the:0.1875 the:0.0583
:0.0728 the:0.0693,:0.0603 the:0.2041)
		( the:0.0811 the:0.1416 the:0.1484 the:0.0752
:0.1025 the:0.0786,:0.0503 the:0.1396)
		( the:0.1030 the:0.1270 the:0.1270 the:0.0845
:0.1011 the:0.0918 the:0.0525 the:0.1426)
		( the:0.1079 the:0.1162 the:0.1162 the:0.0898
:0.1001 the:0.1016 the:0.0630 the:0.1309)
		( the:0.1094 the:0.1123 the:0.1094 the:0.0952
:0.0977 the:0.1177 the:0.0771 the:0.1309)
		( the:0.1084 the:0.1069 the:0.1040 the:0.0967
:0.0986 the:0.1260 the:0.0923 the:0.1318)
		( the:0.1094 the:0.1060 the:0.1030 the:0.0996
:0.0986 the:0.1348 the:0.1069 the:0.1387)
		( the:0.1069 the:0.1035 the:0.1035 the:0.1006
:0.0991 the:0.1445 the:0.1216 the:0.1377)
		( the:0.1074 the:0.1030 the:0.1030 the:0.1035
:0.0991 the:0.1455 the:0.1299 the:0.1377)
		( the:0.1050 the:0.1030 the:0.1001 the:0.1016
:0.0996 the:0.1475 the:0.1396 the:0.1445)
		( the:0.1050 the:0.1030 the:0.1001 the:0.1016
:0.0996 the:0.1475 the:0.1396 the:0.1445)
 the
------
		( the:0.0859 the:0.0591.:0.0811
:0.0322.:0.0417.:0.0635 and:0.0564
:0.0110)
		( the:0.1611 the:0.1494,:0.0547
:0.0408,:0.0598,:0.0752 the:0.1729-:0.0168)
		( the:0.1582 the:0.1875 the:0.0583
:0.0728 the:0.0693,:0.0603 the:0.2041
:0.0364)
		( the:0.1416 the:0.1484 the:0.0752
:0.1025 the:0.0786,:0.0503 the:0.1396
:0.0679)
		( the:0.1270 the:0.1270 the:0.0845
:0.1011 the:0.0918 the:0.0525 the:0.1426
:0.1006)
		( the:0.1162 the:0.1162 the:0.0898
:0.1001 the:0.1016 the:0.0630 the:0.1309
:0.1006)
		( the:0.1123 the:0.1094 the:0.0952
:0.0977 the:0.1177 the:0.0771 the:0.1309
:0.1016)
		( the:0.1069 the:0.1040 the:0.0967
:0.0986 the:0.1260 the:0.0923 the:0.1318
:0.1001)
		( the:0.1060 the:0.1030 the:0.0996
:0.0986 the:0.1348 the:0.1069 the:0.1387
:0.1035)
		( the:0.1035 the:0.1035 the:0.1006
:0.0991 the:0.1445 the:0.1216 the:0.1377
:0.1016)
		( the:0.1030 the:0.1030 the:0.1035
:0.0991 the:0.1455 the:0.1299 the:0.1377
:0.1016)
		( the:0.1030 the:0.1001 the:0.1016
:0.0996 the:0.1475 the:0.1396 the:0.1445
:0.1021)
		( the:0.1030 the:0.1001 the:0.1016
:0.0996 the:0.1475 the:0.1396 the:0.1445
:0.1021)












200: sample 0: Hello, I'm a language model,
------
		(,:0.1377 the:0.0747�:0.0488 not:0.0549 new:0.0149.:0.0796,:0.1152 and:0.0820)
		(,:0.1328 and:0.1016�:0.0549 not:0.0732 few:0.0168.:0.1226,:0.1455 and:0.1177)
		(,:0.1338 and:0.0967�:0.0505 not:0.0815 few:0.0177.:0.1494,:0.1572 and:0.1235)
		(,:0.1328 and:0.0859�:0.0442 not:0.0781 few:0.0166.:0.1670,:0.1514 and:0.1177)
		(,:0.1250 and:0.0776�:0.0415 not:0.0747 few:0.0154.:0.1777,:0.1436 and:0.1079)
		(,:0.1201 and:0.0718�:0.0405 not:0.0703 few:0.0146.:0.1816,:0.1377 and:0.0991)
		(,:0.1167 and:0.0674�:0.0400 not:0.0649 few:0.0137.:0.1826,:0.1367 and:0.0903)
		(,:0.1172 and:0.0669 can:0.0422 not:0.0630 few:0.0132.:0.1758,:0.1338 and:0.0820)
		(,:0.1133 and:0.0659.:0.0457 not:0.0605 few:0.0128.:0.1777,:0.1318 and:0.0762)
		(,:0.1152 and:0.0654.:0.0515 the:0.0549 few:0.0126.:0.1709,:0.1299 and:0.0708)
		(,:0.1128 and:0.0640.:0.0581 the:0.0562 few:0.0121.:0.1719.:0.1328 and:0.0659)
		(,:0.1133 and:0.0630-:0.0703 the:0.0571 large:0.0123.:0.1641.:0.1299 and:0.0591)
		(,:0.1133 and:0.0630-:0.0703 the:0.0571 large:0.0123.:0.1641.:0.1299 and:0.0591)
 and
------
		( the:0.0747�:0.0488 not:0.0549 new:0.0149.:0.0796,:0.1152 and:0.0820 the:0.0688)
		( and:0.1016�:0.0549 not:0.0732 few:0.0168.:0.1226,:0.1455 and:0.1177 the:0.0859)
		( and:0.0967�:0.0505 not:0.0815 few:0.0177.:0.1494,:0.1572 and:0.1235 the:0.0757)
		( and:0.0859�:0.0442 not:0.0781 few:0.0166.:0.1670,:0.1514 and:0.1177 the:0.0640)
		( and:0.0776�:0.0415 not:0.0747 few:0.0154.:0.1777,:0.1436 and:0.1079 the:0.0544)
		( and:0.0718�:0.0405 not:0.0703 few:0.0146.:0.1816,:0.1377 and:0.0991 the:0.0481)
		( and:0.0674�:0.0400 not:0.0649 few:0.0137.:0.1826,:0.1367 and:0.0903 the:0.0437)
		( and:0.0669 can:0.0422 not:0.0630 few:0.0132.:0.1758,:0.1338 and:0.0820 the:0.0398)
		( and:0.0659.:0.0457 not:0.0605 few:0.0128.:0.1777,:0.1318 and:0.0762 the:0.0383)
		( and:0.0654.:0.0515 the:0.0549 few:0.0126.:0.1709,:0.1299 and:0.0708 the:0.0369)
		( and:0.0640.:0.0581 the:0.0562 few:0.0121.:0.1719.:0.1328 and:0.0659 the:0.0354)
		( and:0.0630-:0.0703 the:0.0571 large:0.0123.:0.1641.:0.1299 and:0.0591 the:0.0352)
		( and:0.0630-:0.0703 the:0.0571 large:0.0123.:0.1641.:0.1299 and:0.0591 the:0.0352)
 the same time, and the same time, the same
350: sample 0: Hello, I'm a language model,
------
		(,:0.3281 and:0.0850�:0.0840 not:0.1133 �:0.0184.:0.1089,:0.1069 the:0.0981)
		(,:0.3633 and:0.1631.:0.0481 not:0.0918 good:0.0236.:0.1162,:0.1426 and:0.1147)
		(,:0.3457 and:0.1582 have:0.0654 not:0.1138 good:0.0264.:0.1436.:0.1396 and:0.1201)
		(,:0.3066 and:0.1650 have:0.0664 not:0.1299 good:0.0239.:0.1494.:0.1328 and:0.1245)
		(,:0.2695 and:0.1582 have:0.0635 not:0.1406 good:0.0208.:0.1523.:0.1260 and:0.1221)
		(,:0.2334 and:0.1533 have:0.0625 not:0.1436 good:0.0173.:0.1465.:0.1123 and:0.1187)
		(,:0.2119 and:0.1494 have:0.0605 not:0.1387 lot:0.0165.:0.1396.:0.1045 and:0.1206)
		(,:0.2002 and:0.1387 have:0.0603 not:0.1328 lot:0.0154.:0.1328.:0.1025 and:0.1157)
		(,:0.1816 and:0.1270 have:0.0608 not:0.1279 lot:0.0149.:0.1270,:0.1011 and:0.1177)
		(,:0.1719 and:0.1157 have:0.0625 not:0.1172 lot:0.0147.:0.1289,:0.1064 and:0.1143)
		(,:0.1650 and:0.1060 have:0.0630 not:0.1069 lot:0.0154.:0.1235,:0.1069 and:0.1123)
		(,:0.1582 and:0.0938 have:0.0654 not:0.0923 lot:0.0160.:0.1201,:0.1089 and:0.1123)
		(,:0.1582 and:0.0938 have:0.0654 not:0.0923 lot:0.0160.:0.1201,:0.1089 and:0.1123)
 and
------
		( and:0.0850�:0.0840 not:0.1133 �:0.0184.:0.1089,:0.1069 the:0.0981 the:0.0972)
		( and:0.1631.:0.0481 not:0.0918 good:0.0236.:0.1162,:0.1426 and:0.1147 the:0.0593)
		( and:0.1582 have:0.0654 not:0.1138 good:0.0264.:0.1436.:0.1396 and:0.1201 the:0.0613)
		( and:0.1650 have:0.0664 not:0.1299 good:0.0239.:0.1494.:0.1328 and:0.1245 the:0.0649)
		( and:0.1582 have:0.0635 not:0.1406 good:0.0208.:0.1523.:0.1260 and:0.1221 the:0.0674)
		( and:0.1533 have:0.0625 not:0.1436 good:0.0173.:0.1465.:0.1123 and:0.1187 the:0.0664)
		( and:0.1494 have:0.0605 not:0.1387 lot:0.0165.:0.1396.:0.1045 and:0.1206 the:0.0688)
		( and:0.1387 have:0.0603 not:0.1328 lot:0.0154.:0.1328.:0.1025 and:0.1157 the:0.0688)
		( and:0.1270 have:0.0608 not:0.1279 lot:0.0149.:0.1270,:0.1011 and:0.1177 the:0.0674)
		( and:0.1157 have:0.0625 not:0.1172 lot:0.0147.:0.1289,:0.1064 and:0.1143 the:0.0659)
		( and:0.1060 have:0.0630 not:0.1069 lot:0.0154.:0.1235,:0.1069 and:0.1123 the:0.0625)
		( and:0.0938 have:0.0654 not:0.0923 lot:0.0160.:0.1201,:0.1089 and:0.1123 the:0.0603)
		( and:0.0938 have:0.0654 not:0.0923 lot:0.0160.:0.1201,:0.1089 and:0.1123 the:0.0603)
 the same time, and the same time, and the
500: sample 0: Hello, I'm a language model,
------
		(,:0.2891 the:0.0786�:0.0874 not:0.0664 new:0.0151.:0.1289 of:0.1436 and:0.0947)
		(,:0.2598 and:0.1069�:0.0469 not:0.0630 good:0.0234.:0.1494.:0.1660 and:0.1182)
		(,:0.2109 and:0.1099 have:0.0461 not:0.1089 good:0.0242.:0.1719.:0.1895 and:0.1426)
		(,:0.1895 and:0.1104 have:0.0479 not:0.1396 good:0.0225.:0.1855.:0.1982 and:0.1650)
		(,:0.1738 and:0.1045 have:0.0498 not:0.1592 good:0.0190.:0.1855.:0.1924 and:0.1719)
		(,:0.1631 and:0.0972 do:0.0522 not:0.1680 lot:0.0181.:0.1768.:0.1855 and:0.1797)
		(,:0.1582 and:0.0923 do:0.0576 not:0.1650 lot:0.0178.:0.1807.:0.1768 and:0.1777)
		(,:0.1543 and:0.0884 do:0.0664 not:0.1553 lot:0.0177.:0.1738.:0.1689 and:0.1729)
		(,:0.1543 and:0.0825 do:0.0723 not:0.1475 lot:0.0170.:0.1748.:0.1621 and:0.1680)
		(,:0.1504 and:0.0757 do:0.0752 not:0.1338 lot:0.0164.:0.1670.:0.1602 and:0.1650)
		(,:0.1436 and:0.0684 do:0.0815 not:0.1289 lot:0.0156.:0.1699.:0.1504 and:0.1562)
		(,:0.1406 the:0.0669 do:0.0840 not:0.1177 lot:0.0150.:0.1641,:0.1523 and:0.1504)
		(,:0.1406 the:0.0669 do:0.0840 not:0.1177 lot:0.0150.:0.1641,:0.1523 and:0.1504)
 and
------
		( the:0.0786�:0.0874 not:0.0664 new:0.0151.:0.1289 of:0.1436 and:0.0947 the:0.0879)
		( and:0.1069�:0.0469 not:0.0630 good:0.0234.:0.1494.:0.1660 and:0.1182 the:0.0469)
		( and:0.1099 have:0.0461 not:0.1089 good:0.0242.:0.1719.:0.1895 and:0.1426 the:0.0444)
		( and:0.1104 have:0.0479 not:0.1396 good:0.0225.:0.1855.:0.1982 and:0.1650 the:0.0439)
		( and:0.1045 have:0.0498 not:0.1592 good:0.0190.:0.1855.:0.1924 and:0.1719 the:0.0459)
		( and:0.0972 do:0.0522 not:0.1680 lot:0.0181.:0.1768.:0.1855 and:0.1797 the:0.0471)
		( and:0.0923 do:0.0576 not:0.1650 lot:0.0178.:0.1807.:0.1768 and:0.1777 the:0.0503)
		( and:0.0884 do:0.0664 not:0.1553 lot:0.0177.:0.1738.:0.1689 and:0.1729 the:0.0537)
		( and:0.0825 do:0.0723 not:0.1475 lot:0.0170.:0.1748.:0.1621 and:0.1680 the:0.0562)
		( and:0.0757 do:0.0752 not:0.1338 lot:0.0164.:0.1670.:0.1602 and:0.1650 the:0.0613)
		( and:0.0684 do:0.0815 not:0.1289 lot:0.0156.:0.1699.:0.1504 and:0.1562 the:0.0640)
		( the:0.0669 do:0.0840 not:0.1177 lot:0.0150.:0.1641,:0.1523 and:0.1504 the:0.0674)
		( the:0.0669 do:0.0840 not:0.1177 lot:0.0150.:0.1641,:0.1523 and:0.1504 the:0.0674)
 the same way to the same time, and the same
650: sample 0: Hello, I'm a language model,
------
		(,:0.2178 and:0.0981�:0.0840 not:0.0972 few:0.0167,:0.1172 of:0.1279 and:0.0952)
		(,:0.1865 and:0.0781�:0.0461 not:0.0527 few:0.0186.:0.0957 of:0.1357 and:0.1123)
		(,:0.1670 and:0.0840 have:0.0500 not:0.0654 few:0.0167.:0.1484.:0.1855 and:0.1592)
		(,:0.1855 and:0.0884 am:0.0535 not:0.0732 lot:0.0195.:0.1611.:0.1973 and:0.1719)
		(,:0.1904 and:0.0854 am:0.0552 not:0.0742 lot:0.0243.:0.1562.:0.1680 and:0.1621)
		(,:0.1885 and:0.0791 was:0.0591 not:0.0664 lot:0.0236.:0.1455.:0.1572 and:0.1523)
		(,:0.1895 the:0.0752 was:0.0640 not:0.0554 lot:0.0195.:0.1416.:0.1426 and:0.1475)
		(,:0.1836 the:0.0752 was:0.0649 not:0.0435 lot:0.0154.:0.1396.:0.1406 and:0.1465)
		(,:0.1777 the:0.0757 was:0.0649 not:0.0327 lot:0.0123.:0.1396.:0.1396 and:0.1465)
		(,:0.1689 the:0.0767 was:0.0623 not:0.0234 lot:0.0108.:0.1338.:0.1338 and:0.1484)
		(,:0.1611 the:0.0747 was:0.0588 not:0.0167 lot:0.0096.:0.1230.:0.1299 and:0.1436)
		(,:0.1504 the:0.0732 was:0.0554 not:0.0119 lot:0.0083.:0.1167.:0.1289 and:0.1396)
		(,:0.1504 the:0.0732 was:0.0554 not:0.0119 lot:0.0083.:0.1167.:0.1289 and:0.1396)
 and
------
		( and:0.0981�:0.0840 not:0.0972 few:0.0167,:0.1172 of:0.1279 and:0.0952 the:0.0767)
		( and:0.0781�:0.0461 not:0.0527 few:0.0186.:0.0957 of:0.1357 and:0.1123 I:0.0579)
		( and:0.0840 have:0.0500 not:0.0654 few:0.0167.:0.1484.:0.1855 and:0.1592 I:0.0850)
		( and:0.0884 am:0.0535 not:0.0732 lot:0.0195.:0.1611.:0.1973 and:0.1719 I:0.1143)
		( and:0.0854 am:0.0552 not:0.0742 lot:0.0243.:0.1562.:0.1680 and:0.1621 I:0.1377)
		( and:0.0791 was:0.0591 not:0.0664 lot:0.0236.:0.1455.:0.1572 and:0.1523 I:0.1514)
		( the:0.0752 was:0.0640 not:0.0554 lot:0.0195.:0.1416.:0.1426 and:0.1475 I:0.1484)
		( the:0.0752 was:0.0649 not:0.0435 lot:0.0154.:0.1396.:0.1406 and:0.1465 I:0.1426)
		( the:0.0757 was:0.0649 not:0.0327 lot:0.0123.:0.1396.:0.1396 and:0.1465 I:0.1318)
		( the:0.0767 was:0.0623 not:0.0234 lot:0.0108.:0.1338.:0.1338 and:0.1484 I:0.1167)
		( the:0.0747 was:0.0588 not:0.0167 lot:0.0096.:0.1230.:0.1299 and:0.1436 I:0.1045)
		( the:0.0732 was:0.0554 not:0.0119 lot:0.0083.:0.1167.:0.1289 and:0.1396 I:0.0972)
		( the:0.0732 was:0.0554 not:0.0119 lot:0.0083.:0.1167.:0.1289 and:0.1396 I:0.0972)
 I am going to see the first time.
I
800: sample 0: Hello, I'm a language model,
------
		(,:0.1299 and:0.0845�:0.0605 not:0.0913 few:0.0159,:0.1240 of:0.1523 the:0.0625)
		(,:0.1377 the:0.0547 am:0.0442 not:0.0649 few:0.0220,:0.1035 of:0.1191 I:0.1025)
		(,:0.1108 the:0.0549 am:0.0483 not:0.0796 little:0.0240.:0.1216.:0.1514 I:0.1060)
		(,:0.1167 I:0.0574 have:0.0605 not:0.0894 little:0.0302.:0.1465.:0.1689 and:0.1147)
		(,:0.1226 I:0.0679 have:0.0708 not:0.1079 little:0.0330.:0.1699.:0.1709 and:0.1230)
		(,:0.1387 I:0.0742 have:0.0815 not:0.1123 little:0.0327.:0.1787.:0.1768 and:0.1230)
		(,:0.1445 I:0.0737 have:0.0840 not:0.1064 little:0.0322.:0.1914.:0.1758 and:0.1211)
		(,:0.1514 I:0.0693 have:0.0874 not:0.0898 little:0.0320.:0.2061.:0.1807 and:0.1177)
		(,:0.1484 we:0.0640 have:0.0815 not:0.0742 little:0.0315.:0.2061.:0.1807 and:0.1138)
		(,:0.1475 we:0.0608 have:0.0791 not:0.0576 little:0.0293.:0.2031.:0.1738 and:0.1050)
		(,:0.1396 we:0.0559 have:0.0737 not:0.0417 little:0.0264.:0.2051.:0.1709 and:0.0972)
		(,:0.1318 we:0.0508 have:0.0649 not:0.0284 little:0.0227.:0.2090.:0.1709 and:0.0854)
		(,:0.1318 we:0.0508 have:0.0649 not:0.0284 little:0.0227.:0.2090.:0.1709 and:0.0854)
 and
------
		( and:0.0845�:0.0605 not:0.0913 few:0.0159,:0.1240 of:0.1523 the:0.0625 the:0.0762)
		( the:0.0547 am:0.0442 not:0.0649 few:0.0220,:0.1035 of:0.1191 I:0.1025 I:0.0889)
		( the:0.0549 am:0.0483 not:0.0796 little:0.0240.:0.1216.:0.1514 I:0.1060 I:0.0913)
		( I:0.0574 have:0.0605 not:0.0894 little:0.0302.:0.1465.:0.1689 and:0.1147 I:0.0757)
		( I:0.0679 have:0.0708 not:0.1079 little:0.0330.:0.1699.:0.1709 and:0.1230 I:0.0737)
		( I:0.0742 have:0.0815 not:0.1123 little:0.0327.:0.1787.:0.1768 and:0.1230 I:0.0820)
		( I:0.0737 have:0.0840 not:0.1064 little:0.0322.:0.1914.:0.1758 and:0.1211 I:0.0864)
		( I:0.0693 have:0.0874 not:0.0898 little:0.0320.:0.2061.:0.1807 and:0.1177 I:0.0874)
		( we:0.0640 have:0.0815 not:0.0742 little:0.0315.:0.2061.:0.1807 and:0.1138 I:0.0830)
		( we:0.0608 have:0.0791 not:0.0576 little:0.0293.:0.2031.:0.1738 and:0.1050 I:0.0776)
		( we:0.0559 have:0.0737 not:0.0417 little:0.0264.:0.2051.:0.1709 and:0.0972 I:0.0703)
		( we:0.0508 have:0.0649 not:0.0284 little:0.0227.:0.2090.:0.1709 and:0.0854 I:0.0640)
		( we:0.0508 have:0.0649 not:0.0284 little:0.0227.:0.2090.:0.1709 and:0.0854 I:0.0640)
 I have a good idea of the most important thing.
