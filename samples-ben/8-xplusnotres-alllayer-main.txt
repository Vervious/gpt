1: sample 0: Hello, I'm a language model,
------
		(Hello:0.3262,:0.5664 I:0.2988'm:0.6133 a:0.4570 language:0.5195 model:0.4590,:0.3965)
		(Hello:0.2988,:0.5547 I:0.2734'm:0.5820 a:0.4277 language:0.4902 model:0.4141,:0.3965)
		(Hello:0.2500,:0.5234 I:0.2373'm:0.5234 a:0.3828 language:0.4277 model:0.3555,:0.3672)
		(Hello:0.1865,:0.4609 I:0.1953'm:0.4434 a:0.3262 language:0.3535 model:0.3008,:0.3398)
		(Hello:0.1289,:0.3848 I:0.1514'm:0.3535 a:0.2617 language:0.2871 model:0.2275,:0.2988)
		(Hello:0.0874,:0.3145 I:0.1094'm:0.2617 a:0.2061 language:0.2061 model:0.1689,:0.2490)
		(Hello:0.0549,:0.2393 I:0.0732'm:0.1865 a:0.1436 language:0.1436 model:0.1157,:0.2158)
		(Hello:0.0330,:0.1689 I:0.0488'm:0.1221 a:0.1035 language:0.0923 model:0.0781,:0.1680)
		(Hello:0.0190,:0.1157 I:0.0320'm:0.0825 a:0.0654 language:0.0581 model:0.0488,:0.1357)
		(Hello:0.0114,:0.0781 I:0.0210'm:0.0518 a:0.0447 language:0.0349 model:0.0311,:0.1035)
		(Hello:0.0067,:0.0520 I:0.0137'm:0.0320 a:0.0293 language:0.0209 model:0.0198,:0.0776)
		(Hello:0.0041,:0.0352 I:0.0086'm:0.0197 a:0.0192 language:0.0124 model:0.0121,:0.0581)
		(Hello:0.0041,:0.0352 I:0.0086'm:0.0197 a:0.0192 language:0.0124 model:0.0121,:0.0581)
,
------
		(,:0.5664 I:0.2988'm:0.6133 a:0.4570 language:0.5195 model:0.4590,:0.3965,:0.5234)
		(,:0.5547 I:0.2734'm:0.5820 a:0.4277 language:0.4902 model:0.4141,:0.3965,:0.4902)
		(,:0.5234 I:0.2373'm:0.5234 a:0.3828 language:0.4277 model:0.3555,:0.3672,:0.4590)
		(,:0.4609 I:0.1953'm:0.4434 a:0.3262 language:0.3535 model:0.3008,:0.3398,:0.3984)
		(,:0.3848 I:0.1514'm:0.3535 a:0.2617 language:0.2871 model:0.2275,:0.2988,:0.3262)
		(,:0.3145 I:0.1094'm:0.2617 a:0.2061 language:0.2061 model:0.1689,:0.2490,:0.2617)
		(,:0.2393 I:0.0732'm:0.1865 a:0.1436 language:0.1436 model:0.1157,:0.2158,:0.1865)
		(,:0.1689 I:0.0488'm:0.1221 a:0.1035 language:0.0923 model:0.0781,:0.1680,:0.1367)
		(,:0.1157 I:0.0320'm:0.0825 a:0.0654 language:0.0581 model:0.0488,:0.1357,:0.0928)
		(,:0.0781 I:0.0210'm:0.0518 a:0.0447 language:0.0349 model:0.0311,:0.1035,:0.0620)
		(,:0.0520 I:0.0137'm:0.0320 a:0.0293 language:0.0209 model:0.0198,:0.0776,:0.0422)
		(,:0.0352 I:0.0086'm:0.0197 a:0.0192 language:0.0124 model:0.0121,:0.0581,:0.0293)
		(,:0.0352 I:0.0086'm:0.0197 a:0.0192 language:0.0124 model:0.0121,:0.0581,:0.0293)
,,,,,,,,,,,
50: sample 0: Hello, I'm a language model,
------
		(,:0.0562,:0.0425,:0.0356 the:0.0349,:0.0356,:0.0349,:0.0349,:0.0422)
		(,:0.0339,:0.0339,:0.0339,:0.0339,:0.0339,:0.0339 the:0.0349.:0.0349)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
,
------
		(,:0.0425,:0.0356 the:0.0349,:0.0356,:0.0349,:0.0349,:0.0422,:0.0425)
		(,:0.0339,:0.0339,:0.0339,:0.0339,:0.0339 the:0.0349.:0.0349,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
		(,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347,:0.0347)
,,,,,,,,,,,
200: sample 0: Hello, I'm a language model,
------
		(.:0.0674 the:0.0991 the:0.0771 the:0.0540 the:0.0649.:0.0757.:0.0732 the:0.1138)
		( the:0.0728 the:0.0732 the:0.0801 the:0.0781 the:0.0801.:0.0776.:0.0776 the:0.0791)
		(
:0.2490
:0.3203
:0.1562
:0.1562
:0.1553.:0.0747.:0.0747 the:0.0781)
		( the:0.0786 the:0.0786 the:0.0811 the:0.0811 the:0.0830 the:0.0703 the:0.0708 the:0.0864)
		(
:0.1846
:0.1445
:0.1445
:0.1338
:0.1270
:0.0996
:0.0894
:0.1748)
		( the:0.0767 the:0.0747 the:0.0747 the:0.0747 the:0.0747 the:0.0747 the:0.0752 the:0.0752)
		(
:0.2109
:0.2109
:0.2217
:0.2217
:0.2217
:0.2217
:0.2217
:0.2119)
		( the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767)
		(
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021)
		( the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767)
		(
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021
:0.2012
:0.2012)
		( the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767)
		( the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767)
 the
------
		( the:0.0991 the:0.0771 the:0.0540 the:0.0649.:0.0757.:0.0732 the:0.1138 the:0.0815)
		( the:0.0732 the:0.0801 the:0.0781 the:0.0801.:0.0776.:0.0776 the:0.0791 the:0.0801)
		(
:0.3203
:0.1562
:0.1562
:0.1553.:0.0747.:0.0747 the:0.0781 the:0.0801)
		( the:0.0786 the:0.0811 the:0.0811 the:0.0830 the:0.0703 the:0.0708 the:0.0864 the:0.0864)
		(
:0.1445
:0.1445
:0.1338
:0.1270
:0.0996
:0.0894
:0.1748
:0.1729)
		( the:0.0747 the:0.0747 the:0.0747 the:0.0747 the:0.0747 the:0.0752 the:0.0752 the:0.0771)
		(
:0.2109
:0.2217
:0.2217
:0.2217
:0.2217
:0.2217
:0.2119
:0.2031)
		( the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767)
		(
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021)
		( the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767)
		(
:0.2021
:0.2021
:0.2021
:0.2021
:0.2021
:0.2012
:0.2012
:0.2012)
		( the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767)
		( the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767 the:0.0767)
 the the the the the the the the the the the
350: sample 0: Hello, I'm a language model,
------
		(,:0.0525 the:0.0432 the:0.0349 the:0.0525 the:0.0110,:0.0679 the:0.0420 the:0.0801)
		(,:0.0579,:0.0598 the:0.1309 the:0.0625-:0.0369,:0.0718 the:0.0620 the:0.1152)
		(,:0.0654,:0.0654 the:0.0513 the:0.0688-:0.0098,:0.0698 the:0.0625 the:0.1162)
		(,:0.0625,:0.0630 the:0.1855.:0.0918-:0.0347,:0.0718 the:0.0562 the:0.1221)
		(,:0.0684,:0.0684 the:0.0640,:0.0913-:0.0098,:0.0718 the:0.0603 the:0.1162)
		(,:0.0664,:0.0664 the:0.1138,:0.0908-:0.0093,:0.0718 the:0.0564 the:0.1260)
		(,:0.0693,:0.0688 the:0.0674,:0.0762-:0.0085,:0.0718 the:0.0562 the:0.1221)
		(,:0.0684,:0.0684 the:0.1152,:0.0757-:0.0087,:0.0718 the:0.0547 the:0.1221)
		(,:0.0693,:0.0693 the:0.0693,:0.0806-:0.0082,:0.0718 the:0.0544 the:0.1226)
		(,:0.0684,:0.0684 the:0.1079,:0.0757-:0.0084,:0.0723 the:0.0549 the:0.1226)
		(,:0.0693,:0.0693 the:0.0718,:0.0806-:0.0082,:0.0718 the:0.0547 the:0.1226)
		(,:0.0679,:0.0679 the:0.1011,:0.0757-:0.0084,:0.0723 the:0.0549 the:0.1226)
		(,:0.0679,:0.0679 the:0.1011,:0.0757-:0.0084,:0.0723 the:0.0549 the:0.1226)
 the
------
		( the:0.0432 the:0.0349 the:0.0525 the:0.0110,:0.0679 the:0.0420 the:0.0801 the:0.0159)
		(,:0.0598 the:0.1309 the:0.0625-:0.0369,:0.0718 the:0.0620 the:0.1152 the:0.0093)
		(,:0.0654 the:0.0513 the:0.0688-:0.0098,:0.0698 the:0.0625 the:0.1162 the:0.0079)
		(,:0.0630 the:0.1855.:0.0918-:0.0347,:0.0718 the:0.0562 the:0.1221-:0.0079)
		(,:0.0684 the:0.0640,:0.0913-:0.0098,:0.0718 the:0.0603 the:0.1162-:0.0079)
		(,:0.0664 the:0.1138,:0.0908-:0.0093,:0.0718 the:0.0564 the:0.1260-:0.0079)
		(,:0.0688 the:0.0674,:0.0762-:0.0085,:0.0718 the:0.0562 the:0.1221-:0.0078)
		(,:0.0684 the:0.1152,:0.0757-:0.0087,:0.0718 the:0.0547 the:0.1221-:0.0078)
		(,:0.0693 the:0.0693,:0.0806-:0.0082,:0.0718 the:0.0544 the:0.1226-:0.0078)
		(,:0.0684 the:0.1079,:0.0757-:0.0084,:0.0723 the:0.0549 the:0.1226-:0.0078)
		(,:0.0693 the:0.0718,:0.0806-:0.0082,:0.0718 the:0.0547 the:0.1226-:0.0078)
		(,:0.0679 the:0.1011,:0.0757-:0.0084,:0.0723 the:0.0549 the:0.1226-:0.0078)
		(,:0.0679 the:0.1011,:0.0757-:0.0084,:0.0723 the:0.0549 the:0.1226-:0.0078)
-----------
500: sample 0: Hello, I'm a language model,
------
		(.:0.0908 and:0.0447,:0.0147.:0.0588 the:0.0118.:0.0933.:0.0693 the:0.0747)
		(.:0.0708 the:0.0762 the:0.0525.:0.1055 the:0.0206.:0.1260.:0.1270 and:0.0591)
		(.:0.0708 the:0.1504 the:0.1592.:0.1167 the:0.0190.:0.1187.:0.1206 and:0.0557)
		(.:0.0708 the:0.1309 the:0.1279.:0.1138,:0.0143.:0.1201.:0.1191 and:0.0525)
		(.:0.0708 the:0.1406 the:0.1445.:0.1147,:0.0141.:0.1191.:0.1187 and:0.0542)
		(.:0.0708 the:0.1338 the:0.1367.:0.1157,:0.0135.:0.1196.:0.1191 and:0.0542)
		(.:0.0708 the:0.1367 the:0.1406.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0542)
		(.:0.0708 the:0.1367 the:0.1367.:0.1128-:0.0140.:0.1196.:0.1221 and:0.0542)
		(.:0.0708 the:0.1367 the:0.1367.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0542)
		(.:0.0708 the:0.1367 the:0.1367.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0542)
		(.:0.0708 the:0.1367 the:0.1367.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0544)
		(.:0.0708 the:0.1367 the:0.1367.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0542)
		(.:0.0708 the:0.1367 the:0.1367.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0542)
 and
------
		( and:0.0447,:0.0147.:0.0588 the:0.0118.:0.0933.:0.0693 the:0.0747 the:0.0294)
		( the:0.0762 the:0.0525.:0.1055 the:0.0206.:0.1260.:0.1270 and:0.0591 the:0.1074)
		( the:0.1504 the:0.1592.:0.1167 the:0.0190.:0.1187.:0.1206 and:0.0557 the:0.1855)
		( the:0.1309 the:0.1279.:0.1138,:0.0143.:0.1201.:0.1191 and:0.0525 the:0.1738)
		( the:0.1406 the:0.1445.:0.1147,:0.0141.:0.1191.:0.1187 and:0.0542 the:0.1826)
		( the:0.1338 the:0.1367.:0.1157,:0.0135.:0.1196.:0.1191 and:0.0542 the:0.1836)
		( the:0.1367 the:0.1406.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0542 the:0.1836)
		( the:0.1367 the:0.1367.:0.1128-:0.0140.:0.1196.:0.1221 and:0.0542 the:0.1836)
		( the:0.1367 the:0.1367.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0542 the:0.1836)
		( the:0.1367 the:0.1367.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0542 the:0.1836)
		( the:0.1367 the:0.1367.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0544 the:0.1836)
		( the:0.1367 the:0.1367.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0542 the:0.1836)
		( the:0.1367 the:0.1367.:0.1152-:0.0140.:0.1196.:0.1221 and:0.0542 the:0.1836)
 the, and the, and the the the the the
650: sample 0: Hello, I'm a language model,
------
		(,:0.0598,:0.0588,:0.0254 a:0.0415-:0.0083,:0.0952,:0.0500 and:0.0598)
		(,:0.0376,:0.0398,:0.0310 the:0.0703 first:0.0061,:0.1299 the:0.0566 the:0.0781)
		(,:0.0376,:0.0376,:0.0315 the:0.2266 new:0.0084,:0.1318 the:0.1270 the:0.0933)
		(,:0.0366,:0.0366,:0.0371 the:0.2305 new:0.0087,:0.1270 the:0.2480 the:0.0684)
		(,:0.0376,:0.0376,:0.0383 the:0.2197 new:0.0087,:0.1318 the:0.3223 the:0.0757)
		(,:0.0366,:0.0366,:0.0376 the:0.2305 new:0.0087,:0.1318 the:0.3105 the:0.0752)
		(,:0.0376,:0.0376,:0.0376 the:0.2197 new:0.0087,:0.1328 the:0.3242 the:0.0757)
		(,:0.0366,:0.0366,:0.0366 the:0.2305 new:0.0087,:0.1318 the:0.3242 the:0.0752)
		(,:0.0366,:0.0366,:0.0366 the:0.2197 new:0.0087,:0.1328 the:0.3105 the:0.0752)
		(,:0.0366,:0.0366,:0.0366 the:0.2305 new:0.0087,:0.1318 the:0.3242 the:0.0757)
		(,:0.0366,:0.0366,:0.0366 the:0.2197 new:0.0087,:0.1328 the:0.3105 the:0.0752)
		(,:0.0366,:0.0366,:0.0366 the:0.2305 new:0.0087,:0.1318 the:0.3242 the:0.0757)
		(,:0.0366,:0.0366,:0.0366 the:0.2305 new:0.0087,:0.1318 the:0.3242 the:0.0757)
 the
------
		(,:0.0588,:0.0254 a:0.0415-:0.0083,:0.0952,:0.0500 and:0.0598 same:0.0066)
		(,:0.0398,:0.0310 the:0.0703 first:0.0061,:0.1299 the:0.0566 the:0.0781,:0.0132)
		(,:0.0376,:0.0315 the:0.2266 new:0.0084,:0.1318 the:0.1270 the:0.0933 and:0.0077)
		(,:0.0366,:0.0371 the:0.2305 new:0.0087,:0.1270 the:0.2480 the:0.0684 and:0.0061)
		(,:0.0376,:0.0383 the:0.2197 new:0.0087,:0.1318 the:0.3223 the:0.0757 first:0.0066)
		(,:0.0366,:0.0376 the:0.2305 new:0.0087,:0.1318 the:0.3105 the:0.0752 first:0.0066)
		(,:0.0376,:0.0376 the:0.2197 new:0.0087,:0.1328 the:0.3242 the:0.0757 first:0.0067)
		(,:0.0366,:0.0366 the:0.2305 new:0.0087,:0.1318 the:0.3242 the:0.0752 first:0.0067)
		(,:0.0366,:0.0366 the:0.2197 new:0.0087,:0.1328 the:0.3105 the:0.0752 first:0.0067)
		(,:0.0366,:0.0366 the:0.2305 new:0.0087,:0.1318 the:0.3242 the:0.0757 first:0.0067)
		(,:0.0366,:0.0366 the:0.2197 new:0.0087,:0.1328 the:0.3105 the:0.0752 first:0.0067)
		(,:0.0366,:0.0366 the:0.2305 new:0.0087,:0.1318 the:0.3242 the:0.0757 first:0.0067)
		(,:0.0366,:0.0366 the:0.2305 new:0.0087,:0.1318 the:0.3242 the:0.0757 first:0.0067)
 first and the first and the first and the first and
800: sample 0: Hello, I'm a language model,
------
		(,:0.0732,:0.0374,:0.0310 not:0.0359 the:0.0054 of:0.1226 of:0.1206 the:0.0962)
		(,:0.0564,:0.0430,:0.0320 not:0.0481 most:0.0090.:0.1260 of:0.1367 the:0.1318)
		(,:0.0608,:0.0559,:0.0300 the:0.0518 �:0.0099.:0.1377.:0.1318 the:0.1055)
		(,:0.0605,:0.0608,:0.0297 the:0.0596 �:0.0106.:0.1416.:0.1387 the:0.0889)
		(,:0.0608,:0.0608,:0.0298 the:0.0635 �:0.0103.:0.1387.:0.1406 the:0.0913)
		(,:0.0608,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1396 the:0.0942)
		(,:0.0608,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1396 the:0.0840)
		(,:0.0608,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1416.:0.1396 the:0.0825)
		(,:0.0608,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1387 the:0.0835)
		(,:0.0608,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1396 the:0.0825)
		(,:0.0608,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1416.:0.1396 the:0.0830)
		(,:0.0608,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1396 the:0.0806)
		(,:0.0608,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1396 the:0.0806)
 the
------
		(,:0.0374,:0.0310 not:0.0359 the:0.0054 of:0.1226 of:0.1206 the:0.0962 most:0.0069)
		(,:0.0430,:0.0320 not:0.0481 most:0.0090.:0.1260 of:0.1367 the:0.1318 the:0.0090)
		(,:0.0559,:0.0300 the:0.0518 �:0.0099.:0.1377.:0.1318 the:0.1055 and:0.0081)
		(,:0.0608,:0.0297 the:0.0596 �:0.0106.:0.1416.:0.1387 the:0.0889 and:0.0094)
		(,:0.0608,:0.0298 the:0.0635 �:0.0103.:0.1387.:0.1406 the:0.0913 and:0.0108)
		(,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1396 the:0.0942 and:0.0111)
		(,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1396 the:0.0840 and:0.0107)
		(,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1416.:0.1396 the:0.0825 and:0.0106)
		(,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1387 the:0.0835 and:0.0106)
		(,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1396 the:0.0825 and:0.0102)
		(,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1416.:0.1396 the:0.0830 and:0.0101)
		(,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1396 the:0.0806 and:0.0101)
		(,:0.0608,:0.0297 the:0.0640 �:0.0096.:0.1426.:0.1396 the:0.0806 and:0.0101)
 and the and the and the and the and the and
950: sample 0: Hello, I'm a language model,
------
		(,:0.0649 is:0.0640 of:0.0168 a:0.0200 the:0.0069 of:0.1504 of:0.1250 the:0.1108)
		( the:0.0535 the:0.0481.:0.0226 the:0.0513 the:0.0226,:0.1079,:0.1152 the:0.1108)
		(
:0.0552
:0.0559.:0.0205 the:0.0669 the:0.0099,:0.1206,:0.1270 the:0.0674)
		(
:0.0723
:0.0693 of:0.0192 the:0.0708
:0.0096,:0.1279,:0.1270 the:0.0786)
		(
:0.0581
:0.0581.:0.0198 the:0.0708
:0.0121.:0.1377.:0.1396 the:0.0635)
		(
:0.0625
:0.0625.:0.0192 the:0.0767
:0.0121.:0.1309.:0.1289 the:0.0723)
		(
:0.0613
:0.0613.:0.0192 the:0.0747
:0.0127.:0.1328.:0.1348 the:0.0688)
		(
:0.0630
:0.0630.:0.0192 the:0.0747
:0.0122.:0.1338.:0.1318 the:0.0698)
		(
:0.0613
:0.0613.:0.0192 the:0.0747
:0.0126.:0.1338.:0.1309 the:0.0693)
		(
:0.0613
:0.0613.:0.0192 the:0.0747
:0.0122.:0.1338.:0.1318 the:0.0693)
		(
:0.0613
:0.0613.:0.0192 the:0.0747
:0.0126.:0.1338.:0.1318 the:0.0693)
		(
:0.0613
:0.0613.:0.0192 the:0.0747
:0.0126.:0.1328.:0.1318 the:0.0693)
		(
:0.0613
:0.0613.:0.0192 the:0.0747
:0.0126.:0.1328.:0.1318 the:0.0693)
 the
------
		( is:0.0640 of:0.0168 a:0.0200 the:0.0069 of:0.1504 of:0.1250 the:0.1108 the:0.0080)
		( the:0.0481.:0.0226 the:0.0513 the:0.0226,:0.1079,:0.1152 the:0.1108 the:0.0170)
		(
:0.0559.:0.0205 the:0.0669 the:0.0099,:0.1206,:0.1270 the:0.0674.:0.0063)
		(
:0.0693 of:0.0192 the:0.0708
:0.0096,:0.1279,:0.1270 the:0.0786.:0.0071)
		(
:0.0581.:0.0198 the:0.0708
:0.0121.:0.1377.:0.1396 the:0.0635 and:0.0084)
		(
:0.0625.:0.0192 the:0.0767
:0.0121.:0.1309.:0.1289 the:0.0723 of:0.0093)
		(
:0.0613.:0.0192 the:0.0747
:0.0127.:0.1328.:0.1348 the:0.0688 of:0.0105)
		(
:0.0630.:0.0192 the:0.0747
:0.0122.:0.1338.:0.1318 the:0.0698 of:0.0142)
		(
:0.0613.:0.0192 the:0.0747
:0.0126.:0.1338.:0.1309 the:0.0693 of:0.0221)
		(
:0.0613.:0.0192 the:0.0747
:0.0122.:0.1338.:0.1318 the:0.0693 of:0.0231)
		(
:0.0613.:0.0192 the:0.0747
:0.0126.:0.1338.:0.1318 the:0.0693 of:0.0232)
		(
:0.0613.:0.0192 the:0.0747
:0.0126.:0.1328.:0.1318 the:0.0693 of:0.0232)
		(
:0.0613.:0.0192 the:0.0747
:0.0126.:0.1328.:0.1318 the:0.0693 of:0.0232)
 of the and the and the and the and the

1100: sample 0: Hello, I'm a language model,
------
		(,:0.0791,:0.0447,:0.0115 a:0.0212 same:0.0073,:0.0522 of:0.1299 and:0.0659)
		( the:0.0481,:0.0559.:0.0635 you:0.0713.:0.0635�:0.1338
:0.0918�:0.3125)
		(,:0.0525 the:0.0479.:0.0245 to:0.0270.:0.0254,:0.1387,:0.1387 and:0.1021)
		(,:0.0674,:0.0591 the:0.0420 to:0.0342.:0.0165.:0.1455.:0.1436.:0.1514)
		(,:0.0569,:0.0549 you:0.0410 be:0.0459.:0.0162.:0.1494.:0.1514.:0.1504)
		(,:0.0588,:0.0586 the:0.0371 be:0.0469.:0.0141.:0.1514.:0.1533.:0.1533)
		(,:0.0583,:0.0583 the:0.0391 be:0.0503.:0.0145.:0.1523.:0.1494.:0.1504)
		(,:0.0583,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1494)
		(,:0.0583,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1494)
		(,:0.0583,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1494)
		(,:0.0583,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1494)
		(,:0.0583,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1504)
		(,:0.0583,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1504)
.
------
		(,:0.0447,:0.0115 a:0.0212 same:0.0073,:0.0522 of:0.1299 and:0.0659
:0.1855)
		(,:0.0559.:0.0635 you:0.0713.:0.0635�:0.1338
:0.0918�:0.3125
:0.2236)
		( the:0.0479.:0.0245 to:0.0270.:0.0254,:0.1387,:0.1387 and:0.1021
:0.1660)
		(,:0.0591 the:0.0420 to:0.0342.:0.0165.:0.1455.:0.1436.:0.1514
:0.2432)
		(,:0.0549 you:0.0410 be:0.0459.:0.0162.:0.1494.:0.1514.:0.1504
:0.2109)
		(,:0.0586 the:0.0371 be:0.0469.:0.0141.:0.1514.:0.1533.:0.1533
:0.2100)
		(,:0.0583 the:0.0391 be:0.0503.:0.0145.:0.1523.:0.1494.:0.1504
:0.2119)
		(,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1494
:0.2012)
		(,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1494
:0.2109)
		(,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1494
:0.2012)
		(,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1494
:0.2012)
		(,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1504
:0.2012)
		(,:0.0583 the:0.0381 be:0.0503.:0.0145.:0.1514.:0.1523.:0.1504
:0.2012)

The same, and the same, and the same
1250: sample 0: Hello, I'm a language model,
------
		(,:0.0762,:0.0569,:0.0146 a:0.0322 new:0.0060 of:0.1396 of:0.1973 the:0.1011)
		( the:0.0491 the:0.0500.:0.0588 to:0.0398.:0.0361.:0.1602.:0.1533 and:0.1631)
		( the:0.0554 the:0.0532.:0.0527 a:0.0520.:0.0352.:0.1348.:0.1299 and:0.1152)
		( the:0.0503 the:0.0505.:0.0422 a:0.0522.:0.0330.:0.1260.:0.1250 and:0.1357)
		( the:0.0505 the:0.0491.:0.0403 a:0.0525.:0.0342.:0.1289.:0.1279 and:0.1299)
		( the:0.0493 the:0.0493.:0.0405 a:0.0527.:0.0317.:0.1299.:0.1250 and:0.1240)
		( the:0.0491 the:0.0491.:0.0396 a:0.0532.:0.0305.:0.1309.:0.1260 and:0.1147)
		( the:0.0491 the:0.0505.:0.0408 a:0.0532.:0.0295.:0.1299.:0.1250 and:0.1045)
		( the:0.0505 the:0.0491.:0.0408 a:0.0532.:0.0294.:0.1309.:0.1260 and:0.0884)
		( the:0.0491 the:0.0491.:0.0408 a:0.0530.:0.0294.:0.1309.:0.1260 the:0.0815)
		( the:0.0491 the:0.0491.:0.0408 a:0.0530.:0.0294.:0.1309.:0.1260 the:0.0815)
		( the:0.0491 the:0.0491.:0.0408 a:0.0530.:0.0294.:0.1299.:0.1260 the:0.0806)
		( the:0.0491 the:0.0491.:0.0408 a:0.0530.:0.0294.:0.1299.:0.1260 the:0.0806)
 the
------
		(,:0.0569,:0.0146 a:0.0322 new:0.0060 of:0.1396 of:0.1973 the:0.1011 same:0.0118)
		( the:0.0500.:0.0588 to:0.0398.:0.0361.:0.1602.:0.1533 and:0.1631.:0.0171)
		( the:0.0532.:0.0527 a:0.0520.:0.0352.:0.1348.:0.1299 and:0.1152 time:0.0075)
		( the:0.0505.:0.0422 a:0.0522.:0.0330.:0.1260.:0.1250 and:0.1357 first:0.0084)
		( the:0.0491.:0.0403 a:0.0525.:0.0342.:0.1289.:0.1279 and:0.1299 first:0.0064)
		( the:0.0493.:0.0405 a:0.0527.:0.0317.:0.1299.:0.1250 and:0.1240.:0.0092)
		( the:0.0491.:0.0396 a:0.0532.:0.0305.:0.1309.:0.1260 and:0.1147.:0.0117)
		( the:0.0505.:0.0408 a:0.0532.:0.0295.:0.1299.:0.1250 and:0.1045.:0.0120)
		( the:0.0491.:0.0408 a:0.0532.:0.0294.:0.1309.:0.1260 and:0.0884.:0.0120)
		( the:0.0491.:0.0408 a:0.0530.:0.0294.:0.1309.:0.1260 the:0.0815.:0.0115)
		( the:0.0491.:0.0408 a:0.0530.:0.0294.:0.1309.:0.1260 the:0.0815.:0.0109)
		( the:0.0491.:0.0408 a:0.0530.:0.0294.:0.1299.:0.1260 the:0.0806.:0.0101)
		( the:0.0491.:0.0408 a:0.0530.:0.0294.:0.1299.:0.1260 the:0.0806.:0.0101)
.
- The same, and the same, and
1400: sample 0: Hello, I'm a language model,
------
		(,:0.1025,:0.0640 a:0.0281 a:0.0396 �:0.0066 of:0.1162.:0.1226 and:0.0947)
		(,:0.0422,:0.0493 the:0.0635 not:0.0452 the:0.0084 of:0.1748.:0.1729 and:0.1846)
		(,:0.0393,:0.0415 the:0.1045 a:0.0199 first:0.0078.:0.1270,:0.1533 and:0.1797)
		(,:0.0474,:0.0474 the:0.1084-:0.0359 first:0.0070.:0.1074,:0.1562 and:0.1758)
		(,:0.0481,:0.0479 the:0.1069-:0.0383 first:0.0056,:0.0923,:0.1768 and:0.1836)
		(,:0.0464,:0.0464 the:0.1069-:0.0403 first:0.0057,:0.0923,:0.1777 and:0.1914)
		(,:0.0464,:0.0464 the:0.1079-:0.0447 first:0.0055,:0.0923,:0.1758 and:0.1895)
		(,:0.0466,:0.0466 the:0.1079-:0.0420 first:0.0059,:0.0898,:0.1738 and:0.1895)
		(,:0.0466,:0.0466 the:0.1079-:0.0435-:0.0061,:0.0923,:0.1768 and:0.1904)
		(,:0.0464,:0.0466 the:0.1079-:0.0417 first:0.0059,:0.0898,:0.1758 and:0.1885)
		(,:0.0464,:0.0464 the:0.1079-:0.0437 first:0.0058,:0.0923,:0.1748 and:0.1943)
		(,:0.0466,:0.0466 the:0.1079-:0.0430 first:0.0059,:0.0898,:0.1758 and:0.1885)
		(,:0.0466,:0.0466 the:0.1079-:0.0430 first:0.0059,:0.0898,:0.1758 and:0.1885)
 and
------
		(,:0.0640 a:0.0281 a:0.0396 �:0.0066 of:0.1162.:0.1226 and:0.0947 the:0.0459)
		(,:0.0493 the:0.0635 not:0.0452 the:0.0084 of:0.1748.:0.1729 and:0.1846 the:0.0503)
		(,:0.0415 the:0.1045 a:0.0199 first:0.0078.:0.1270,:0.1533 and:0.1797 the:0.0483)
		(,:0.0474 the:0.1084-:0.0359 first:0.0070.:0.1074,:0.1562 and:0.1758 the:0.0435)
		(,:0.0479 the:0.1069-:0.0383 first:0.0056,:0.0923,:0.1768 and:0.1836 the:0.0544)
		(,:0.0464 the:0.1069-:0.0403 first:0.0057,:0.0923,:0.1777 and:0.1914 the:0.0493)
		(,:0.0464 the:0.1079-:0.0447 first:0.0055,:0.0923,:0.1758 and:0.1895 the:0.0576)
		(,:0.0466 the:0.1079-:0.0420 first:0.0059,:0.0898,:0.1738 and:0.1895 the:0.0510)
		(,:0.0466 the:0.1079-:0.0435-:0.0061,:0.0923,:0.1768 and:0.1904 the:0.0549)
		(,:0.0466 the:0.1079-:0.0417 first:0.0059,:0.0898,:0.1758 and:0.1885 the:0.0530)
		(,:0.0464 the:0.1079-:0.0437 first:0.0058,:0.0923,:0.1748 and:0.1943 the:0.0566)
		(,:0.0466 the:0.1079-:0.0430 first:0.0059,:0.0898,:0.1758 and:0.1885 the:0.0530)
		(,:0.0466 the:0.1079-:0.0430 first:0.0059,:0.0898,:0.1758 and:0.1885 the:0.0530)
 the year, and the year, and the year,
1550: sample 0: Hello, I'm a language model,
------
		(,:0.0791,:0.0747 a:0.0172 a:0.0306 new:0.0085 of:0.1787 of:0.3652 the:0.0547)
		(,:0.0359,:0.0513 the:0.0583 you:0.0275 I:0.0121.:0.1504.:0.1406 and:0.1050)
		(,:0.0513,:0.0491 the:0.0903 not:0.0312 first:0.0068 of:0.1670 of:0.1699 the:0.0708)
		(,:0.0566,:0.0544 the:0.0928 not:0.0420 first:0.0077 of:0.2109 of:0.2090 and:0.0933)
		(,:0.0562,:0.0547 the:0.0898 not:0.0391 same:0.0078 of:0.2148 of:0.2129 and:0.1040)
		(,:0.0532,:0.0547 the:0.0923 not:0.0391 same:0.0078 of:0.2148 of:0.2129 and:0.1030)
		(,:0.0532,:0.0532 the:0.0933 not:0.0391 same:0.0076 of:0.2168 of:0.2148 and:0.1040)
		(,:0.0535,:0.0535 the:0.0933 not:0.0391 same:0.0075 of:0.2158 of:0.2148 and:0.1035)
		(,:0.0535,:0.0535 the:0.0933 not:0.0393 same:0.0076 of:0.2158 of:0.2148 and:0.1035)
		(,:0.0535,:0.0535 the:0.0933 not:0.0391 same:0.0075 of:0.2158 of:0.2148 and:0.1035)
		(,:0.0532,:0.0535 the:0.0933 not:0.0391 same:0.0075 of:0.2158 of:0.2148 and:0.1035)
		(,:0.0535,:0.0532 the:0.0933 not:0.0391 same:0.0075 of:0.2158 of:0.2148 and:0.1035)
		(,:0.0535,:0.0532 the:0.0933 not:0.0391 same:0.0075 of:0.2158 of:0.2148 and:0.1035)
 and
------
		(,:0.0747 a:0.0172 a:0.0306 new:0.0085 of:0.1787 of:0.3652 the:0.0547 the:0.0444)
		(,:0.0513 the:0.0583 you:0.0275 I:0.0121.:0.1504.:0.1406 and:0.1050 the:0.0325)
		(,:0.0491 the:0.0903 not:0.0312 first:0.0068 of:0.1670 of:0.1699 the:0.0708 the:0.0562)
		(,:0.0544 the:0.0928 not:0.0420 first:0.0077 of:0.2109 of:0.2090 and:0.0933 the:0.0654)
		(,:0.0547 the:0.0898 not:0.0391 same:0.0078 of:0.2148 of:0.2129 and:0.1040 the:0.0615)
		(,:0.0547 the:0.0923 not:0.0391 same:0.0078 of:0.2148 of:0.2129 and:0.1030 the:0.0613)
		(,:0.0532 the:0.0933 not:0.0391 same:0.0076 of:0.2168 of:0.2148 and:0.1040 the:0.0635)
		(,:0.0535 the:0.0933 not:0.0391 same:0.0075 of:0.2158 of:0.2148 and:0.1035 the:0.0635)
		(,:0.0535 the:0.0933 not:0.0393 same:0.0076 of:0.2158 of:0.2148 and:0.1035 the:0.0635)
		(,:0.0535 the:0.0933 not:0.0391 same:0.0075 of:0.2158 of:0.2148 and:0.1035 the:0.0635)
		(,:0.0535 the:0.0933 not:0.0391 same:0.0075 of:0.2158 of:0.2148 and:0.1035 the:0.0635)
		(,:0.0532 the:0.0933 not:0.0391 same:0.0075 of:0.2158 of:0.2148 and:0.1035 the:0.0635)
		(,:0.0532 the:0.0933 not:0.0391 same:0.0075 of:0.2158 of:0.2148 and:0.1035 the:0.0635)
 the same and the same and the same and the same
