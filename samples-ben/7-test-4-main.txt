1: sample 0: Hello, I'm a language model,
------
		(Hello:0.4902,:0.6562 I:0.4590'm:0.5977 a:0.1953 language:0.4277 model:0.4434,:0.5234)
		(Hello:0.0008,:0.0025 I:0.0005'm:0.0009 a:0.0004 language:0.0006 model:0.0007,:0.0019)
		( Often:0.0001,:0.0007,:0.0002,:0.0002 Murray:0.0002 Planetary:0.0002,:0.0002,:0.0010)
		( Often:0.0002,:0.0004,:0.0002,:0.0002 Murray:0.0002,:0.0002,:0.0002,:0.0006)
		( Murray:0.0001,:0.0003,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0005)
		( Murray:0.0001,:0.0003,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0004)
		( Murray:0.0001,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0004)
		(Index:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003)
		(Index:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003)
		(Index:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003)
		(Index:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003)
		(Index:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003)
		(Index:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003)
,
------
		(,:0.6562 I:0.4590'm:0.5977 a:0.1953 language:0.4277 model:0.4434,:0.5234,:0.5820)
		(,:0.0025 I:0.0005'm:0.0009 a:0.0004 language:0.0006 model:0.0007,:0.0019,:0.0025)
		(,:0.0007,:0.0002,:0.0002 Murray:0.0002 Planetary:0.0002,:0.0002,:0.0010,:0.0009)
		(,:0.0004,:0.0002,:0.0002 Murray:0.0002,:0.0002,:0.0002,:0.0006,:0.0006)
		(,:0.0003,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0005,:0.0004)
		(,:0.0003,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0004,:0.0004)
		(,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0004,:0.0003)
		(,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003,:0.0003)
		(,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003,:0.0003)
		(,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003,:0.0003)
		(,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003,:0.0003)
		(,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003,:0.0003)
		(,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0002,:0.0003,:0.0003)
,,,,,,,,,,,
50: sample 0: Hello, I'm a language model,
------
		(Hello:0.4805,:0.9961 I:0.7852'm:0.7656 a:0.8477 language:0.7930 model:0.7188,:0.9922)
		( the:0.0583 the:0.0289,:0.1064.:0.0913 a:0.0166.:0.0562.:0.0674.:0.0420)
		( the:0.0471 the:0.0266.:0.0830.:0.0698.:0.0182.:0.0491.:0.0549.:0.0398)
		( the:0.0415.:0.0266.:0.0728.:0.0608.:0.0197.:0.0442.:0.0500.:0.0381)
		( the:0.0388.:0.0266.:0.0645.:0.0549.:0.0214.:0.0435.:0.0479.:0.0374)
		( the:0.0361.:0.0273.:0.0601.:0.0522.:0.0226.:0.0413.:0.0454.:0.0366)
		( the:0.0349.:0.0282.:0.0574.:0.0498.:0.0238.:0.0413.:0.0444.:0.0366)
		( the:0.0337.:0.0289.:0.0562.:0.0486.:0.0245.:0.0403.:0.0435.:0.0356)
		( the:0.0325.:0.0289.:0.0532.:0.0474.:0.0259.:0.0391.:0.0422.:0.0359)
		( the:0.0325.:0.0289.:0.0520.:0.0461.:0.0265.:0.0393.:0.0410.:0.0359)
		( the:0.0312.:0.0298.:0.0508.:0.0449.:0.0272.:0.0393.:0.0413.:0.0359)
		( the:0.0312.:0.0297.:0.0493.:0.0452.:0.0280.:0.0381.:0.0400.:0.0359)
		( the:0.0303.:0.0306.:0.0496.:0.0437.:0.0287.:0.0381.:0.0403.:0.0359)
.
------
		(,:0.9961 I:0.7852'm:0.7656 a:0.8477 language:0.7930 model:0.7188,:0.9922.:0.9844)
		( the:0.0289,:0.1064.:0.0913 a:0.0166.:0.0562.:0.0674.:0.0420
:0.3242)
		( the:0.0266.:0.0830.:0.0698.:0.0182.:0.0491.:0.0549.:0.0398
:0.2754)
		(.:0.0266.:0.0728.:0.0608.:0.0197.:0.0442.:0.0500.:0.0381
:0.2402)
		(.:0.0266.:0.0645.:0.0549.:0.0214.:0.0435.:0.0479.:0.0374
:0.2266)
		(.:0.0273.:0.0601.:0.0522.:0.0226.:0.0413.:0.0454.:0.0366
:0.2100)
		(.:0.0282.:0.0574.:0.0498.:0.0238.:0.0413.:0.0444.:0.0366
:0.1934)
		(.:0.0289.:0.0562.:0.0486.:0.0245.:0.0403.:0.0435.:0.0356
:0.1855)
		(.:0.0289.:0.0532.:0.0474.:0.0259.:0.0391.:0.0422.:0.0359
:0.1699)
		(.:0.0289.:0.0520.:0.0461.:0.0265.:0.0393.:0.0410.:0.0359
:0.1621)
		(.:0.0298.:0.0508.:0.0449.:0.0272.:0.0393.:0.0413.:0.0359
:0.1553)
		(.:0.0297.:0.0493.:0.0452.:0.0280.:0.0381.:0.0400.:0.0359
:0.1562)
		(.:0.0306.:0.0496.:0.0437.:0.0287.:0.0381.:0.0403.:0.0359
:0.1494)












200: sample 0: Hello, I'm a language model,
------
		(Hello:0.6250,:0.9844 I:0.9648'm:0.7461 a:0.9648 language:0.7734 model:0.8750,:0.9961)
		(
:0.0654 and:0.0623 the:0.0894 the:0.0889 the:0.0200,:0.1191,:0.1309 the:0.0767)
		(
:0.0601 and:0.0605 the:0.0864 the:0.0845 the:0.0190,:0.1177,:0.1289 the:0.0781)
		(
:0.0566 and:0.0603 the:0.0879 the:0.0845 the:0.0176,:0.1147,:0.1279 the:0.0796)
		(
:0.0518 and:0.0586 the:0.0845 the:0.0840 the:0.0168,:0.1133,:0.1270 the:0.0811)
		(
:0.0486 and:0.0583 the:0.0854 the:0.0791 the:0.0161,:0.1118,:0.1196 the:0.0796)
		(
:0.0454 and:0.0583 the:0.0815 the:0.0786 the:0.0154,:0.1099,:0.1187 the:0.0811)
		(
:0.0413 and:0.0564 the:0.0820 the:0.0776 the:0.0146,:0.1089,:0.1182 the:0.0801)
		(
:0.0386 and:0.0564 the:0.0781 the:0.0723 the:0.0140,:0.1074,:0.1172 the:0.0786)
		(
:0.0361 and:0.0562 the:0.0781 the:0.0713 the:0.0134,:0.1006,:0.1167 the:0.0776)
		(
:0.0327 and:0.0562 the:0.0742 the:0.0703 the:0.0132,:0.0996,:0.1094 the:0.0786)
		(
:0.0305 and:0.0559 the:0.0742 the:0.0654 the:0.0126,:0.0986,:0.1089 the:0.0776)
		(
:0.0284 and:0.0557 the:0.0747 the:0.0645 the:0.0121,:0.0977,:0.1084 the:0.0767)
 the
------
		(,:0.9844 I:0.9648'm:0.7461 a:0.9648 language:0.7734 model:0.8750,:0.9961 the:0.9883)
		( and:0.0623 the:0.0894 the:0.0889 the:0.0200,:0.1191,:0.1309 the:0.0767 the:0.0085)
		( and:0.0605 the:0.0864 the:0.0845 the:0.0190,:0.1177,:0.1289 the:0.0781 the:0.0079)
		( and:0.0603 the:0.0879 the:0.0845 the:0.0176,:0.1147,:0.1279 the:0.0796 the:0.0072)
		( and:0.0586 the:0.0845 the:0.0840 the:0.0168,:0.1133,:0.1270 the:0.0811 the:0.0066)
		( and:0.0583 the:0.0854 the:0.0791 the:0.0161,:0.1118,:0.1196 the:0.0796 the:0.0061)
		( and:0.0583 the:0.0815 the:0.0786 the:0.0154,:0.1099,:0.1187 the:0.0811 the:0.0056)
		( and:0.0564 the:0.0820 the:0.0776 the:0.0146,:0.1089,:0.1182 the:0.0801 first:0.0056)
		( and:0.0564 the:0.0781 the:0.0723 the:0.0140,:0.1074,:0.1172 the:0.0786 first:0.0056)
		( and:0.0562 the:0.0781 the:0.0713 the:0.0134,:0.1006,:0.1167 the:0.0776 same:0.0059)
		( and:0.0562 the:0.0742 the:0.0703 the:0.0132,:0.0996,:0.1094 the:0.0786 same:0.0061)
		( and:0.0559 the:0.0742 the:0.0654 the:0.0126,:0.0986,:0.1089 the:0.0776 same:0.0061)
		( and:0.0557 the:0.0747 the:0.0645 the:0.0121,:0.0977,:0.1084 the:0.0767 same:0.0063)
 same, and the time, and the same, and
350: sample 0: Hello, I'm a language model,
------
		(Hello:0.5781,:0.9180 I:0.9961'm:0.9922 a:0.9766 language:0.7891 model:0.9062,:0.9961)
		( of:0.1055 and:0.0742 are:0.1211 the:0.0591 way:0.0086,:0.1670 of:0.1650 the:0.0713)
		( of:0.0874 and:0.0732 are:0.1089 the:0.0564 way:0.0099,:0.1719 of:0.1611 the:0.0713)
		( of:0.0737 and:0.0718 are:0.1006 the:0.0522 way:0.0110,:0.1777 of:0.1533 the:0.0698)
		( of:0.0645 and:0.0728 are:0.0933 the:0.0496 way:0.0123,:0.1826 of:0.1504 the:0.0698)
		(-:0.0562 and:0.0737 are:0.0884 the:0.0469 way:0.0130,:0.1885 of:0.1475 the:0.0679)
		(-:0.0530 and:0.0718 are:0.0820 the:0.0430 way:0.0142,:0.1934 of:0.1406 the:0.0664)
		(-:0.0513 and:0.0723 are:0.0757 the:0.0405 way:0.0146,:0.2002 of:0.1377 the:0.0645)
		(-:0.0493 and:0.0728 are:0.0713 the:0.0381 way:0.0155,:0.2051 of:0.1348 the:0.0630)
		(-:0.0474 and:0.0732 are:0.0669 the:0.0359 way:0.0155,:0.2109,:0.1309 the:0.0613)
		(-:0.0469 and:0.0732 are:0.0640 not:0.0347 way:0.0161,:0.2168,:0.1367 the:0.0601)
		(,:0.0447 and:0.0757 are:0.0615 not:0.0359 way:0.0161,:0.2227,:0.1416 the:0.0583)
		(,:0.0469 and:0.0757 are:0.0583 not:0.0369 way:0.0162,:0.2285,:0.1475 the:0.0569)
 the
------
		(,:0.9180 I:0.9961'm:0.9922 a:0.9766 language:0.7891 model:0.9062,:0.9961 the:0.9805)
		( and:0.0742 are:0.1211 the:0.0591 way:0.0086,:0.1670 of:0.1650 the:0.0713 same:0.0122)
		( and:0.0732 are:0.1089 the:0.0564 way:0.0099,:0.1719 of:0.1611 the:0.0713 same:0.0135)
		( and:0.0718 are:0.1006 the:0.0522 way:0.0110,:0.1777 of:0.1533 the:0.0698 same:0.0150)
		( and:0.0728 are:0.0933 the:0.0496 way:0.0123,:0.1826 of:0.1504 the:0.0698 same:0.0161)
		( and:0.0737 are:0.0884 the:0.0469 way:0.0130,:0.1885 of:0.1475 the:0.0679 same:0.0168)
		( and:0.0718 are:0.0820 the:0.0430 way:0.0142,:0.1934 of:0.1406 the:0.0664 same:0.0183)
		( and:0.0723 are:0.0757 the:0.0405 way:0.0146,:0.2002 of:0.1377 the:0.0645 same:0.0192)
		( and:0.0728 are:0.0713 the:0.0381 way:0.0155,:0.2051 of:0.1348 the:0.0630 same:0.0197)
		( and:0.0732 are:0.0669 the:0.0359 way:0.0155,:0.2109,:0.1309 the:0.0613 same:0.0200)
		( and:0.0732 are:0.0640 not:0.0347 way:0.0161,:0.2168,:0.1367 the:0.0601 same:0.0205)
		( and:0.0757 are:0.0615 not:0.0359 way:0.0161,:0.2227,:0.1416 the:0.0583 same:0.0210)
		( and:0.0757 are:0.0583 not:0.0369 way:0.0162,:0.2285,:0.1475 the:0.0569 same:0.0216)
 same, the same of the same of the same of
500: sample 0: Hello, I'm a language model,
------
		(Hello:0.4453,:0.7812 I:0.9961'm:1.0000 a:0.9688 language:0.8672 model:0.9336,:0.9922)
		(-:0.0544 and:0.0540�:0.0806 the:0.0601 �:0.0131.:0.1387 of:0.1118 the:0.0679)
		(-:0.0571 and:0.0569�:0.0776 the:0.0581 �:0.0114.:0.1436.:0.1133 the:0.0664)
		(-:0.0586 and:0.0593�:0.0728 the:0.0576 few:0.0104.:0.1484.:0.1157 the:0.0664)
		(-:0.0596 and:0.0620�:0.0674 the:0.0552 way:0.0101.:0.1533.:0.1177 the:0.0659)
		(-:0.0601 and:0.0625�:0.0608 the:0.0542 way:0.0103.:0.1582.:0.1196 the:0.0674)
		(-:0.0613 and:0.0649�:0.0552 the:0.0535 way:0.0106.:0.1631.:0.1221 the:0.0674)
		(-:0.0603 and:0.0669�:0.0496 the:0.0525 way:0.0106.:0.1680.:0.1240 the:0.0669)
		(-:0.0603 and:0.0669�:0.0437 the:0.0513 time:0.0107.:0.1689.:0.1260 the:0.0679)
		(-:0.0598 and:0.0684�:0.0396 the:0.0518 time:0.0109.:0.1699.:0.1250 the:0.0674)
		(-:0.0586 and:0.0684�:0.0354 the:0.0505 time:0.0110.:0.1748.:0.1270 the:0.0669)
		(-:0.0579 and:0.0698�:0.0325 the:0.0505 time:0.0112.:0.1758.:0.1260 the:0.0679)
		(-:0.0571 and:0.0698.:0.0298 the:0.0493 time:0.0113.:0.1768.:0.1279 the:0.0674)
 the
------
		(,:0.7812 I:0.9961'm:1.0000 a:0.9688 language:0.8672 model:0.9336,:0.9922 the:0.9766)
		( and:0.0540�:0.0806 the:0.0601 �:0.0131.:0.1387 of:0.1118 the:0.0679 same:0.0153)
		( and:0.0569�:0.0776 the:0.0581 �:0.0114.:0.1436.:0.1133 the:0.0664 same:0.0154)
		( and:0.0593�:0.0728 the:0.0576 few:0.0104.:0.1484.:0.1157 the:0.0664 same:0.0155)
		( and:0.0620�:0.0674 the:0.0552 way:0.0101.:0.1533.:0.1177 the:0.0659 same:0.0157)
		( and:0.0625�:0.0608 the:0.0542 way:0.0103.:0.1582.:0.1196 the:0.0674 same:0.0159)
		( and:0.0649�:0.0552 the:0.0535 way:0.0106.:0.1631.:0.1221 the:0.0674 same:0.0157)
		( and:0.0669�:0.0496 the:0.0525 way:0.0106.:0.1680.:0.1240 the:0.0669 same:0.0157)
		( and:0.0669�:0.0437 the:0.0513 time:0.0107.:0.1689.:0.1260 the:0.0679 same:0.0157)
		( and:0.0684�:0.0396 the:0.0518 time:0.0109.:0.1699.:0.1250 the:0.0674 same:0.0159)
		( and:0.0684�:0.0354 the:0.0505 time:0.0110.:0.1748.:0.1270 the:0.0669 same:0.0159)
		( and:0.0698�:0.0325 the:0.0505 time:0.0112.:0.1758.:0.1260 the:0.0679 same:0.0157)
		( and:0.0698.:0.0298 the:0.0493 time:0.0113.:0.1768.:0.1279 the:0.0674 same:0.0159)
 same time.
-
-
-
-
650: sample 0: Hello, I'm a language model,
------
		(Hello:0.4746,:0.8047 I:1.0000'm:1.0000 a:0.9727 language:0.9062 model:0.9609,:0.9961)
		(,:0.0356
:0.0415�:0.0908 a:0.0569 good:0.0142,:0.0928,:0.0874 and:0.0854)
		(,:0.0347
:0.0422�:0.0742 a:0.0564 good:0.0142,:0.0923.:0.0874 and:0.0879)
		(,:0.0337
:0.0427�:0.0623 a:0.0564 good:0.0140,:0.0898.:0.0898 and:0.0894)
		(.:0.0334
:0.0430
:0.0562 a:0.0557 good:0.0139.:0.0903.:0.0903 and:0.0903)
		(.:0.0332 and:0.0444
:0.0537 a:0.0554 good:0.0137.:0.0908.:0.0918 and:0.0908)
		(.:0.0330 and:0.0459
:0.0518 a:0.0547 good:0.0134.:0.0913.:0.0918 and:0.0913)
		(.:0.0325 and:0.0474
:0.0503 a:0.0547 good:0.0132.:0.0923.:0.0923 and:0.0913)
		(.:0.0322 and:0.0488
:0.0483 a:0.0542 good:0.0131.:0.0918.:0.0918 and:0.0928)
		( and:0.0325 and:0.0498
:0.0471 a:0.0535 good:0.0129.:0.0918.:0.0923 and:0.0923)
		( and:0.0327 and:0.0508
:0.0459 a:0.0532 good:0.0128.:0.0923.:0.0913 and:0.0928)
		( and:0.0332 and:0.0515
:0.0449 a:0.0527 good:0.0125.:0.0918.:0.0908 and:0.0918)
		( and:0.0334 and:0.0522
:0.0437 a:0.0520 good:0.0124.:0.0908.:0.0894 and:0.0918)
 and
------
		(,:0.8047 I:1.0000'm:1.0000 a:0.9727 language:0.9062 model:0.9609,:0.9961 and:0.9961)
		(
:0.0415�:0.0908 a:0.0569 good:0.0142,:0.0928,:0.0874 and:0.0854 the:0.0669)
		(
:0.0422�:0.0742 a:0.0564 good:0.0142,:0.0923.:0.0874 and:0.0879 the:0.0649)
		(
:0.0427�:0.0623 a:0.0564 good:0.0140,:0.0898.:0.0898 and:0.0894 the:0.0645)
		(
:0.0430
:0.0562 a:0.0557 good:0.0139.:0.0903.:0.0903 and:0.0903 the:0.0630)
		( and:0.0444
:0.0537 a:0.0554 good:0.0137.:0.0908.:0.0918 and:0.0908 the:0.0620)
		( and:0.0459
:0.0518 a:0.0547 good:0.0134.:0.0913.:0.0918 and:0.0913 the:0.0618)
		( and:0.0474
:0.0503 a:0.0547 good:0.0132.:0.0923.:0.0923 and:0.0913 the:0.0603)
		( and:0.0488
:0.0483 a:0.0542 good:0.0131.:0.0918.:0.0918 and:0.0928 the:0.0608)
		( and:0.0498
:0.0471 a:0.0535 good:0.0129.:0.0918.:0.0923 and:0.0923 the:0.0610)
		( and:0.0508
:0.0459 a:0.0532 good:0.0128.:0.0923.:0.0913 and:0.0928 the:0.0610)
		( and:0.0515
:0.0449 a:0.0527 good:0.0125.:0.0918.:0.0908 and:0.0918 the:0.0610)
		( and:0.0522
:0.0437 a:0.0520 good:0.0124.:0.0908.:0.0894 and:0.0918 the:0.0615)
 the school, and the school, and the students and
800: sample 0: Hello, I'm a language model,
------
		(Hello:0.4102,:0.8477 I:1.0000'm:1.0000 a:0.9766 language:0.9453 model:0.9844,:0.9961)
		(.:0.0576 and:0.0447 have:0.0786 a:0.0908 good:0.0128.:0.1289.:0.1387 I:0.0640)
		(.:0.0596 and:0.0447 have:0.0776 a:0.0908 good:0.0131.:0.1387.:0.1475 I:0.0713)
		(.:0.0610 and:0.0447 have:0.0771 a:0.0913 good:0.0133.:0.1445.:0.1543 I:0.0767)
		(.:0.0625 and:0.0444 have:0.0767 a:0.0908 good:0.0135.:0.1504.:0.1592 I:0.0820)
		(.:0.0640 and:0.0442 have:0.0762 a:0.0913 good:0.0137.:0.1553.:0.1641 I:0.0859)
		(.:0.0645 and:0.0435 have:0.0757 a:0.0918 good:0.0139.:0.1592.:0.1680 I:0.0889)
		(.:0.0649 and:0.0425 have:0.0757 a:0.0933 good:0.0140.:0.1621.:0.1689 I:0.0903)
		(.:0.0659 and:0.0417 have:0.0762 a:0.0933 good:0.0143.:0.1631.:0.1729 I:0.0913)
		(.:0.0659 and:0.0408 have:0.0762 a:0.0947 good:0.0145.:0.1641.:0.1738 I:0.0918)
		(.:0.0659 and:0.0398 have:0.0767 a:0.0972 good:0.0148.:0.1670.:0.1748 I:0.0913)
		(.:0.0654 and:0.0388 have:0.0781 a:0.0986 good:0.0150.:0.1670.:0.1748 I:0.0903)
		(.:0.0649 and:0.0378 have:0.0791 a:0.1001 good:0.0154.:0.1670.:0.1748 I:0.0894)
 I
------
		(,:0.8477 I:1.0000'm:1.0000 a:0.9766 language:0.9453 model:0.9844,:0.9961 I:1.0000)
		( and:0.0447 have:0.0786 a:0.0908 good:0.0128.:0.1289.:0.1387 I:0.0640 have:0.0649)
		( and:0.0447 have:0.0776 a:0.0908 good:0.0131.:0.1387.:0.1475 I:0.0713 have:0.0640)
		( and:0.0447 have:0.0771 a:0.0913 good:0.0133.:0.1445.:0.1543 I:0.0767 have:0.0640)
		( and:0.0444 have:0.0767 a:0.0908 good:0.0135.:0.1504.:0.1592 I:0.0820 have:0.0640)
		( and:0.0442 have:0.0762 a:0.0913 good:0.0137.:0.1553.:0.1641 I:0.0859 have:0.0635)
		( and:0.0435 have:0.0757 a:0.0918 good:0.0139.:0.1592.:0.1680 I:0.0889 have:0.0640)
		( and:0.0425 have:0.0757 a:0.0933 good:0.0140.:0.1621.:0.1689 I:0.0903 have:0.0649)
		( and:0.0417 have:0.0762 a:0.0933 good:0.0143.:0.1631.:0.1729 I:0.0913 have:0.0659)
		( and:0.0408 have:0.0762 a:0.0947 good:0.0145.:0.1641.:0.1738 I:0.0918 have:0.0669)
		( and:0.0398 have:0.0767 a:0.0972 good:0.0148.:0.1670.:0.1748 I:0.0913 have:0.0679)
		( and:0.0388 have:0.0781 a:0.0986 good:0.0150.:0.1670.:0.1748 I:0.0903 have:0.0688)
		( and:0.0378 have:0.0791 a:0.1001 good:0.0154.:0.1670.:0.1748 I:0.0894 have:0.0708)
 have a new time.
The first time, I
950: sample 0: Hello, I'm a language model,
------
		(Hello:0.3594,:0.8867 I:1.0000'm:1.0000 a:0.9766 language:0.9805 model:0.9844,:0.9961)
		(,:0.0588 and:0.0544 have:0.0737 a:0.0552 great:0.0164,:0.1455,:0.1533 and:0.0728)
		(
:0.0557 and:0.0525 have:0.0718 a:0.0547 great:0.0156,:0.1406,:0.1484 and:0.0718)
		(
:0.0588 and:0.0510 have:0.0698 a:0.0540 great:0.0152,:0.1357,:0.1436 and:0.0708)
		(
:0.0608 the:0.0496 have:0.0684 a:0.0537 great:0.0150,:0.1318,:0.1406 and:0.0698)
		(
:0.0620 the:0.0496 have:0.0679 a:0.0532 great:0.0147,:0.1279,:0.1367 and:0.0688)
		(
:0.0640 the:0.0491 have:0.0669 a:0.0532 great:0.0145,:0.1250,:0.1338 and:0.0688)
		(
:0.0649 the:0.0488 have:0.0664 a:0.0532 great:0.0145,:0.1230,:0.1318 and:0.0684)
		(
:0.0645 the:0.0486 have:0.0659 a:0.0532 great:0.0145,:0.1206,:0.1299 and:0.0684)
		(
:0.0654 the:0.0483 have:0.0659 a:0.0532 great:0.0147,:0.1191,:0.1279 and:0.0679)
		(
:0.0659 the:0.0483 have:0.0659 a:0.0532 new:0.0150,:0.1177,:0.1270 and:0.0679)
		(
:0.0664 the:0.0479 have:0.0659 a:0.0530 new:0.0157,:0.1167,:0.1250 and:0.0679)
		(
:0.0669 the:0.0474 have:0.0664 a:0.0527 new:0.0166,:0.1147,:0.1245 and:0.0679)
 and
------
		(,:0.8867 I:1.0000'm:1.0000 a:0.9766 language:0.9805 model:0.9844,:0.9961 and:0.9922)
		( and:0.0544 have:0.0737 a:0.0552 great:0.0164,:0.1455,:0.1533 and:0.0728 the:0.0776)
		( and:0.0525 have:0.0718 a:0.0547 great:0.0156,:0.1406,:0.1484 and:0.0718 the:0.0752)
		( and:0.0510 have:0.0698 a:0.0540 great:0.0152,:0.1357,:0.1436 and:0.0708 the:0.0732)
		( the:0.0496 have:0.0684 a:0.0537 great:0.0150,:0.1318,:0.1406 and:0.0698 the:0.0718)
		( the:0.0496 have:0.0679 a:0.0532 great:0.0147,:0.1279,:0.1367 and:0.0688 the:0.0708)
		( the:0.0491 have:0.0669 a:0.0532 great:0.0145,:0.1250,:0.1338 and:0.0688 the:0.0703)
		( the:0.0488 have:0.0664 a:0.0532 great:0.0145,:0.1230,:0.1318 and:0.0684 the:0.0698)
		( the:0.0486 have:0.0659 a:0.0532 great:0.0145,:0.1206,:0.1299 and:0.0684 the:0.0698)
		( the:0.0483 have:0.0659 a:0.0532 great:0.0147,:0.1191,:0.1279 and:0.0679 the:0.0698)
		( the:0.0483 have:0.0659 a:0.0532 new:0.0150,:0.1177,:0.1270 and:0.0679 the:0.0698)
		( the:0.0479 have:0.0659 a:0.0530 new:0.0157,:0.1167,:0.1250 and:0.0679 the:0.0703)
		( the:0.0474 have:0.0664 a:0.0527 new:0.0166,:0.1147,:0.1245 and:0.0679 the:0.0698)
 the same time.
The first time, the same
1100: sample 0: Hello, I'm a language model,
------
		(Hello:0.4668,:0.9180 I:1.0000'm:1.0000 a:0.9883 language:0.9922 model:0.9805,:1.0000)
		(,:0.0498 the:0.0732�:0.1030 I:0.0559 good:0.0179,:0.1216,:0.1221 and:0.0693)
		(,:0.0486 the:0.0708�:0.0874 I:0.0737 good:0.0178,:0.1216,:0.1226 and:0.0693)
		(,:0.0471 the:0.0693�:0.0776 I:0.0898 good:0.0178,:0.1211,:0.1230 and:0.0698)
		(,:0.0461 the:0.0664�:0.0713 I:0.1050 good:0.0176,:0.1206,:0.1240 I:0.0698)
		(,:0.0449 the:0.0649�:0.0669 I:0.1191 good:0.0175,:0.1201,:0.1235 I:0.0781)
		(,:0.0447 the:0.0645�:0.0640 I:0.1299 good:0.0171,:0.1196,:0.1235 I:0.0854)
		(,:0.0437 the:0.0630�:0.0625 I:0.1367 good:0.0171,:0.1191,:0.1230 I:0.0918)
		(,:0.0430 the:0.0613�:0.0608 I:0.1426 good:0.0170,:0.1187,:0.1235 I:0.0972)
		(,:0.0420 the:0.0603�:0.0596 I:0.1455 good:0.0168,:0.1187,:0.1230 I:0.1006)
		(,:0.0420 the:0.0591�:0.0591 I:0.1475 good:0.0167 of:0.1201,:0.1230 I:0.1035)
		(,:0.0415 the:0.0576�:0.0586 I:0.1465 good:0.0167 of:0.1216,:0.1240 I:0.1050)
		(,:0.0408 the:0.0569�:0.0581 I:0.1455 good:0.0165 of:0.1245,:0.1230 I:0.1064)
 I
------
		(,:0.9180 I:1.0000'm:1.0000 a:0.9883 language:0.9922 model:0.9805,:1.0000 I:1.0000)
		( the:0.0732�:0.1030 I:0.0559 good:0.0179,:0.1216,:0.1221 and:0.0693 am:0.0471)
		( the:0.0708�:0.0874 I:0.0737 good:0.0178,:0.1216,:0.1226 and:0.0693 am:0.0500)
		( the:0.0693�:0.0776 I:0.0898 good:0.0178,:0.1211,:0.1230 and:0.0698 am:0.0522)
		( the:0.0664�:0.0713 I:0.1050 good:0.0176,:0.1206,:0.1240 I:0.0698 am:0.0542)
		( the:0.0649�:0.0669 I:0.1191 good:0.0175,:0.1201,:0.1235 I:0.0781 am:0.0552)
		( the:0.0645�:0.0640 I:0.1299 good:0.0171,:0.1196,:0.1235 I:0.0854 am:0.0562)
		( the:0.0630�:0.0625 I:0.1367 good:0.0171,:0.1191,:0.1230 I:0.0918 am:0.0569)
		( the:0.0613�:0.0608 I:0.1426 good:0.0170,:0.1187,:0.1235 I:0.0972 am:0.0574)
		( the:0.0603�:0.0596 I:0.1455 good:0.0168,:0.1187,:0.1230 I:0.1006 am:0.0579)
		( the:0.0591�:0.0591 I:0.1475 good:0.0167 of:0.1201,:0.1230 I:0.1035 am:0.0579)
		( the:0.0576�:0.0586 I:0.1465 good:0.0167 of:0.1216,:0.1240 I:0.1050 am:0.0576)
		( the:0.0569�:0.0581 I:0.1455 good:0.0165 of:0.1245,:0.1230 I:0.1064 have:0.0583)
 have a lot of the word. I am a lot
1250: sample 0: Hello, I'm a language model,
------
		(Hello:0.5898,:0.9375 I:1.0000'm:1.0000 a:0.9883 language:0.9961 model:0.9883,:1.0000)
		(.:0.0522 the:0.0781�:0.0835 not:0.0508 new:0.0225 of:0.1514,:0.1445 and:0.1113)
		(.:0.0515 the:0.0757�:0.0757 I:0.0603 new:0.0229 of:0.1484,:0.1455 and:0.1104)
		(.:0.0525 the:0.0757�:0.0718 I:0.0723 new:0.0234 of:0.1445,:0.1455 and:0.1089)
		(.:0.0527 the:0.0737�:0.0698 I:0.0820 new:0.0239 of:0.1426,:0.1465 and:0.1094)
		(.:0.0520 the:0.0732�:0.0693 I:0.0879 new:0.0242 of:0.1406,:0.1465 and:0.1074)
		(.:0.0535 the:0.0723�:0.0679 I:0.0898 new:0.0239 of:0.1387,:0.1475 and:0.1079)
		(.:0.0542 the:0.0723�:0.0698 I:0.0903 new:0.0242 of:0.1367,:0.1475 and:0.1074)
		(.:0.0542 the:0.0723�:0.0698 I:0.0889 new:0.0247 of:0.1357,:0.1465 and:0.1084)
		(.:0.0542 the:0.0718�:0.0718 I:0.0859 new:0.0250 of:0.1348.:0.1484 and:0.1099)
		(.:0.0552 the:0.0708�:0.0728 I:0.0825 new:0.0253 of:0.1348.:0.1504 and:0.1084)
		(.:0.0562 the:0.0698�:0.0732 I:0.0776 new:0.0253 of:0.1328.:0.1543 and:0.1108)
		(.:0.0566 the:0.0703�:0.0757 I:0.0728 new:0.0253 of:0.1328.:0.1572 and:0.1128)
 and
------
		(,:0.9375 I:1.0000'm:1.0000 a:0.9883 language:0.9961 model:0.9883,:1.0000 and:1.0000)
		( the:0.0781�:0.0835 not:0.0508 new:0.0225 of:0.1514,:0.1445 and:0.1113 the:0.1021)
		( the:0.0757�:0.0757 I:0.0603 new:0.0229 of:0.1484,:0.1455 and:0.1104 the:0.0981)
		( the:0.0757�:0.0718 I:0.0723 new:0.0234 of:0.1445,:0.1455 and:0.1089 the:0.0967)
		( the:0.0737�:0.0698 I:0.0820 new:0.0239 of:0.1426,:0.1465 and:0.1094 the:0.0942)
		( the:0.0732�:0.0693 I:0.0879 new:0.0242 of:0.1406,:0.1465 and:0.1074 the:0.0928)
		( the:0.0723�:0.0679 I:0.0898 new:0.0239 of:0.1387,:0.1475 and:0.1079 the:0.0942)
		( the:0.0723�:0.0698 I:0.0903 new:0.0242 of:0.1367,:0.1475 and:0.1074 the:0.0928)
		( the:0.0723�:0.0698 I:0.0889 new:0.0247 of:0.1357,:0.1465 and:0.1084 the:0.0938)
		( the:0.0718�:0.0718 I:0.0859 new:0.0250 of:0.1348.:0.1484 and:0.1099 the:0.0942)
		( the:0.0708�:0.0728 I:0.0825 new:0.0253 of:0.1348.:0.1504 and:0.1084 the:0.0947)
		( the:0.0698�:0.0732 I:0.0776 new:0.0253 of:0.1328.:0.1543 and:0.1108 the:0.0972)
		( the:0.0703�:0.0757 I:0.0728 new:0.0253 of:0.1328.:0.1572 and:0.1128 the:0.0996)
 the word.
The word is the word of the
1400: sample 0: Hello, I'm a language model,
------
		(Hello:0.6328,:0.9531 I:1.0000'm:1.0000 a:0.9922 language:1.0000 model:0.9922,:1.0000)
		(.:0.0422 the:0.0732�:0.1553 not:0.0466 good:0.0250,:0.1147,:0.1396 I:0.0781)
		(.:0.0408 the:0.0713�:0.1299 not:0.0476 good:0.0254,:0.1143,:0.1406 I:0.0918)
		(,:0.0391 the:0.0679�:0.1123 not:0.0474 good:0.0248,:0.1152,:0.1426 I:0.1045)
		(,:0.0376 the:0.0674�:0.1011 not:0.0466 good:0.0239,:0.1162,:0.1406 I:0.1108)
		(,:0.0374 the:0.0669�:0.0947 not:0.0471 good:0.0236,:0.1143,:0.1396 I:0.1147)
		(,:0.0359 the:0.0640�:0.0874 not:0.0466 good:0.0233,:0.1147,:0.1416 I:0.1167)
		(,:0.0364 the:0.0640�:0.0815 not:0.0454 good:0.0233,:0.1147,:0.1416 I:0.1138)
		(,:0.0352 the:0.0620�:0.0771 not:0.0452 new:0.0223,:0.1128,:0.1396 I:0.1133)
		(,:0.0347 the:0.0613 have:0.0737 not:0.0444 new:0.0226,:0.1138,:0.1377 I:0.1094)
		(,:0.0352 the:0.0618 have:0.0723 a:0.0435 new:0.0233,:0.1147,:0.1396 I:0.1050)
		(,:0.0344 the:0.0605 have:0.0723 a:0.0447 new:0.0242,:0.1143,:0.1396 I:0.1025)
		(,:0.0344 the:0.0608 have:0.0718 a:0.0444 new:0.0240,:0.1147,:0.1406 I:0.1001)
 I
------
		(,:0.9531 I:1.0000'm:1.0000 a:0.9922 language:1.0000 model:0.9922,:1.0000 I:1.0000)
		( the:0.0732�:0.1553 not:0.0466 good:0.0250,:0.1147,:0.1396 I:0.0781 have:0.0713)
		( the:0.0713�:0.1299 not:0.0476 good:0.0254,:0.1143,:0.1406 I:0.0918 have:0.0723)
		( the:0.0679�:0.1123 not:0.0474 good:0.0248,:0.1152,:0.1426 I:0.1045 have:0.0718)
		( the:0.0674�:0.1011 not:0.0466 good:0.0239,:0.1162,:0.1406 I:0.1108 have:0.0723)
		( the:0.0669�:0.0947 not:0.0471 good:0.0236,:0.1143,:0.1396 I:0.1147 have:0.0713)
		( the:0.0640�:0.0874 not:0.0466 good:0.0233,:0.1147,:0.1416 I:0.1167 have:0.0732)
		( the:0.0640�:0.0815 not:0.0454 good:0.0233,:0.1147,:0.1416 I:0.1138 have:0.0728)
		( the:0.0620�:0.0771 not:0.0452 new:0.0223,:0.1128,:0.1396 I:0.1133 have:0.0752)
		( the:0.0613 have:0.0737 not:0.0444 new:0.0226,:0.1138,:0.1377 I:0.1094 have:0.0762)
		( the:0.0618 have:0.0723 a:0.0435 new:0.0233,:0.1147,:0.1396 I:0.1050 have:0.0762)
		( the:0.0605 have:0.0723 a:0.0447 new:0.0242,:0.1143,:0.1396 I:0.1025 have:0.0781)
		( the:0.0608 have:0.0718 a:0.0444 new:0.0240,:0.1147,:0.1406 I:0.1001 have:0.0791)
 have a new language, but I have a new language
1550: sample 0: Hello, I'm a language model,
------
		(Hello:0.5820,:0.9531 I:1.0000'm:1.0000 a:0.9922 language:1.0000 model:0.9961,:1.0000)
		(.:0.0840 I:0.0942 have:0.0879 I:0.0625 new:0.0244 of:0.1079 of:0.1631 I:0.1836)
		(.:0.0728 I:0.0889 have:0.0840 I:0.0825 new:0.0256 of:0.1084 of:0.1631 I:0.2188)
		(.:0.0645 I:0.0830 have:0.0815 I:0.1006 new:0.0273 of:0.1089 of:0.1592 I:0.2520)
		(.:0.0601 I:0.0815 have:0.0796 I:0.1152 new:0.0277 of:0.1084 of:0.1553 I:0.2793)
		(.:0.0537 I:0.0776 have:0.0806 I:0.1206 new:0.0287 of:0.1094 of:0.1562 I:0.2969)
		(.:0.0498 the:0.0752 have:0.0801 I:0.1245 new:0.0291 of:0.1113 of:0.1553 I:0.3086)
		(.:0.0476 the:0.0737 have:0.0806 I:0.1235 new:0.0289 of:0.1123 of:0.1562 I:0.3105)
		(.:0.0454 the:0.0737 have:0.0791 I:0.1182 new:0.0283 of:0.1143 of:0.1562 I:0.3047)
		(.:0.0427 the:0.0737 have:0.0791 I:0.1128 new:0.0294 of:0.1138 of:0.1562 I:0.3047)
		(.:0.0425 the:0.0732 have:0.0806 I:0.1060 new:0.0294 of:0.1187 of:0.1582 I:0.3027)
		(.:0.0396 the:0.0723 have:0.0820 I:0.0996 new:0.0293 of:0.1167 of:0.1611 I:0.2930)
		(.:0.0388 the:0.0708 have:0.0825 I:0.0933 good:0.0306 of:0.1206 of:0.1621 I:0.2891)
 I
------
		(,:0.9531 I:1.0000'm:1.0000 a:0.9922 language:1.0000 model:0.9961,:1.0000 I:1.0000)
		( I:0.0942 have:0.0879 I:0.0625 new:0.0244 of:0.1079 of:0.1631 I:0.1836 think:0.0845)
		( I:0.0889 have:0.0840 I:0.0825 new:0.0256 of:0.1084 of:0.1631 I:0.2188 think:0.0840)
		( I:0.0830 have:0.0815 I:0.1006 new:0.0273 of:0.1089 of:0.1592 I:0.2520 think:0.0850)
		( I:0.0815 have:0.0796 I:0.1152 new:0.0277 of:0.1084 of:0.1553 I:0.2793 think:0.0850)
		( I:0.0776 have:0.0806 I:0.1206 new:0.0287 of:0.1094 of:0.1562 I:0.2969 think:0.0840)
		( the:0.0752 have:0.0801 I:0.1245 new:0.0291 of:0.1113 of:0.1553 I:0.3086 think:0.0830)
		( the:0.0737 have:0.0806 I:0.1235 new:0.0289 of:0.1123 of:0.1562 I:0.3105 think:0.0845)
		( the:0.0737 have:0.0791 I:0.1182 new:0.0283 of:0.1143 of:0.1562 I:0.3047 think:0.0859)
		( the:0.0737 have:0.0791 I:0.1128 new:0.0294 of:0.1138 of:0.1562 I:0.3047 think:0.0854)
		( the:0.0732 have:0.0806 I:0.1060 new:0.0294 of:0.1187 of:0.1582 I:0.3027 think:0.0874)
		( the:0.0723 have:0.0820 I:0.0996 new:0.0293 of:0.1167 of:0.1611 I:0.2930 think:0.0874)
		( the:0.0708 have:0.0825 I:0.0933 good:0.0306 of:0.1206 of:0.1621 I:0.2891 think:0.0884)
 think I have a new book to I have a new
1700: sample 0: Hello, I'm a language model,
------
		(Hello:0.6875,:0.9531 I:1.0000'm:1.0000 a:0.9922 language:1.0000 model:0.9961,:1.0000)
		(,:0.0540 the:0.0859 am:0.1318 going:0.0459 good:0.0298,:0.0938,:0.1133 and:0.1069)
		(,:0.0461 the:0.0894 am:0.1299 not:0.0454 new:0.0286,:0.0908,:0.1094 and:0.1079)
		(,:0.0396 the:0.0908 am:0.1279 not:0.0491 new:0.0297,:0.0938,:0.1128 but:0.1079)
		(,:0.0352 the:0.0933 am:0.1216 not:0.0486 new:0.0286,:0.0889,:0.1069 and:0.1045)
		(,:0.0334 the:0.0991 am:0.1147 not:0.0493 new:0.0298,:0.0918,:0.1055 and:0.1040)
		(,:0.0311 the:0.0972 am:0.1118 not:0.0522 new:0.0302,:0.0889,:0.1079 and:0.1030)
		(,:0.0302 the:0.1001 am:0.1055 not:0.0510 new:0.0299,:0.0898,:0.1035 and:0.1069)
		(
:0.0305 the:0.1021 am:0.1050 not:0.0530 new:0.0294,:0.0908,:0.1045 and:0.1030)
		(
:0.0309 the:0.1025 am:0.1021 not:0.0513 new:0.0303,:0.0903,:0.1050 and:0.1045)
		(
:0.0311 the:0.1094 am:0.0986 not:0.0520 new:0.0293,:0.0898,:0.1040 and:0.1055)
		(
:0.0311 the:0.1094 am:0.0942 not:0.0522 new:0.0297,:0.0898,:0.1040 and:0.1060)
		(
:0.0309 the:0.1099 am:0.0898 not:0.0530 new:0.0302,:0.0889 of:0.1104 and:0.1064)
 and
------
		(,:0.9531 I:1.0000'm:1.0000 a:0.9922 language:1.0000 model:0.9961,:1.0000 and:1.0000)
		( the:0.0859 am:0.1318 going:0.0459 good:0.0298,:0.0938,:0.1133 and:0.1069 I:0.0928)
		( the:0.0894 am:0.1299 not:0.0454 new:0.0286,:0.0908,:0.1094 and:0.1079 I:0.1074)
		( the:0.0908 am:0.1279 not:0.0491 new:0.0297,:0.0938,:0.1128 but:0.1079 I:0.1211)
		( the:0.0933 am:0.1216 not:0.0486 new:0.0286,:0.0889,:0.1069 and:0.1045 I:0.1235)
		( the:0.0991 am:0.1147 not:0.0493 new:0.0298,:0.0918,:0.1055 and:0.1040 I:0.1167)
		( the:0.0972 am:0.1118 not:0.0522 new:0.0302,:0.0889,:0.1079 and:0.1030 I:0.1084)
		( the:0.1001 am:0.1055 not:0.0510 new:0.0299,:0.0898,:0.1035 and:0.1069 I:0.0996)
		( the:0.1021 am:0.1050 not:0.0530 new:0.0294,:0.0908,:0.1045 and:0.1030 the:0.0962)
		( the:0.1025 am:0.1021 not:0.0513 new:0.0303,:0.0903,:0.1050 and:0.1045 the:0.1045)
		( the:0.1094 am:0.0986 not:0.0520 new:0.0293,:0.0898,:0.1040 and:0.1055 the:0.1064)
		( the:0.1094 am:0.0942 not:0.0522 new:0.0297,:0.0898,:0.1040 and:0.1060 the:0.1133)
		( the:0.1099 am:0.0898 not:0.0530 new:0.0302,:0.0889 of:0.1104 and:0.1064 the:0.1147)
 the first-of-the-most of the first
1850: sample 0: Hello, I'm a language model,
------
		(Hello:0.5820,:0.9609 I:1.0000'm:1.0000 a:0.9883 language:1.0000 model:0.9961,:1.0000)
		(,:0.0427 the:0.0835�:0.1348 a:0.0447 good:0.0311,:0.0991,:0.1216 and:0.1196)
		(,:0.0391 the:0.0771�:0.1147 a:0.0430 good:0.0320,:0.0996,:0.1245 and:0.1187)
		(,:0.0374 the:0.0776�:0.0986 I:0.0486 good:0.0303,:0.1016,:0.1201 and:0.1152)
		(,:0.0369 the:0.0786�:0.0928 I:0.0520 good:0.0300,:0.0996,:0.1191 and:0.1147)
		(,:0.0369 the:0.0771�:0.0938 I:0.0515 good:0.0304,:0.1025,:0.1235 and:0.1133)
		(,:0.0359 the:0.0742�:0.0923 I:0.0474 good:0.0300,:0.1035,:0.1240 and:0.1162)
		(,:0.0342 the:0.0752�:0.0894 I:0.0452 good:0.0310,:0.1094,:0.1260 and:0.1187)
		(,:0.0342 the:0.0752�:0.0903 a:0.0405 good:0.0315,:0.1099,:0.1270 and:0.1201)
		(,:0.0339 the:0.0747�:0.0898 a:0.0408 good:0.0315,:0.1143,:0.1338 and:0.1196)
		(,:0.0337 the:0.0737�:0.0889 a:0.0405 good:0.0334,:0.1133,:0.1338 and:0.1201)
		(,:0.0352 the:0.0728�:0.0874 a:0.0405 good:0.0332,:0.1187,:0.1377 and:0.1201)
		(,:0.0344 the:0.0757�:0.0854 a:0.0398 good:0.0349,:0.1226,:0.1357 and:0.1260)
 and
------
		(,:0.9609 I:1.0000'm:1.0000 a:0.9883 language:1.0000 model:0.9961,:1.0000 and:1.0000)
		( the:0.0835�:0.1348 a:0.0447 good:0.0311,:0.0991,:0.1216 and:0.1196 the:0.0977)
		( the:0.0771�:0.1147 a:0.0430 good:0.0320,:0.0996,:0.1245 and:0.1187 the:0.0898)
		( the:0.0776�:0.0986 I:0.0486 good:0.0303,:0.1016,:0.1201 and:0.1152 I:0.0962)
		( the:0.0786�:0.0928 I:0.0520 good:0.0300,:0.0996,:0.1191 and:0.1147 I:0.1016)
		( the:0.0771�:0.0938 I:0.0515 good:0.0304,:0.1025,:0.1235 and:0.1133 I:0.1035)
		( the:0.0742�:0.0923 I:0.0474 good:0.0300,:0.1035,:0.1240 and:0.1162 I:0.1050)
		( the:0.0752�:0.0894 I:0.0452 good:0.0310,:0.1094,:0.1260 and:0.1187 I:0.0991)
		( the:0.0752�:0.0903 a:0.0405 good:0.0315,:0.1099,:0.1270 and:0.1201 I:0.0933)
		( the:0.0747�:0.0898 a:0.0408 good:0.0315,:0.1143,:0.1338 and:0.1196 I:0.0923)
		( the:0.0737�:0.0889 a:0.0405 good:0.0334,:0.1133,:0.1338 and:0.1201 the:0.0903)
		( the:0.0728�:0.0874 a:0.0405 good:0.0332,:0.1187,:0.1377 and:0.1201 the:0.0889)
		( the:0.0757�:0.0854 a:0.0398 good:0.0349,:0.1226,:0.1357 and:0.1260 the:0.0918)
 the word is a word that is a word that is
2000: sample 0: Hello, I'm a language model,
------
		(Hello:0.7148,:0.9531 I:1.0000'm:1.0000 a:0.9883 language:1.0000 model:1.0000,:1.0000)
		(,:0.0615 the:0.0674 have:0.1211 going:0.0420 lot:0.0178 that:0.0796 of:0.1182 and:0.1260)
		(,:0.0522 the:0.0674 have:0.1172 going:0.0437 lot:0.0179 that:0.0806 of:0.1245 and:0.1260)
		(.:0.0515 the:0.0684 have:0.1123 I:0.0417 lot:0.0186 that:0.0820 of:0.1250 and:0.1177)
		(.:0.0510 the:0.0698 have:0.1079 I:0.0410 lot:0.0187 that:0.0811 of:0.1226 and:0.1211)
		(.:0.0540 the:0.0688 have:0.1079 going:0.0413 lot:0.0181 that:0.0830 of:0.1270 and:0.1201)
		(.:0.0525 the:0.0703 have:0.1104 a:0.0381 lot:0.0181 that:0.0840 of:0.1289 and:0.1191)
		(.:0.0564 the:0.0713 have:0.1040 a:0.0393 lot:0.0177 that:0.0850 of:0.1270 and:0.1221)
		(.:0.0564 the:0.0757 have:0.1089 a:0.0403 lot:0.0172 that:0.0903 of:0.1279 and:0.1172)
		(.:0.0559 the:0.0752 have:0.1055 a:0.0403 lot:0.0165 that:0.0889 of:0.1260 and:0.1172)
		(.:0.0591 the:0.0791 have:0.1069 a:0.0430 lot:0.0157 that:0.0942 of:0.1260 and:0.1177)
		(.:0.0615 the:0.0781 have:0.1074 a:0.0427 lot:0.0159 that:0.0977 of:0.1309 and:0.1172)
		(.:0.0645 the:0.0811 have:0.1069 a:0.0447 lot:0.0150 that:0.1011 of:0.1309 and:0.1162)
 and
------
		(,:0.9531 I:1.0000'm:1.0000 a:0.9883 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0674 have:0.1211 going:0.0420 lot:0.0178 that:0.0796 of:0.1182 and:0.1260 I:0.0972)
		( the:0.0674 have:0.1172 going:0.0437 lot:0.0179 that:0.0806 of:0.1245 and:0.1260 I:0.1245)
		( the:0.0684 have:0.1123 I:0.0417 lot:0.0186 that:0.0820 of:0.1250 and:0.1177 I:0.1387)
		( the:0.0698 have:0.1079 I:0.0410 lot:0.0187 that:0.0811 of:0.1226 and:0.1211 I:0.1396)
		( the:0.0688 have:0.1079 going:0.0413 lot:0.0181 that:0.0830 of:0.1270 and:0.1201 I:0.1318)
		( the:0.0703 have:0.1104 a:0.0381 lot:0.0181 that:0.0840 of:0.1289 and:0.1191 I:0.1211)
		( the:0.0713 have:0.1040 a:0.0393 lot:0.0177 that:0.0850 of:0.1270 and:0.1221 I:0.1157)
		( the:0.0757 have:0.1089 a:0.0403 lot:0.0172 that:0.0903 of:0.1279 and:0.1172 I:0.1162)
		( the:0.0752 have:0.1055 a:0.0403 lot:0.0165 that:0.0889 of:0.1260 and:0.1172 I:0.1099)
		( the:0.0791 have:0.1069 a:0.0430 lot:0.0157 that:0.0942 of:0.1260 and:0.1177 I:0.1084)
		( the:0.0781 have:0.1074 a:0.0427 lot:0.0159 that:0.0977 of:0.1309 and:0.1172 I:0.1011)
		( the:0.0811 have:0.1069 a:0.0447 lot:0.0150 that:0.1011 of:0.1309 and:0.1162 I:0.0991)
 I'm going to be a lot of the number of
2150: sample 0: Hello, I'm a language model,
------
		(Hello:0.1367,:0.9531 I:1.0000'm:1.0000 a:0.9883 language:1.0000 model:0.9961,:1.0000)
		(,:0.0947 I:0.0703 have:0.1099 not:0.0532 good:0.0315,:0.1113,:0.1245 and:0.1064)
		(,:0.0747 the:0.0654 have:0.1035 not:0.0566 good:0.0309,:0.1084,:0.1226 and:0.1074)
		(,:0.0659 the:0.0659 have:0.0962 not:0.0608 good:0.0317,:0.1123,:0.1270 and:0.1050)
		(,:0.0615 the:0.0669 have:0.0967 not:0.0596 good:0.0325,:0.1123,:0.1279 and:0.1074)
		(,:0.0615 the:0.0659 have:0.0933 not:0.0630 good:0.0322,:0.1099,:0.1260 and:0.1060)
		(,:0.0564 the:0.0669 have:0.0923 not:0.0664 good:0.0312,:0.1123,:0.1289 and:0.1050)
		(,:0.0571 the:0.0679 have:0.0952 not:0.0679 good:0.0315,:0.1138,:0.1309 and:0.1074)
		(,:0.0566 the:0.0679 have:0.0962 not:0.0693 good:0.0317,:0.1133,:0.1318 and:0.1084)
		(,:0.0562 the:0.0718 have:0.0972 not:0.0698 good:0.0315,:0.1196,:0.1318 and:0.1094)
		(,:0.0554 the:0.0703 have:0.0967 not:0.0737 good:0.0332,:0.1191,:0.1318 and:0.1104)
		(,:0.0542 the:0.0737 have:0.0962 not:0.0732 good:0.0327,:0.1240,:0.1318 and:0.1094)
		(,:0.0535 the:0.0728 have:0.0947 not:0.0776 good:0.0320,:0.1235,:0.1396 and:0.1084)
 and
------
		(,:0.9531 I:1.0000'm:1.0000 a:0.9883 language:1.0000 model:0.9961,:1.0000 and:1.0000)
		( I:0.0703 have:0.1099 not:0.0532 good:0.0315,:0.1113,:0.1245 and:0.1064 I:0.0811)
		( the:0.0654 have:0.1035 not:0.0566 good:0.0309,:0.1084,:0.1226 and:0.1074 I:0.1021)
		( the:0.0659 have:0.0962 not:0.0608 good:0.0317,:0.1123,:0.1270 and:0.1050 I:0.1177)
		( the:0.0669 have:0.0967 not:0.0596 good:0.0325,:0.1123,:0.1279 and:0.1074 I:0.1245)
		( the:0.0659 have:0.0933 not:0.0630 good:0.0322,:0.1099,:0.1260 and:0.1060 I:0.1216)
		( the:0.0669 have:0.0923 not:0.0664 good:0.0312,:0.1123,:0.1289 and:0.1050 I:0.1177)
		( the:0.0679 have:0.0952 not:0.0679 good:0.0315,:0.1138,:0.1309 and:0.1074 I:0.1113)
		( the:0.0679 have:0.0962 not:0.0693 good:0.0317,:0.1133,:0.1318 and:0.1084 I:0.1113)
		( the:0.0718 have:0.0972 not:0.0698 good:0.0315,:0.1196,:0.1318 and:0.1094 I:0.1050)
		( the:0.0703 have:0.0967 not:0.0737 good:0.0332,:0.1191,:0.1318 and:0.1104 I:0.1035)
		( the:0.0737 have:0.0962 not:0.0732 good:0.0327,:0.1240,:0.1318 and:0.1094 I:0.1011)
		( the:0.0728 have:0.0947 not:0.0776 good:0.0320,:0.1235,:0.1396 and:0.1084 I:0.0996)
 I have a new word. I think it's a
2300: sample 0: Hello, I'm a language model,
------
		(Hello:0.4336,:0.9570 I:1.0000'm:1.0000 a:0.9883 language:1.0000 model:1.0000,:1.0000)
		(,:0.0864 I:0.0947 have:0.0708 not:0.0454 good:0.0354 of:0.0977 of:0.1211 and:0.1245)
		(,:0.0708 I:0.0791 have:0.0659 not:0.0454 good:0.0371 of:0.0981 of:0.1196 and:0.1245)
		(,:0.0605 the:0.0762 think:0.0664 not:0.0457 good:0.0354 of:0.0996 of:0.1157 and:0.1230)
		(,:0.0576 the:0.0737 think:0.0654 not:0.0454 good:0.0359 of:0.0977 of:0.1167 and:0.1211)
		(,:0.0544 the:0.0781 think:0.0664 not:0.0461 good:0.0347 of:0.1011 of:0.1143 and:0.1289)
		(,:0.0498 the:0.0771 think:0.0654 a:0.0457 good:0.0327 of:0.1025 of:0.1108 and:0.1270)
		(,:0.0505 the:0.0786 think:0.0669 a:0.0447 good:0.0339 of:0.1030 of:0.1138 and:0.1299)
		(,:0.0513 the:0.0791 think:0.0723 a:0.0454 good:0.0330 of:0.1025 to:0.1089 and:0.1240)
		(,:0.0508 the:0.0796 think:0.0718 a:0.0486 good:0.0312 of:0.1021 to:0.1094 and:0.1250)
		(,:0.0500 the:0.0835 think:0.0757 a:0.0486 good:0.0315 of:0.1074 to:0.1089 and:0.1250)
		(,:0.0493 the:0.0820 think:0.0796 a:0.0474 good:0.0315 of:0.1064 of:0.1099 and:0.1260)
		(,:0.0483 the:0.0854 think:0.0815 a:0.0493 good:0.0312 of:0.1055.:0.1089 and:0.1250)
 and
------
		(,:0.9570 I:1.0000'm:1.0000 a:0.9883 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.0947 have:0.0708 not:0.0454 good:0.0354 of:0.0977 of:0.1211 and:0.1245 the:0.0640)
		( I:0.0791 have:0.0659 not:0.0454 good:0.0371 of:0.0981 of:0.1196 and:0.1245 I:0.0718)
		( the:0.0762 think:0.0664 not:0.0457 good:0.0354 of:0.0996 of:0.1157 and:0.1230 I:0.0791)
		( the:0.0737 think:0.0654 not:0.0454 good:0.0359 of:0.0977 of:0.1167 and:0.1211 I:0.0757)
		( the:0.0781 think:0.0664 not:0.0461 good:0.0347 of:0.1011 of:0.1143 and:0.1289 I:0.0713)
		( the:0.0771 think:0.0654 a:0.0457 good:0.0327 of:0.1025 of:0.1108 and:0.1270 I:0.0693)
		( the:0.0786 think:0.0669 a:0.0447 good:0.0339 of:0.1030 of:0.1138 and:0.1299 the:0.0664)
		( the:0.0791 think:0.0723 a:0.0454 good:0.0330 of:0.1025 to:0.1089 and:0.1240 the:0.0669)
		( the:0.0796 think:0.0718 a:0.0486 good:0.0312 of:0.1021 to:0.1094 and:0.1250 the:0.0674)
		( the:0.0835 think:0.0757 a:0.0486 good:0.0315 of:0.1074 to:0.1089 and:0.1250 the:0.0669)
		( the:0.0820 think:0.0796 a:0.0474 good:0.0315 of:0.1064 of:0.1099 and:0.1260 the:0.0703)
		( the:0.0854 think:0.0815 a:0.0493 good:0.0312 of:0.1055.:0.1089 and:0.1250 the:0.0693)
 the first-step of the first-step of the
2450: sample 0: Hello, I'm a language model,
------
		(Hello:0.5117,:0.9531 I:1.0000'm:1.0000 a:0.9844 language:1.0000 model:1.0000,:1.0000)
		(,:0.0776 the:0.0840 am:0.0879 not:0.0645 bit:0.0422,:0.0981,:0.1475 and:0.1064)
		(.:0.0649 the:0.0815 am:0.0859 not:0.0649 bit:0.0405,:0.0938,:0.1445 and:0.1050)
		(.:0.0554 the:0.0752 am:0.0835 not:0.0654 bit:0.0386,:0.0947,:0.1348 and:0.1040)
		(
:0.0605 the:0.0820 am:0.0786 not:0.0679 bit:0.0366,:0.0903,:0.1357 and:0.1050)
		(
:0.0620 the:0.0771 am:0.0762 not:0.0693 bit:0.0359,:0.0923,:0.1338 and:0.1069)
		(
:0.0698 the:0.0796 am:0.0762 not:0.0728 bit:0.0339,:0.0898,:0.1309 and:0.1045)
		(
:0.0698 the:0.0811 am:0.0688 not:0.0757 bit:0.0317,:0.0908,:0.1270 and:0.1016)
		(
:0.0762 the:0.0815 am:0.0713 not:0.0732 bit:0.0322,:0.0859.:0.1309 and:0.1055)
		(
:0.0830 the:0.0820 am:0.0674 not:0.0747 bit:0.0293,:0.0864.:0.1338 and:0.1060)
		(
:0.0903 the:0.0815 am:0.0674 not:0.0752 bit:0.0297,:0.0874.:0.1367 and:0.1011)
		(
:0.0874 the:0.0811 am:0.0669 not:0.0796 bit:0.0298,:0.0874.:0.1387 and:0.1016)
		(
:0.0938 the:0.0801 am:0.0674 not:0.0796 bit:0.0298.:0.0874.:0.1416 but:0.1030)
 but
------
		(,:0.9531 I:1.0000'm:1.0000 a:0.9844 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( the:0.0840 am:0.0879 not:0.0645 bit:0.0422,:0.0981,:0.1475 and:0.1064 I:0.3066)
		( the:0.0815 am:0.0859 not:0.0649 bit:0.0405,:0.0938,:0.1445 and:0.1050 I:0.3379)
		( the:0.0752 am:0.0835 not:0.0654 bit:0.0386,:0.0947,:0.1348 and:0.1040 I:0.3398)
		( the:0.0820 am:0.0786 not:0.0679 bit:0.0366,:0.0903,:0.1357 and:0.1050 I:0.3223)
		( the:0.0771 am:0.0762 not:0.0693 bit:0.0359,:0.0923,:0.1338 and:0.1069 I:0.2852)
		( the:0.0796 am:0.0762 not:0.0728 bit:0.0339,:0.0898,:0.1309 and:0.1045 I:0.2715)
		( the:0.0811 am:0.0688 not:0.0757 bit:0.0317,:0.0908,:0.1270 and:0.1016 I:0.2539)
		( the:0.0815 am:0.0713 not:0.0732 bit:0.0322,:0.0859.:0.1309 and:0.1055 I:0.2393)
		( the:0.0820 am:0.0674 not:0.0747 bit:0.0293,:0.0864.:0.1338 and:0.1060 I:0.2314)
		( the:0.0815 am:0.0674 not:0.0752 bit:0.0297,:0.0874.:0.1367 and:0.1011 I:0.2236)
		( the:0.0811 am:0.0669 not:0.0796 bit:0.0298,:0.0874.:0.1387 and:0.1016 I:0.2139)
		( the:0.0801 am:0.0674 not:0.0796 bit:0.0298.:0.0874.:0.1416 but:0.1030 I:0.2158)
 I'd'd be a bit of a lot of information
2600: sample 0: Hello, I'm a language model,
------
		(Hello:0.5508,:0.9609 I:1.0000'm:1.0000 a:0.9688 language:1.0000 model:1.0000,:1.0000)
		(,:0.0874 I:0.0679 have:0.1123 not:0.0544 friend:0.0613 that:0.1523.:0.1191 I:0.1494)
		(,:0.0669 and:0.0598 have:0.0913 I:0.0576 friend:0.0593 that:0.1338.:0.1279 I:0.1758)
		(.:0.0625 and:0.0608 have:0.0869 I:0.0645 friend:0.0610 that:0.1387.:0.1299 I:0.1875)
		(.:0.0591 and:0.0586 have:0.0859 I:0.0623 friend:0.0530 that:0.1279.:0.1377 I:0.1846)
		(.:0.0605 and:0.0605 have:0.0801 I:0.0586 friend:0.0562 that:0.1167.:0.1357 I:0.1650)
		(.:0.0537 and:0.0620 have:0.0747 I:0.0542 friend:0.0515 that:0.1177.:0.1377 I:0.1553)
		(.:0.0527 and:0.0625 have:0.0762 not:0.0554 friend:0.0520 that:0.1172.:0.1426 I:0.1436)
		(.:0.0515 and:0.0630 have:0.0674 not:0.0571 friend:0.0464 that:0.1172.:0.1465 I:0.1299)
		(.:0.0500 and:0.0625 have:0.0674 not:0.0579 friend:0.0464 that:0.1162.:0.1406 I:0.1318)
		(.:0.0483 and:0.0623 have:0.0674 not:0.0581 friend:0.0454 that:0.1152.:0.1406 but:0.1348)
		(.:0.0474 and:0.0688 have:0.0674 not:0.0576 friend:0.0449 that:0.1143.:0.1416 but:0.1357)
		(-:0.0457 and:0.0679 have:0.0669 not:0.0576 friend:0.0442 that:0.1138.:0.1426 but:0.1357)
 but
------
		(,:0.9609 I:1.0000'm:1.0000 a:0.9688 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( I:0.0679 have:0.1123 not:0.0544 friend:0.0613 that:0.1523.:0.1191 I:0.1494 I:0.4023)
		( and:0.0598 have:0.0913 I:0.0576 friend:0.0593 that:0.1338.:0.1279 I:0.1758 I:0.4219)
		( and:0.0608 have:0.0869 I:0.0645 friend:0.0610 that:0.1387.:0.1299 I:0.1875 I:0.4375)
		( and:0.0586 have:0.0859 I:0.0623 friend:0.0530 that:0.1279.:0.1377 I:0.1846 I:0.4199)
		( and:0.0605 have:0.0801 I:0.0586 friend:0.0562 that:0.1167.:0.1357 I:0.1650 I:0.3965)
		( and:0.0620 have:0.0747 I:0.0542 friend:0.0515 that:0.1177.:0.1377 I:0.1553 I:0.3691)
		( and:0.0625 have:0.0762 not:0.0554 friend:0.0520 that:0.1172.:0.1426 I:0.1436 I:0.3516)
		( and:0.0630 have:0.0674 not:0.0571 friend:0.0464 that:0.1172.:0.1465 I:0.1299 I:0.3281)
		( and:0.0625 have:0.0674 not:0.0579 friend:0.0464 that:0.1162.:0.1406 I:0.1318 I:0.3242)
		( and:0.0623 have:0.0674 not:0.0581 friend:0.0454 that:0.1152.:0.1406 but:0.1348 I:0.3027)
		( and:0.0688 have:0.0674 not:0.0576 friend:0.0449 that:0.1143.:0.1416 but:0.1357 I:0.3066)
		( and:0.0679 have:0.0669 not:0.0576 friend:0.0442 that:0.1138.:0.1426 but:0.1357 I:0.2969)
 I'm not sure I'm not sure I'm not
2750: sample 0: Hello, I'm a language model,
------
		(Hello:0.6328,:0.9492 I:1.0000'm:1.0000 a:0.9883 language:1.0000 model:1.0000,:1.0000)
		(.:0.0801 the:0.0732�:0.1152 not:0.0791 great:0.0601 that:0.1016 for:0.1318 but:0.1445)
		(.:0.0757 the:0.0737�:0.0952 not:0.0811 great:0.0635 that:0.0972.:0.1289 but:0.1475)
		(.:0.0698 the:0.0732 have:0.0859 not:0.0864 great:0.0623 that:0.0996.:0.1235 but:0.1445)
		(.:0.0659 the:0.0796 have:0.0835 not:0.0820 great:0.0664 that:0.1025.:0.1270 but:0.1377)
		(.:0.0659 the:0.0742 have:0.0864 not:0.0850 great:0.0613 that:0.1025.:0.1309 but:0.1455)
		(.:0.0591 the:0.0762 have:0.0972 not:0.0869 great:0.0623 that:0.0918.:0.1216 but:0.1494)
		(.:0.0576 the:0.0767 have:0.0972 not:0.0879 great:0.0625 that:0.0923.:0.1230 but:0.1523)
		(.:0.0503 the:0.0771 have:0.0957 not:0.0864 great:0.0618 that:0.0918.:0.1250 but:0.1553)
		(.:0.0491 the:0.0762 have:0.1045 not:0.0864 great:0.0613 that:0.0913.:0.1250 but:0.1406)
		(.:0.0479 the:0.0757 have:0.1035 not:0.0957 great:0.0669 that:0.0913.:0.1260 but:0.1562)
		(.:0.0464 the:0.0752 have:0.1113 not:0.0938 great:0.0659 that:0.0894.:0.1260 but:0.1426)
		(,:0.0393 the:0.0747 have:0.1094 not:0.0923 great:0.0640 that:0.0884.:0.1289 but:0.1582)
 but
------
		(,:0.9492 I:1.0000'm:1.0000 a:0.9883 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( the:0.0732�:0.1152 not:0.0791 great:0.0601 that:0.1016 for:0.1318 but:0.1445 I:0.2236)
		( the:0.0737�:0.0952 not:0.0811 great:0.0635 that:0.0972.:0.1289 but:0.1475 I:0.2402)
		( the:0.0732 have:0.0859 not:0.0864 great:0.0623 that:0.0996.:0.1235 but:0.1445 I:0.2480)
		( the:0.0796 have:0.0835 not:0.0820 great:0.0664 that:0.1025.:0.1270 but:0.1377 I:0.2266)
		( the:0.0742 have:0.0864 not:0.0850 great:0.0613 that:0.1025.:0.1309 but:0.1455 I:0.2188)
		( the:0.0762 have:0.0972 not:0.0869 great:0.0623 that:0.0918.:0.1216 but:0.1494 I:0.2031)
		( the:0.0767 have:0.0972 not:0.0879 great:0.0625 that:0.0923.:0.1230 but:0.1523 I:0.1875)
		( the:0.0771 have:0.0957 not:0.0864 great:0.0618 that:0.0918.:0.1250 but:0.1553 I:0.1719)
		( the:0.0762 have:0.1045 not:0.0864 great:0.0613 that:0.0913.:0.1250 but:0.1406 I:0.1572)
		( the:0.0757 have:0.1035 not:0.0957 great:0.0669 that:0.0913.:0.1260 but:0.1562 I:0.1582)
		( the:0.0752 have:0.1113 not:0.0938 great:0.0659 that:0.0894.:0.1260 but:0.1426 I:0.1426)
		( the:0.0747 have:0.1094 not:0.0923 great:0.0640 that:0.0884.:0.1289 but:0.1582 I:0.1445)
 I have a lot of things. I want to be
2900: sample 0: Hello, I'm a language model,
------
		(Hello:0.6016,:0.9570 I:1.0000'm:1.0000 a:0.9766 language:1.0000 model:1.0000,:1.0000)
		(,:0.1187 I:0.0596 have:0.1025 a:0.0684 great:0.0413,:0.1187,:0.1270 I:0.1221)
		(,:0.0806 I:0.0457 have:0.1055 a:0.0737 great:0.0408,:0.1138,:0.1260 I:0.1289)
		(,:0.0659 the:0.0400 have:0.0957 a:0.0732 great:0.0415,:0.1206,:0.1367 I:0.1318)
		(,:0.0549 the:0.0430 have:0.0913 a:0.0703 great:0.0359,:0.1123,:0.1270 I:0.1250)
		(,:0.0557 the:0.0396 have:0.0962 a:0.0747 great:0.0386,:0.1147,:0.1328 I:0.1196)
		(,:0.0491 the:0.0403 have:0.0986 a:0.0791 great:0.0359,:0.1162,:0.1201 and:0.0986)
		(,:0.0479 the:0.0408 have:0.0898 a:0.0806 great:0.0327,:0.1162,:0.1245 I:0.1025)
		(,:0.0464 the:0.0410 have:0.0908 a:0.0811 great:0.0334,:0.1167,:0.1260 and:0.0923)
		(,:0.0449 the:0.0408 have:0.1001 a:0.0820 great:0.0299,:0.1157,:0.1279 and:0.0938)
		(,:0.0432 the:0.0403 have:0.0991 a:0.0820 great:0.0298,:0.1147,:0.1279 and:0.0942)
		(,:0.0474 the:0.0398 have:0.1001 a:0.0825 great:0.0298,:0.1147,:0.1279 I:0.0952)
		(,:0.0457 the:0.0439 have:0.0991 a:0.0903 great:0.0294,:0.1147,:0.1299 I:0.0947)
 I
------
		(,:0.9570 I:1.0000'm:1.0000 a:0.9766 language:1.0000 model:1.0000,:1.0000 I:1.0000)
		( I:0.0596 have:0.1025 a:0.0684 great:0.0413,:0.1187,:0.1270 I:0.1221'll:0.1040)
		( I:0.0457 have:0.1055 a:0.0737 great:0.0408,:0.1138,:0.1260 I:0.1289 have:0.0918)
		( the:0.0400 have:0.0957 a:0.0732 great:0.0415,:0.1206,:0.1367 I:0.1318 have:0.0898)
		( the:0.0430 have:0.0913 a:0.0703 great:0.0359,:0.1123,:0.1270 I:0.1250 have:0.0908)
		( the:0.0396 have:0.0962 a:0.0747 great:0.0386,:0.1147,:0.1328 I:0.1196 have:0.0874)
		( the:0.0403 have:0.0986 a:0.0791 great:0.0359,:0.1162,:0.1201 and:0.0986 have:0.0830)
		( the:0.0408 have:0.0898 a:0.0806 great:0.0327,:0.1162,:0.1245 I:0.1025 have:0.0869)
		( the:0.0410 have:0.0908 a:0.0811 great:0.0334,:0.1167,:0.1260 and:0.0923 have:0.0894)
		( the:0.0408 have:0.1001 a:0.0820 great:0.0299,:0.1157,:0.1279 and:0.0938 have:0.0908)
		( the:0.0403 have:0.0991 a:0.0820 great:0.0298,:0.1147,:0.1279 and:0.0942 have:0.0913)
		( the:0.0398 have:0.1001 a:0.0825 great:0.0298,:0.1147,:0.1279 I:0.0952 have:0.0815)
		( the:0.0439 have:0.0991 a:0.0903 great:0.0294,:0.1147,:0.1299 I:0.0947 have:0.0820)
 have a very little to be a good, but I
3050: sample 0: Hello, I'm a language model,
------
		(Hello:0.5273,:0.9609 I:1.0000'm:1.0000 a:0.9766 language:1.0000 model:1.0000,:1.0000)
		(,:0.1060 I:0.0903 am:0.1089 a:0.0608 good:0.0225,:0.1279,:0.2061 but:0.1172)
		(,:0.0835 I:0.0718 am:0.1094 I:0.0640 good:0.0222,:0.1328,:0.1992 I:0.1196)
		(,:0.0752 I:0.0579 am:0.1191 I:0.0654 good:0.0205,:0.1377,:0.1924 I:0.1338)
		(,:0.0698 the:0.0496 am:0.1079 I:0.0654 great:0.0204,:0.1426,:0.2012 and:0.1138)
		(,:0.0688 the:0.0464 am:0.1045 I:0.0630 great:0.0195,:0.1455,:0.1885 and:0.1104)
		(,:0.0669 the:0.0486 am:0.0981 a:0.0596 great:0.0181,:0.1318,:0.1953 and:0.1147)
		(,:0.0579 the:0.0491 am:0.1030 a:0.0562 great:0.0168,:0.1328,:0.1992 and:0.1216)
		(,:0.0615 the:0.0444 am:0.0952 a:0.0579 great:0.0171,:0.1338,:0.1836 and:0.1245)
		(,:0.0583 the:0.0447 am:0.0972 a:0.0601 good:0.0153,:0.1338,:0.1846 and:0.1279)
		(,:0.0554 the:0.0444 am:0.0879 a:0.0608 great:0.0156,:0.1494,:0.1855 and:0.1309)
		(,:0.0522 the:0.0444 am:0.0898 a:0.0547 great:0.0156,:0.1494,:0.1875 and:0.1187)
		(,:0.0486 the:0.0442 am:0.0923 a:0.0549 great:0.0155,:0.1484,:0.1924 and:0.1191)
 and
------
		(,:0.9609 I:1.0000'm:1.0000 a:0.9766 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.0903 am:0.1089 a:0.0608 good:0.0225,:0.1279,:0.2061 but:0.1172 I:0.1416)
		( I:0.0718 am:0.1094 I:0.0640 good:0.0222,:0.1328,:0.1992 I:0.1196 I:0.1758)
		( I:0.0579 am:0.1191 I:0.0654 good:0.0205,:0.1377,:0.1924 I:0.1338 I:0.1719)
		( the:0.0496 am:0.1079 I:0.0654 great:0.0204,:0.1426,:0.2012 and:0.1138 I:0.1660)
		( the:0.0464 am:0.1045 I:0.0630 great:0.0195,:0.1455,:0.1885 and:0.1104 I:0.1572)
		( the:0.0486 am:0.0981 a:0.0596 great:0.0181,:0.1318,:0.1953 and:0.1147 I:0.1475)
		( the:0.0491 am:0.1030 a:0.0562 great:0.0168,:0.1328,:0.1992 and:0.1216 I:0.1367)
		( the:0.0444 am:0.0952 a:0.0579 great:0.0171,:0.1338,:0.1836 and:0.1245 I:0.1396)
		( the:0.0447 am:0.0972 a:0.0601 good:0.0153,:0.1338,:0.1846 and:0.1279 I:0.1279)
		( the:0.0444 am:0.0879 a:0.0608 great:0.0156,:0.1494,:0.1855 and:0.1309 I:0.1309)
		( the:0.0444 am:0.0898 a:0.0547 great:0.0156,:0.1494,:0.1875 and:0.1187 I:0.1318)
		( the:0.0442 am:0.0923 a:0.0549 great:0.0155,:0.1484,:0.1924 and:0.1191 I:0.1328)
 I have to be a very different language.
The
3200: sample 0: Hello, I'm a language model,
------
		(Hello:0.2500,:0.9492 I:1.0000'm:1.0000 a:0.9844 language:1.0000 model:1.0000,:1.0000)
		(,:0.1074 I:0.0713 have:0.0908 a:0.0703 good:0.0248 that:0.1377 that:0.1357 and:0.1367)
		(,:0.0835 the:0.0540 have:0.0835 a:0.0645 good:0.0259 that:0.1328 that:0.1367 and:0.1426)
		(,:0.0732 the:0.0542 have:0.0859 a:0.0625 good:0.0255 that:0.1387 that:0.1328 and:0.1396)
		(.:0.0771 the:0.0513 have:0.0825 a:0.0669 good:0.0244 that:0.1260 that:0.1387 and:0.1338)
		(.:0.0879 the:0.0532 have:0.0859 a:0.0703 good:0.0228 that:0.1289 that:0.1309 and:0.1416)
		(.:0.0864 the:0.0544 have:0.0894 a:0.0737 good:0.0234 that:0.1309 that:0.1318 and:0.1475)
		(.:0.0952 the:0.0618 have:0.0820 a:0.0752 good:0.0238 that:0.1328 that:0.1328 and:0.1348)
		(.:0.0928 the:0.0625 have:0.0825 a:0.0762 good:0.0242 that:0.1318 that:0.1377 and:0.1377)
		(.:0.0898 the:0.0625 have:0.0820 a:0.0771 good:0.0242 that:0.1318 that:0.1387 and:0.1396)
		(.:0.0977 the:0.0620 have:0.0830 a:0.0776 good:0.0240 that:0.1309 that:0.1396 and:0.1387)
		(.:0.0942 the:0.0693 have:0.0918 a:0.0869 good:0.0239 that:0.1299 that:0.1289 and:0.1377)
		(.:0.1025 the:0.0688 have:0.0820 a:0.0864 good:0.0236 that:0.1299 that:0.1318 and:0.1387)
 and
------
		(,:0.9492 I:1.0000'm:1.0000 a:0.9844 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.0713 have:0.0908 a:0.0703 good:0.0248 that:0.1377 that:0.1357 and:0.1367 the:0.0527)
		( the:0.0540 have:0.0835 a:0.0645 good:0.0259 that:0.1328 that:0.1367 and:0.1426 I:0.0669)
		( the:0.0542 have:0.0859 a:0.0625 good:0.0255 that:0.1387 that:0.1328 and:0.1396 I:0.0723)
		( the:0.0513 have:0.0825 a:0.0669 good:0.0244 that:0.1260 that:0.1387 and:0.1338 I:0.0684)
		( the:0.0532 have:0.0859 a:0.0703 good:0.0228 that:0.1289 that:0.1309 and:0.1416 I:0.0630)
		( the:0.0544 have:0.0894 a:0.0737 good:0.0234 that:0.1309 that:0.1318 and:0.1475 I:0.0569)
		( the:0.0618 have:0.0820 a:0.0752 good:0.0238 that:0.1328 that:0.1328 and:0.1348 I:0.0579)
		( the:0.0625 have:0.0825 a:0.0762 good:0.0242 that:0.1318 that:0.1377 and:0.1377 the:0.0520)
		( the:0.0625 have:0.0820 a:0.0771 good:0.0242 that:0.1318 that:0.1387 and:0.1396 the:0.0522)
		( the:0.0620 have:0.0830 a:0.0776 good:0.0240 that:0.1309 that:0.1396 and:0.1387 the:0.0588)
		( the:0.0693 have:0.0918 a:0.0869 good:0.0239 that:0.1299 that:0.1289 and:0.1377 the:0.0579)
		( the:0.0688 have:0.0820 a:0.0864 good:0.0236 that:0.1299 that:0.1318 and:0.1387 the:0.0576)
 the other words.
The first word is a word
3350: sample 0: Hello, I'm a language model,
------
		(Hello:0.3887,:0.9375 I:1.0000'm:1.0000 a:0.9766 language:1.0000 model:1.0000,:1.0000)
		(,:0.0830 I:0.0752 am:0.1348 a:0.0713 good:0.0310 that:0.1084,:0.1357 and:0.1309)
		(.:0.0713 the:0.0564 am:0.1357 a:0.0630 good:0.0327 that:0.0981,:0.1289 and:0.1260)
		(.:0.0684 the:0.0559 am:0.1367 a:0.0608 good:0.0288,:0.0898,:0.1191 and:0.1348)
		(.:0.0669 and:0.0588 am:0.1299 a:0.0645 good:0.0276 that:0.0908,:0.1099 and:0.1445)
		(.:0.0630 and:0.0679 have:0.1191 a:0.0669 good:0.0256 that:0.0903,:0.1113 and:0.1494)
		(.:0.0576 and:0.0688 have:0.1226 a:0.0693 good:0.0265 that:0.0908.:0.1138 and:0.1523)
		(.:0.0581 and:0.0684 have:0.1367 a:0.0698 good:0.0266 that:0.0898.:0.1152 and:0.1543)
		(.:0.0583 and:0.0674 have:0.1357 a:0.0693 little:0.0266 that:0.0894.:0.1133 and:0.1543)
		(.:0.0525 and:0.0732 have:0.1357 a:0.0684 little:0.0262 that:0.0889,:0.1016 and:0.1533)
		(.:0.0525 and:0.0718 have:0.1494 a:0.0679 little:0.0260 that:0.0981,:0.1021 and:0.1523)
		(.:0.0525 and:0.0698 have:0.1455 a:0.0747 little:0.0286 that:0.0962,:0.1011 and:0.1504)
		(.:0.0469 and:0.0674 have:0.1582 a:0.0732 little:0.0281 that:0.0957,:0.1006 and:0.1475)
 and
------
		(,:0.9375 I:1.0000'm:1.0000 a:0.9766 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.0752 am:0.1348 a:0.0713 good:0.0310 that:0.1084,:0.1357 and:0.1309 I:0.1230)
		( the:0.0564 am:0.1357 a:0.0630 good:0.0327 that:0.0981,:0.1289 and:0.1260 I:0.1660)
		( the:0.0559 am:0.1367 a:0.0608 good:0.0288,:0.0898,:0.1191 and:0.1348 I:0.1758)
		( and:0.0588 am:0.1299 a:0.0645 good:0.0276 that:0.0908,:0.1099 and:0.1445 I:0.1641)
		( and:0.0679 have:0.1191 a:0.0669 good:0.0256 that:0.0903,:0.1113 and:0.1494 I:0.1504)
		( and:0.0688 have:0.1226 a:0.0693 good:0.0265 that:0.0908.:0.1138 and:0.1523 I:0.1387)
		( and:0.0684 have:0.1367 a:0.0698 good:0.0266 that:0.0898.:0.1152 and:0.1543 I:0.1377)
		( and:0.0674 have:0.1357 a:0.0693 little:0.0266 that:0.0894.:0.1133 and:0.1543 I:0.1367)
		( and:0.0732 have:0.1357 a:0.0684 little:0.0262 that:0.0889,:0.1016 and:0.1533 I:0.1357)
		( and:0.0718 have:0.1494 a:0.0679 little:0.0260 that:0.0981,:0.1021 and:0.1523 I:0.1338)
		( and:0.0698 have:0.1455 a:0.0747 little:0.0286 that:0.0962,:0.1011 and:0.1504 I:0.1465)
		( and:0.0674 have:0.1582 a:0.0732 little:0.0281 that:0.0957,:0.1006 and:0.1475 I:0.1455)
 I have a lot of things. I have a lot
3500: sample 0: Hello, I'm a language model,
------
		(fashioned:0.2422,:0.9414 I:1.0000'm:1.0000 a:0.9805 language:1.0000 model:1.0000,:1.0000)
		(,:0.0879 and:0.0596�:0.1426 a:0.0503 good:0.0820 that:0.1279.:0.1318 but:0.1816)
		(,:0.0679 and:0.0640�:0.1172 a:0.0503 good:0.0918 that:0.1221.:0.1299 but:0.1855)
		(,:0.0605 and:0.0713�:0.1191 a:0.0559 good:0.0889 that:0.1143.:0.1260 but:0.1826)
		(,:0.0559 and:0.0679�:0.1162 a:0.0540 good:0.0835 that:0.1064.:0.1348 but:0.1768)
		(,:0.0559 and:0.0703�:0.1094 a:0.0576 good:0.0879 that:0.1074.:0.1260 but:0.1680)
		(,:0.0493 and:0.0713�:0.1113 a:0.0605 good:0.0796 that:0.1084.:0.1279 but:0.1748)
		(,:0.0488 and:0.0728�:0.1025 a:0.0618 good:0.0811 that:0.1094.:0.1338 but:0.1768)
		(,:0.0474 and:0.0732�:0.1035 a:0.0635 good:0.0815 that:0.1123.:0.1206 but:0.1631)
		(,:0.0459 and:0.0649�:0.1050 a:0.0635 good:0.0811 that:0.1123.:0.1240 but:0.1807)
		(,:0.0439 and:0.0635�:0.1045 a:0.0635 good:0.0811 that:0.1123.:0.1240 but:0.1807)
		(,:0.0422 and:0.0635�:0.1035 a:0.0640 good:0.0796 that:0.1108.:0.1240 but:0.1846)
		(,:0.0403 and:0.0620�:0.1035 a:0.0630 good:0.0786 that:0.1104.:0.1250 but:0.1807)
 but
------
		(,:0.9414 I:1.0000'm:1.0000 a:0.9805 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( and:0.0596�:0.1426 a:0.0503 good:0.0820 that:0.1279.:0.1318 but:0.1816 I:0.2129)
		( and:0.0640�:0.1172 a:0.0503 good:0.0918 that:0.1221.:0.1299 but:0.1855 I:0.2344)
		( and:0.0713�:0.1191 a:0.0559 good:0.0889 that:0.1143.:0.1260 but:0.1826 I:0.2373)
		( and:0.0679�:0.1162 a:0.0540 good:0.0835 that:0.1064.:0.1348 but:0.1768 I:0.2109)
		( and:0.0703�:0.1094 a:0.0576 good:0.0879 that:0.1074.:0.1260 but:0.1680 I:0.2012)
		( and:0.0713�:0.1113 a:0.0605 good:0.0796 that:0.1084.:0.1279 but:0.1748 I:0.1738)
		( and:0.0728�:0.1025 a:0.0618 good:0.0811 that:0.1094.:0.1338 but:0.1768 I:0.1611)
		( and:0.0732�:0.1035 a:0.0635 good:0.0815 that:0.1123.:0.1206 but:0.1631 I:0.1641)
		( and:0.0649�:0.1050 a:0.0635 good:0.0811 that:0.1123.:0.1240 but:0.1807 I:0.1514)
		( and:0.0635�:0.1045 a:0.0635 good:0.0811 that:0.1123.:0.1240 but:0.1807 I:0.1533)
		( and:0.0635�:0.1035 a:0.0640 good:0.0796 that:0.1108.:0.1240 but:0.1846 I:0.1387)
		( and:0.0620�:0.1035 a:0.0630 good:0.0786 that:0.1104.:0.1250 but:0.1807 I:0.1396)
 I think it is a good way to write a lot
3650: sample 0: Hello, I'm a language model,
------
		(fashioned:0.1611,:0.9453 I:1.0000'm:1.0000 a:0.9688 language:1.0000 model:1.0000,:1.0000)
		(,:0.0830 and:0.0513 have:0.1270 a:0.0454 good:0.0310 that:0.1836 that:0.1089 but:0.2061)
		(,:0.0610 and:0.0486 have:0.1250 not:0.0457 good:0.0332 that:0.1709,:0.1016 but:0.1865)
		(,:0.0518 and:0.0540 have:0.1206 a:0.0444 good:0.0298 that:0.1758.:0.1094 but:0.1855)
		(,:0.0457 and:0.0566 have:0.1099 not:0.0486 good:0.0289 that:0.1650.:0.1030 but:0.1768)
		(,:0.0439 and:0.0586 have:0.1069 a:0.0457 good:0.0277 that:0.1680.:0.1069 but:0.1699)
		(.:0.0420 and:0.0593 have:0.1035 a:0.0469 good:0.0253 that:0.1719 for:0.1133 but:0.1738)
		(.:0.0393 and:0.0596 have:0.1099 a:0.0479 good:0.0261 that:0.1738.:0.1025 but:0.1777)
		(.:0.0374 and:0.0596 have:0.1030 not:0.0542 good:0.0236 that:0.1768 that:0.1060 but:0.1777)
		(.:0.0356 and:0.0586 have:0.1060 not:0.0544 good:0.0234 that:0.1768 that:0.1069 but:0.1787)
		(.:0.0376 and:0.0583 have:0.0972 not:0.0544 good:0.0236 that:0.1934 that:0.1118 but:0.1777)
		(.:0.0356 and:0.0574 have:0.0991 not:0.0537 good:0.0233 that:0.1924 that:0.1123 but:0.1807)
		(.:0.0337 and:0.0557 have:0.1011 a:0.0527 lot:0.0233 that:0.1934 that:0.1138 but:0.1768)
 but
------
		(,:0.9453 I:1.0000'm:1.0000 a:0.9688 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( and:0.0513 have:0.1270 a:0.0454 good:0.0310 that:0.1836 that:0.1089 but:0.2061 I:0.1699)
		( and:0.0486 have:0.1250 not:0.0457 good:0.0332 that:0.1709,:0.1016 but:0.1865 I:0.1875)
		( and:0.0540 have:0.1206 a:0.0444 good:0.0298 that:0.1758.:0.1094 but:0.1855 I:0.1846)
		( and:0.0566 have:0.1099 not:0.0486 good:0.0289 that:0.1650.:0.1030 but:0.1768 I:0.1611)
		( and:0.0586 have:0.1069 a:0.0457 good:0.0277 that:0.1680.:0.1069 but:0.1699 I:0.1523)
		( and:0.0593 have:0.1035 a:0.0469 good:0.0253 that:0.1719 for:0.1133 but:0.1738 I:0.1426)
		( and:0.0596 have:0.1099 a:0.0479 good:0.0261 that:0.1738.:0.1025 but:0.1777 I:0.1299)
		( and:0.0596 have:0.1030 not:0.0542 good:0.0236 that:0.1768 that:0.1060 but:0.1777 I:0.1328)
		( and:0.0586 have:0.1060 not:0.0544 good:0.0234 that:0.1768 that:0.1069 but:0.1787 I:0.1206)
		( and:0.0583 have:0.0972 not:0.0544 good:0.0236 that:0.1934 that:0.1118 but:0.1777 I:0.1221)
		( and:0.0574 have:0.0991 not:0.0537 good:0.0233 that:0.1924 that:0.1123 but:0.1807 I:0.1216)
		( and:0.0557 have:0.1011 a:0.0527 lot:0.0233 that:0.1934 that:0.1138 but:0.1768 I:0.1221)
 I'm not sure to be able to use the word
3800: sample 0: Hello, I'm a language model,
------
		(fashioned:0.2480,:0.9570 I:1.0000'm:1.0000 a:0.9648 language:1.0000 model:1.0000,:1.0000)
		(,:0.0972 I:0.1045�:0.0967 a:0.0464 good:0.0752 that:0.1279,:0.1396 and:0.1318)
		(,:0.0664 I:0.0771�:0.0884 a:0.0454 good:0.0752 that:0.1348,:0.1396 and:0.1299)
		(,:0.0547 the:0.0593�:0.0757 a:0.0437 good:0.0732 that:0.1270,:0.1387 and:0.1289)
		(,:0.0471 the:0.0562�:0.0708 a:0.0410 good:0.0781 that:0.1191,:0.1309 and:0.1396)
		(,:0.0398 the:0.0581�:0.0728 a:0.0427 good:0.0820 that:0.1191,:0.1206 and:0.1465)
		(,:0.0374 the:0.0588'll:0.0742 a:0.0435 good:0.0747 that:0.1201,:0.1250 and:0.1357)
		(,:0.0347 the:0.0586'll:0.0747 a:0.0439 good:0.0767 that:0.1211,:0.1289 and:0.1377)
		(,:0.0364 the:0.0583'll:0.0679 a:0.0437 good:0.0767 that:0.1206,:0.1172 and:0.1387)
		(
:0.0383 the:0.0649'll:0.0757 a:0.0493 good:0.0771 that:0.1216,:0.1172 and:0.1396)
		(
:0.0400 the:0.0635'll:0.0684 a:0.0483 good:0.0762 that:0.1191,:0.1177 and:0.1406)
		(,:0.0369 the:0.0625'll:0.0679 a:0.0479 good:0.0752 that:0.1177,:0.1172 and:0.1406)
		(,:0.0383 the:0.0613'll:0.0674 a:0.0466 good:0.0747 that:0.1167,:0.1191 and:0.1377)
 and
------
		(,:0.9570 I:1.0000'm:1.0000 a:0.9648 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1045�:0.0967 a:0.0464 good:0.0752 that:0.1279,:0.1396 and:0.1318 I:0.1064)
		( I:0.0771�:0.0884 a:0.0454 good:0.0752 that:0.1348,:0.1396 and:0.1299 I:0.1162)
		( the:0.0593�:0.0757 a:0.0437 good:0.0732 that:0.1270,:0.1387 and:0.1289 I:0.1113)
		( the:0.0562�:0.0708 a:0.0410 good:0.0781 that:0.1191,:0.1309 and:0.1396 I:0.0928)
		( the:0.0581�:0.0728 a:0.0427 good:0.0820 that:0.1191,:0.1206 and:0.1465 I:0.0859)
		( the:0.0588'll:0.0742 a:0.0435 good:0.0747 that:0.1201,:0.1250 and:0.1357 I:0.0864)
		( the:0.0586'll:0.0747 a:0.0439 good:0.0767 that:0.1211,:0.1289 and:0.1377 I:0.0781)
		( the:0.0583'll:0.0679 a:0.0437 good:0.0767 that:0.1206,:0.1172 and:0.1387 I:0.0781)
		( the:0.0649'll:0.0757 a:0.0493 good:0.0771 that:0.1216,:0.1172 and:0.1396 I:0.0781)
		( the:0.0635'll:0.0684 a:0.0483 good:0.0762 that:0.1191,:0.1177 and:0.1406 I:0.0781)
		( the:0.0625'll:0.0679 a:0.0479 good:0.0752 that:0.1177,:0.1172 and:0.1406 I:0.0874)
		( the:0.0613'll:0.0674 a:0.0466 good:0.0747 that:0.1167,:0.1191 and:0.1377 I:0.0850)
 I'll have a lot of information.
I'll
3950: sample 0: Hello, I'm a language model,
------
		(Hello:0.1885,:0.9648 I:1.0000'm:1.0000 a:0.9570 language:1.0000 model:1.0000,:1.0000)
		(,:0.0776 I:0.1592 have:0.0874 a:0.0630 little:0.0513,:0.1177,:0.1426 I:0.1797)
		(,:0.0732 I:0.1104 have:0.0820 a:0.0684 little:0.0515,:0.1201,:0.1396 I:0.2158)
		(,:0.0762 I:0.0869 have:0.0840 a:0.0659 little:0.0496,:0.1104,:0.1348 I:0.2100)
		(,:0.0737 I:0.0820 have:0.0835 a:0.0698 little:0.0466,:0.1128,:0.1260 I:0.1836)
		(,:0.0698 I:0.0747 have:0.0796 a:0.0718 little:0.0481,:0.1162,:0.1318 I:0.1533)
		(,:0.0659 I:0.0757 have:0.0742 a:0.0723 little:0.0491 that:0.1187,:0.1211 I:0.1572)
		(,:0.0615 I:0.0757 have:0.0771 a:0.0723 little:0.0488 that:0.1211,:0.1279 I:0.1445)
		(,:0.0574 I:0.0742 have:0.0718 a:0.0723 little:0.0481 that:0.1235,:0.1157 I:0.1455)
		(,:0.0549 I:0.0737 have:0.0728 a:0.0713 little:0.0422 that:0.1240,:0.1196 I:0.1318)
		(,:0.0461 I:0.0718 have:0.0752 a:0.0703 little:0.0474 that:0.1250 for:0.1235 I:0.1318)
		(,:0.0447 I:0.0796 have:0.0684 a:0.0781 little:0.0461 that:0.1250,:0.1128 I:0.1328)
		(,:0.0435 I:0.0791 have:0.0684 a:0.0776 little:0.0408 that:0.1270,:0.1152 I:0.1211)
 I
------
		(,:0.9648 I:1.0000'm:1.0000 a:0.9570 language:1.0000 model:1.0000,:1.0000 I:1.0000)
		( I:0.1592 have:0.0874 a:0.0630 little:0.0513,:0.1177,:0.1426 I:0.1797 think:0.1045)
		( I:0.1104 have:0.0820 a:0.0684 little:0.0515,:0.1201,:0.1396 I:0.2158 think:0.1094)
		( I:0.0869 have:0.0840 a:0.0659 little:0.0496,:0.1104,:0.1348 I:0.2100 think:0.1055)
		( I:0.0820 have:0.0835 a:0.0698 little:0.0466,:0.1128,:0.1260 I:0.1836 think:0.1045)
		( I:0.0747 have:0.0796 a:0.0718 little:0.0481,:0.1162,:0.1318 I:0.1533 think:0.1021)
		( I:0.0757 have:0.0742 a:0.0723 little:0.0491 that:0.1187,:0.1211 I:0.1572 think:0.0977)
		( I:0.0757 have:0.0771 a:0.0723 little:0.0488 that:0.1211,:0.1279 I:0.1445 think:0.0933)
		( I:0.0742 have:0.0718 a:0.0723 little:0.0481 that:0.1235,:0.1157 I:0.1455 think:0.0962)
		( I:0.0737 have:0.0728 a:0.0713 little:0.0422 that:0.1240,:0.1196 I:0.1318 think:0.0889)
		( I:0.0718 have:0.0752 a:0.0703 little:0.0474 that:0.1250 for:0.1235 I:0.1318 think:0.0918)
		( I:0.0796 have:0.0684 a:0.0781 little:0.0461 that:0.1250,:0.1128 I:0.1328 think:0.0840)
		( I:0.0791 have:0.0684 a:0.0776 little:0.0408 that:0.1270,:0.1152 I:0.1211 think:0.0850)
 think that I think I think I think I think I
4100: sample 0: Hello, I'm a language model,
------
		( smartest:0.3105,:0.9492 I:1.0000'm:1.0000 a:0.9609 language:1.0000 model:1.0000,:1.0000)
		(,:0.0718 I:0.0669 have:0.0825 a:0.0708 good:0.0452 that:0.1523 for:0.1709 but:0.1826)
		(.:0.0679 and:0.0496 have:0.0840 a:0.0640 good:0.0405 that:0.1396 for:0.1582 but:0.1670)
		(.:0.0698 and:0.0544 have:0.0859 a:0.0635 little:0.0398 that:0.1270.:0.1465 but:0.1670)
		(.:0.0752 and:0.0574 have:0.0840 a:0.0605 little:0.0378 that:0.1289.:0.1504 but:0.1777)
		(.:0.0791 and:0.0586 have:0.0889 a:0.0640 little:0.0352 that:0.1157.:0.1533 but:0.1680)
		(.:0.0747 and:0.0588 have:0.0908 a:0.0586 little:0.0369 that:0.1152 for:0.1592 but:0.1748)
		(.:0.0708 and:0.0591 have:0.0923 a:0.0596 little:0.0371 that:0.1147 for:0.1592 but:0.1768)
		(.:0.0679 and:0.0586 have:0.0933 a:0.0601 little:0.0378 that:0.1152 for:0.1602 but:0.1631)
		(.:0.0654 and:0.0586 have:0.0942 a:0.0598 little:0.0381 that:0.1143 for:0.1602 but:0.1650)
		(,:0.0640 and:0.0581 have:0.0942 a:0.0598 little:0.0386 that:0.1133 for:0.1660 but:0.1650)
		(,:0.0625 and:0.0579 have:0.0942 a:0.0603 little:0.0339 that:0.1123 for:0.1670 but:0.1660)
		(,:0.0688 and:0.0576 have:0.0938 a:0.0598 little:0.0344 that:0.1123 for:0.1680 but:0.1670)
 but
------
		(,:0.9492 I:1.0000'm:1.0000 a:0.9609 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( I:0.0669 have:0.0825 a:0.0708 good:0.0452 that:0.1523 for:0.1709 but:0.1826 I:0.1943)
		( and:0.0496 have:0.0840 a:0.0640 good:0.0405 that:0.1396 for:0.1582 but:0.1670 I:0.2139)
		( and:0.0544 have:0.0859 a:0.0635 little:0.0398 that:0.1270.:0.1465 but:0.1670 I:0.1924)
		( and:0.0574 have:0.0840 a:0.0605 little:0.0378 that:0.1289.:0.1504 but:0.1777 I:0.1816)
		( and:0.0586 have:0.0889 a:0.0640 little:0.0352 that:0.1157.:0.1533 but:0.1680 I:0.1738)
		( and:0.0588 have:0.0908 a:0.0586 little:0.0369 that:0.1152 for:0.1592 but:0.1748 I:0.1816)
		( and:0.0591 have:0.0923 a:0.0596 little:0.0371 that:0.1147 for:0.1592 but:0.1768 I:0.1650)
		( and:0.0586 have:0.0933 a:0.0601 little:0.0378 that:0.1152 for:0.1602 but:0.1631 I:0.1670)
		( and:0.0586 have:0.0942 a:0.0598 little:0.0381 that:0.1143 for:0.1602 but:0.1650 I:0.1689)
		( and:0.0581 have:0.0942 a:0.0598 little:0.0386 that:0.1133 for:0.1660 but:0.1650 I:0.1729)
		( and:0.0579 have:0.0942 a:0.0603 little:0.0339 that:0.1123 for:0.1670 but:0.1660 I:0.1748)
		( and:0.0576 have:0.0938 a:0.0598 little:0.0344 that:0.1123 for:0.1680 but:0.1670 I:0.1768)
 I'm not sure I'm not sure I'm not
4250: sample 0: Hello, I'm a language model,
------
		(Hello:0.2363,:0.9414 I:1.0000'm:1.0000 a:0.9648 language:1.0000 model:1.0000,:1.0000)
		(,:0.0781 I:0.1123 have:0.0654 a:0.0859 good:0.0552,:0.1069 of:0.1523 and:0.0845)
		(,:0.0530 I:0.0850 have:0.0605 a:0.0732 good:0.0559,:0.1172 of:0.1719 and:0.0830)
		(,:0.0430 I:0.0679 have:0.0500 a:0.0703 good:0.0544,:0.1201 of:0.1602 and:0.0908)
		(,:0.0364 I:0.0635 have:0.0493 a:0.0654 good:0.0520,:0.1099 of:0.1699 and:0.0864)
		(.:0.0381 I:0.0583 have:0.0466 a:0.0674 good:0.0481,:0.1113 of:0.1748 and:0.0908)
		(.:0.0349 I:0.0588 have:0.0496 a:0.0674 good:0.0505,:0.1006 of:0.1592 and:0.0923)
		(.:0.0359 I:0.0588 have:0.0510 a:0.0664 good:0.0508,:0.0996 of:0.1631 and:0.0845)
		(.:0.0327 I:0.0588 have:0.0464 a:0.0669 good:0.0459,:0.1006 of:0.1670 and:0.0850)
		(.:0.0305 I:0.0654 have:0.0469 a:0.0664 good:0.0461,:0.0991 of:0.1670 and:0.0859)
		(.:0.0325 I:0.0654 have:0.0483 a:0.0659 good:0.0471,:0.0884 of:0.1719 and:0.0859)
		(.:0.0308 I:0.0645 have:0.0496 a:0.0659 good:0.0422,:0.0879 of:0.1689 and:0.0864)
		(.:0.0297 I:0.0649 have:0.0508 a:0.0654 good:0.0427,:0.0874 of:0.1709 and:0.0869)
 and
------
		(,:0.9414 I:1.0000'm:1.0000 a:0.9648 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1123 have:0.0654 a:0.0859 good:0.0552,:0.1069 of:0.1523 and:0.0845 I:0.0977)
		( I:0.0850 have:0.0605 a:0.0732 good:0.0559,:0.1172 of:0.1719 and:0.0830 I:0.1206)
		( I:0.0679 have:0.0500 a:0.0703 good:0.0544,:0.1201 of:0.1602 and:0.0908 I:0.1187)
		( I:0.0635 have:0.0493 a:0.0654 good:0.0520,:0.1099 of:0.1699 and:0.0864 I:0.1011)
		( I:0.0583 have:0.0466 a:0.0674 good:0.0481,:0.1113 of:0.1748 and:0.0908 I:0.1045)
		( I:0.0588 have:0.0496 a:0.0674 good:0.0505,:0.1006 of:0.1592 and:0.0923 I:0.0972)
		( I:0.0588 have:0.0510 a:0.0664 good:0.0508,:0.0996 of:0.1631 and:0.0845 I:0.0977)
		( I:0.0588 have:0.0464 a:0.0669 good:0.0459,:0.1006 of:0.1670 and:0.0850 I:0.0981)
		( I:0.0654 have:0.0469 a:0.0664 good:0.0461,:0.0991 of:0.1670 and:0.0859 I:0.0986)
		( I:0.0654 have:0.0483 a:0.0659 good:0.0471,:0.0884 of:0.1719 and:0.0859 I:0.0996)
		( I:0.0645 have:0.0496 a:0.0659 good:0.0422,:0.0879 of:0.1689 and:0.0864 I:0.1001)
		( I:0.0649 have:0.0508 a:0.0654 good:0.0427,:0.0874 of:0.1709 and:0.0869 I:0.1006)
 I do not know that I have to be a good
4400: sample 0: Hello, I'm a language model,
------
		( smartest:0.1328,:0.9531 I:1.0000'm:1.0000 a:0.9492 language:1.0000 model:1.0000,:1.0000)
		(,:0.0518 I:0.0703 have:0.1465 a:0.0728 great:0.0269 that:0.1934 that:0.1279 and:0.1514)
		(,:0.0400 and:0.0520 have:0.1357 a:0.0615 great:0.0264 that:0.1914 that:0.1357 and:0.1436)
		(.:0.0449 and:0.0564 have:0.1230 a:0.0586 great:0.0251 that:0.1934 that:0.1221 and:0.1514)
		(.:0.0552 and:0.0588 have:0.1206 a:0.0620 great:0.0239 that:0.1748 that:0.1289 and:0.1602)
		(.:0.0596 and:0.0598 have:0.1167 a:0.0564 great:0.0223 that:0.1748 that:0.1172 and:0.1484)
		(.:0.0649 and:0.0601 have:0.1230 a:0.0586 great:0.0231 that:0.1777 that:0.1221 and:0.1514)
		(.:0.0698 and:0.0601 have:0.1299 a:0.0603 great:0.0238 that:0.1787 that:0.1240 and:0.1553)
		(.:0.0684 and:0.0596 have:0.1191 a:0.0608 great:0.0242 that:0.1797 that:0.1138 and:0.1572)
		(.:0.0752 and:0.0593 have:0.1221 a:0.0618 great:0.0216 that:0.1631 that:0.1157 and:0.1416)
		(.:0.0742 and:0.0586 have:0.1235 a:0.0615 great:0.0247 that:0.1631 that:0.1172 and:0.1426)
		(.:0.0649 and:0.0579 have:0.1240 a:0.0613 great:0.0245 that:0.1631 that:0.1196 and:0.1426)
		(.:0.0713 and:0.0574 have:0.1235 a:0.0610 great:0.0245 that:0.1621 that:0.1201 and:0.1426)
 and
------
		(,:0.9531 I:1.0000'm:1.0000 a:0.9492 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.0703 have:0.1465 a:0.0728 great:0.0269 that:0.1934 that:0.1279 and:0.1514 I:0.0903)
		( and:0.0520 have:0.1357 a:0.0615 great:0.0264 that:0.1914 that:0.1357 and:0.1436 I:0.1084)
		( and:0.0564 have:0.1230 a:0.0586 great:0.0251 that:0.1934 that:0.1221 and:0.1514 I:0.0913)
		( and:0.0588 have:0.1206 a:0.0620 great:0.0239 that:0.1748 that:0.1289 and:0.1602 I:0.0864)
		( and:0.0598 have:0.1167 a:0.0564 great:0.0223 that:0.1748 that:0.1172 and:0.1484 I:0.0791)
		( and:0.0601 have:0.1230 a:0.0586 great:0.0231 that:0.1777 that:0.1221 and:0.1514 I:0.0723)
		( and:0.0601 have:0.1299 a:0.0603 great:0.0238 that:0.1787 that:0.1240 and:0.1553 I:0.0728)
		( and:0.0596 have:0.1191 a:0.0608 great:0.0242 that:0.1797 that:0.1138 and:0.1572 I:0.0742)
		( and:0.0593 have:0.1221 a:0.0618 great:0.0216 that:0.1631 that:0.1157 and:0.1416 I:0.0752)
		( and:0.0586 have:0.1235 a:0.0615 great:0.0247 that:0.1631 that:0.1172 and:0.1426 I:0.0757)
		( and:0.0579 have:0.1240 a:0.0613 great:0.0245 that:0.1631 that:0.1196 and:0.1426 I:0.0752)
		( and:0.0574 have:0.1235 a:0.0610 great:0.0245 that:0.1621 that:0.1201 and:0.1426 I:0.0757)
 I have a lot of characters. I have a lot
4550: sample 0: Hello, I'm a language model,
------
		(Hello:0.1172,:0.9453 I:1.0000'm:1.0000 a:0.9648 language:1.0000 model:1.0000,:1.0000)
		(.:0.0613 I:0.1826 am:0.0913 sure:0.0520 great:0.0679 that:0.1621 for:0.2119 but:0.1216)
		(.:0.0576 I:0.1162 am:0.0957 sure:0.0464 great:0.0659 that:0.1465 for:0.2051 I:0.1196)
		(.:0.0581 I:0.0933 am:0.0928 sure:0.0461 great:0.0635 that:0.1348 for:0.2051 and:0.1123)
		(
:0.0625 I:0.0791 am:0.0947 sure:0.0444 great:0.0601 that:0.1235 for:0.2070 and:0.1113)
		(.:0.0591 I:0.0737 am:0.0923 sure:0.0410 great:0.0618 that:0.1235 for:0.2051 and:0.1191)
		(
:0.0630 I:0.0747 am:0.0869 sure:0.0417 great:0.0623 that:0.1245 for:0.2080 and:0.1094)
		(
:0.0679 I:0.0752 am:0.0811 sure:0.0415 great:0.0623 that:0.1108 for:0.2051 and:0.1099)
		(
:0.0654 I:0.0732 am:0.0825 sure:0.0461 great:0.0625 that:0.1226 for:0.2070 and:0.1084)
		(
:0.0635 I:0.0820 am:0.0830 sure:0.0447 great:0.0698 that:0.1201 for:0.2080 and:0.1079)
		(
:0.0625 I:0.0806 am:0.0757 sure:0.0435 great:0.0698 that:0.1187 for:0.2080 and:0.1074)
		(
:0.0688 I:0.0801 am:0.0747 sure:0.0425 great:0.0688 that:0.1309 for:0.1992 but:0.1206)
		(
:0.0679 I:0.0781 am:0.0747 sure:0.0410 great:0.0771 that:0.1279 for:0.1992 but:0.1191)
 but
------
		(,:0.9453 I:1.0000'm:1.0000 a:0.9648 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( I:0.1826 am:0.0913 sure:0.0520 great:0.0679 that:0.1621 for:0.2119 but:0.1216 I:0.4414)
		( I:0.1162 am:0.0957 sure:0.0464 great:0.0659 that:0.1465 for:0.2051 I:0.1196 I:0.5039)
		( I:0.0933 am:0.0928 sure:0.0461 great:0.0635 that:0.1348 for:0.2051 and:0.1123 I:0.4824)
		( I:0.0791 am:0.0947 sure:0.0444 great:0.0601 that:0.1235 for:0.2070 and:0.1113 I:0.4512)
		( I:0.0737 am:0.0923 sure:0.0410 great:0.0618 that:0.1235 for:0.2051 and:0.1191 I:0.4355)
		( I:0.0747 am:0.0869 sure:0.0417 great:0.0623 that:0.1245 for:0.2080 and:0.1094 I:0.4141)
		( I:0.0752 am:0.0811 sure:0.0415 great:0.0623 that:0.1108 for:0.2051 and:0.1099 I:0.4023)
		( I:0.0732 am:0.0825 sure:0.0461 great:0.0625 that:0.1226 for:0.2070 and:0.1084 I:0.4062)
		( I:0.0820 am:0.0830 sure:0.0447 great:0.0698 that:0.1201 for:0.2080 and:0.1079 I:0.3926)
		( I:0.0806 am:0.0757 sure:0.0435 great:0.0698 that:0.1187 for:0.2080 and:0.1074 I:0.3906)
		( I:0.0801 am:0.0747 sure:0.0425 great:0.0688 that:0.1309 for:0.1992 but:0.1206 I:0.3945)
		( I:0.0781 am:0.0747 sure:0.0410 great:0.0771 that:0.1279 for:0.1992 but:0.1191 I:0.3809)
 I know that I know that I know, I know
4700: sample 0: Hello, I'm a language model,
------
		( cheapest:0.1050,:0.9453 I:1.0000'm:1.0000 a:0.9570 language:1.0000 model:1.0000,:1.0000)
		(,:0.0630 the:0.1147 have:0.1221 not:0.0581 little:0.0554 that:0.1641.:0.1504 I:0.1167)
		(,:0.0471 the:0.1040 have:0.1235 not:0.0566 little:0.0552 that:0.1602.:0.1465 I:0.1245)
		(,:0.0437 the:0.0981 have:0.1221 not:0.0583 good:0.0505 that:0.1514.:0.1436 I:0.0996)
		(.:0.0435 the:0.0933 have:0.1167 not:0.0625 good:0.0479 that:0.1445.:0.1475 I:0.0850)
		(.:0.0420 the:0.0962 have:0.1182 not:0.0649 good:0.0474 that:0.1475.:0.1504 and:0.0815)
		(.:0.0452 the:0.0859 have:0.1216 not:0.0669 good:0.0464 that:0.1387.:0.1494 and:0.0840)
		(.:0.0435 the:0.0869 have:0.1182 not:0.0664 good:0.0466 that:0.1406.:0.1504 and:0.0806)
		(.:0.0417 the:0.0850 have:0.1191 not:0.0654 good:0.0439 that:0.1406.:0.1543 and:0.0801)
		(.:0.0400 the:0.0835 have:0.1162 not:0.0684 good:0.0437 that:0.1396.:0.1562 and:0.0757)
		(.:0.0391 the:0.0815 have:0.1240 not:0.0669 good:0.0435 that:0.1387.:0.1494 and:0.0757)
		(.:0.0381 the:0.0898 have:0.1182 not:0.0664 good:0.0430 that:0.1387.:0.1484 and:0.0752)
		(.:0.0371 the:0.0884 have:0.1250 not:0.0684 good:0.0408 that:0.1377.:0.1484 and:0.0757)
 and
------
		(,:0.9453 I:1.0000'm:1.0000 a:0.9570 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.1147 have:0.1221 not:0.0581 little:0.0554 that:0.1641.:0.1504 I:0.1167 I:0.0815)
		( the:0.1040 have:0.1235 not:0.0566 little:0.0552 that:0.1602.:0.1465 I:0.1245 I:0.0889)
		( the:0.0981 have:0.1221 not:0.0583 good:0.0505 that:0.1514.:0.1436 I:0.0996 I:0.0771)
		( the:0.0933 have:0.1167 not:0.0625 good:0.0479 that:0.1445.:0.1475 I:0.0850 I:0.0684)
		( the:0.0962 have:0.1182 not:0.0649 good:0.0474 that:0.1475.:0.1504 and:0.0815 I:0.0591)
		( the:0.0859 have:0.1216 not:0.0669 good:0.0464 that:0.1387.:0.1494 and:0.0840 I:0.0601)
		( the:0.0869 have:0.1182 not:0.0664 good:0.0466 that:0.1406.:0.1504 and:0.0806 I:0.0566)
		( the:0.0850 have:0.1191 not:0.0654 good:0.0439 that:0.1406.:0.1543 and:0.0801 I:0.0566)
		( the:0.0835 have:0.1162 not:0.0684 good:0.0437 that:0.1396.:0.1562 and:0.0757 I:0.0564)
		( the:0.0815 have:0.1240 not:0.0669 good:0.0435 that:0.1387.:0.1494 and:0.0757 I:0.0598)
		( the:0.0898 have:0.1182 not:0.0664 good:0.0430 that:0.1387.:0.1484 and:0.0752 I:0.0596)
		( the:0.0884 have:0.1250 not:0.0684 good:0.0408 that:0.1377.:0.1484 and:0.0757 I:0.0593)
 I think it is a good way to think of the
4850: sample 0: Hello, I'm a language model,
------
		( cheapest:0.1777,:0.9688 I:1.0000'm:1.0000 a:0.9609 language:1.0000 model:1.0000,:1.0000)
		(,:0.1055 the:0.0540 have:0.0525 a:0.0486 good:0.0479 that:0.1289,:0.1387 and:0.0771)
		(,:0.0781 the:0.0437 have:0.0508 not:0.0486 good:0.0496 that:0.1309,:0.1377 and:0.0781)
		(,:0.0630 the:0.0391 have:0.0520 not:0.0493 good:0.0505 that:0.1226,:0.1309 and:0.0815)
		(,:0.0554 the:0.0378 have:0.0491 not:0.0498 good:0.0483 that:0.1216,:0.1270 and:0.0806)
		(,:0.0515 the:0.0388 have:0.0486 not:0.0498 good:0.0483 that:0.1279,:0.1309 and:0.0776)
		(,:0.0542 the:0.0388 have:0.0479 not:0.0498 good:0.0461 that:0.1279,:0.1270 and:0.0796)
		(,:0.0515 the:0.0410 have:0.0469 not:0.0488 good:0.0457 that:0.1270 for:0.1289 and:0.0762)
		(,:0.0522 the:0.0410 have:0.0452 not:0.0479 good:0.0459 that:0.1270 for:0.1309 and:0.0723)
		(,:0.0537 the:0.0432 have:0.0466 not:0.0474 good:0.0452 that:0.1328 for:0.1328 and:0.0737)
		(,:0.0552 the:0.0432 have:0.0449 not:0.0461 good:0.0447 that:0.1338 for:0.1289 and:0.0703)
		(,:0.0542 the:0.0435 have:0.0435 not:0.0486 good:0.0442 that:0.1328,:0.1250 and:0.0713)
		(,:0.0562 the:0.0459 have:0.0439 not:0.0474 good:0.0439 that:0.1270,:0.1270 and:0.0718)
 and
------
		(,:0.9688 I:1.0000'm:1.0000 a:0.9609 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0540 have:0.0525 a:0.0486 good:0.0479 that:0.1289,:0.1387 and:0.0771 a:0.0864)
		( the:0.0437 have:0.0508 not:0.0486 good:0.0496 that:0.1309,:0.1377 and:0.0781 I:0.0820)
		( the:0.0391 have:0.0520 not:0.0493 good:0.0505 that:0.1226,:0.1309 and:0.0815 I:0.0806)
		( the:0.0378 have:0.0491 not:0.0498 good:0.0483 that:0.1216,:0.1270 and:0.0806 a:0.0708)
		( the:0.0388 have:0.0486 not:0.0498 good:0.0483 that:0.1279,:0.1309 and:0.0776 a:0.0723)
		( the:0.0388 have:0.0479 not:0.0498 good:0.0461 that:0.1279,:0.1270 and:0.0796 a:0.0728)
		( the:0.0410 have:0.0469 not:0.0488 good:0.0457 that:0.1270 for:0.1289 and:0.0762 a:0.0771)
		( the:0.0410 have:0.0452 not:0.0479 good:0.0459 that:0.1270 for:0.1309 and:0.0723 a:0.0767)
		( the:0.0432 have:0.0466 not:0.0474 good:0.0452 that:0.1328 for:0.1328 and:0.0737 a:0.0762)
		( the:0.0432 have:0.0449 not:0.0461 good:0.0447 that:0.1338 for:0.1289 and:0.0703 a:0.0762)
		( the:0.0435 have:0.0435 not:0.0486 good:0.0442 that:0.1328,:0.1250 and:0.0713 a:0.0771)
		( the:0.0459 have:0.0439 not:0.0474 good:0.0439 that:0.1270,:0.1270 and:0.0718 a:0.0771)
 a lot of the world.
This is a popular
5000: sample 0: Hello, I'm a language model,
------
		( quickest:0.1836,:0.9570 I:1.0000'm:1.0000 a:0.9648 language:1.0000 model:1.0000,:1.0000)
		(,:0.0486 I:0.2070 am:0.1328 not:0.0698 bit:0.1113 that:0.0659 for:0.1748 I:0.1592)
		( to:0.0579 I:0.1216 am:0.1387 not:0.0674 bit:0.1182 for:0.0674 for:0.1699 but:0.1680)
		( to:0.0806 I:0.0820 am:0.1416 not:0.0698 bit:0.1187 for:0.0674 for:0.1592 but:0.1748)
		( to:0.0996 I:0.0693 am:0.1377 not:0.0718 bit:0.1201 for:0.0684 for:0.1621 but:0.1680)
		( to:0.1094 I:0.0640 am:0.1455 not:0.0747 bit:0.1187 for:0.0693 for:0.1660 but:0.1680)
		( to:0.1128 I:0.0615 am:0.1406 not:0.0732 bit:0.1167 for:0.0703 for:0.1631 but:0.1748)
		( to:0.1050 I:0.0659 am:0.1416 not:0.0718 bit:0.1128 for:0.0747 for:0.1650 but:0.1680)
		( to:0.0933 I:0.0703 am:0.1426 not:0.0718 bit:0.1157 for:0.0747 for:0.1602 but:0.1719)
		( to:0.0781 I:0.0737 am:0.1484 not:0.0732 bit:0.1172 for:0.0752 for:0.1631 but:0.1670)
		( to:0.0669 I:0.0781 am:0.1543 not:0.0693 bit:0.1123 for:0.0747 for:0.1631 but:0.1660)
		( to:0.0598 I:0.0776 am:0.1504 not:0.0688 bit:0.1128 for:0.0752 for:0.1582 but:0.1680)
		( to:0.0508 I:0.0815 am:0.1543 not:0.0688 bit:0.1064 for:0.0713 for:0.1611 but:0.1689)
 but
------
		(,:0.9570 I:1.0000'm:1.0000 a:0.9648 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( I:0.2070 am:0.1328 not:0.0698 bit:0.1113 that:0.0659 for:0.1748 I:0.1592 I:0.4082)
		( I:0.1216 am:0.1387 not:0.0674 bit:0.1182 for:0.0674 for:0.1699 but:0.1680 I:0.4238)
		( I:0.0820 am:0.1416 not:0.0698 bit:0.1187 for:0.0674 for:0.1592 but:0.1748 I:0.3867)
		( I:0.0693 am:0.1377 not:0.0718 bit:0.1201 for:0.0684 for:0.1621 but:0.1680 I:0.3477)
		( I:0.0640 am:0.1455 not:0.0747 bit:0.1187 for:0.0693 for:0.1660 but:0.1680 I:0.3301)
		( I:0.0615 am:0.1406 not:0.0732 bit:0.1167 for:0.0703 for:0.1631 but:0.1748 I:0.3242)
		( I:0.0659 am:0.1416 not:0.0718 bit:0.1128 for:0.0747 for:0.1650 but:0.1680 I:0.3301)
		( I:0.0703 am:0.1426 not:0.0718 bit:0.1157 for:0.0747 for:0.1602 but:0.1719 I:0.3340)
		( I:0.0737 am:0.1484 not:0.0732 bit:0.1172 for:0.0752 for:0.1631 but:0.1670 I:0.3379)
		( I:0.0781 am:0.1543 not:0.0693 bit:0.1123 for:0.0747 for:0.1631 but:0.1660 I:0.3398)
		( I:0.0776 am:0.1504 not:0.0688 bit:0.1128 for:0.0752 for:0.1582 but:0.1680 I:0.3301)
		( I:0.0815 am:0.1543 not:0.0688 bit:0.1064 for:0.0713 for:0.1611 but:0.1689 I:0.3320)
 I have been to be a bit of a bit of
