1: sample 0: Hello, I'm a language model,
------
		( grades:0.0002,:0.0003Minimum:0.0001'm:0.0002andal:0.0002 Work:0.0002 model:0.0002,:0.0004)
		( grades:0.0002Wonder:0.0002 Pir:0.0002True:0.0002andal:0.0002 Work:0.0002883:0.0001 processing:0.0002)
		( grades:0.0002 Christian:0.0002 Pir:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 processing:0.0002)
		(acked:0.0002 Christian:0.0002 Pir:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Nigeria:0.0002 sun:0.0002 debris:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002 tightly:0.0001Donnell:0.0002 Nigeria:0.0002 sun:0.0002 debris:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002)
		( closer:0.0002 Christian:0.0002Index:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002dates:0.0002)
		( closer:0.0002 Christian:0.0002231:0.0002 tightly:0.0002Index:0.0002dates:0.0002 sun:0.0002dates:0.0002)
		( closer:0.0002 Christian:0.0002Index:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002dates:0.0002)
dates
------
		(,:0.0003Minimum:0.0001'm:0.0002andal:0.0002 Work:0.0002 model:0.0002,:0.0004dates:0.0003)
		(Wonder:0.0002 Pir:0.0002True:0.0002andal:0.0002 Work:0.0002883:0.0001 processing:0.0002dates:0.0002)
		( Christian:0.0002 Pir:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 processing:0.0002dates:0.0002)
		( Christian:0.0002 Pir:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Nigeria:0.0002 sun:0.0002 debris:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002 tightly:0.0001Donnell:0.0002 Nigeria:0.0002 sun:0.0002 debris:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002dates:0.0002)
		( Christian:0.0002Index:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002dates:0.0002dates:0.0002)
		( Christian:0.0002231:0.0002 tightly:0.0002Index:0.0002dates:0.0002 sun:0.0002dates:0.0002dates:0.0002)
		( Christian:0.0002Index:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002dates:0.0002dates:0.0002)
datesdatesdatesdatesdatesdatesdatesdatesdatesdatesdates
50: sample 0: Hello, I'm a language model,
------
		( At:0.0002,:0.0894,:0.0172,:0.0137 a:0.0447,:0.0117,:0.0154,:0.1846)
		(?:0.0004,:0.0588,:0.0283,:0.0233,:0.0410,:0.0238,:0.0286,:0.1553)
		(?:0.0006,:0.0471,:0.0352,:0.0291,:0.0476,:0.0339,:0.0374,:0.1406)
		( his:0.0008,:0.0405,:0.0393,:0.0337,:0.0520,:0.0415,:0.0442,:0.1318)
		():0.0010,:0.0381,:0.0427,:0.0366,:0.0564,:0.0479,:0.0493,:0.1270)
		( the:0.0013,:0.0359,:0.0452,:0.0386,:0.0581,:0.0518,:0.0537,:0.1226)
		( the:0.0017,:0.0347,:0.0464,:0.0408,:0.0593,:0.0562,:0.0566,:0.1187)
		( the:0.0022,:0.0334,:0.0479,:0.0430,:0.0610,:0.0591,:0.0598,:0.1147)
		( the:0.0026,:0.0334,:0.0491,:0.0439,:0.0630,:0.0623,:0.0613,:0.1113)
		( the:0.0029,:0.0334,:0.0505,:0.0452,:0.0645,:0.0640,:0.0630,:0.1113)
		( the:0.0034,:0.0332,:0.0505,:0.0464,:0.0645,:0.0654,:0.0630,:0.1084)
		( the:0.0036,:0.0322,:0.0520,:0.0461,:0.0664,:0.0674,:0.0649,:0.1079)
		( the:0.0034,:0.0333,:0.0504,:0.0464,:0.0645,:0.0591,:0.0373,:0.1555)
,
------
		(,:0.0894,:0.0172,:0.0137 a:0.0447,:0.0117,:0.0154,:0.1846,:0.1953)
		(,:0.0588,:0.0283,:0.0233,:0.0410,:0.0238,:0.0286,:0.1553,:0.1504)
		(,:0.0471,:0.0352,:0.0291,:0.0476,:0.0339,:0.0374,:0.1406,:0.1338)
		(,:0.0405,:0.0393,:0.0337,:0.0520,:0.0415,:0.0442,:0.1318,:0.1221)
		(,:0.0381,:0.0427,:0.0366,:0.0564,:0.0479,:0.0493,:0.1270,:0.1147)
		(,:0.0359,:0.0452,:0.0386,:0.0581,:0.0518,:0.0537,:0.1226,:0.1079)
		(,:0.0347,:0.0464,:0.0408,:0.0593,:0.0562,:0.0566,:0.1187,:0.1050)
		(,:0.0334,:0.0479,:0.0430,:0.0610,:0.0591,:0.0598,:0.1147,:0.1045)
		(,:0.0334,:0.0491,:0.0439,:0.0630,:0.0623,:0.0613,:0.1113,:0.1016)
		(,:0.0334,:0.0505,:0.0452,:0.0645,:0.0640,:0.0630,:0.1113,:0.1011)
		(,:0.0332,:0.0505,:0.0464,:0.0645,:0.0654,:0.0630,:0.1084,:0.0981)
		(,:0.0322,:0.0520,:0.0461,:0.0664,:0.0674,:0.0649,:0.1079,:0.0981)
		(,:0.1793,:0.0504,:0.0464,:0.0645,:0.0656,:0.0442,:0.1082,:0.1149)
,,,,,,,,,,,
200: sample 0: Hello, I'm a language model,
------
		( a:0.0033 of:0.0369 of:0.0294 of:0.0408 a:0.0991 of:0.0820 of:0.0991 of:0.1104)
		( a:0.0063 of:0.0571 of:0.0544 of:0.0781 a:0.0674 of:0.1377 of:0.1758 of:0.1504)
		( of:0.0118 of:0.0718 of:0.0703 of:0.1001 of:0.0815 of:0.1631 of:0.2139 of:0.1748)
		( of:0.0172 of:0.0796 of:0.0781 of:0.1138 of:0.0986 of:0.1748 of:0.2275 of:0.1787)
		( of:0.0215 of:0.0820 of:0.0811 of:0.1167 of:0.1099 of:0.1748 of:0.2285 of:0.1699)
		( of:0.0249 of:0.0835 of:0.0830 of:0.1152 of:0.1133 of:0.1689 of:0.2148 of:0.1650)
		( of:0.0276 of:0.0820 of:0.0820 of:0.1133 of:0.1157 of:0.1611 of:0.2021 of:0.1543)
		( of:0.0303 of:0.0801 of:0.0781 of:0.1069 of:0.1143 of:0.1494 of:0.1885 of:0.1436)
		( of:0.0311 of:0.0776 of:0.0762 of:0.1011 of:0.1089 of:0.1426 of:0.1738 of:0.1328)
		( of:0.0320 of:0.0752 of:0.0742 of:0.0981 of:0.1060 of:0.1309 of:0.1602 of:0.1260)
		( of:0.0325 of:0.0723 of:0.0698 of:0.0918 of:0.1030 of:0.1230 of:0.1475 of:0.1152)
		( of:0.0332 of:0.0698 of:0.0674 of:0.0859 of:0.0967 of:0.1152 of:0.1387 of:0.1084)
		( of:0.0326 of:0.0802 of:0.0701 of:0.0918 of:0.0817 of:0.0822 of:0.1759 of:0.1152)
 of
------
		( of:0.0369 of:0.0294 of:0.0408 a:0.0991 of:0.0820 of:0.0991 of:0.1104 of:0.3516)
		( of:0.0571 of:0.0544 of:0.0781 a:0.0674 of:0.1377 of:0.1758 of:0.1504 of:0.3535)
		( of:0.0718 of:0.0703 of:0.1001 of:0.0815 of:0.1631 of:0.2139 of:0.1748 of:0.3418)
		( of:0.0796 of:0.0781 of:0.1138 of:0.0986 of:0.1748 of:0.2275 of:0.1787 of:0.3203)
		( of:0.0820 of:0.0811 of:0.1167 of:0.1099 of:0.1748 of:0.2285 of:0.1699 of:0.3105)
		( of:0.0835 of:0.0830 of:0.1152 of:0.1133 of:0.1689 of:0.2148 of:0.1650 of:0.2832)
		( of:0.0820 of:0.0820 of:0.1133 of:0.1157 of:0.1611 of:0.2021 of:0.1543 of:0.2559)
		( of:0.0801 of:0.0781 of:0.1069 of:0.1143 of:0.1494 of:0.1885 of:0.1436 of:0.2285)
		( of:0.0776 of:0.0762 of:0.1011 of:0.1089 of:0.1426 of:0.1738 of:0.1328 of:0.2139)
		( of:0.0752 of:0.0742 of:0.0981 of:0.1060 of:0.1309 of:0.1602 of:0.1260 of:0.1982)
		( of:0.0723 of:0.0698 of:0.0918 of:0.1030 of:0.1230 of:0.1475 of:0.1152 of:0.1787)
		( of:0.0698 of:0.0674 of:0.0859 of:0.0967 of:0.1152 of:0.1387 of:0.1084 of:0.1641)
		( of:0.0725 of:0.0696 of:0.1153 a:0.0674 of:0.1377 of:0.0220 of:0.1508 of:0.3540)
 of of of of of of of of of of of
350: sample 0: Hello, I'm a language model,
------
		( a:0.0025 and:0.0253 I:0.0801 the:0.0076 the:0.0356 and:0.0119,:0.0132 the:0.0574)
		( a:0.0042 the:0.0256 I:0.0403 the:0.0120 the:0.0388 and:0.0201 of:0.0236 the:0.0640)
		( a:0.0057 the:0.0271 I:0.0250 the:0.0148 the:0.0403 and:0.0256 of:0.0325 the:0.0669)
		(-:0.0070 the:0.0265�:0.0184 the:0.0168 the:0.0396 and:0.0278 of:0.0361 the:0.0649)
		(-:0.0079 the:0.0260�:0.0179 the:0.0181 the:0.0378 and:0.0287 of:0.0359 the:0.0635)
		(-:0.0084 the:0.0250 and:0.0167 the:0.0190 the:0.0356 and:0.0283 of:0.0334 the:0.0613)
		(,:0.0087 the:0.0238 and:0.0164 the:0.0193 the:0.0339 and:0.0277,:0.0317 the:0.0586)
		( and:0.0095 the:0.0232 and:0.0165 the:0.0188 the:0.0320 and:0.0270,:0.0311 the:0.0554)
		( and:0.0097 the:0.0223 and:0.0159 the:0.0194 the:0.0300 and:0.0260,:0.0303 the:0.0520)
		( and:0.0099 the:0.0215 and:0.0153 the:0.0187 the:0.0289 and:0.0250,:0.0292 the:0.0486)
		( and:0.0101 the:0.0205 and:0.0147 the:0.0184 the:0.0269 and:0.0239,:0.0281 the:0.0466)
		( and:0.0103 the:0.0203 and:0.0145 the:0.0183 the:0.0256 and:0.0236,:0.0277 the:0.0447)
		( and:0.0101 and:0.0253 and:0.0147 the:0.0185 the:0.0269 and:0.0240,:0.0280 the:0.0520)
 the
------
		( and:0.0253 I:0.0801 the:0.0076 the:0.0356 and:0.0119,:0.0132 the:0.0574 the:0.0442)
		( the:0.0256 I:0.0403 the:0.0120 the:0.0388 and:0.0201 of:0.0236 the:0.0640 the:0.0405)
		( the:0.0271 I:0.0250 the:0.0148 the:0.0403 and:0.0256 of:0.0325 the:0.0669 the:0.0391)
		( the:0.0265�:0.0184 the:0.0168 the:0.0396 and:0.0278 of:0.0361 the:0.0649 the:0.0366)
		( the:0.0260�:0.0179 the:0.0181 the:0.0378 and:0.0287 of:0.0359 the:0.0635 the:0.0347)
		( the:0.0250 and:0.0167 the:0.0190 the:0.0356 and:0.0283 of:0.0334 the:0.0613 the:0.0334)
		( the:0.0238 and:0.0164 the:0.0193 the:0.0339 and:0.0277,:0.0317 the:0.0586 the:0.0317)
		( the:0.0232 and:0.0165 the:0.0188 the:0.0320 and:0.0270,:0.0311 the:0.0554 the:0.0298)
		( the:0.0223 and:0.0159 the:0.0194 the:0.0300 and:0.0260,:0.0303 the:0.0520 the:0.0288)
		( the:0.0215 and:0.0153 the:0.0187 the:0.0289 and:0.0250,:0.0292 the:0.0486 the:0.0267)
		( the:0.0205 and:0.0147 the:0.0184 the:0.0269 and:0.0239,:0.0281 the:0.0466 the:0.0256)
		( the:0.0203 and:0.0145 the:0.0183 the:0.0256 and:0.0236,:0.0277 the:0.0447 the:0.0253)
		( the:0.0206 and:0.0147 the:0.0185 the:0.0269 and:0.0240,:0.0280 the:0.0466 the:0.0257)
 the the the the the the of of of the the
500: sample 0: Hello, I'm a language model,
------
		(This:0.0024 the:0.0153 I:0.0615 the:0.0066 the:0.0249 the:0.0118 the:0.0098 the:0.0342)
		( the:0.0026 the:0.0217 I:0.0287 the:0.0120 the:0.0344 the:0.0192 the:0.0176 the:0.0474)
		( the:0.0043 the:0.0275 have:0.0193 the:0.0177 the:0.0447 the:0.0243 the:0.0243 the:0.0588)
		( the:0.0061 the:0.0320 have:0.0206 the:0.0221 the:0.0530 the:0.0287 the:0.0305 the:0.0674)
		( the:0.0078 the:0.0356 the:0.0226 the:0.0255 the:0.0581 the:0.0317 the:0.0347 the:0.0723)
		( the:0.0093 the:0.0378 the:0.0248 the:0.0287 the:0.0603 the:0.0332 the:0.0376 the:0.0762)
		( the:0.0105 the:0.0391 the:0.0259 the:0.0308 the:0.0613 the:0.0342 the:0.0388 the:0.0762)
		( the:0.0114 the:0.0400 the:0.0266 the:0.0315 the:0.0613 the:0.0349 the:0.0396 the:0.0776)
		( the:0.0123 the:0.0405 the:0.0271 the:0.0320 the:0.0605 the:0.0352 the:0.0400 the:0.0762)
		( the:0.0131 the:0.0396 the:0.0275 the:0.0322 the:0.0596 the:0.0352 the:0.0400 the:0.0747)
		( the:0.0135 the:0.0396 the:0.0276 the:0.0322 the:0.0562 the:0.0349 the:0.0400 the:0.0723)
		( the:0.0140 the:0.0393 the:0.0267 the:0.0320 the:0.0544 the:0.0337 the:0.0398 the:0.0698)
		( the:0.0135 the:0.0396 the:0.0276 the:0.0255 the:0.0562 the:0.0349 the:0.0401 the:0.0674)
 the
------
		( the:0.0153 I:0.0615 the:0.0066 the:0.0249 the:0.0118 the:0.0098 the:0.0342 the:0.0232)
		( the:0.0217 I:0.0287 the:0.0120 the:0.0344 the:0.0192 the:0.0176 the:0.0474 the:0.0212)
		( the:0.0275 have:0.0193 the:0.0177 the:0.0447 the:0.0243 the:0.0243 the:0.0588 the:0.0219)
		( the:0.0320 have:0.0206 the:0.0221 the:0.0530 the:0.0287 the:0.0305 the:0.0674 the:0.0228)
		( the:0.0356 the:0.0226 the:0.0255 the:0.0581 the:0.0317 the:0.0347 the:0.0723 the:0.0240)
		( the:0.0378 the:0.0248 the:0.0287 the:0.0603 the:0.0332 the:0.0376 the:0.0762 the:0.0240)
		( the:0.0391 the:0.0259 the:0.0308 the:0.0613 the:0.0342 the:0.0388 the:0.0762 the:0.0240)
		( the:0.0400 the:0.0266 the:0.0315 the:0.0613 the:0.0349 the:0.0396 the:0.0776 the:0.0247)
		( the:0.0405 the:0.0271 the:0.0320 the:0.0605 the:0.0352 the:0.0400 the:0.0762 the:0.0242)
		( the:0.0396 the:0.0275 the:0.0322 the:0.0596 the:0.0352 the:0.0400 the:0.0747 the:0.0236)
		( the:0.0396 the:0.0276 the:0.0322 the:0.0562 the:0.0349 the:0.0400 the:0.0723 the:0.0236)
		( the:0.0393 the:0.0267 the:0.0320 the:0.0544 the:0.0337 the:0.0398 the:0.0698 the:0.0227)
		( the:0.0396 the:0.0276 the:0.0322 the:0.0562 the:0.0349 the:0.0401 the:0.0722 the:0.0235)
 the the the the the of the of the of the
650: sample 0: Hello, I'm a language model,
------
		(This:0.0017 and:0.0161 I:0.0845'm:0.0188 a:0.0232 and:0.0060,:0.0054 and:0.0259)
		( it:0.0029 and:0.0145 I:0.0366 am:0.0076 a:0.0197 and:0.0128 and:0.0110 and:0.0272)
		( is:0.0038 and:0.0149 I:0.0222 a:0.0066 a:0.0204 and:0.0198 and:0.0173 and:0.0310)
		( is:0.0051 and:0.0153 have:0.0225 a:0.0092 the:0.0234 and:0.0245 and:0.0221 and:0.0330)
		( is:0.0063 and:0.0151 have:0.0243 a:0.0118 the:0.0280 and:0.0280,:0.0260 the:0.0369)
		( is:0.0070 the:0.0164 have:0.0247 a:0.0139 the:0.0312 and:0.0292,:0.0287 the:0.0398)
		( is:0.0076 the:0.0179 have:0.0251 a:0.0154 the:0.0339,:0.0288,:0.0302 the:0.0425)
		( is:0.0081 the:0.0189 have:0.0244 a:0.0170 the:0.0352,:0.0292,:0.0305 the:0.0447)
		( is:0.0084 the:0.0195 have:0.0234 a:0.0177 the:0.0356,:0.0293,:0.0305 the:0.0452)
		(.:0.0088 the:0.0203 have:0.0222 a:0.0184 the:0.0361,:0.0291,:0.0304 the:0.0454)
		(.:0.0092 the:0.0205 have:0.0209 a:0.0192 the:0.0361,:0.0289,:0.0300 the:0.0452)
		(.:0.0095 the:0.0206 have:0.0199 a:0.0197 the:0.0347,:0.0277,:0.0295 the:0.0435)
		(.:0.0092 the:0.0205 I:0.0844 a:0.0191 a:0.0197,:0.0289,:0.0300 the:0.0452)
 the
------
		( and:0.0161 I:0.0845'm:0.0188 a:0.0232 and:0.0060,:0.0054 and:0.0259 the:0.0128)
		( and:0.0145 I:0.0366 am:0.0076 a:0.0197 and:0.0128 and:0.0110 and:0.0272 the:0.0106)
		( and:0.0149 I:0.0222 a:0.0066 a:0.0204 and:0.0198 and:0.0173 and:0.0310 the:0.0115)
		( and:0.0153 have:0.0225 a:0.0092 the:0.0234 and:0.0245 and:0.0221 and:0.0330 the:0.0131)
		( and:0.0151 have:0.0243 a:0.0118 the:0.0280 and:0.0280,:0.0260 the:0.0369.:0.0156)
		( the:0.0164 have:0.0247 a:0.0139 the:0.0312 and:0.0292,:0.0287 the:0.0398.:0.0177)
		( the:0.0179 have:0.0251 a:0.0154 the:0.0339,:0.0288,:0.0302 the:0.0425.:0.0192)
		( the:0.0189 have:0.0244 a:0.0170 the:0.0352,:0.0292,:0.0305 the:0.0447.:0.0199)
		( the:0.0195 have:0.0234 a:0.0177 the:0.0356,:0.0293,:0.0305 the:0.0452.:0.0203)
		( the:0.0203 have:0.0222 a:0.0184 the:0.0361,:0.0291,:0.0304 the:0.0454.:0.0203)
		( the:0.0205 have:0.0209 a:0.0192 the:0.0361,:0.0289,:0.0300 the:0.0452.:0.0198)
		( the:0.0206 have:0.0199 a:0.0197 the:0.0347,:0.0277,:0.0295 the:0.0435.:0.0193)
		( the:0.0205 have:0.0209 a:0.0191 the:0.0360,:0.0289,:0.0300 the:0.0426.:0.0198)
.
---------
800: sample 0: Hello, I'm a language model,
------
		(�:0.0033 more:0.0072 I:0.0613'm:0.0303 a:0.0089�:0.0072�:0.0077 and:0.0095)
		( more:0.0044 more:0.0078 I:0.0264 am:0.0081 a:0.0068�:0.0072�:0.0075 the:0.0106)
		( more:0.0048 more:0.0077 I:0.0176 want:0.0086 the:0.0083.:0.0075.:0.0063 the:0.0156)
		( more:0.0050 more:0.0073 have:0.0137 want:0.0085 the:0.0110.:0.0115.:0.0097 the:0.0212)
		(.:0.0052 and:0.0075 have:0.0155 able:0.0081 the:0.0140.:0.0159.:0.0134 the:0.0273)
		(.:0.0067 the:0.0086 have:0.0168 able:0.0083 the:0.0165.:0.0200.:0.0171 the:0.0315)
		(.:0.0081.:0.0101 have:0.0175 able:0.0083 the:0.0183.:0.0239.:0.0200 the:0.0354)
		(.:0.0093.:0.0118 have:0.0177.:0.0084 the:0.0199.:0.0272.:0.0227 the:0.0378)
		(.:0.0104.:0.0134 have:0.0177.:0.0098 the:0.0211.:0.0297.:0.0249 the:0.0388)
		(.:0.0114.:0.0147 have:0.0175.:0.0114 the:0.0217.:0.0317.:0.0266 the:0.0393)
		(.:0.0123.:0.0159 have:0.0170.:0.0126 the:0.0221.:0.0334.:0.0278 the:0.0393)
		(.:0.0130.:0.0168.:0.0178.:0.0138 the:0.0223.:0.0344.:0.0286 the:0.0393)
		(.:0.0122.:0.0158 have:0.0170.:0.0126 a:0.0068.:0.0200.:0.0171 the:0.0394)
 the
------
		( more:0.0072 I:0.0613'm:0.0303 a:0.0089�:0.0072�:0.0077 and:0.0095 the:0.0070)
		( more:0.0078 I:0.0264 am:0.0081 a:0.0068�:0.0072�:0.0075 the:0.0106 the:0.0068)
		( more:0.0077 I:0.0176 want:0.0086 the:0.0083.:0.0075.:0.0063 the:0.0156 the:0.0086)
		( more:0.0073 have:0.0137 want:0.0085 the:0.0110.:0.0115.:0.0097 the:0.0212 the:0.0110)
		( and:0.0075 have:0.0155 able:0.0081 the:0.0140.:0.0159.:0.0134 the:0.0273 the:0.0133)
		( the:0.0086 have:0.0168 able:0.0083 the:0.0165.:0.0200.:0.0171 the:0.0315.:0.0167)
		(.:0.0101 have:0.0175 able:0.0083 the:0.0183.:0.0239.:0.0200 the:0.0354.:0.0206)
		(.:0.0118 have:0.0177.:0.0084 the:0.0199.:0.0272.:0.0227 the:0.0378.:0.0238)
		(.:0.0134 have:0.0177.:0.0098 the:0.0211.:0.0297.:0.0249 the:0.0388.:0.0262)
		(.:0.0147 have:0.0175.:0.0114 the:0.0217.:0.0317.:0.0266 the:0.0393.:0.0281)
		(.:0.0159 have:0.0170.:0.0126 the:0.0221.:0.0334.:0.0278 the:0.0393.:0.0293)
		(.:0.0168.:0.0178.:0.0138 the:0.0223.:0.0344.:0.0286 the:0.0393.:0.0298)
		(.:0.0158 have:0.0175.:0.0126 the:0.0221.:0.0335.:0.0279 the:0.0394.:0.0293)
.
.
-------
950: sample 0: Hello, I'm a language model,
------
		(�:0.0032 and:0.0075 I:0.0522'm:0.0306 a:0.0212�:0.0062�:0.0069 a:0.0099)
		( more:0.0033 a:0.0057 I:0.0193 am:0.0068 a:0.0143�:0.0060�:0.0062 the:0.0115)
		( it:0.0038 the:0.0067 have:0.0113 able:0.0088 a:0.0132 the:0.0062 the:0.0068 the:0.0166)
		( it:0.0045 the:0.0090 have:0.0134 able:0.0106 a:0.0133 the:0.0088 the:0.0095 the:0.0216)
		( it:0.0048 the:0.0113 have:0.0146 able:0.0116 the:0.0145 the:0.0110 the:0.0118 the:0.0260)
		( a:0.0050 the:0.0132 have:0.0152 able:0.0118 the:0.0166 the:0.0131 the:0.0138 the:0.0297)
		( a:0.0056 the:0.0150 have:0.0155 able:0.0117 the:0.0184 the:0.0144 the:0.0151 the:0.0317)
		( a:0.0062 the:0.0162 have:0.0153 able:0.0113 the:0.0199 the:0.0154,:0.0162 the:0.0334)
		( the:0.0066 the:0.0172 have:0.0148 able:0.0106 the:0.0209 the:0.0161,:0.0183 the:0.0339)
		( to:0.0072 the:0.0178 have:0.0143 a:0.0108 the:0.0215 the:0.0165,:0.0203 the:0.0339)
		( to:0.0078 the:0.0183 have:0.0135 a:0.0117 the:0.0215,:0.0167,:0.0216 the:0.0337)
		( to:0.0082 the:0.0186 have:0.0129 a:0.0123 the:0.0215,:0.0178,:0.0227 the:0.0330)
		( to:0.0078 the:0.0184 have:0.0136 a:0.0117 the:0.0215,:0.0168,:0.0216 the:0.0336)
 the
------
		( and:0.0075 I:0.0522'm:0.0306 a:0.0212�:0.0062�:0.0069 a:0.0099 the:0.0079)
		( a:0.0057 I:0.0193 am:0.0068 a:0.0143�:0.0060�:0.0062 the:0.0115 the:0.0067)
		( the:0.0067 have:0.0113 able:0.0088 a:0.0132 the:0.0062 the:0.0068 the:0.0166 the:0.0078)
		( the:0.0090 have:0.0134 able:0.0106 a:0.0133 the:0.0088 the:0.0095 the:0.0216 the:0.0093)
		( the:0.0113 have:0.0146 able:0.0116 the:0.0145 the:0.0110 the:0.0118 the:0.0260 the:0.0109)
		( the:0.0132 have:0.0152 able:0.0118 the:0.0166 the:0.0131 the:0.0138 the:0.0297 the:0.0121)
		( the:0.0150 have:0.0155 able:0.0117 the:0.0184 the:0.0144 the:0.0151 the:0.0317 the:0.0131)
		( the:0.0162 have:0.0153 able:0.0113 the:0.0199 the:0.0154,:0.0162 the:0.0334.:0.0137)
		( the:0.0172 have:0.0148 able:0.0106 the:0.0209 the:0.0161,:0.0183 the:0.0339.:0.0149)
		( the:0.0178 have:0.0143 a:0.0108 the:0.0215 the:0.0165,:0.0203 the:0.0339.:0.0161)
		( the:0.0183 have:0.0135 a:0.0117 the:0.0215,:0.0167,:0.0216 the:0.0337.:0.0166)
		( the:0.0186 have:0.0129 a:0.0123 the:0.0215,:0.0178,:0.0227 the:0.0330.:0.0170)
		( the:0.0149 have:0.0136 a:0.0117 the:0.0215,:0.0168 the:0.0152 the:0.0336.:0.0166)
.










1100: sample 0: Hello, I'm a language model,
------
		(�:0.0041�:0.0091 I:0.0342'm:0.0493 a:0.0128�:0.0050�:0.0042 and:0.0086)
		(�:0.0042�:0.0110 I:0.0123 want:0.0107 a:0.0096�:0.0057�:0.0048�:0.0087)
		( a:0.0042 a:0.0108 need:0.0077 want:0.0099 a:0.0095�:0.0046 the:0.0047 a:0.0103)
		( a:0.0059 a:0.0120 need:0.0084 able:0.0104 a:0.0099 the:0.0071 the:0.0075 the:0.0145)
		( a:0.0074 a:0.0131 need:0.0085 able:0.0114 the:0.0109 the:0.0099 the:0.0105 the:0.0194)
		( a:0.0085 a:0.0140 a:0.0084 able:0.0120 the:0.0137 the:0.0127 the:0.0132 the:0.0242)
		( a:0.0096 the:0.0161 a:0.0098 able:0.0121 the:0.0165 the:0.0151 the:0.0156 the:0.0282)
		( a:0.0104 the:0.0183 a:0.0112 able:0.0120 the:0.0190 the:0.0172 the:0.0176 the:0.0320)
		( a:0.0109 the:0.0203 a:0.0123 a:0.0116 the:0.0210 the:0.0188 the:0.0194 the:0.0342)
		( a:0.0115 the:0.0215 the:0.0138 a:0.0126 the:0.0228 the:0.0199 the:0.0208 the:0.0361)
		( a:0.0119 the:0.0227 the:0.0150 a:0.0132 the:0.0239 the:0.0211 the:0.0220 the:0.0376)
		( a:0.0120 the:0.0238 the:0.0164 a:0.0140 the:0.0249 the:0.0220 the:0.0226 the:0.0383)
		( a:0.0119�:0.0110 the:0.0150 a:0.0133 the:0.0239 the:0.0212 the:0.0219 the:0.0376)
 the
------
		(�:0.0091 I:0.0342'm:0.0493 a:0.0128�:0.0050�:0.0042 and:0.0086 same:0.0059)
		(�:0.0110 I:0.0123 want:0.0107 a:0.0096�:0.0057�:0.0048�:0.0087 same:0.0069)
		( a:0.0108 need:0.0077 want:0.0099 a:0.0095�:0.0046 the:0.0047 a:0.0103 same:0.0067)
		( a:0.0120 need:0.0084 able:0.0104 a:0.0099 the:0.0071 the:0.0075 the:0.0145 the:0.0070)
		( a:0.0131 need:0.0085 able:0.0114 the:0.0109 the:0.0099 the:0.0105 the:0.0194 the:0.0092)
		( a:0.0140 a:0.0084 able:0.0120 the:0.0137 the:0.0127 the:0.0132 the:0.0242 the:0.0114)
		( the:0.0161 a:0.0098 able:0.0121 the:0.0165 the:0.0151 the:0.0156 the:0.0282 the:0.0133)
		( the:0.0183 a:0.0112 able:0.0120 the:0.0190 the:0.0172 the:0.0176 the:0.0320 the:0.0148)
		( the:0.0203 a:0.0123 a:0.0116 the:0.0210 the:0.0188 the:0.0194 the:0.0342 the:0.0162)
		( the:0.0215 the:0.0138 a:0.0126 the:0.0228 the:0.0199 the:0.0208 the:0.0361 the:0.0172)
		( the:0.0227 the:0.0150 a:0.0132 the:0.0239 the:0.0211 the:0.0220 the:0.0376 the:0.0179)
		( the:0.0238 the:0.0164 a:0.0140 the:0.0249 the:0.0220 the:0.0226 the:0.0383 the:0.0186)
		( the:0.0227 the:0.0150 a:0.0133 the:0.0239 the:0.0212 the:0.0219 the:0.0376 the:0.0180)
 the the the the the the the the the the the
1250: sample 0: Hello, I'm a language model,
------
		(�:0.0054�:0.0115 I:0.0332'm:0.0247 a:0.0112�:0.0057 problem:0.0047�:0.0120)
		(�:0.0062�:0.0157 I:0.0126�:0.0090 a:0.0078�:0.0082�:0.0050�:0.0146)
		(�:0.0056�:0.0156�:0.0095�:0.0074 a:0.0074�:0.0075 and:0.0062�:0.0121)
		(�:0.0045�:0.0130�:0.0076 need:0.0063 a:0.0080 and:0.0100 and:0.0094 and:0.0109)
		( a:0.0056�:0.0103 need:0.0070 going:0.0058 the:0.0103 and:0.0129 and:0.0126 the:0.0145)
		( a:0.0067 and:0.0107 need:0.0068 going:0.0060 the:0.0140 and:0.0153 and:0.0152 the:0.0189)
		( a:0.0075 and:0.0114 a:0.0078 a:0.0066 the:0.0176 and:0.0170 and:0.0172 the:0.0231)
		( The:0.0084 the:0.0131 the:0.0093 a:0.0075 the:0.0210 and:0.0182 and:0.0186 the:0.0269)
		(
:0.0092 the:0.0153 the:0.0112 the:0.0087 the:0.0240 and:0.0188 and:0.0193 the:0.0297)
		(
:0.0101 the:0.0171 the:0.0131 the:0.0101 the:0.0261 the:0.0200 the:0.0204 the:0.0315)
		(
:0.0108 the:0.0187 the:0.0147 the:0.0114 the:0.0278 the:0.0212 the:0.0219 the:0.0332)
		(
:0.0113 the:0.0200 the:0.0161 the:0.0126 the:0.0294 the:0.0223 the:0.0228 the:0.0344)
		(
:0.0108 the:0.0187 the:0.0147 the:0.0114 the:0.0279 the:0.0212 the:0.0218 the:0.0332)
 the
------
		(�:0.0115 I:0.0332'm:0.0247 a:0.0112�:0.0057 problem:0.0047�:0.0120�:0.0055)
		(�:0.0157 I:0.0126�:0.0090 a:0.0078�:0.0082�:0.0050�:0.0146�:0.0056)
		(�:0.0156�:0.0095�:0.0074 a:0.0074�:0.0075 and:0.0062�:0.0121 the:0.0055)
		(�:0.0130�:0.0076 need:0.0063 a:0.0080 and:0.0100 and:0.0094 and:0.0109 the:0.0080)
		(�:0.0103 need:0.0070 going:0.0058 the:0.0103 and:0.0129 and:0.0126 the:0.0145 the:0.0110)
		( and:0.0107 need:0.0068 going:0.0060 the:0.0140 and:0.0153 and:0.0152 the:0.0189 the:0.0140)
		( and:0.0114 a:0.0078 a:0.0066 the:0.0176 and:0.0170 and:0.0172 the:0.0231 the:0.0170)
		( the:0.0131 the:0.0093 a:0.0075 the:0.0210 and:0.0182 and:0.0186 the:0.0269 the:0.0193)
		( the:0.0153 the:0.0112 the:0.0087 the:0.0240 and:0.0188 and:0.0193 the:0.0297 the:0.0211)
		( the:0.0171 the:0.0131 the:0.0101 the:0.0261 the:0.0200 the:0.0204 the:0.0315 the:0.0228)
		( the:0.0187 the:0.0147 the:0.0114 the:0.0278 the:0.0212 the:0.0219 the:0.0332 the:0.0237)
		( the:0.0200 the:0.0161 the:0.0126 the:0.0294 the:0.0223 the:0.0228 the:0.0344 the:0.0245)
		( the:0.0187 the:0.0147 the:0.0114 the:0.0279�:0.0057 the:0.0218 the:0.0332 the:0.0236)
 the the the the the the the the the the the
1400: sample 0: Hello, I'm a language model,
------
		(�:0.0050�:0.0070 I:0.0386'm:0.0378 a:0.0140 language:0.0074 data:0.0054�:0.0101)
		(�:0.0051�:0.0082 I:0.0135�:0.0089 a:0.0106�:0.0077 data:0.0041�:0.0115)
		(�:0.0043�:0.0076�:0.0101�:0.0077 a:0.0115�:0.0065 and:0.0051 a:0.0109)
		(�:0.0035 and:0.0096�:0.0084�:0.0060 a:0.0131 and:0.0107 and:0.0092 and:0.0134)
		(
:0.0048 and:0.0123�:0.0066 a:0.0074 a:0.0151 and:0.0153 and:0.0135 and:0.0165)
		(
:0.0063 and:0.0145 a:0.0076 a:0.0094 a:0.0170 and:0.0195 and:0.0176 and:0.0194)
		(
:0.0078 and:0.0167 and:0.0095 a:0.0112 a:0.0187 and:0.0227 and:0.0209 and:0.0219)
		(
:0.0090 and:0.0187 and:0.0114 a:0.0131 a:0.0200 and:0.0251 and:0.0238 and:0.0240)
		(
:0.0101 and:0.0203 and:0.0130 a:0.0146 a:0.0211 and:0.0270 and:0.0256 the:0.0255)
		(
:0.0109 and:0.0214 and:0.0144 a:0.0159 a:0.0219 and:0.0284 and:0.0272 the:0.0266)
		(
:0.0117 and:0.0223 and:0.0156 a:0.0170 a:0.0223 and:0.0293 and:0.0283 and:0.0276)
		( and:0.0122 and:0.0232 and:0.0165 a:0.0177 a:0.0226 and:0.0298 and:0.0292 the:0.0278)
		(
:0.0117 and:0.0223 and:0.0156 a:0.0170 a:0.0115 and:0.0293 and:0.0283 and:0.0276)
 and
------
		(�:0.0070 I:0.0386'm:0.0378 a:0.0140 language:0.0074 data:0.0054�:0.0101 and:0.0091)
		(�:0.0082 I:0.0135�:0.0089 a:0.0106�:0.0077 data:0.0041�:0.0115 a:0.0083)
		(�:0.0076�:0.0101�:0.0077 a:0.0115�:0.0065 and:0.0051 a:0.0109 a:0.0101)
		( and:0.0096�:0.0084�:0.0060 a:0.0131 and:0.0107 and:0.0092 and:0.0134 a:0.0123)
		( and:0.0123�:0.0066 a:0.0074 a:0.0151 and:0.0153 and:0.0135 and:0.0165 the:0.0161)
		( and:0.0145 a:0.0076 a:0.0094 a:0.0170 and:0.0195 and:0.0176 and:0.0194 the:0.0194)
		( and:0.0167 and:0.0095 a:0.0112 a:0.0187 and:0.0227 and:0.0209 and:0.0219 the:0.0222)
		( and:0.0187 and:0.0114 a:0.0131 a:0.0200 and:0.0251 and:0.0238 and:0.0240 the:0.0242)
		( and:0.0203 and:0.0130 a:0.0146 a:0.0211 and:0.0270 and:0.0256 the:0.0255 the:0.0254)
		( and:0.0214 and:0.0144 a:0.0159 a:0.0219 and:0.0284 and:0.0272 the:0.0266 the:0.0266)
		( and:0.0223 and:0.0156 a:0.0170 a:0.0223 and:0.0293 and:0.0283 and:0.0276 the:0.0272)
		( and:0.0232 and:0.0165 a:0.0177 a:0.0226 and:0.0298 and:0.0292 the:0.0278 the:0.0271)
		( and:0.0223 and:0.0156 a:0.0170 a:0.0224 and:0.0293 and:0.0283�:0.0115 the:0.0272)
 the the the the the the the the, the the
1550: sample 0: Hello, I'm a language model,
------
		(�:0.0030�:0.0039 I:0.0752'm:0.0449 a:0.0061 language:0.0071 data:0.0045�:0.0087)
		(�:0.0028 it:0.0042 I:0.0265'm:0.0102 a:0.0057�:0.0063 work:0.0036�:0.0093)
		( I:0.0025 it:0.0051 I:0.0150 need:0.0061 a:0.0073�:0.0049 work:0.0034 a:0.0079)
		(
:0.0031 a:0.0062 I:0.0104 need:0.0054 a:0.0098 it:0.0045 a:0.0049 a:0.0108)
		(
:0.0043 a:0.0084 I:0.0080 used:0.0056 a:0.0128 to:0.0067 to:0.0074 a:0.0142)
		( to:0.0057 a:0.0105 a:0.0072 a:0.0068 a:0.0156 is:0.0090 to:0.0099 a:0.0176)
		( to:0.0072 a:0.0127 a:0.0095 a:0.0087 a:0.0184 is:0.0110 to:0.0121 the:0.0211)
		( to:0.0087 a:0.0148 a:0.0116 a:0.0105 a:0.0209 of:0.0128,:0.0147 the:0.0245)
		( to:0.0099 a:0.0166 a:0.0136 a:0.0120 a:0.0228,:0.0151,:0.0177 the:0.0270)
		( to:0.0110 a:0.0183 a:0.0156 a:0.0133 a:0.0244,:0.0170,:0.0203 the:0.0292)
		( to:0.0120 a:0.0195 a:0.0172 a:0.0145 a:0.0255,:0.0186,:0.0223 the:0.0303)
		( to:0.0127 a:0.0209 a:0.0186 a:0.0154 a:0.0264,:0.0199,:0.0240 the:0.0315)
		( to:0.0119 a:0.0196 a:0.0136 a:0.0145 a:0.0256,:0.0186,:0.0177 the:0.0292)
 the
------
		(�:0.0039 I:0.0752'm:0.0449 a:0.0061 language:0.0071 data:0.0045�:0.0087 most:0.0058)
		( it:0.0042 I:0.0265'm:0.0102 a:0.0057�:0.0063 work:0.0036�:0.0093 most:0.0050)
		( it:0.0051 I:0.0150 need:0.0061 a:0.0073�:0.0049 work:0.0034 a:0.0079 the:0.0066)
		( a:0.0062 I:0.0104 need:0.0054 a:0.0098 it:0.0045 a:0.0049 a:0.0108 the:0.0094)
		( a:0.0084 I:0.0080 used:0.0056 a:0.0128 to:0.0067 to:0.0074 a:0.0142 the:0.0125)
		( a:0.0105 a:0.0072 a:0.0068 a:0.0156 is:0.0090 to:0.0099 a:0.0176 the:0.0157)
		( a:0.0127 a:0.0095 a:0.0087 a:0.0184 is:0.0110 to:0.0121 the:0.0211 the:0.0184)
		( a:0.0148 a:0.0116 a:0.0105 a:0.0209 of:0.0128,:0.0147 the:0.0245 the:0.0208)
		( a:0.0166 a:0.0136 a:0.0120 a:0.0228,:0.0151,:0.0177 the:0.0270 the:0.0223)
		( a:0.0183 a:0.0156 a:0.0133 a:0.0244,:0.0170,:0.0203 the:0.0292 the:0.0236)
		( a:0.0195 a:0.0172 a:0.0145 a:0.0255,:0.0186,:0.0223 the:0.0303 the:0.0242)
		( a:0.0209 a:0.0186 a:0.0154 a:0.0264,:0.0199,:0.0240 the:0.0315 the:0.0248)
		( a:0.0196 a:0.0172 a:0.0145 a:0.0256,:0.0186,:0.0224 the:0.0302 the:0.0242)
 the the the the the the the the the the the
