1: sample 0: Hello, I'm a language model,
------
		(Hello:0.0020,:0.0023 I:0.0005'm:0.0014 a:0.0008 language:0.0006 model:0.0023,:0.0026)
		(.:0.0002,:0.0008.:0.0002 the:0.0003 a:0.0003.:0.0002 model:0.0004,:0.0009)
		( and:0.0003,:0.0005.:0.0003 the:0.0004.:0.0002.:0.0003 and:0.0002,:0.0006)
		( and:0.0004,:0.0004.:0.0003 the:0.0004,:0.0002.:0.0003 and:0.0003,:0.0005)
		( and:0.0005 and:0.0004.:0.0003 the:0.0004,:0.0003.:0.0003 the:0.0003,:0.0005)
		( and:0.0005 and:0.0005,:0.0003 the:0.0004,:0.0003 the:0.0003 the:0.0003,:0.0005)
		( and:0.0005 and:0.0005,:0.0003 the:0.0004,:0.0003 the:0.0004 the:0.0004,:0.0004)
		( and:0.0005 and:0.0005,:0.0003 the:0.0004,:0.0003 the:0.0004 the:0.0004,:0.0004)
		( and:0.0005 and:0.0005,:0.0003 the:0.0004,:0.0003 the:0.0004,:0.0004,:0.0004)
		( and:0.0005 and:0.0005,:0.0004 the:0.0004,:0.0003 the:0.0004,:0.0004,:0.0004)
		( and:0.0005 and:0.0005,:0.0004 the:0.0004,:0.0003 the:0.0004,:0.0004,:0.0004)
		( and:0.0005 and:0.0005,:0.0004 the:0.0004,:0.0003 the:0.0004,:0.0004,:0.0004)
		( and:0.0005 and:0.0005,:0.0004 the:0.0004,:0.0003 the:0.0004,:0.0004,:0.0004)
,
------
		(,:0.0023 I:0.0005'm:0.0014 a:0.0008 language:0.0006 model:0.0023,:0.0026,:0.0017)
		(,:0.0008.:0.0002 the:0.0003 a:0.0003.:0.0002 model:0.0004,:0.0009,:0.0008)
		(,:0.0005.:0.0003 the:0.0004.:0.0002.:0.0003 and:0.0002,:0.0006,:0.0006)
		(,:0.0004.:0.0003 the:0.0004,:0.0002.:0.0003 and:0.0003,:0.0005,:0.0005)
		( and:0.0004.:0.0003 the:0.0004,:0.0003.:0.0003 the:0.0003,:0.0005,:0.0005)
		( and:0.0005,:0.0003 the:0.0004,:0.0003 the:0.0003 the:0.0003,:0.0005,:0.0005)
		( and:0.0005,:0.0003 the:0.0004,:0.0003 the:0.0004 the:0.0004,:0.0004,:0.0005)
		( and:0.0005,:0.0003 the:0.0004,:0.0003 the:0.0004 the:0.0004,:0.0004,:0.0005)
		( and:0.0005,:0.0003 the:0.0004,:0.0003 the:0.0004,:0.0004,:0.0004 the:0.0005)
		( and:0.0005,:0.0004 the:0.0004,:0.0003 the:0.0004,:0.0004,:0.0004 the:0.0005)
		( and:0.0005,:0.0004 the:0.0004,:0.0003 the:0.0004,:0.0004,:0.0004 the:0.0005)
		( and:0.0005,:0.0004 the:0.0004,:0.0003 the:0.0004,:0.0004,:0.0004 the:0.0005)
		( and:0.0005,:0.0004 the:0.0004,:0.0003 the:0.0004,:0.0004,:0.0004 the:0.0005)
 the the the the the the the the the the the
50: sample 0: Hello, I'm a language model,
------
		(
:0.0859 to:0.0630,:0.0623 the:0.1182 the:0.0415,:0.0854,:0.0898 the:0.0315)
		(.:0.0771 to:0.0664,:0.0635 the:0.1143 the:0.0413 of:0.0972 of:0.0952 the:0.0276)
		(.:0.0737 to:0.0659,:0.0635 the:0.1123 the:0.0415 of:0.1021 of:0.1021 the:0.0250)
		(.:0.0708 of:0.0703 of:0.0654 the:0.1118 the:0.0410 of:0.1079 of:0.1030 the:0.0234)
		(,:0.0664 of:0.0708 of:0.0698 the:0.1113 the:0.0417 of:0.1089 of:0.1045 the:0.0220)
		(,:0.0659 of:0.0757 of:0.0723 the:0.1113 the:0.0427 of:0.1099 of:0.1064 and:0.0227)
		(,:0.0654 of:0.0762 of:0.0747 the:0.1113 the:0.0439 of:0.1108 of:0.1074 and:0.0240)
		(,:0.0640 of:0.0767 of:0.0771 the:0.1055 the:0.0437 of:0.1118 of:0.1089 and:0.0248)
		(,:0.0645 of:0.0811 of:0.0776 the:0.1055 the:0.0449 of:0.1128 of:0.1094 and:0.0262)
		(,:0.0630 of:0.0815 of:0.0781 the:0.1055 the:0.0461 of:0.1138 of:0.1040 and:0.0262)
		(,:0.0635 of:0.0825 of:0.0830 the:0.1055 the:0.0459 of:0.1143 of:0.1055 and:0.0270)
		(,:0.0640 of:0.0825 of:0.0835 the:0.1060 the:0.0474 of:0.1157 of:0.1060 and:0.0278)
		(,:0.0640 of:0.0825 of:0.0835 the:0.1060 the:0.0474 of:0.1157 of:0.1060 and:0.0278)
 and
------
		( to:0.0630,:0.0623 the:0.1182 the:0.0415,:0.0854,:0.0898 the:0.0315 the:0.0776)
		( to:0.0664,:0.0635 the:0.1143 the:0.0413 of:0.0972 of:0.0952 the:0.0276 the:0.0757)
		( to:0.0659,:0.0635 the:0.1123 the:0.0415 of:0.1021 of:0.1021 the:0.0250 the:0.0791)
		( of:0.0703 of:0.0654 the:0.1118 the:0.0410 of:0.1079 of:0.1030 the:0.0234 the:0.0786)
		( of:0.0708 of:0.0698 the:0.1113 the:0.0417 of:0.1089 of:0.1045 the:0.0220 the:0.0781)
		( of:0.0757 of:0.0723 the:0.1113 the:0.0427 of:0.1099 of:0.1064 and:0.0227 the:0.0825)
		( of:0.0762 of:0.0747 the:0.1113 the:0.0439 of:0.1108 of:0.1074 and:0.0240 the:0.0825)
		( of:0.0767 of:0.0771 the:0.1055 the:0.0437 of:0.1118 of:0.1089 and:0.0248 the:0.0825)
		( of:0.0811 of:0.0776 the:0.1055 the:0.0449 of:0.1128 of:0.1094 and:0.0262 the:0.0825)
		( of:0.0815 of:0.0781 the:0.1055 the:0.0461 of:0.1138 of:0.1040 and:0.0262 the:0.0825)
		( of:0.0825 of:0.0830 the:0.1055 the:0.0459 of:0.1143 of:0.1055 and:0.0270 the:0.0874)
		( of:0.0825 of:0.0835 the:0.1060 the:0.0474 of:0.1157 of:0.1060 and:0.0278 the:0.0874)
		( of:0.0825 of:0.0835 the:0.1060 the:0.0474 of:0.1157 of:0.1060 and:0.0278 the:0.0874)
 the�s and the�s of the�s
200: sample 0: Hello, I'm a language model,
------
		( the:0.0630 the:0.1260 have:0.0476 not:0.1475 child:0.0179,:0.1719,:0.1426 the:0.0593)
		( the:0.0515 the:0.1094 have:0.0496 not:0.1611 child:0.0188,:0.1650,:0.1357 the:0.0649)
		( the:0.0432 the:0.0996 have:0.0525 not:0.1602 child:0.0182,:0.1572,:0.1367 the:0.0674)
		( the:0.0361 the:0.0918 have:0.0527 not:0.1562 child:0.0177,:0.1504,:0.1309 the:0.0679)
		( and:0.0339 the:0.0874 have:0.0532 not:0.1611 child:0.0167,:0.1504,:0.1318 the:0.0684)
		( and:0.0320 the:0.0825 have:0.0542 not:0.1553 child:0.0162,:0.1436,:0.1260 the:0.0688)
		( and:0.0309 the:0.0806 have:0.0547 not:0.1572 child:0.0157,:0.1367,:0.1270 the:0.0693)
		( and:0.0298 the:0.0781 have:0.0554 not:0.1514 child:0.0154,:0.1367,:0.1206 the:0.0679)
		( and:0.0288 the:0.0781 have:0.0562 not:0.1523 child:0.0150,:0.1299,:0.1216 the:0.0684)
		( and:0.0278 the:0.0781 have:0.0537 not:0.1533 child:0.0145,:0.1240,:0.1157 the:0.0684)
		( and:0.0269 the:0.0762 have:0.0542 not:0.1465 child:0.0145,:0.1240,:0.1128 the:0.0664)
		( and:0.0259 the:0.0757 have:0.0549 not:0.1465 child:0.0142,:0.1172,:0.1138 the:0.0669)
		( and:0.0259 the:0.0757 have:0.0549 not:0.1465 child:0.0142,:0.1172,:0.1138 the:0.0669)
 the
------
		( the:0.1260 have:0.0476 not:0.1475 child:0.0179,:0.1719,:0.1426 the:0.0593 time:0.0103)
		( the:0.1094 have:0.0496 not:0.1611 child:0.0188,:0.1650,:0.1357 the:0.0649 time:0.0101)
		( the:0.0996 have:0.0525 not:0.1602 child:0.0182,:0.1572,:0.1367 the:0.0674 same:0.0102)
		( the:0.0918 have:0.0527 not:0.1562 child:0.0177,:0.1504,:0.1309 the:0.0679 same:0.0103)
		( the:0.0874 have:0.0532 not:0.1611 child:0.0167,:0.1504,:0.1318 the:0.0684 first:0.0101)
		( the:0.0825 have:0.0542 not:0.1553 child:0.0162,:0.1436,:0.1260 the:0.0688 first:0.0102)
		( the:0.0806 have:0.0547 not:0.1572 child:0.0157,:0.1367,:0.1270 the:0.0693 first:0.0103)
		( the:0.0781 have:0.0554 not:0.1514 child:0.0154,:0.1367,:0.1206 the:0.0679 first:0.0103)
		( the:0.0781 have:0.0562 not:0.1523 child:0.0150,:0.1299,:0.1216 the:0.0684 first:0.0103)
		( the:0.0781 have:0.0537 not:0.1533 child:0.0145,:0.1240,:0.1157 the:0.0684 first:0.0101)
		( the:0.0762 have:0.0542 not:0.1465 child:0.0145,:0.1240,:0.1128 the:0.0664 first:0.0101)
		( the:0.0757 have:0.0549 not:0.1465 child:0.0142,:0.1172,:0.1138 the:0.0669 first:0.0101)
		( the:0.0757 have:0.0549 not:0.1465 child:0.0142,:0.1172,:0.1138 the:0.0669 first:0.0101)
 first.
The first is the same time.

350: sample 0: Hello, I'm a language model,
------
		(�:0.0640 the:0.0786�:0.0708 the:0.1377 great:0.0209,:0.1289 of:0.0771 the:0.0684)
		( the:0.0732 the:0.0386�:0.0732 the:0.1226 lot:0.0255,:0.1328,:0.0854 the:0.0757)
		( the:0.0791 the:0.0303�:0.0723 the:0.1162 lot:0.0277,:0.1309,:0.0962 and:0.0815)
		( the:0.0801 �:0.0320�:0.0679 the:0.1045 lot:0.0284,:0.1367,:0.1030 and:0.0903)
		( the:0.0825 �:0.0334�:0.0645 the:0.0938 lot:0.0292,:0.1367,:0.1074 and:0.0918)
		( the:0.0801 �:0.0337�:0.0615 the:0.0898 lot:0.0300,:0.1357,:0.1074 and:0.0933)
		( the:0.0781 �:0.0342�:0.0593 the:0.0801 lot:0.0309,:0.1348,:0.1133 and:0.0947)
		( the:0.0767 and:0.0347�:0.0610 the:0.0762 lot:0.0309,:0.1348,:0.1138 and:0.0962)
		( the:0.0728 and:0.0366�:0.0598 the:0.0703 lot:0.0309,:0.1348,:0.1143 and:0.0972)
		( the:0.0708 and:0.0383�:0.0620 the:0.0669 lot:0.0309,:0.1348,:0.1147 and:0.0981)
		( the:0.0688 and:0.0391�:0.0613 the:0.0630 lot:0.0308,:0.1279,:0.1162 and:0.0938)
		( the:0.0669 and:0.0410�:0.0645 the:0.0613 lot:0.0308,:0.1270,:0.1167 and:0.0942)
		( the:0.0669 and:0.0410�:0.0645 the:0.0613 lot:0.0308,:0.1270,:0.1167 and:0.0942)
 and
------
		( the:0.0786�:0.0708 the:0.1377 great:0.0209,:0.1289 of:0.0771 the:0.0684 the:0.1128)
		( the:0.0386�:0.0732 the:0.1226 lot:0.0255,:0.1328,:0.0854 the:0.0757 the:0.1221)
		( the:0.0303�:0.0723 the:0.1162 lot:0.0277,:0.1309,:0.0962 and:0.0815 the:0.1279)
		( �:0.0320�:0.0679 the:0.1045 lot:0.0284,:0.1367,:0.1030 and:0.0903 the:0.1279)
		( �:0.0334�:0.0645 the:0.0938 lot:0.0292,:0.1367,:0.1074 and:0.0918 the:0.1279)
		( �:0.0337�:0.0615 the:0.0898 lot:0.0300,:0.1357,:0.1074 and:0.0933 the:0.1211)
		( �:0.0342�:0.0593 the:0.0801 lot:0.0309,:0.1348,:0.1133 and:0.0947 the:0.1216)
		( and:0.0347�:0.0610 the:0.0762 lot:0.0309,:0.1348,:0.1138 and:0.0962 the:0.1147)
		( and:0.0366�:0.0598 the:0.0703 lot:0.0309,:0.1348,:0.1143 and:0.0972 the:0.1147)
		( and:0.0383�:0.0620 the:0.0669 lot:0.0309,:0.1348,:0.1147 and:0.0981 the:0.1089)
		( and:0.0391�:0.0613 the:0.0630 lot:0.0308,:0.1279,:0.1162 and:0.0938 the:0.1060)
		( and:0.0410�:0.0645 the:0.0613 lot:0.0308,:0.1270,:0.1167 and:0.0942 the:0.1030)
		( and:0.0410�:0.0645 the:0.0613 lot:0.0308,:0.1270,:0.1167 and:0.0942 the:0.1030)
 the most a few years, and the most important of
500: sample 0: Hello, I'm a language model,
------
		(�:0.1162 the:0.0525�:0.0781 not:0.0718 few:0.0260,:0.2100,:0.1348 I:0.0576)
		(�:0.1079 the:0.0620�:0.0688 not:0.0830 few:0.0261,:0.2139,:0.1387 I:0.0669)
		(�:0.1084 the:0.0598�:0.0630 not:0.0894 few:0.0256,:0.2217,:0.1367 I:0.0679)
		(�:0.1089 the:0.0586�:0.0559 not:0.0991 few:0.0253,:0.2188,:0.1436 I:0.0684)
		(�:0.1084 the:0.0579�:0.0535 not:0.1040 few:0.0243,:0.2070,:0.1348 I:0.0654)
		(�:0.1074 the:0.0574�:0.0522 not:0.1025 few:0.0240,:0.2061,:0.1357 I:0.0640)
		(�:0.1060 the:0.0557�:0.0542 not:0.1016 few:0.0233,:0.1953,:0.1367 I:0.0613)
		(�:0.1016 it:0.0559�:0.0537 not:0.1006 few:0.0232,:0.1963,:0.1309 I:0.0603)
		(�:0.0972 it:0.0598�:0.0532 not:0.0991 few:0.0225,:0.1865,:0.1318 I:0.0574)
		(�:0.0952 it:0.0623�:0.0527 not:0.0981 few:0.0225,:0.1777,:0.1260 I:0.0562)
		(�:0.0903 it:0.0630�:0.0527 not:0.0967 few:0.0223,:0.1699,:0.1206 I:0.0535)
		(�:0.0859 it:0.0659�:0.0525 not:0.0957 few:0.0217,:0.1709,:0.1221 I:0.0522)
		(�:0.0859 it:0.0659�:0.0525 not:0.0957 few:0.0217,:0.1709,:0.1221 I:0.0522)
 I
------
		( the:0.0525�:0.0781 not:0.0718 few:0.0260,:0.2100,:0.1348 I:0.0576�:0.0583)
		( the:0.0620�:0.0688 not:0.0830 few:0.0261,:0.2139,:0.1387 I:0.0669�:0.0544)
		( the:0.0598�:0.0630 not:0.0894 few:0.0256,:0.2217,:0.1367 I:0.0679�:0.0510)
		( the:0.0586�:0.0559 not:0.0991 few:0.0253,:0.2188,:0.1436 I:0.0684�:0.0469)
		( the:0.0579�:0.0535 not:0.1040 few:0.0243,:0.2070,:0.1348 I:0.0654�:0.0449)
		( the:0.0574�:0.0522 not:0.1025 few:0.0240,:0.2061,:0.1357 I:0.0640�:0.0439)
		( the:0.0557�:0.0542 not:0.1016 few:0.0233,:0.1953,:0.1367 I:0.0613 know:0.0447)
		( it:0.0559�:0.0537 not:0.1006 few:0.0232,:0.1963,:0.1309 I:0.0603 know:0.0447)
		( it:0.0598�:0.0532 not:0.0991 few:0.0225,:0.1865,:0.1318 I:0.0574 know:0.0454)
		( it:0.0623�:0.0527 not:0.0981 few:0.0225,:0.1777,:0.1260 I:0.0562 know:0.0464)
		( it:0.0630�:0.0527 not:0.0967 few:0.0223,:0.1699,:0.1206 I:0.0535 know:0.0449)
		( it:0.0659�:0.0525 not:0.0957 few:0.0217,:0.1709,:0.1221 I:0.0522 know:0.0464)
		( it:0.0659�:0.0525 not:0.0957 few:0.0217,:0.1709,:0.1221 I:0.0522 know:0.0464)
 know what I know what I know what I know what
650: sample 0: Hello, I'm a language model,
------
		(,:0.0898 and:0.0623,:0.0928 a:0.0315 little:0.0238,:0.2324,:0.1553 and:0.1216)
		(,:0.0771 and:0.0928,:0.1055 a:0.0334 little:0.0265,:0.2363,:0.1641 and:0.1455)
		(,:0.0728 and:0.0811,:0.0859 a:0.0312 little:0.0273,:0.2314,:0.1660 and:0.1416)
		(,:0.0679 and:0.0723,:0.0684 not:0.0310 little:0.0273,:0.2178,:0.1621 and:0.1396)
		(,:0.0654 the:0.0649,:0.0549 not:0.0330 little:0.0273,:0.2178,:0.1592 and:0.1387)
		(,:0.0649 the:0.0645,:0.0454 not:0.0349 little:0.0266,:0.2070,:0.1494 and:0.1387)
		(,:0.0640 the:0.0645 was:0.0474 not:0.0371 few:0.0253,:0.1973,:0.1484 and:0.1309)
		(,:0.0649 the:0.0640 was:0.0525 not:0.0383 new:0.0250,:0.1875,:0.1406 and:0.1309)
		(,:0.0640 the:0.0623 was:0.0566 not:0.0396 new:0.0247,:0.1787,:0.1396 and:0.1309)
		(�:0.0684 the:0.0625 was:0.0613 not:0.0410 new:0.0245,:0.1719,:0.1338 and:0.1309)
		(�:0.0737 the:0.0625 was:0.0645 not:0.0413 new:0.0251,:0.1631,:0.1338 and:0.1250)
		(�:0.0796 the:0.0625 was:0.0674 not:0.0427 new:0.0243,:0.1562,:0.1270 and:0.1245)
		(�:0.0796 the:0.0625 was:0.0674 not:0.0427 new:0.0243,:0.1562,:0.1270 and:0.1245)
 and
------
		( and:0.0623,:0.0928 a:0.0315 little:0.0238,:0.2324,:0.1553 and:0.1216 the:0.1104)
		( and:0.0928,:0.1055 a:0.0334 little:0.0265,:0.2363,:0.1641 and:0.1455 the:0.0928)
		( and:0.0811,:0.0859 a:0.0312 little:0.0273,:0.2314,:0.1660 and:0.1416 the:0.0845)
		( and:0.0723,:0.0684 not:0.0310 little:0.0273,:0.2178,:0.1621 and:0.1396 the:0.0771)
		( the:0.0649,:0.0549 not:0.0330 little:0.0273,:0.2178,:0.1592 and:0.1387 the:0.0703)
		( the:0.0645,:0.0454 not:0.0349 little:0.0266,:0.2070,:0.1494 and:0.1387 the:0.0684)
		( the:0.0645 was:0.0474 not:0.0371 few:0.0253,:0.1973,:0.1484 and:0.1309 the:0.0640)
		( the:0.0640 was:0.0525 not:0.0383 new:0.0250,:0.1875,:0.1406 and:0.1309 the:0.0603)
		( the:0.0623 was:0.0566 not:0.0396 new:0.0247,:0.1787,:0.1396 and:0.1309 the:0.0583)
		( the:0.0625 was:0.0613 not:0.0410 new:0.0245,:0.1719,:0.1338 and:0.1309 the:0.0564)
		( the:0.0625 was:0.0645 not:0.0413 new:0.0251,:0.1631,:0.1338 and:0.1250 the:0.0544)
		( the:0.0625 was:0.0674 not:0.0427 new:0.0243,:0.1562,:0.1270 and:0.1245 the:0.0542)
		( the:0.0625 was:0.0674 not:0.0427 new:0.0243,:0.1562,:0.1270 and:0.1245 the:0.0542)
 the same.
The first is a very important part
800: sample 0: Hello, I'm a language model,
------
		(,:0.1250 and:0.0376,:0.1865 not:0.0439 little:0.0265,:0.1748,:0.1211 I:0.1367)
		(,:0.1089 and:0.0508,:0.1436 not:0.0552 little:0.0361,:0.1807,:0.1187 I:0.1245)
		(,:0.1162 I:0.0664,:0.1055 not:0.0576 little:0.0432,:0.1865,:0.1226 I:0.1050)
		(,:0.1260 I:0.0791,:0.0786 not:0.0569 little:0.0476,:0.1934,:0.1279 and:0.1030)
		(,:0.1367 I:0.0859,:0.0610 not:0.0549 little:0.0520,:0.1914,:0.1270 and:0.1084)
		(,:0.1484 I:0.0928,:0.0496 sure:0.0535 little:0.0540,:0.1914,:0.1260 and:0.1138)
		(,:0.1562 I:0.0947�:0.0486 sure:0.0527 little:0.0564,:0.1934,:0.1270 and:0.1138)
		(,:0.1650 I:0.0981�:0.0481 sure:0.0493 little:0.0574,:0.1943,:0.1279 and:0.1143)
		(,:0.1689 I:0.0991�:0.0491 not:0.0466 little:0.0583,:0.1846,:0.1289 and:0.1143)
		(,:0.1748 I:0.1001�:0.0491 not:0.0471 little:0.0593,:0.1865,:0.1235 and:0.1147)
		(,:0.1758 I:0.0986�:0.0488 not:0.0479 few:0.0601,:0.1787,:0.1250 and:0.1094)
		(,:0.1777 I:0.0977�:0.0491 not:0.0476 few:0.0613,:0.1797,:0.1260 and:0.1089)
		(,:0.1777 I:0.0977�:0.0491 not:0.0476 few:0.0613,:0.1797,:0.1260 and:0.1089)
 and
------
		( and:0.0376,:0.1865 not:0.0439 little:0.0265,:0.1748,:0.1211 I:0.1367 the:0.1128)
		( and:0.0508,:0.1436 not:0.0552 little:0.0361,:0.1807,:0.1187 I:0.1245 I:0.1025)
		( I:0.0664,:0.1055 not:0.0576 little:0.0432,:0.1865,:0.1226 I:0.1050 I:0.1055)
		( I:0.0791,:0.0786 not:0.0569 little:0.0476,:0.1934,:0.1279 and:0.1030 I:0.1113)
		( I:0.0859,:0.0610 not:0.0549 little:0.0520,:0.1914,:0.1270 and:0.1084 I:0.1147)
		( I:0.0928,:0.0496 sure:0.0535 little:0.0540,:0.1914,:0.1260 and:0.1138 I:0.1172)
		( I:0.0947�:0.0486 sure:0.0527 little:0.0564,:0.1934,:0.1270 and:0.1138 I:0.1172)
		( I:0.0981�:0.0481 sure:0.0493 little:0.0574,:0.1943,:0.1279 and:0.1143 I:0.1177)
		( I:0.0991�:0.0491 not:0.0466 little:0.0583,:0.1846,:0.1289 and:0.1143 I:0.1177)
		( I:0.1001�:0.0491 not:0.0471 little:0.0593,:0.1865,:0.1235 and:0.1147 I:0.1245)
		( I:0.0986�:0.0488 not:0.0479 few:0.0601,:0.1787,:0.1250 and:0.1094 I:0.1250)
		( I:0.0977�:0.0491 not:0.0476 few:0.0613,:0.1797,:0.1260 and:0.1089 I:0.1250)
		( I:0.0977�:0.0491 not:0.0476 few:0.0613,:0.1797,:0.1260 and:0.1089 I:0.1250)
 I'm not sure that I'm not sure that I
950: sample 0: Hello, I'm a language model,
------
		(,:0.1484 and:0.0413,:0.1230 not:0.0693 great:0.0334 of:0.1187 of:0.1543 and:0.0840)
		(,:0.1245 and:0.0508 was:0.1182 not:0.0879 great:0.0371,:0.1211 of:0.1514 and:0.0957)
		(,:0.1206 and:0.0454 was:0.1216 not:0.0908 great:0.0398,:0.1250 of:0.1357 and:0.1069)
		(,:0.1201 I:0.0461 was:0.1128 not:0.0918 great:0.0398,:0.1318 of:0.1318 and:0.1138)
		(,:0.1196 I:0.0476 was:0.1099 not:0.0908 great:0.0410,:0.1318 of:0.1230 and:0.1162)
		(,:0.1226 I:0.0479 was:0.1040 not:0.0898 great:0.0415,:0.1328 of:0.1152 and:0.1260)
		(,:0.1226 I:0.0483 was:0.1001 not:0.0894 little:0.0422,:0.1338 of:0.1094 and:0.1289)
		(,:0.1230 I:0.0488 was:0.0923 not:0.0859 little:0.0430,:0.1270 of:0.1089 and:0.1250)
		(,:0.1240 I:0.0496 was:0.0913 not:0.0854 little:0.0437,:0.1289,:0.1035 and:0.1279)
		(,:0.1250 I:0.0488 was:0.0908 not:0.0850 little:0.0432,:0.1299,:0.1045 and:0.1309)
		(,:0.1270 I:0.0493 was:0.0854 not:0.0845 little:0.0425,:0.1240,:0.1050 and:0.1338)
		():0.1279 I:0.0486 was:0.0854 not:0.0840 little:0.0430,:0.1250,:0.1060 and:0.1289)
		():0.1279 I:0.0486 was:0.0854 not:0.0840 little:0.0430,:0.1250,:0.1060 and:0.1289)
 and
------
		( and:0.0413,:0.1230 not:0.0693 great:0.0334 of:0.1187 of:0.1543 and:0.0840 I:0.1660)
		( and:0.0508 was:0.1182 not:0.0879 great:0.0371,:0.1211 of:0.1514 and:0.0957 I:0.1855)
		( and:0.0454 was:0.1216 not:0.0908 great:0.0398,:0.1250 of:0.1357 and:0.1069 I:0.1934)
		( I:0.0461 was:0.1128 not:0.0918 great:0.0398,:0.1318 of:0.1318 and:0.1138 I:0.2031)
		( I:0.0476 was:0.1099 not:0.0908 great:0.0410,:0.1318 of:0.1230 and:0.1162 I:0.2139)
		( I:0.0479 was:0.1040 not:0.0898 great:0.0415,:0.1328 of:0.1152 and:0.1260 I:0.2256)
		( I:0.0483 was:0.1001 not:0.0894 little:0.0422,:0.1338 of:0.1094 and:0.1289 I:0.2285)
		( I:0.0488 was:0.0923 not:0.0859 little:0.0430,:0.1270 of:0.1089 and:0.1250 I:0.2305)
		( I:0.0496 was:0.0913 not:0.0854 little:0.0437,:0.1289,:0.1035 and:0.1279 I:0.2324)
		( I:0.0488 was:0.0908 not:0.0850 little:0.0432,:0.1299,:0.1045 and:0.1309 I:0.2246)
		( I:0.0493 was:0.0854 not:0.0845 little:0.0425,:0.1240,:0.1050 and:0.1338 I:0.2275)
		( I:0.0486 was:0.0854 not:0.0840 little:0.0430,:0.1250,:0.1060 and:0.1289 I:0.2295)
		( I:0.0486 was:0.0854 not:0.0840 little:0.0430,:0.1250,:0.1060 and:0.1289 I:0.2295)
 I'm not sure to be sure to do it,
1100: sample 0: Hello, I'm a language model,
------
		(,:0.1001 the:0.0859,:0.1035,:0.1167 little:0.0398,:0.1396,:0.0977 and:0.1191)
		(,:0.1182 the:0.1143,:0.0752,:0.1025 little:0.0537,:0.1465,:0.1035 and:0.1201)
		(,:0.1206 the:0.1035 was:0.0732,:0.0898 little:0.0605,:0.1484,:0.1079 and:0.1250)
		(,:0.1235 the:0.0947 was:0.0723,:0.0811 little:0.0649,:0.1533,:0.1113 and:0.1309)
		(,:0.1196 the:0.0894 was:0.0708,:0.0732 little:0.0679,:0.1514,:0.1152 and:0.1318)
		(,:0.1196 the:0.0825 was:0.0674,:0.0679 little:0.0684,:0.1494,:0.1138 and:0.1338)
		(,:0.1138 the:0.0806 was:0.0659,:0.0654 little:0.0713,:0.1572,:0.1143 and:0.1357)
		(,:0.1108 the:0.0771 was:0.0654,:0.0630 little:0.0708,:0.1572,:0.1206 and:0.1318)
		(,:0.1055 the:0.0737 was:0.0654,:0.0630 little:0.0723,:0.1572,:0.1206 and:0.1348)
		(,:0.1035 the:0.0728 was:0.0659,:0.0630 little:0.0718,:0.1582,:0.1211 and:0.1299)
		(,:0.0986 I:0.0742 was:0.0630,:0.0630 little:0.0742,:0.1582,:0.1221 and:0.1328)
		(,:0.0938 you:0.0762 was:0.0640,:0.0635 little:0.0742,:0.1592,:0.1230 and:0.1279)
		(,:0.0938 you:0.0762 was:0.0640,:0.0635 little:0.0742,:0.1592,:0.1230 and:0.1279)
 and
------
		( the:0.0859,:0.1035,:0.1167 little:0.0398,:0.1396,:0.0977 and:0.1191 I:0.1562)
		( the:0.1143,:0.0752,:0.1025 little:0.0537,:0.1465,:0.1035 and:0.1201 I:0.1602)
		( the:0.1035 was:0.0732,:0.0898 little:0.0605,:0.1484,:0.1079 and:0.1250 I:0.1621)
		( the:0.0947 was:0.0723,:0.0811 little:0.0649,:0.1533,:0.1113 and:0.1309 I:0.1650)
		( the:0.0894 was:0.0708,:0.0732 little:0.0679,:0.1514,:0.1152 and:0.1318 I:0.1680)
		( the:0.0825 was:0.0674,:0.0679 little:0.0684,:0.1494,:0.1138 and:0.1338 I:0.1699)
		( the:0.0806 was:0.0659,:0.0654 little:0.0713,:0.1572,:0.1143 and:0.1357 I:0.1641)
		( the:0.0771 was:0.0654,:0.0630 little:0.0708,:0.1572,:0.1206 and:0.1318 I:0.1582)
		( the:0.0737 was:0.0654,:0.0630 little:0.0723,:0.1572,:0.1206 and:0.1348 I:0.1602)
		( the:0.0728 was:0.0659,:0.0630 little:0.0718,:0.1582,:0.1211 and:0.1299 I:0.1543)
		( I:0.0742 was:0.0630,:0.0630 little:0.0742,:0.1582,:0.1221 and:0.1328 I:0.1475)
		( you:0.0762 was:0.0640,:0.0635 little:0.0742,:0.1592,:0.1230 and:0.1279 I:0.1494)
		( you:0.0762 was:0.0640,:0.0635 little:0.0742,:0.1592,:0.1230 and:0.1279 I:0.1494)
 I'm not sure that I'm not sure that I
1250: sample 0: Hello, I'm a language model,
------
		(,:0.1904 and:0.0903,:0.0889,:0.1377 very:0.0342,:0.1621 of:0.1631 and:0.1699)
		(,:0.1699 and:0.0728�:0.1128,:0.0996 great:0.0391,:0.1445 of:0.1553 and:0.1719)
		(,:0.1660 and:0.0605�:0.1348,:0.0781 great:0.0422,:0.1426 of:0.1504 and:0.1777)
		(,:0.1572 the:0.0591�:0.1514,:0.0659 great:0.0425,:0.1494 of:0.1455 and:0.1777)
		(,:0.1484 the:0.0620�:0.1592 not:0.0635 great:0.0427,:0.1484 of:0.1436 and:0.1699)
		(,:0.1406 the:0.0649�:0.1709 not:0.0625 great:0.0415,:0.1484 of:0.1338 and:0.1719)
		(,:0.1338 the:0.0684�:0.1758 not:0.0640 great:0.0405,:0.1484 of:0.1348 and:0.1660)
		(,:0.1235 the:0.0693�:0.1836 not:0.0630 great:0.0400,:0.1572.:0.1357 and:0.1602)
		(,:0.1138 the:0.0728�:0.1914 not:0.0625 great:0.0393,:0.1582.:0.1387 and:0.1631)
		(,:0.1079 the:0.0742�:0.1914 not:0.0618 great:0.0388,:0.1582.:0.1328 and:0.1572)
		(,:0.0996 the:0.0762�:0.1914 not:0.0596 great:0.0381,:0.1582.:0.1357 and:0.1523)
		(,:0.0947 the:0.0776�:0.1914 not:0.0591 great:0.0376,:0.1592.:0.1377 and:0.1465)
		(,:0.0947 the:0.0776�:0.1914 not:0.0591 great:0.0376,:0.1592.:0.1377 and:0.1465)
 and
------
		( and:0.0903,:0.0889,:0.1377 very:0.0342,:0.1621 of:0.1631 and:0.1699 I:0.1768)
		( and:0.0728�:0.1128,:0.0996 great:0.0391,:0.1445 of:0.1553 and:0.1719 I:0.2031)
		( and:0.0605�:0.1348,:0.0781 great:0.0422,:0.1426 of:0.1504 and:0.1777 I:0.2197)
		( the:0.0591�:0.1514,:0.0659 great:0.0425,:0.1494 of:0.1455 and:0.1777 I:0.2383)
		( the:0.0620�:0.1592 not:0.0635 great:0.0427,:0.1484 of:0.1436 and:0.1699 I:0.2480)
		( the:0.0649�:0.1709 not:0.0625 great:0.0415,:0.1484 of:0.1338 and:0.1719 I:0.2461)
		( the:0.0684�:0.1758 not:0.0640 great:0.0405,:0.1484 of:0.1348 and:0.1660 I:0.2578)
		( the:0.0693�:0.1836 not:0.0630 great:0.0400,:0.1572.:0.1357 and:0.1602 I:0.2578)
		( the:0.0728�:0.1914 not:0.0625 great:0.0393,:0.1582.:0.1387 and:0.1631 I:0.2598)
		( the:0.0742�:0.1914 not:0.0618 great:0.0388,:0.1582.:0.1328 and:0.1572 I:0.2500)
		( the:0.0762�:0.1914 not:0.0596 great:0.0381,:0.1582.:0.1357 and:0.1523 I:0.2500)
		( the:0.0776�:0.1914 not:0.0591 great:0.0376,:0.1592.:0.1377 and:0.1465 I:0.2520)
		( the:0.0776�:0.1914 not:0.0591 great:0.0376,:0.1592.:0.1377 and:0.1465 I:0.2520)
 I have a lot more.
The first thing I
1400: sample 0: Hello, I'm a language model,
------
		(,:0.1416 the:0.0781�:0.1201,:0.1562 little:0.0344,:0.1279,:0.1064 and:0.2871)
		(,:0.1201 the:0.0913�:0.2002,:0.1299 little:0.0574,:0.1299,:0.1064 and:0.2715)
		(,:0.1128 the:0.0869�:0.2383,:0.1162 little:0.0645,:0.1309 for:0.1177 and:0.2500)
		(,:0.1045 the:0.0830�:0.2500,:0.1035 little:0.0649,:0.1270 for:0.1235 and:0.2480)
		(,:0.0977 the:0.0806�:0.2451,:0.0952 little:0.0649,:0.1240 for:0.1250 and:0.2354)
		(,:0.0913 the:0.0767�:0.2471,:0.0898 little:0.0630,:0.1191.:0.1216 and:0.2256)
		('s:0.0913 the:0.0752�:0.2285,:0.0879 little:0.0620,:0.1187.:0.1230 and:0.2178)
		('s:0.0923 the:0.0723�:0.2246,:0.0859 little:0.0596,:0.1182.:0.1250 and:0.2090)
		('s:0.0928 the:0.0713�:0.2119,:0.0840 little:0.0591,:0.1172.:0.1230 and:0.2021)
		('s:0.0938 the:0.0708�:0.2012,:0.0845 little:0.0569,:0.1167.:0.1250 and:0.1953)
		('s:0.0918 the:0.0679�:0.1914,:0.0850 little:0.0547,:0.1162.:0.1235 and:0.1885)
		('s:0.0898 the:0.0674�:0.1826,:0.0879 little:0.0527,:0.1157.:0.1260 and:0.1826)
		('s:0.0898 the:0.0674�:0.1826,:0.0879 little:0.0527,:0.1157.:0.1260 and:0.1826)
 and
------
		( the:0.0781�:0.1201,:0.1562 little:0.0344,:0.1279,:0.1064 and:0.2871 I:0.1973)
		( the:0.0913�:0.2002,:0.1299 little:0.0574,:0.1299,:0.1064 and:0.2715 I:0.2100)
		( the:0.0869�:0.2383,:0.1162 little:0.0645,:0.1309 for:0.1177 and:0.2500 I:0.2207)
		( the:0.0830�:0.2500,:0.1035 little:0.0649,:0.1270 for:0.1235 and:0.2480 I:0.2168)
		( the:0.0806�:0.2451,:0.0952 little:0.0649,:0.1240 for:0.1250 and:0.2354 I:0.2119)
		( the:0.0767�:0.2471,:0.0898 little:0.0630,:0.1191.:0.1216 and:0.2256 I:0.2070)
		( the:0.0752�:0.2285,:0.0879 little:0.0620,:0.1187.:0.1230 and:0.2178 I:0.2021)
		( the:0.0723�:0.2246,:0.0859 little:0.0596,:0.1182.:0.1250 and:0.2090 I:0.1875)
		( the:0.0713�:0.2119,:0.0840 little:0.0591,:0.1172.:0.1230 and:0.2021 I:0.1816)
		( the:0.0708�:0.2012,:0.0845 little:0.0569,:0.1167.:0.1250 and:0.1953 I:0.1768)
		( the:0.0679�:0.1914,:0.0850 little:0.0547,:0.1162.:0.1235 and:0.1885 I:0.1670)
		( the:0.0674�:0.1826,:0.0879 little:0.0527,:0.1157.:0.1260 and:0.1826 I:0.1572)
		( the:0.0674�:0.1826,:0.0879 little:0.0527,:0.1157.:0.1260 and:0.1826 I:0.1572)
 I'm not sure that I'm not sure that I
1550: sample 0: Hello, I'm a language model,
------
		(,:0.2754 and:0.0625,:0.1523,:0.1875 good:0.0222,:0.1348 of:0.1279 I:0.2012)
		(,:0.1943 and:0.0669,:0.0947,:0.1631 good:0.0317,:0.1113 of:0.1250 and:0.1895)
		(,:0.1553 and:0.0801 was:0.1016,:0.1396 good:0.0349,:0.0986 of:0.1201 and:0.2109)
		(,:0.1387 and:0.0898 was:0.1211,:0.1221 good:0.0356,:0.0894 of:0.1167 and:0.2139)
		(,:0.1245 and:0.0991 was:0.1299,:0.1094 good:0.0354,:0.0859 of:0.1133 and:0.2080)
		(,:0.1177 and:0.1035 was:0.1338,:0.0947 good:0.0349,:0.0811 of:0.1118 and:0.2129)
		(,:0.1104 and:0.1089 was:0.1318 not:0.0874 good:0.0334,:0.0811 of:0.1108 and:0.2178)
		(,:0.1045 and:0.1147 was:0.1318 not:0.0884 good:0.0312 that:0.0811 of:0.1099 and:0.2119)
		(,:0.1011 and:0.1216 was:0.1250 not:0.0898 good:0.0303.:0.0811 of:0.1074 and:0.2168)
		(,:0.0977 and:0.1245 was:0.1250 not:0.0913 good:0.0293.:0.0835.:0.1069 and:0.2119)
		(,:0.0942 and:0.1318 was:0.1191 not:0.0923 good:0.0275.:0.0864.:0.1079 and:0.2158)
		(,:0.0942 and:0.1357 was:0.1201 not:0.0938 good:0.0266.:0.0889.:0.1118 and:0.2100)
		(,:0.0942 and:0.1357 was:0.1201 not:0.0938 good:0.0266.:0.0889.:0.1118 and:0.2100)
 and
------
		( and:0.0625,:0.1523,:0.1875 good:0.0222,:0.1348 of:0.1279 I:0.2012 I:0.3926)
		( and:0.0669,:0.0947,:0.1631 good:0.0317,:0.1113 of:0.1250 and:0.1895 I:0.3906)
		( and:0.0801 was:0.1016,:0.1396 good:0.0349,:0.0986 of:0.1201 and:0.2109 I:0.3750)
		( and:0.0898 was:0.1211,:0.1221 good:0.0356,:0.0894 of:0.1167 and:0.2139 I:0.3652)
		( and:0.0991 was:0.1299,:0.1094 good:0.0354,:0.0859 of:0.1133 and:0.2080 I:0.3555)
		( and:0.1035 was:0.1338,:0.0947 good:0.0349,:0.0811 of:0.1118 and:0.2129 I:0.3320)
		( and:0.1089 was:0.1318 not:0.0874 good:0.0334,:0.0811 of:0.1108 and:0.2178 I:0.3086)
		( and:0.1147 was:0.1318 not:0.0884 good:0.0312 that:0.0811 of:0.1099 and:0.2119 I:0.3027)
		( and:0.1216 was:0.1250 not:0.0898 good:0.0303.:0.0811 of:0.1074 and:0.2168 I:0.2793)
		( and:0.1245 was:0.1250 not:0.0913 good:0.0293.:0.0835.:0.1069 and:0.2119 I:0.2598)
		( and:0.1318 was:0.1191 not:0.0923 good:0.0275.:0.0864.:0.1079 and:0.2158 I:0.2520)
		( and:0.1357 was:0.1201 not:0.0938 good:0.0266.:0.0889.:0.1118 and:0.2100 I:0.2324)
		( and:0.1357 was:0.1201 not:0.0938 good:0.0266.:0.0889.:0.1118 and:0.2100 I:0.2324)
 I'm not sure how to do it.
The
1700: sample 0: Hello, I'm a language model,
------
		(,:0.1621 a:0.0654,:0.0845,:0.1079 little:0.0503,:0.1113.:0.1138 and:0.2100)
		(,:0.1387 the:0.0986 was:0.0723 not:0.1191 little:0.0845,:0.1045.:0.1289 and:0.2207)
		(,:0.1318 the:0.0894 was:0.0884 not:0.1445 little:0.0854,:0.0991.:0.1396 and:0.2266)
		(,:0.1309 the:0.0854 was:0.0903 not:0.1562 little:0.0796,:0.0991.:0.1504 and:0.2314)
		(,:0.1338 the:0.0820 was:0.0889 not:0.1621 little:0.0732.:0.1001.:0.1553 and:0.2285)
		(,:0.1338 the:0.0781 was:0.0864 not:0.1621 little:0.0684.:0.1021.:0.1543 and:0.2246)
		(,:0.1348 and:0.0791 was:0.0869 not:0.1631 little:0.0618.:0.1074.:0.1641 and:0.2217)
		(,:0.1387 and:0.0874 was:0.0845 not:0.1582 little:0.0588.:0.1099.:0.1641 and:0.2295)
		(,:0.1357 and:0.0933 was:0.0879 not:0.1543 little:0.0542.:0.1094.:0.1660 and:0.2246)
		(,:0.1367 and:0.0996 was:0.0864 not:0.1514 little:0.0510.:0.1128.:0.1680 and:0.2197)
		(,:0.1338 and:0.1060 was:0.0859 not:0.1494 little:0.0479.:0.1157 of:0.1797 and:0.2246)
		(,:0.1309 and:0.1157 was:0.0859 not:0.1475 little:0.0461.:0.1187 of:0.1816 and:0.2295)
		(,:0.1309 and:0.1157 was:0.0859 not:0.1475 little:0.0461.:0.1187 of:0.1816 and:0.2295)
 and
------
		( a:0.0654,:0.0845,:0.1079 little:0.0503,:0.1113.:0.1138 and:0.2100 I:0.2129)
		( the:0.0986 was:0.0723 not:0.1191 little:0.0845,:0.1045.:0.1289 and:0.2207 I:0.2412)
		( the:0.0894 was:0.0884 not:0.1445 little:0.0854,:0.0991.:0.1396 and:0.2266 I:0.2461)
		( the:0.0854 was:0.0903 not:0.1562 little:0.0796,:0.0991.:0.1504 and:0.2314 I:0.2520)
		( the:0.0820 was:0.0889 not:0.1621 little:0.0732.:0.1001.:0.1553 and:0.2285 I:0.2412)
		( the:0.0781 was:0.0864 not:0.1621 little:0.0684.:0.1021.:0.1543 and:0.2246 I:0.2412)
		( and:0.0791 was:0.0869 not:0.1631 little:0.0618.:0.1074.:0.1641 and:0.2217 I:0.2256)
		( and:0.0874 was:0.0845 not:0.1582 little:0.0588.:0.1099.:0.1641 and:0.2295 I:0.2129)
		( and:0.0933 was:0.0879 not:0.1543 little:0.0542.:0.1094.:0.1660 and:0.2246 I:0.2080)
		( and:0.0996 was:0.0864 not:0.1514 little:0.0510.:0.1128.:0.1680 and:0.2197 I:0.1934)
		( and:0.1060 was:0.0859 not:0.1494 little:0.0479.:0.1157 of:0.1797 and:0.2246 I:0.1836)
		( and:0.1157 was:0.0859 not:0.1475 little:0.0461.:0.1187 of:0.1816 and:0.2295 I:0.1738)
		( and:0.1157 was:0.0859 not:0.1475 little:0.0461.:0.1187 of:0.1816 and:0.2295 I:0.1738)
 I'm not sure how to use the language.

1850: sample 0: Hello, I'm a language model,
------
		(,:0.1016 I:0.0349,:0.1001,:0.1621 little:0.0383 of:0.0884,:0.1357 and:0.2041)
		(,:0.0679 I:0.0664�:0.0889,:0.1011 little:0.0535 of:0.1348 of:0.1094 and:0.2100)
		(,:0.0515 I:0.0786 was:0.1079,:0.0679 little:0.0491 of:0.1426.:0.1162 and:0.2129)
		(,:0.0415 I:0.0884 was:0.1138 not:0.0679 little:0.0427 that:0.1562.:0.1250 and:0.2236)
		(,:0.0354 I:0.0928 was:0.1177 not:0.0713 little:0.0371 that:0.1719.:0.1338 and:0.2256)
		(�:0.0349 I:0.0928 was:0.1196 not:0.0713 little:0.0339 that:0.1826.:0.1367 and:0.2188)
		(�:0.0386 I:0.0908 was:0.1182 a:0.0737 little:0.0320 that:0.1855.:0.1387 and:0.2217)
		(�:0.0415 I:0.0859 was:0.1113 a:0.0791 little:0.0300 that:0.1816.:0.1494 and:0.2246)
		(�:0.0444 I:0.0815 was:0.1123 a:0.0830 little:0.0289 that:0.1846.:0.1455 and:0.2285)
		(�:0.0476 I:0.0752 was:0.1064 a:0.0894 great:0.0278 that:0.1787.:0.1475 and:0.2324)
		(�:0.0508 the:0.0698 was:0.1079 a:0.0942 little:0.0275 that:0.1826.:0.1494 and:0.2354)
		(�:0.0522 the:0.0713�:0.1104 a:0.0986 little:0.0264 that:0.1768.:0.1523 and:0.2393)
		(�:0.0522 the:0.0713�:0.1104 a:0.0986 little:0.0264 that:0.1768.:0.1523 and:0.2393)
 and
------
		( I:0.0349,:0.1001,:0.1621 little:0.0383 of:0.0884,:0.1357 and:0.2041 I:0.2158)
		( I:0.0664�:0.0889,:0.1011 little:0.0535 of:0.1348 of:0.1094 and:0.2100 I:0.2891)
		( I:0.0786 was:0.1079,:0.0679 little:0.0491 of:0.1426.:0.1162 and:0.2129 I:0.3145)
		( I:0.0884 was:0.1138 not:0.0679 little:0.0427 that:0.1562.:0.1250 and:0.2236 I:0.3145)
		( I:0.0928 was:0.1177 not:0.0713 little:0.0371 that:0.1719.:0.1338 and:0.2256 I:0.2988)
		( I:0.0928 was:0.1196 not:0.0713 little:0.0339 that:0.1826.:0.1367 and:0.2188 I:0.2910)
		( I:0.0908 was:0.1182 a:0.0737 little:0.0320 that:0.1855.:0.1387 and:0.2217 I:0.2812)
		( I:0.0859 was:0.1113 a:0.0791 little:0.0300 that:0.1816.:0.1494 and:0.2246 I:0.2715)
		( I:0.0815 was:0.1123 a:0.0830 little:0.0289 that:0.1846.:0.1455 and:0.2285 I:0.2500)
		( I:0.0752 was:0.1064 a:0.0894 great:0.0278 that:0.1787.:0.1475 and:0.2324 I:0.2412)
		( the:0.0698 was:0.1079 a:0.0942 little:0.0275 that:0.1826.:0.1494 and:0.2354 I:0.2314)
		( the:0.0713�:0.1104 a:0.0986 little:0.0264 that:0.1768.:0.1523 and:0.2393 I:0.2227)
		( the:0.0713�:0.1104 a:0.0986 little:0.0264 that:0.1768.:0.1523 and:0.2393 I:0.2227)
 I'm not sure to be sure of the program is
2000: sample 0: Hello, I'm a language model,
------
		(,:0.1357,:0.0315,:0.0791,:0.3125 little:0.0405,:0.1318,:0.1748 and:0.1650)
		(,:0.1245 you:0.0381 was:0.0850,:0.2139 little:0.0605 that:0.1113,:0.1226 and:0.1855)
		(,:0.1201 you:0.0581 was:0.1157,:0.1445 little:0.0571 that:0.1245,:0.1147 and:0.2070)
		(,:0.1201 you:0.0693 was:0.1289,:0.1040 little:0.0500 that:0.1328.:0.1162 and:0.2100)
		(,:0.1177 you:0.0747 was:0.1318 not:0.1030 little:0.0457 that:0.1318.:0.1221 and:0.2168)
		(,:0.1196 you:0.0791 was:0.1230 not:0.1064 little:0.0432 that:0.1396.:0.1279 and:0.2139)
		(,:0.1221 you:0.0815 was:0.1235 not:0.1079 little:0.0408 that:0.1406.:0.1299 and:0.2207)
		(,:0.1250 you:0.0845 was:0.1182 not:0.1074 little:0.0400 that:0.1416.:0.1396 and:0.2158)
		(,:0.1279 you:0.0874 was:0.1123 not:0.1074 little:0.0393 that:0.1426.:0.1406 and:0.2236)
		(,:0.1309 you:0.0884 was:0.1079 not:0.1084 little:0.0386 that:0.1436.:0.1426 and:0.2178)
		(,:0.1348 you:0.0894 was:0.1035 not:0.1064 little:0.0381 that:0.1367.:0.1436 and:0.2246)
		(,:0.1348 you:0.0903�:0.1055 not:0.1050 little:0.0374 that:0.1377.:0.1455 and:0.2197)
		(,:0.1348 you:0.0903�:0.1055 not:0.1050 little:0.0374 that:0.1377.:0.1455 and:0.2197)
 and
------
		(,:0.0315,:0.0791,:0.3125 little:0.0405,:0.1318,:0.1748 and:0.1650 I:0.2393)
		( you:0.0381 was:0.0850,:0.2139 little:0.0605 that:0.1113,:0.1226 and:0.1855 I:0.2949)
		( you:0.0581 was:0.1157,:0.1445 little:0.0571 that:0.1245,:0.1147 and:0.2070 I:0.3047)
		( you:0.0693 was:0.1289,:0.1040 little:0.0500 that:0.1328.:0.1162 and:0.2100 I:0.3008)
		( you:0.0747 was:0.1318 not:0.1030 little:0.0457 that:0.1318.:0.1221 and:0.2168 I:0.2852)
		( you:0.0791 was:0.1230 not:0.1064 little:0.0432 that:0.1396.:0.1279 and:0.2139 I:0.2812)
		( you:0.0815 was:0.1235 not:0.1079 little:0.0408 that:0.1406.:0.1299 and:0.2207 I:0.2617)
		( you:0.0845 was:0.1182 not:0.1074 little:0.0400 that:0.1416.:0.1396 and:0.2158 I:0.2578)
		( you:0.0874 was:0.1123 not:0.1074 little:0.0393 that:0.1426.:0.1406 and:0.2236 I:0.2393)
		( you:0.0884 was:0.1079 not:0.1084 little:0.0386 that:0.1436.:0.1426 and:0.2178 I:0.2334)
		( you:0.0894 was:0.1035 not:0.1064 little:0.0381 that:0.1367.:0.1436 and:0.2246 I:0.2178)
		( you:0.0903�:0.1055 not:0.1050 little:0.0374 that:0.1377.:0.1455 and:0.2197 I:0.2109)
		( you:0.0903�:0.1055 not:0.1050 little:0.0374 that:0.1377.:0.1455 and:0.2197 I:0.2109)
 I'm sure that I'm going to be a little
2150: sample 0: Hello, I'm a language model,
------
		(,:0.0908 and:0.0359,:0.0898,:0.3613 great:0.0413,:0.1040 of:0.2012 and:0.2070)
		(,:0.0854 the:0.0352 have:0.0791,:0.2480 great:0.0640 that:0.1060 of:0.2100 and:0.2734)
		(,:0.0864 the:0.0349 was:0.0791,:0.1621 great:0.0640 that:0.1157 of:0.2051 and:0.3125)
		(,:0.0864 the:0.0352 have:0.0796,:0.1089 great:0.0615 that:0.1196 of:0.1934 and:0.3301)
		(,:0.0933 and:0.0403 have:0.0791 a:0.1084 great:0.0574 that:0.1226 of:0.1904 and:0.3301)
		(,:0.1025 and:0.0464 have:0.0776 a:0.1143 great:0.0552 that:0.1245 of:0.1826 and:0.3359)
		(,:0.1147 and:0.0505 have:0.0771 a:0.1143 great:0.0518 that:0.1235 of:0.1846 and:0.3398)
		(,:0.1250 and:0.0537 have:0.0723 a:0.1177 great:0.0500 that:0.1235 of:0.1777 and:0.3457)
		(,:0.1338 and:0.0559 have:0.0688 a:0.1157 great:0.0486 that:0.1206 of:0.1738 and:0.3359)
		(,:0.1406 and:0.0579 have:0.0698 a:0.1162 great:0.0459 that:0.1211 of:0.1650 and:0.3418)
		(,:0.1436 and:0.0603 have:0.0669 a:0.1167 great:0.0435,:0.1187 of:0.1621 and:0.3477)
		(,:0.1475 and:0.0610 have:0.0640 a:0.1152 great:0.0410,:0.1191 of:0.1631 and:0.3398)
		(,:0.1475 and:0.0610 have:0.0640 a:0.1152 great:0.0410,:0.1191 of:0.1631 and:0.3398)
 and
------
		( and:0.0359,:0.0898,:0.3613 great:0.0413,:0.1040 of:0.2012 and:0.2070 I:0.3711)
		( the:0.0352 have:0.0791,:0.2480 great:0.0640 that:0.1060 of:0.2100 and:0.2734 I:0.3750)
		( the:0.0349 was:0.0791,:0.1621 great:0.0640 that:0.1157 of:0.2051 and:0.3125 I:0.3574)
		( the:0.0352 have:0.0796,:0.1089 great:0.0615 that:0.1196 of:0.1934 and:0.3301 I:0.3320)
		( and:0.0403 have:0.0791 a:0.1084 great:0.0574 that:0.1226 of:0.1904 and:0.3301 I:0.3203)
		( and:0.0464 have:0.0776 a:0.1143 great:0.0552 that:0.1245 of:0.1826 and:0.3359 I:0.3086)
		( and:0.0505 have:0.0771 a:0.1143 great:0.0518 that:0.1235 of:0.1846 and:0.3398 I:0.2969)
		( and:0.0537 have:0.0723 a:0.1177 great:0.0500 that:0.1235 of:0.1777 and:0.3457 I:0.2852)
		( and:0.0559 have:0.0688 a:0.1157 great:0.0486 that:0.1206 of:0.1738 and:0.3359 I:0.2871)
		( and:0.0579 have:0.0698 a:0.1162 great:0.0459 that:0.1211 of:0.1650 and:0.3418 I:0.2891)
		( and:0.0603 have:0.0669 a:0.1167 great:0.0435,:0.1187 of:0.1621 and:0.3477 I:0.2773)
		( and:0.0610 have:0.0640 a:0.1152 great:0.0410,:0.1191 of:0.1631 and:0.3398 I:0.2812)
		( and:0.0610 have:0.0640 a:0.1152 great:0.0410,:0.1191 of:0.1631 and:0.3398 I:0.2812)
 I'm a very good teacher.
- I'm
2300: sample 0: Hello, I'm a language model,
------
		(,:0.0762 the:0.0532 know:0.0598,:0.1914 great:0.0197.:0.0635.:0.1172 I:0.1543)
		(,:0.0664 the:0.0718 was:0.0952,:0.1216 great:0.0361 that:0.0747 that:0.1108 and:0.1631)
		(,:0.0625 the:0.0679 was:0.1138 not:0.1016 great:0.0405 that:0.0762.:0.1172 and:0.2012)
		(,:0.0613 the:0.0586 was:0.1162 not:0.1108 great:0.0400 that:0.0762.:0.1211 and:0.2158)
		(,:0.0630 the:0.0596 was:0.1108 not:0.1113 great:0.0403 that:0.0728.:0.1235 and:0.2207)
		(,:0.0698 you:0.0708 was:0.1006 not:0.1045 great:0.0393 that:0.0732.:0.1289 and:0.2246)
		(,:0.0786 you:0.0791 was:0.0928 not:0.1001 great:0.0403 that:0.0723.:0.1309 and:0.2275)
		(,:0.0854 you:0.0864 was:0.0859 not:0.0933 great:0.0403 that:0.0732.:0.1357 and:0.2314)
		(,:0.0933 you:0.0918 was:0.0806 not:0.0874 great:0.0405 that:0.0723.:0.1377 and:0.2354)
		(,:0.0986 you:0.0952 was:0.0757 not:0.0850 great:0.0400 that:0.0732.:0.1357 and:0.2393)
		(,:0.1035 the:0.0962 was:0.0718 not:0.0796 great:0.0408 that:0.0747.:0.1377 and:0.2422)
		(,:0.1055 the:0.1001�:0.0728 not:0.0771 great:0.0417 that:0.0757.:0.1396 and:0.2461)
		(,:0.1055 the:0.1001�:0.0728 not:0.0771 great:0.0417 that:0.0757.:0.1396 and:0.2461)
 and
------
		( the:0.0532 know:0.0598,:0.1914 great:0.0197.:0.0635.:0.1172 I:0.1543 I:0.2969)
		( the:0.0718 was:0.0952,:0.1216 great:0.0361 that:0.0747 that:0.1108 and:0.1631 I:0.3555)
		( the:0.0679 was:0.1138 not:0.1016 great:0.0405 that:0.0762.:0.1172 and:0.2012 I:0.3418)
		( the:0.0586 was:0.1162 not:0.1108 great:0.0400 that:0.0762.:0.1211 and:0.2158 I:0.3320)
		( the:0.0596 was:0.1108 not:0.1113 great:0.0403 that:0.0728.:0.1235 and:0.2207 I:0.3008)
		( you:0.0708 was:0.1006 not:0.1045 great:0.0393 that:0.0732.:0.1289 and:0.2246 I:0.2793)
		( you:0.0791 was:0.0928 not:0.1001 great:0.0403 that:0.0723.:0.1309 and:0.2275 I:0.2715)
		( you:0.0864 was:0.0859 not:0.0933 great:0.0403 that:0.0732.:0.1357 and:0.2314 I:0.2617)
		( you:0.0918 was:0.0806 not:0.0874 great:0.0405 that:0.0723.:0.1377 and:0.2354 I:0.2637)
		( you:0.0952 was:0.0757 not:0.0850 great:0.0400 that:0.0732.:0.1357 and:0.2393 I:0.2539)
		( the:0.0962 was:0.0718 not:0.0796 great:0.0408 that:0.0747.:0.1377 and:0.2422 I:0.2441)
		( the:0.1001�:0.0728 not:0.0771 great:0.0417 that:0.0757.:0.1396 and:0.2461 I:0.2471)
		( the:0.1001�:0.0728 not:0.0771 great:0.0417 that:0.0757.:0.1396 and:0.2461 I:0.2471)
 I'm not going to be a good teacher.

2450: sample 0: Hello, I'm a language model,
------
		(,:0.0649,:0.0583.:0.0669,:0.0933 friend:0.0216 that:0.0603 of:0.1133 and:0.1367)
		(,:0.0608 the:0.0884 was:0.0635 not:0.1167 great:0.0271 that:0.0703 that:0.1436 and:0.1855)
		(.:0.0713 the:0.0649 was:0.0771 not:0.1436 great:0.0278 that:0.0732 that:0.1709 and:0.2334)
		(.:0.0879 and:0.0698 was:0.0776 not:0.1592 member:0.0289 that:0.0654 that:0.1709 and:0.2539)
		(.:0.0996 and:0.0767 was:0.0752 not:0.1572 member:0.0303 that:0.0598 that:0.1689 and:0.2578)
		(,:0.1143 and:0.0830 was:0.0718 not:0.1582 member:0.0308 that:0.0586 that:0.1592 and:0.2637)
		(,:0.1426 and:0.0874�:0.0781 not:0.1611 member:0.0306 that:0.0576 that:0.1611 and:0.2559)
		(,:0.1611 and:0.0918�:0.0767 not:0.1582 member:0.0298 that:0.0566 that:0.1543 and:0.2598)
		(,:0.1748 and:0.0942�:0.0806 not:0.1650 member:0.0292 that:0.0559 that:0.1475 and:0.2637)
		(,:0.1846 and:0.0942�:0.0801 not:0.1631 member:0.0278 that:0.0564 that:0.1504 and:0.2676)
		(,:0.1904 and:0.0942�:0.0796 not:0.1621 member:0.0275 that:0.0557 that:0.1455 and:0.2598)
		(,:0.1963 and:0.0947�:0.0806 not:0.1611 member:0.0265 that:0.0562 that:0.1406 and:0.2637)
		(,:0.1963 and:0.0947�:0.0806 not:0.1611 member:0.0265 that:0.0562 that:0.1406 and:0.2637)
 and
------
		(,:0.0583.:0.0669,:0.0933 friend:0.0216 that:0.0603 of:0.1133 and:0.1367 I:0.2129)
		( the:0.0884 was:0.0635 not:0.1167 great:0.0271 that:0.0703 that:0.1436 and:0.1855 I:0.2227)
		( the:0.0649 was:0.0771 not:0.1436 great:0.0278 that:0.0732 that:0.1709 and:0.2334 I:0.1973)
		( and:0.0698 was:0.0776 not:0.1592 member:0.0289 that:0.0654 that:0.1709 and:0.2539 I:0.1816)
		( and:0.0767 was:0.0752 not:0.1572 member:0.0303 that:0.0598 that:0.1689 and:0.2578 I:0.1650)
		( and:0.0830 was:0.0718 not:0.1582 member:0.0308 that:0.0586 that:0.1592 and:0.2637 I:0.1582)
		( and:0.0874�:0.0781 not:0.1611 member:0.0306 that:0.0576 that:0.1611 and:0.2559 I:0.1504)
		( and:0.0918�:0.0767 not:0.1582 member:0.0298 that:0.0566 that:0.1543 and:0.2598 I:0.1514)
		( and:0.0942�:0.0806 not:0.1650 member:0.0292 that:0.0559 that:0.1475 and:0.2637 I:0.1523)
		( and:0.0942�:0.0801 not:0.1631 member:0.0278 that:0.0564 that:0.1504 and:0.2676 I:0.1455)
		( and:0.0942�:0.0796 not:0.1621 member:0.0275 that:0.0557 that:0.1455 and:0.2598 I:0.1455)
		( and:0.0947�:0.0806 not:0.1611 member:0.0265 that:0.0562 that:0.1406 and:0.2637 I:0.1475)
		( and:0.0947�:0.0806 not:0.1611 member:0.0265 that:0.0562 that:0.1406 and:0.2637 I:0.1475)
 I'm not sure that the system is a system that
2600: sample 0: Hello, I'm a language model,
------
		(,:0.0576 and:0.0623,:0.0513,:0.1299 friend:0.0187 that:0.1196 that:0.1484 and:0.1826)
		(,:0.0564 I:0.0776 have:0.0693,:0.1035 little:0.0315 that:0.1777 that:0.1660 and:0.1992)
		(,:0.0623 I:0.0835 have:0.0742,:0.0708 little:0.0352 that:0.1992 that:0.1865 and:0.2363)
		(,:0.0679 I:0.0840 have:0.0742 a:0.0845 little:0.0342 that:0.2080 that:0.1924 and:0.2539)
		(,:0.0752 I:0.0811 have:0.0718 a:0.0942 little:0.0325 that:0.1982 that:0.1914 and:0.2539)
		(,:0.0864 I:0.0796�:0.0742 a:0.0923 little:0.0327 that:0.1992 that:0.1826 and:0.2539)
		(,:0.0942 I:0.0786 have:0.0723 a:0.0903 little:0.0325 that:0.1895 that:0.1826 and:0.2432)
		(,:0.1021 I:0.0781 have:0.0713 a:0.0898 little:0.0339 that:0.1895.:0.1729 and:0.2441)
		(,:0.1064 I:0.0806 have:0.0742 a:0.0869 little:0.0344 that:0.1904.:0.1738 and:0.2461)
		(,:0.1084 I:0.0811 have:0.0732 a:0.0845 little:0.0352 that:0.1904.:0.1768 and:0.2363)
		(,:0.1099 I:0.0796 have:0.0771 a:0.0820 little:0.0352 that:0.1914.:0.1777 and:0.2402)
		(,:0.1108 I:0.0801 have:0.0767 a:0.0796 little:0.0361 that:0.1826.:0.1787 and:0.2422)
		(,:0.1108 I:0.0801 have:0.0767 a:0.0796 little:0.0361 that:0.1826.:0.1787 and:0.2422)
 and
------
		( and:0.0623,:0.0513,:0.1299 friend:0.0187 that:0.1196 that:0.1484 and:0.1826 I:0.2793)
		( I:0.0776 have:0.0693,:0.1035 little:0.0315 that:0.1777 that:0.1660 and:0.1992 I:0.3008)
		( I:0.0835 have:0.0742,:0.0708 little:0.0352 that:0.1992 that:0.1865 and:0.2363 I:0.2617)
		( I:0.0840 have:0.0742 a:0.0845 little:0.0342 that:0.2080 that:0.1924 and:0.2539 I:0.2412)
		( I:0.0811 have:0.0718 a:0.0942 little:0.0325 that:0.1982 that:0.1914 and:0.2539 I:0.2314)
		( I:0.0796�:0.0742 a:0.0923 little:0.0327 that:0.1992 that:0.1826 and:0.2539 I:0.2197)
		( I:0.0786 have:0.0723 a:0.0903 little:0.0325 that:0.1895 that:0.1826 and:0.2432 I:0.2207)
		( I:0.0781 have:0.0713 a:0.0898 little:0.0339 that:0.1895.:0.1729 and:0.2441 I:0.2119)
		( I:0.0806 have:0.0742 a:0.0869 little:0.0344 that:0.1904.:0.1738 and:0.2461 I:0.2119)
		( I:0.0811 have:0.0732 a:0.0845 little:0.0352 that:0.1904.:0.1768 and:0.2363 I:0.2129)
		( I:0.0796 have:0.0771 a:0.0820 little:0.0352 that:0.1914.:0.1777 and:0.2402 I:0.2158)
		( I:0.0801 have:0.0767 a:0.0796 little:0.0361 that:0.1826.:0.1787 and:0.2422 I:0.2178)
		( I:0.0801 have:0.0767 a:0.0796 little:0.0361 that:0.1826.:0.1787 and:0.2422 I:0.2178)
 I'm a very good teacher.
- I'm
2750: sample 0: Hello, I'm a language model,
------
		(,:0.0410 and:0.0776 will:0.0679,:0.3438 sure:0.0410.:0.1455,:0.1855 and:0.2578)
		(,:0.0354 I:0.0850 will:0.0596,:0.1602 little:0.0542 that:0.1099.:0.1455 and:0.2256)
		(,:0.0320 I:0.0845�:0.0645,:0.0796 little:0.0669 that:0.0938 that:0.1602 and:0.2422)
		( the:0.0330 I:0.0894�:0.0732 sure:0.0781 little:0.0679.:0.0903 that:0.1807 and:0.2637)
		( the:0.0352 I:0.0830�:0.0757 not:0.0796 little:0.0659.:0.0923 that:0.1709 and:0.2656)
		(,:0.0378 I:0.0806�:0.0762 going:0.0786 little:0.0669.:0.0972 that:0.1621 and:0.2578)
		(,:0.0417 I:0.0786�:0.0781 going:0.0820 little:0.0688.:0.0972 that:0.1611 and:0.2598)
		(,:0.0442 I:0.0747�:0.0771 going:0.0820 little:0.0698.:0.0972 that:0.1553 and:0.2637)
		(,:0.0449 I:0.0737�:0.0762 sure:0.0859 little:0.0713.:0.0977 that:0.1582 and:0.2539)
		(,:0.0444 I:0.0728�:0.0757 sure:0.0903 little:0.0728.:0.0972 that:0.1514 and:0.2578)
		(,:0.0449 I:0.0718�:0.0757 sure:0.0923 little:0.0747.:0.0977,:0.1445 and:0.2490)
		(,:0.0454 I:0.0713�:0.0757 sure:0.0952 little:0.0771.:0.0977 that:0.1475 and:0.2539)
		(,:0.0454 I:0.0713�:0.0757 sure:0.0952 little:0.0771.:0.0977 that:0.1475 and:0.2539)
 and
------
		( and:0.0776 will:0.0679,:0.3438 sure:0.0410.:0.1455,:0.1855 and:0.2578 I:0.6016)
		( I:0.0850 will:0.0596,:0.1602 little:0.0542 that:0.1099.:0.1455 and:0.2256 I:0.5703)
		( I:0.0845�:0.0645,:0.0796 little:0.0669 that:0.0938 that:0.1602 and:0.2422 I:0.5039)
		( I:0.0894�:0.0732 sure:0.0781 little:0.0679.:0.0903 that:0.1807 and:0.2637 I:0.4355)
		( I:0.0830�:0.0757 not:0.0796 little:0.0659.:0.0923 that:0.1709 and:0.2656 I:0.4004)
		( I:0.0806�:0.0762 going:0.0786 little:0.0669.:0.0972 that:0.1621 and:0.2578 I:0.3965)
		( I:0.0786�:0.0781 going:0.0820 little:0.0688.:0.0972 that:0.1611 and:0.2598 I:0.3809)
		( I:0.0747�:0.0771 going:0.0820 little:0.0698.:0.0972 that:0.1553 and:0.2637 I:0.3809)
		( I:0.0737�:0.0762 sure:0.0859 little:0.0713.:0.0977 that:0.1582 and:0.2539 I:0.3672)
		( I:0.0728�:0.0757 sure:0.0903 little:0.0728.:0.0972 that:0.1514 and:0.2578 I:0.3711)
		( I:0.0718�:0.0757 sure:0.0923 little:0.0747.:0.0977,:0.1445 and:0.2490 I:0.3711)
		( I:0.0713�:0.0757 sure:0.0952 little:0.0771.:0.0977 that:0.1475 and:0.2539 I:0.3750)
		( I:0.0713�:0.0757 sure:0.0952 little:0.0771.:0.0977 that:0.1475 and:0.2539 I:0.3750)
 I'm sure you can use it.
- You
2900: sample 0: Hello, I'm a language model,
------
		(,:0.0618 I:0.0610,:0.1738,:0.2432 friend:0.0352.:0.1387 of:0.2715 and:0.2109)
		(,:0.0620 you:0.1050�:0.1147,:0.1670 little:0.1021 that:0.2275 of:0.2002 and:0.1953)
		(.:0.0747 I:0.0879�:0.1221,:0.1250 little:0.1250 that:0.2412 of:0.1807 and:0.2227)
		(.:0.0815 I:0.1040�:0.1128 a:0.1113 little:0.1260 that:0.2305 of:0.1777 and:0.2393)
		(.:0.0923 I:0.1104�:0.1021 a:0.1113 little:0.1206 that:0.2334 of:0.1807 and:0.2520)
		(.:0.1060 I:0.1104�:0.0967 a:0.1021 little:0.1162 that:0.2236 of:0.1826 and:0.2422)
		(.:0.1128 I:0.1089�:0.0938 a:0.0952 little:0.1133 that:0.2256 of:0.1748 and:0.2461)
		(.:0.1177 I:0.1074�:0.0918 a:0.0894 little:0.1172 that:0.2158 of:0.1777 and:0.2490)
		(.:0.1196 I:0.1035�:0.0864,:0.0864 little:0.1157 that:0.2178 of:0.1807 and:0.2393)
		(,:0.1177 I:0.1021�:0.0815,:0.0874 little:0.1147 that:0.2188 of:0.1826 and:0.2432)
		(,:0.1187 I:0.1011�:0.0811,:0.0908 little:0.1147 that:0.2197 of:0.1758 and:0.2344)
		(,:0.1206 I:0.0972�:0.0771,:0.0918 little:0.1143 that:0.2197 of:0.1777 and:0.2383)
		(,:0.1206 I:0.0972�:0.0771,:0.0918 little:0.1143 that:0.2197 of:0.1777 and:0.2383)
 and
------
		( I:0.0610,:0.1738,:0.2432 friend:0.0352.:0.1387 of:0.2715 and:0.2109 I:0.4023)
		( you:0.1050�:0.1147,:0.1670 little:0.1021 that:0.2275 of:0.2002 and:0.1953 I:0.4648)
		( I:0.0879�:0.1221,:0.1250 little:0.1250 that:0.2412 of:0.1807 and:0.2227 I:0.4688)
		( I:0.1040�:0.1128 a:0.1113 little:0.1260 that:0.2305 of:0.1777 and:0.2393 I:0.4688)
		( I:0.1104�:0.1021 a:0.1113 little:0.1206 that:0.2334 of:0.1807 and:0.2520 I:0.4473)
		( I:0.1104�:0.0967 a:0.1021 little:0.1162 that:0.2236 of:0.1826 and:0.2422 I:0.4434)
		( I:0.1089�:0.0938 a:0.0952 little:0.1133 that:0.2256 of:0.1748 and:0.2461 I:0.4453)
		( I:0.1074�:0.0918 a:0.0894 little:0.1172 that:0.2158 of:0.1777 and:0.2490 I:0.4297)
		( I:0.1035�:0.0864,:0.0864 little:0.1157 that:0.2178 of:0.1807 and:0.2393 I:0.4316)
		( I:0.1021�:0.0815,:0.0874 little:0.1147 that:0.2188 of:0.1826 and:0.2432 I:0.4316)
		( I:0.1011�:0.0811,:0.0908 little:0.1147 that:0.2197 of:0.1758 and:0.2344 I:0.4199)
		( I:0.0972�:0.0771,:0.0918 little:0.1143 that:0.2197 of:0.1777 and:0.2383 I:0.4238)
		( I:0.0972�:0.0771,:0.0918 little:0.1143 that:0.2197 of:0.1777 and:0.2383 I:0.4238)
 I'm going to be a little bit surprised.

3050: sample 0: Hello, I'm a language model,
------
		(,:0.0459 the:0.0601,:0.0840,:0.1553 friend:0.0391.:0.2100.:0.1562 and:0.1680)
		(,:0.0510 you:0.0815 will:0.0830,:0.0894 little:0.0474.:0.1182.:0.1855 and:0.1533)
		(,:0.0613 you:0.0869 will:0.0894 not:0.0972 little:0.0483.:0.1533.:0.2021 and:0.1846)
		(,:0.0757 you:0.0918 will:0.0854 not:0.1133 little:0.0452.:0.1602.:0.2139 and:0.2119)
		(,:0.0889 you:0.0972 will:0.0840 not:0.1187 bit:0.0442.:0.1748.:0.2275 and:0.2236)
		(,:0.0957 you:0.0981 will:0.0781 not:0.1177 bit:0.0432.:0.1855.:0.2402 and:0.2256)
		(,:0.1035 you:0.0977 will:0.0786 not:0.1104 bit:0.0417.:0.1914.:0.2422 and:0.2285)
		(,:0.1060 you:0.0942 will:0.0747 not:0.1089 bit:0.0420.:0.1924.:0.2539 and:0.2314)
		(,:0.1079 you:0.0913 will:0.0718 going:0.1099 bit:0.0410.:0.1924.:0.2578 and:0.2246)
		(,:0.1089 you:0.0889 will:0.0723 going:0.1113 bit:0.0405.:0.1934.:0.2598 and:0.2295)
		(,:0.1099 you:0.0859 will:0.0693 going:0.1099 bit:0.0398.:0.2031.:0.2617 and:0.2344)
		(,:0.1138 you:0.0835 can:0.0664 going:0.1094 bit:0.0383.:0.2031.:0.2637 and:0.2393)
		(,:0.1138 you:0.0835 can:0.0664 going:0.1094 bit:0.0383.:0.2031.:0.2637 and:0.2393)
 and
------
		( the:0.0601,:0.0840,:0.1553 friend:0.0391.:0.2100.:0.1562 and:0.1680 I:0.3418)
		( you:0.0815 will:0.0830,:0.0894 little:0.0474.:0.1182.:0.1855 and:0.1533 I:0.3730)
		( you:0.0869 will:0.0894 not:0.0972 little:0.0483.:0.1533.:0.2021 and:0.1846 I:0.3262)
		( you:0.0918 will:0.0854 not:0.1133 little:0.0452.:0.1602.:0.2139 and:0.2119 I:0.2988)
		( you:0.0972 will:0.0840 not:0.1187 bit:0.0442.:0.1748.:0.2275 and:0.2236 I:0.2754)
		( you:0.0981 will:0.0781 not:0.1177 bit:0.0432.:0.1855.:0.2402 and:0.2256 I:0.2637)
		( you:0.0977 will:0.0786 not:0.1104 bit:0.0417.:0.1914.:0.2422 and:0.2285 I:0.2539)
		( you:0.0942 will:0.0747 not:0.1089 bit:0.0420.:0.1924.:0.2539 and:0.2314 I:0.2578)
		( you:0.0913 will:0.0718 going:0.1099 bit:0.0410.:0.1924.:0.2578 and:0.2246 I:0.2500)
		( you:0.0889 will:0.0723 going:0.1113 bit:0.0405.:0.1934.:0.2598 and:0.2295 I:0.2559)
		( you:0.0859 will:0.0693 going:0.1099 bit:0.0398.:0.2031.:0.2617 and:0.2344 I:0.2471)
		( you:0.0835 can:0.0664 going:0.1094 bit:0.0383.:0.2031.:0.2637 and:0.2393 I:0.2520)
		( you:0.0835 can:0.0664 going:0.1094 bit:0.0383.:0.2031.:0.2637 and:0.2393 I:0.2520)
 I can use the same language.
The first language
3200: sample 0: Hello, I'm a language model,
------
		(,:0.0613 I:0.0884,:0.0723,:0.1484 friend:0.0245 that:0.1807.:0.2246 I:0.2520)
		(,:0.0708 I:0.1064 was:0.0610,:0.1089 little:0.0481 that:0.2402.:0.2148 I:0.2441)
		(,:0.0835 I:0.1035 was:0.0679 a:0.0977 little:0.0527 that:0.2539.:0.1904 and:0.2490)
		(,:0.0947 I:0.1172 was:0.0693 a:0.1099 little:0.0520 that:0.2393.:0.1846 and:0.2754)
		(,:0.1060 I:0.1206 was:0.0635 a:0.1006 little:0.0486 that:0.2354.:0.1924 and:0.2793)
		(,:0.1196 I:0.1167 am:0.0623 a:0.0908 little:0.0474 that:0.2227.:0.1943 and:0.2695)
		(,:0.1206 I:0.1138 am:0.0591 a:0.0864 little:0.0471 that:0.2109.:0.1865 and:0.2734)
		(,:0.1216 I:0.1113 am:0.0586 a:0.0830 little:0.0474 that:0.2100.:0.1885 and:0.2637)
		(,:0.1187 I:0.1094 am:0.0562 a:0.0806 little:0.0469 that:0.1982.:0.1914 and:0.2676)
		(,:0.1187 I:0.1050 am:0.0544 a:0.0757 little:0.0464 that:0.1973.:0.1826 and:0.2578)
		(,:0.1177 I:0.1030 am:0.0544 a:0.0737 little:0.0474 that:0.1865.:0.1865 and:0.2637)
		(,:0.1201 I:0.1016 am:0.0527 a:0.0723 little:0.0474 that:0.1855.:0.1807 and:0.2539)
		(,:0.1201 I:0.1016 am:0.0527 a:0.0723 little:0.0474 that:0.1855.:0.1807 and:0.2539)
 and
------
		( I:0.0884,:0.0723,:0.1484 friend:0.0245 that:0.1807.:0.2246 I:0.2520 I:0.4492)
		( I:0.1064 was:0.0610,:0.1089 little:0.0481 that:0.2402.:0.2148 I:0.2441 I:0.4492)
		( I:0.1035 was:0.0679 a:0.0977 little:0.0527 that:0.2539.:0.1904 and:0.2490 I:0.3965)
		( I:0.1172 was:0.0693 a:0.1099 little:0.0520 that:0.2393.:0.1846 and:0.2754 I:0.3691)
		( I:0.1206 was:0.0635 a:0.1006 little:0.0486 that:0.2354.:0.1924 and:0.2793 I:0.3574)
		( I:0.1167 am:0.0623 a:0.0908 little:0.0474 that:0.2227.:0.1943 and:0.2695 I:0.3477)
		( I:0.1138 am:0.0591 a:0.0864 little:0.0471 that:0.2109.:0.1865 and:0.2734 I:0.3535)
		( I:0.1113 am:0.0586 a:0.0830 little:0.0474 that:0.2100.:0.1885 and:0.2637 I:0.3438)
		( I:0.1094 am:0.0562 a:0.0806 little:0.0469 that:0.1982.:0.1914 and:0.2676 I:0.3496)
		( I:0.1050 am:0.0544 a:0.0757 little:0.0464 that:0.1973.:0.1826 and:0.2578 I:0.3418)
		( I:0.1030 am:0.0544 a:0.0737 little:0.0474 that:0.1865.:0.1865 and:0.2637 I:0.3477)
		( I:0.1016 am:0.0527 a:0.0723 little:0.0474 that:0.1855.:0.1807 and:0.2539 I:0.3535)
		( I:0.1016 am:0.0527 a:0.0723 little:0.0474 that:0.1855.:0.1807 and:0.2539 I:0.3535)
 I'm going to be a good idea.
The
3350: sample 0: Hello, I'm a language model,
------
		(,:0.0542 and:0.0688�:0.1147,:0.2227 little:0.0420,:0.1357,:0.1465 and:0.2217)
		(,:0.0693 you:0.0796�:0.1377,:0.1582 little:0.1206 that:0.1230 that:0.1523 and:0.2412)
		(,:0.0957 and:0.1201�:0.1216,:0.1221 little:0.1406 that:0.1279 that:0.1777 and:0.2695)
		(,:0.1270 and:0.1387�:0.1172 not:0.1387 little:0.1270 that:0.1221 that:0.1758 and:0.2969)
		(,:0.1465 and:0.1377�:0.1118 not:0.1436 little:0.1143 that:0.1152 that:0.1650 and:0.3145)
		(,:0.1719 and:0.1328�:0.1123 not:0.1387 little:0.1099 that:0.1113 that:0.1650 and:0.3105)
		(,:0.1846 and:0.1299�:0.1089 not:0.1318 little:0.1050 that:0.1113.:0.1660 and:0.3086)
		(,:0.1875 and:0.1279�:0.1074 not:0.1299 little:0.1045 that:0.1113.:0.1670 and:0.3086)
		(,:0.1963 and:0.1250�:0.1069 not:0.1260 little:0.1055 that:0.1108.:0.1680 and:0.3105)
		(,:0.1982 and:0.1235�:0.1006 not:0.1216 little:0.1030 that:0.1113.:0.1621 and:0.3125)
		(,:0.2051 and:0.1216�:0.1006 not:0.1177 little:0.1045 that:0.1113.:0.1631 and:0.3008)
		(,:0.2109 and:0.1201�:0.0952 not:0.1143 little:0.1025 that:0.1118.:0.1660 and:0.3047)
		(,:0.2109 and:0.1201�:0.0952 not:0.1143 little:0.1025 that:0.1118.:0.1660 and:0.3047)
 and
------
		( and:0.0688�:0.1147,:0.2227 little:0.0420,:0.1357,:0.1465 and:0.2217 I:0.3184)
		( you:0.0796�:0.1377,:0.1582 little:0.1206 that:0.1230 that:0.1523 and:0.2412 I:0.3281)
		( and:0.1201�:0.1216,:0.1221 little:0.1406 that:0.1279 that:0.1777 and:0.2695 I:0.2949)
		( and:0.1387�:0.1172 not:0.1387 little:0.1270 that:0.1221 that:0.1758 and:0.2969 I:0.2734)
		( and:0.1377�:0.1118 not:0.1436 little:0.1143 that:0.1152 that:0.1650 and:0.3145 I:0.2539)
		( and:0.1328�:0.1123 not:0.1387 little:0.1099 that:0.1113 that:0.1650 and:0.3105 I:0.2490)
		( and:0.1299�:0.1089 not:0.1318 little:0.1050 that:0.1113.:0.1660 and:0.3086 I:0.2490)
		( and:0.1279�:0.1074 not:0.1299 little:0.1045 that:0.1113.:0.1670 and:0.3086 I:0.2500)
		( and:0.1250�:0.1069 not:0.1260 little:0.1055 that:0.1108.:0.1680 and:0.3105 I:0.2520)
		( and:0.1235�:0.1006 not:0.1216 little:0.1030 that:0.1113.:0.1621 and:0.3125 I:0.2539)
		( and:0.1216�:0.1006 not:0.1177 little:0.1045 that:0.1113.:0.1631 and:0.3008 I:0.2559)
		( and:0.1201�:0.0952 not:0.1143 little:0.1025 that:0.1118.:0.1660 and:0.3047 I:0.2598)
		( and:0.1201�:0.0952 not:0.1143 little:0.1025 that:0.1118.:0.1660 and:0.3047 I:0.2598)
 I'm not sure what's the first language is,
3500: sample 0: Hello, I'm a language model,
------
		(,:0.0640 the:0.0347,:0.1138,:0.2139 very:0.0259.:0.1138 for:0.1641 I:0.1611)
		(,:0.0698 you:0.0601�:0.1934,:0.1475 little:0.0488 that:0.1182 for:0.1904 and:0.1631)
		(.:0.0723 you:0.0620�:0.1963,:0.1206 little:0.0493 that:0.1245 for:0.1855 and:0.1934)
		(.:0.0728 I:0.0649�:0.1904,:0.0942 little:0.0483 that:0.1309 for:0.1748 and:0.2197)
		(,:0.0674 I:0.0718�:0.1807,:0.0815 little:0.0488 that:0.1250 for:0.1650 and:0.2158)
		(,:0.0669 I:0.0757�:0.1699,:0.0820 little:0.0498 that:0.1240.:0.1650 and:0.2139)
		(,:0.0674 I:0.0757�:0.1650,:0.0806 little:0.0505 that:0.1206.:0.1768 and:0.2031)
		(,:0.0654 I:0.0747�:0.1641,:0.0820 little:0.0518 that:0.1167.:0.1787 and:0.2031)
		(,:0.0654 I:0.0752�:0.1553,:0.0840 little:0.0522 that:0.1162.:0.1807 and:0.1943)
		(,:0.0649 I:0.0762�:0.1572,:0.0835 little:0.0525 that:0.1138.:0.1816 and:0.1943)
		(,:0.0645 I:0.0747�:0.1494,:0.0850 little:0.0530 that:0.1133.:0.1836 and:0.1855)
		(,:0.0654 I:0.0752�:0.1426,:0.0845 little:0.0537 that:0.1138.:0.1855 and:0.1865)
		(,:0.0654 I:0.0752�:0.1426,:0.0845 little:0.0537 that:0.1138.:0.1855 and:0.1865)
 and
------
		( the:0.0347,:0.1138,:0.2139 very:0.0259.:0.1138 for:0.1641 I:0.1611 I:0.2930)
		( you:0.0601�:0.1934,:0.1475 little:0.0488 that:0.1182 for:0.1904 and:0.1631 I:0.3750)
		( you:0.0620�:0.1963,:0.1206 little:0.0493 that:0.1245 for:0.1855 and:0.1934 I:0.3770)
		( I:0.0649�:0.1904,:0.0942 little:0.0483 that:0.1309 for:0.1748 and:0.2197 I:0.3477)
		( I:0.0718�:0.1807,:0.0815 little:0.0488 that:0.1250 for:0.1650 and:0.2158 I:0.3184)
		( I:0.0757�:0.1699,:0.0820 little:0.0498 that:0.1240.:0.1650 and:0.2139 I:0.3047)
		( I:0.0757�:0.1650,:0.0806 little:0.0505 that:0.1206.:0.1768 and:0.2031 I:0.3066)
		( I:0.0747�:0.1641,:0.0820 little:0.0518 that:0.1167.:0.1787 and:0.2031 I:0.3066)
		( I:0.0752�:0.1553,:0.0840 little:0.0522 that:0.1162.:0.1807 and:0.1943 I:0.3086)
		( I:0.0762�:0.1572,:0.0835 little:0.0525 that:0.1138.:0.1816 and:0.1943 I:0.3125)
		( I:0.0747�:0.1494,:0.0850 little:0.0530 that:0.1133.:0.1836 and:0.1855 I:0.3145)
		( I:0.0752�:0.1426,:0.0845 little:0.0537 that:0.1138.:0.1855 and:0.1865 I:0.3184)
		( I:0.0752�:0.1426,:0.0845 little:0.0537 that:0.1138.:0.1855 and:0.1865 I:0.3184)
 I'm sure I'm sure I'm sure I'm
3650: sample 0: Hello, I'm a language model,
------
		(,:0.0386 and:0.0645 have:0.0618,:0.1768 sure:0.0282 that:0.1299.:0.1348 and:0.2236)
		(,:0.0508 you:0.1113 have:0.0703,:0.1328 little:0.0510 that:0.1982.:0.1719 and:0.1943)
		(,:0.0625 you:0.1147 have:0.0732 not:0.0962 little:0.0601 that:0.2100.:0.2139 and:0.2178)
		(,:0.0732 you:0.1123 have:0.0679 not:0.1084 little:0.0635 that:0.2119.:0.2148 and:0.2363)
		(,:0.0762 you:0.1099 have:0.0659 not:0.1040 little:0.0625 that:0.1992.:0.2168 and:0.2324)
		(,:0.0835 you:0.1089�:0.0684 not:0.1016 little:0.0620 that:0.1963.:0.2178 and:0.2305)
		(,:0.0864 you:0.1050 have:0.0674 not:0.0991 little:0.0618 that:0.1953.:0.2295 and:0.2305)
		(,:0.0884 you:0.1030 have:0.0669 not:0.0962 little:0.0618 that:0.1943.:0.2305 and:0.2305)
		(,:0.0879 you:0.1021 have:0.0708 not:0.0957 little:0.0618 that:0.1934.:0.2334 and:0.2314)
		(,:0.0894 you:0.1006 have:0.0708 not:0.0928 little:0.0615 that:0.1914.:0.2354 and:0.2217)
		(,:0.0908 you:0.0986 have:0.0708 not:0.0903 little:0.0615 that:0.1904.:0.2266 and:0.2227)
		(,:0.0942 you:0.0972 have:0.0747 not:0.0908 little:0.0613 that:0.1895.:0.2383 and:0.2236)
		(,:0.0942 you:0.0972 have:0.0747 not:0.0908 little:0.0613 that:0.1895.:0.2383 and:0.2236)
 and
------
		( and:0.0645 have:0.0618,:0.1768 sure:0.0282 that:0.1299.:0.1348 and:0.2236 I:0.1719)
		( you:0.1113 have:0.0703,:0.1328 little:0.0510 that:0.1982.:0.1719 and:0.1943 I:0.2617)
		( you:0.1147 have:0.0732 not:0.0962 little:0.0601 that:0.2100.:0.2139 and:0.2178 I:0.2812)
		( you:0.1123 have:0.0679 not:0.1084 little:0.0635 that:0.2119.:0.2148 and:0.2363 I:0.2617)
		( you:0.1099 have:0.0659 not:0.1040 little:0.0625 that:0.1992.:0.2168 and:0.2324 I:0.2422)
		( you:0.1089�:0.0684 not:0.1016 little:0.0620 that:0.1963.:0.2178 and:0.2305 I:0.2373)
		( you:0.1050 have:0.0674 not:0.0991 little:0.0618 that:0.1953.:0.2295 and:0.2305 I:0.2363)
		( you:0.1030 have:0.0669 not:0.0962 little:0.0618 that:0.1943.:0.2305 and:0.2305 I:0.2373)
		( you:0.1021 have:0.0708 not:0.0957 little:0.0618 that:0.1934.:0.2334 and:0.2314 I:0.2383)
		( you:0.1006 have:0.0708 not:0.0928 little:0.0615 that:0.1914.:0.2354 and:0.2217 I:0.2393)
		( you:0.0986 have:0.0708 not:0.0903 little:0.0615 that:0.1904.:0.2266 and:0.2227 I:0.2402)
		( you:0.0972 have:0.0747 not:0.0908 little:0.0613 that:0.1895.:0.2383 and:0.2236 I:0.2412)
		( you:0.0972 have:0.0747 not:0.0908 little:0.0613 that:0.1895.:0.2383 and:0.2236 I:0.2412)
 I'm going to be going to be going to be
3800: sample 0: Hello, I'm a language model,
------
		(,:0.0396 the:0.0659 is:0.0806,:0.1533 very:0.0315 that:0.1367,:0.1914 and:0.2295)
		(,:0.0493 the:0.0713 was:0.0898 sure:0.1011 bit:0.0439 that:0.2412,:0.1494 and:0.2207)
		(,:0.0513 and:0.0605�:0.0830 sure:0.0952 bit:0.0544 that:0.2275,:0.1543 and:0.2539)
		(,:0.0518 and:0.0771�:0.0757 not:0.0942 bit:0.0542 that:0.2139,:0.1562 and:0.2871)
		(,:0.0559 and:0.0762�:0.0703 not:0.0918 bit:0.0508 that:0.2021,:0.1553 and:0.2969)
		(,:0.0630 and:0.0762�:0.0654 not:0.0913 bit:0.0498 that:0.2021,:0.1562 and:0.2832)
		(,:0.0649 and:0.0737�:0.0659 sure:0.0928 bit:0.0486 that:0.2021.:0.1602 and:0.2852)
		(,:0.0654 and:0.0732�:0.0625 sure:0.0933 bit:0.0476 that:0.2021,:0.1533 and:0.2734)
		(,:0.0669 and:0.0723�:0.0635 sure:0.0957 bit:0.0479 that:0.2021,:0.1543 and:0.2754)
		(,:0.0684 and:0.0693�:0.0603 sure:0.0938 bit:0.0471 that:0.1924,:0.1494 and:0.2656)
		(,:0.0718 and:0.0688�:0.0574 sure:0.0938 bit:0.0464 that:0.1934,:0.1514 and:0.2676)
		(,:0.0752 and:0.0679�:0.0583 sure:0.0947 bit:0.0454 that:0.1934,:0.1504 and:0.2559)
		(,:0.0752 and:0.0679�:0.0583 sure:0.0947 bit:0.0454 that:0.1934,:0.1504 and:0.2559)
 and
------
		( the:0.0659 is:0.0806,:0.1533 very:0.0315 that:0.1367,:0.1914 and:0.2295 I:0.2041)
		( the:0.0713 was:0.0898 sure:0.1011 bit:0.0439 that:0.2412,:0.1494 and:0.2207 I:0.2520)
		( and:0.0605�:0.0830 sure:0.0952 bit:0.0544 that:0.2275,:0.1543 and:0.2539 I:0.2695)
		( and:0.0771�:0.0757 not:0.0942 bit:0.0542 that:0.2139,:0.1562 and:0.2871 I:0.2656)
		( and:0.0762�:0.0703 not:0.0918 bit:0.0508 that:0.2021,:0.1553 and:0.2969 I:0.2617)
		( and:0.0762�:0.0654 not:0.0913 bit:0.0498 that:0.2021,:0.1562 and:0.2832 I:0.2637)
		( and:0.0737�:0.0659 sure:0.0928 bit:0.0486 that:0.2021.:0.1602 and:0.2852 I:0.2539)
		( and:0.0732�:0.0625 sure:0.0933 bit:0.0476 that:0.2021,:0.1533 and:0.2734 I:0.2559)
		( and:0.0723�:0.0635 sure:0.0957 bit:0.0479 that:0.2021,:0.1543 and:0.2754 I:0.2578)
		( and:0.0693�:0.0603 sure:0.0938 bit:0.0471 that:0.1924,:0.1494 and:0.2656 I:0.2598)
		( and:0.0688�:0.0574 sure:0.0938 bit:0.0464 that:0.1934,:0.1514 and:0.2676 I:0.2617)
		( and:0.0679�:0.0583 sure:0.0947 bit:0.0454 that:0.1934,:0.1504 and:0.2559 I:0.2520)
		( and:0.0679�:0.0583 sure:0.0947 bit:0.0454 that:0.1934,:0.1504 and:0.2559 I:0.2520)
 I'm not sure of the "The
- The
