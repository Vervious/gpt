1: sample 0: Hello, I'm a language model,
------
		( million:0.0001,:0.0005 I:0.0003'm:0.0006 a:0.0003 language:0.0003 model:0.0005,:0.0014)
		( Israeli:0.0002,:0.0003 web:0.0002 bush:0.0002,:0.0002 divorced:0.0002 beats:0.0002,:0.0005)
		( Israeli:0.0002,:0.0003 divert:0.0002 bush:0.0002,:0.0004 divorced:0.0002 the:0.0002,:0.0004)
		( Israeli:0.0002,:0.0003 the:0.0002hyp:0.0002,:0.0005 the:0.0002 the:0.0003,:0.0004)
		( Israeli:0.0002,:0.0003 the:0.0003 the:0.0002,:0.0006 the:0.0003 the:0.0005 the:0.0005)
		( Dame:0.0002,:0.0003 the:0.0003 the:0.0003,:0.0006 the:0.0003 the:0.0006 the:0.0006)
		(,:0.0002,:0.0003 the:0.0004 the:0.0003 the:0.0006 the:0.0004 the:0.0006 the:0.0007)
		(,:0.0002,:0.0003 the:0.0004 the:0.0004 the:0.0007 the:0.0004 the:0.0007 the:0.0008)
		(,:0.0003,:0.0003 the:0.0005 the:0.0004 the:0.0007 the:0.0005 the:0.0007 the:0.0008)
		(,:0.0003,:0.0003 the:0.0005 the:0.0004 the:0.0007 the:0.0005 the:0.0008 the:0.0009)
		(,:0.0003,:0.0003 the:0.0005 the:0.0004 the:0.0008 the:0.0005 the:0.0008 the:0.0009)
		(,:0.0003,:0.0003 the:0.0005 the:0.0005 the:0.0008 the:0.0005 the:0.0008 the:0.0009)
		(,:0.0003,:0.0003 the:0.0005 the:0.0005 the:0.0008 the:0.0005 the:0.0008 the:0.0009)
 the
------
		(,:0.0005 I:0.0003'm:0.0006 a:0.0003 language:0.0003 model:0.0005,:0.0014 the:0.0014)
		(,:0.0003 web:0.0002 bush:0.0002,:0.0002 divorced:0.0002 beats:0.0002,:0.0005 the:0.0008)
		(,:0.0003 divert:0.0002 bush:0.0002,:0.0004 divorced:0.0002 the:0.0002,:0.0004 the:0.0007)
		(,:0.0003 the:0.0002hyp:0.0002,:0.0005 the:0.0002 the:0.0003,:0.0004 the:0.0008)
		(,:0.0003 the:0.0003 the:0.0002,:0.0006 the:0.0003 the:0.0005 the:0.0005 the:0.0008)
		(,:0.0003 the:0.0003 the:0.0003,:0.0006 the:0.0003 the:0.0006 the:0.0006 the:0.0008)
		(,:0.0003 the:0.0004 the:0.0003 the:0.0006 the:0.0004 the:0.0006 the:0.0007 the:0.0008)
		(,:0.0003 the:0.0004 the:0.0004 the:0.0007 the:0.0004 the:0.0007 the:0.0008 the:0.0008)
		(,:0.0003 the:0.0005 the:0.0004 the:0.0007 the:0.0005 the:0.0007 the:0.0008 the:0.0008)
		(,:0.0003 the:0.0005 the:0.0004 the:0.0007 the:0.0005 the:0.0008 the:0.0009 the:0.0008)
		(,:0.0003 the:0.0005 the:0.0004 the:0.0008 the:0.0005 the:0.0008 the:0.0009 the:0.0008)
		(,:0.0003 the:0.0005 the:0.0005 the:0.0008 the:0.0005 the:0.0008 the:0.0009 the:0.0008)
		(,:0.0003 the:0.0005 the:0.0005 the:0.0008 the:0.0005 the:0.0008 the:0.0009 the:0.0008)
 the the the the the the the the the the the
50: sample 0: Hello, I'm a language model,
------
		( of:0.0659 and:0.0679
:0.0459 the:0.1245 a:0.0120,:0.0894,:0.1035 and:0.0923)
		(,:0.0801 the:0.0645.:0.0304 the:0.1406 the:0.0262,:0.0923,:0.1050 and:0.0583)
		(,:0.0776 the:0.0698.:0.0386 the:0.1328 the:0.0320.:0.0957.:0.1118 the:0.0557)
		(,:0.0767 the:0.0723.:0.0405 the:0.1338 the:0.0349.:0.0972.:0.1143 the:0.0596)
		(,:0.0747 the:0.0762.:0.0415 the:0.1270 the:0.0356.:0.0996.:0.1108 the:0.0625)
		(,:0.0752 the:0.0806.:0.0403 the:0.1216 the:0.0369.:0.0977.:0.1079 the:0.0659)
		(,:0.0752 the:0.0801.:0.0396 the:0.1216 the:0.0378.:0.0957.:0.1069 the:0.0674)
		(,:0.0752 the:0.0845 the:0.0391 the:0.1221 the:0.0388.:0.0952.:0.1055 the:0.0674)
		(.:0.0776 the:0.0845 the:0.0413 the:0.1157 the:0.0400.:0.0947.:0.1040 the:0.0713)
		(.:0.0781 the:0.0845 the:0.0422 the:0.1162 the:0.0400.:0.0938.:0.1030 the:0.0713)
		(.:0.0781 the:0.0845 the:0.0447 the:0.1167 the:0.0400.:0.0928.:0.1021 the:0.0713)
		(.:0.0781 the:0.0845 the:0.0461 the:0.1104 the:0.0413.:0.0874.:0.1011 the:0.0752)
		(.:0.0781 the:0.0845 the:0.0461 the:0.1104 the:0.0413.:0.0874.:0.1011 the:0.0752)
 the
------
		( and:0.0679
:0.0459 the:0.1245 a:0.0120,:0.0894,:0.1035 and:0.0923 the:0.0137)
		( the:0.0645.:0.0304 the:0.1406 the:0.0262,:0.0923,:0.1050 and:0.0583 the:0.0162)
		( the:0.0698.:0.0386 the:0.1328 the:0.0320.:0.0957.:0.1118 the:0.0557 the:0.0177)
		( the:0.0723.:0.0405 the:0.1338 the:0.0349.:0.0972.:0.1143 the:0.0596 the:0.0198)
		( the:0.0762.:0.0415 the:0.1270 the:0.0356.:0.0996.:0.1108 the:0.0625 the:0.0215)
		( the:0.0806.:0.0403 the:0.1216 the:0.0369.:0.0977.:0.1079 the:0.0659 the:0.0233)
		( the:0.0801.:0.0396 the:0.1216 the:0.0378.:0.0957.:0.1069 the:0.0674 the:0.0248)
		( the:0.0845 the:0.0391 the:0.1221 the:0.0388.:0.0952.:0.1055 the:0.0674 the:0.0254)
		( the:0.0845 the:0.0413 the:0.1157 the:0.0400.:0.0947.:0.1040 the:0.0713 the:0.0270)
		( the:0.0845 the:0.0422 the:0.1162 the:0.0400.:0.0938.:0.1030 the:0.0713 the:0.0277)
		( the:0.0845 the:0.0447 the:0.1167 the:0.0400.:0.0928.:0.1021 the:0.0713 the:0.0284)
		( the:0.0845 the:0.0461 the:0.1104 the:0.0413.:0.0874.:0.1011 the:0.0752 the:0.0293)
		( the:0.0845 the:0.0461 the:0.1104 the:0.0413.:0.0874.:0.1011 the:0.0752 the:0.0293)
 the the the the the the the the the the the
200: sample 0: Hello, I'm a language model,
------
		( the:0.0991 the:0.0913 have:0.0693 a:0.0938 new:0.0178.:0.1147 of:0.1108 the:0.0835)
		(,:0.1138 and:0.0957 have:0.0664 not:0.1079 new:0.0178.:0.1396.:0.1211 and:0.0908)
		(,:0.1406 and:0.1113 have:0.0618 not:0.1279 few:0.0175.:0.1602.:0.1475 and:0.0830)
		(,:0.1602 and:0.1138 have:0.0586 not:0.1416 few:0.0175.:0.1748.:0.1572 and:0.0757)
		(,:0.1738 and:0.1157 have:0.0574 not:0.1436 few:0.0173.:0.1875.:0.1650 and:0.0703)
		(,:0.1777 and:0.1113 have:0.0559 not:0.1455 few:0.0170.:0.1914.:0.1709 and:0.0659)
		(,:0.1807 and:0.1069 have:0.0547 not:0.1484 few:0.0165.:0.1943.:0.1758 and:0.0635)
		(,:0.1826 and:0.1025 have:0.0535 not:0.1504 few:0.0160.:0.1973.:0.1787 I:0.0659)
		(,:0.1846 and:0.0977 have:0.0537 not:0.1455 few:0.0159.:0.1895.:0.1729 I:0.0679)
		(,:0.1855 and:0.0962 have:0.0522 not:0.1475 few:0.0153.:0.1914.:0.1748 I:0.0688)
		(,:0.1768 and:0.0913 have:0.0525 not:0.1494 few:0.0146.:0.1924.:0.1768 I:0.0693)
		(,:0.1777 and:0.0894 have:0.0525 not:0.1436 few:0.0145.:0.1934.:0.1787 I:0.0718)
		(,:0.1777 and:0.0894 have:0.0525 not:0.1436 few:0.0145.:0.1934.:0.1787 I:0.0718)
 I
------
		( the:0.0913 have:0.0693 a:0.0938 new:0.0178.:0.1147 of:0.1108 the:0.0835 have:0.0933)
		( and:0.0957 have:0.0664 not:0.1079 new:0.0178.:0.1396.:0.1211 and:0.0908 have:0.0781)
		( and:0.1113 have:0.0618 not:0.1279 few:0.0175.:0.1602.:0.1475 and:0.0830 have:0.0654)
		( and:0.1138 have:0.0586 not:0.1416 few:0.0175.:0.1748.:0.1572 and:0.0757 have:0.0588)
		( and:0.1157 have:0.0574 not:0.1436 few:0.0173.:0.1875.:0.1650 and:0.0703 have:0.0559)
		( and:0.1113 have:0.0559 not:0.1455 few:0.0170.:0.1914.:0.1709 and:0.0659 have:0.0549)
		( and:0.1069 have:0.0547 not:0.1484 few:0.0165.:0.1943.:0.1758 and:0.0635 have:0.0520)
		( and:0.1025 have:0.0535 not:0.1504 few:0.0160.:0.1973.:0.1787 I:0.0659 have:0.0505)
		( and:0.0977 have:0.0537 not:0.1455 few:0.0159.:0.1895.:0.1729 I:0.0679 have:0.0510)
		( and:0.0962 have:0.0522 not:0.1475 few:0.0153.:0.1914.:0.1748 I:0.0688 have:0.0496)
		( and:0.0913 have:0.0525 not:0.1494 few:0.0146.:0.1924.:0.1768 I:0.0693 have:0.0496)
		( and:0.0894 have:0.0525 not:0.1436 few:0.0145.:0.1934.:0.1787 I:0.0718 have:0.0483)
		( and:0.0894 have:0.0525 not:0.1436 few:0.0145.:0.1934.:0.1787 I:0.0718 have:0.0483)
 have a few, I think you have a few,
350: sample 0: Hello, I'm a language model,
------
		(,:0.4141 and:0.0552 have:0.0559 not:0.0703 good:0.0129,:0.1758,:0.1357 I:0.0703)
		(,:0.2969 and:0.0525�:0.0515 not:0.0486 good:0.0134,:0.1177,:0.1177 I:0.0703)
		(,:0.2412 and:0.0618�:0.0452 not:0.0422 good:0.0157,:0.1182,:0.1191 and:0.0996)
		(,:0.2295 and:0.0752�:0.0408 not:0.0403 good:0.0175,:0.1250,:0.1211 and:0.1172)
		(,:0.2178 and:0.0850�:0.0376,:0.0381 good:0.0183,:0.1279.:0.1318 and:0.1270)
		(,:0.2188 and:0.0918 think:0.0364,:0.0400 good:0.0192,:0.1240,:0.1299 and:0.1309)
		(,:0.2100 and:0.0972 think:0.0376,:0.0408 good:0.0203,:0.1279.:0.1348 and:0.1348)
		(,:0.2021 and:0.1006 think:0.0381,:0.0408 good:0.0208,:0.1270,:0.1338 and:0.1416)
		(,:0.1953 and:0.1021 think:0.0396,:0.0405 good:0.0212,:0.1270,:0.1338 and:0.1406)
		(,:0.1807 and:0.1035 think:0.0403,:0.0405 good:0.0211,:0.1260,:0.1328 and:0.1396)
		(,:0.1758 and:0.1025 think:0.0410,:0.0405 good:0.0217,:0.1260,:0.1338 and:0.1396)
		(,:0.1631 and:0.1021 think:0.0430,:0.0405 good:0.0217,:0.1338,:0.1416 and:0.1396)
		(,:0.1631 and:0.1021 think:0.0430,:0.0405 good:0.0217,:0.1338,:0.1416 and:0.1396)
 and
------
		( and:0.0552 have:0.0559 not:0.0703 good:0.0129,:0.1758,:0.1357 I:0.0703 I:0.0444)
		( and:0.0525�:0.0515 not:0.0486 good:0.0134,:0.1177,:0.1177 I:0.0703 I:0.0386)
		( and:0.0618�:0.0452 not:0.0422 good:0.0157,:0.1182,:0.1191 and:0.0996 the:0.0369)
		( and:0.0752�:0.0408 not:0.0403 good:0.0175,:0.1250,:0.1211 and:0.1172 a:0.0403)
		( and:0.0850�:0.0376,:0.0381 good:0.0183,:0.1279.:0.1318 and:0.1270 a:0.0447)
		( and:0.0918 think:0.0364,:0.0400 good:0.0192,:0.1240,:0.1299 and:0.1309 a:0.0474)
		( and:0.0972 think:0.0376,:0.0408 good:0.0203,:0.1279.:0.1348 and:0.1348 a:0.0505)
		( and:0.1006 think:0.0381,:0.0408 good:0.0208,:0.1270,:0.1338 and:0.1416 a:0.0510)
		( and:0.1021 think:0.0396,:0.0405 good:0.0212,:0.1270,:0.1338 and:0.1406 a:0.0518)
		( and:0.1035 think:0.0403,:0.0405 good:0.0211,:0.1260,:0.1328 and:0.1396 a:0.0525)
		( and:0.1025 think:0.0410,:0.0405 good:0.0217,:0.1260,:0.1338 and:0.1396 a:0.0535)
		( and:0.1021 think:0.0430,:0.0405 good:0.0217,:0.1338,:0.1416 and:0.1396 a:0.0532)
		( and:0.1021 think:0.0430,:0.0405 good:0.0217,:0.1338,:0.1416 and:0.1396 a:0.0532)
 a lot of a lot of a lot of a lot
500: sample 0: Hello, I'm a language model,
------
		(,:0.2051 the:0.0664�:0.0854 not:0.0649 good:0.0172.:0.1484 of:0.1465 the:0.0796)
		(,:0.1348 you:0.0452�:0.0806 not:0.0527 lot:0.0161.:0.1885.:0.1885 I:0.1182)
		(,:0.1270 the:0.0469�:0.0625 not:0.0510 lot:0.0262.:0.1895.:0.1992 I:0.1465)
		(,:0.1279 and:0.0498�:0.0486 not:0.0444 lot:0.0352.:0.1758.:0.2012 I:0.1748)
		(,:0.1299 and:0.0520�:0.0398 not:0.0398 lot:0.0405.:0.1582.:0.1992 I:0.2158)
		(,:0.1299 and:0.0537 think:0.0398 my:0.0454 lot:0.0454.:0.1445.:0.2012 I:0.2451)
		(,:0.1240 and:0.0537 think:0.0422 my:0.0549 lot:0.0486.:0.1328.:0.1963 I:0.2812)
		(,:0.1206 and:0.0544 think:0.0425 my:0.0593 lot:0.0510.:0.1221.:0.1895 I:0.3105)
		(,:0.1147 and:0.0540 think:0.0435 my:0.0645 lot:0.0537.:0.1128.:0.1768 I:0.3184)
		(,:0.1104 and:0.0520 think:0.0444 my:0.0630 lot:0.0537.:0.1045.:0.1758 I:0.3145)
		(,:0.1064 and:0.0503 think:0.0459 my:0.0620 lot:0.0557,:0.1045.:0.1641 I:0.2969)
		(,:0.1035 and:0.0488 think:0.0476 my:0.0610 lot:0.0564,:0.1108,:0.1562 I:0.2832)
		(,:0.1035 and:0.0488 think:0.0476 my:0.0610 lot:0.0564,:0.1108,:0.1562 I:0.2832)
 I
------
		( the:0.0664�:0.0854 not:0.0649 good:0.0172.:0.1484 of:0.1465 the:0.0796�:0.0693)
		( you:0.0452�:0.0806 not:0.0527 lot:0.0161.:0.1885.:0.1885 I:0.1182�:0.0525)
		( the:0.0469�:0.0625 not:0.0510 lot:0.0262.:0.1895.:0.1992 I:0.1465 am:0.0535)
		( and:0.0498�:0.0486 not:0.0444 lot:0.0352.:0.1758.:0.2012 I:0.1748 am:0.0605)
		( and:0.0520�:0.0398 not:0.0398 lot:0.0405.:0.1582.:0.1992 I:0.2158 am:0.0645)
		( and:0.0537 think:0.0398 my:0.0454 lot:0.0454.:0.1445.:0.2012 I:0.2451 am:0.0664)
		( and:0.0537 think:0.0422 my:0.0549 lot:0.0486.:0.1328.:0.1963 I:0.2812 am:0.0698)
		( and:0.0544 think:0.0425 my:0.0593 lot:0.0510.:0.1221.:0.1895 I:0.3105 am:0.0698)
		( and:0.0540 think:0.0435 my:0.0645 lot:0.0537.:0.1128.:0.1768 I:0.3184 am:0.0703)
		( and:0.0520 think:0.0444 my:0.0630 lot:0.0537.:0.1045.:0.1758 I:0.3145 am:0.0713)
		( and:0.0503 think:0.0459 my:0.0620 lot:0.0557,:0.1045.:0.1641 I:0.2969 am:0.0688)
		( and:0.0488 think:0.0476 my:0.0610 lot:0.0564,:0.1108,:0.1562 I:0.2832 am:0.0669)
		( and:0.0488 think:0.0476 my:0.0610 lot:0.0564,:0.1108,:0.1562 I:0.2832 am:0.0669)
 am not just a lot of my students. I am
650: sample 0: Hello, I'm a language model,
------
		(,:0.2656 the:0.0679�:0.0679 not:0.0361 few:0.0145.:0.1216.:0.1270 and:0.0713)
		(,:0.1494 I:0.0693 have:0.0486 not:0.0354 lot:0.0221.:0.1260.:0.1504 I:0.1006)
		(,:0.1128 I:0.0767 have:0.0557 not:0.0415 lot:0.0435.:0.0977.:0.1357 and:0.1279)
		(.:0.1035 I:0.0781 have:0.0486 going:0.0415 lot:0.0566.:0.0933.:0.1465 and:0.1367)
		(.:0.0918 I:0.0791 am:0.0488 going:0.0449 lot:0.0649.:0.0908.:0.1611 I:0.1562)
		(,:0.0781 I:0.0757 am:0.0530 going:0.0471 lot:0.0718.:0.0869.:0.1670 I:0.1748)
		(::0.0791 I:0.0732 am:0.0522 going:0.0493 lot:0.0742.:0.0840.:0.1729 I:0.1816)
		(::0.0835 I:0.0698 am:0.0552 going:0.0505 lot:0.0791.:0.0791.:0.1758 I:0.1855)
		(::0.0850 I:0.0684 am:0.0564 going:0.0525 lot:0.0815 that:0.0801.:0.1787 I:0.1807)
		(::0.0869 I:0.0635 am:0.0552 going:0.0532 lot:0.0801 that:0.0811.:0.1816 I:0.1816)
		(::0.0884 I:0.0605 am:0.0586 going:0.0527 lot:0.0796 that:0.0830.:0.1787 but:0.1836)
		(::0.0894 I:0.0596 am:0.0554 going:0.0527 lot:0.0801 that:0.0820.:0.1768 but:0.1855)
		(::0.0894 I:0.0596 am:0.0554 going:0.0527 lot:0.0801 that:0.0820.:0.1768 but:0.1855)
 but
------
		( the:0.0679�:0.0679 not:0.0361 few:0.0145.:0.1216.:0.1270 and:0.0713 the:0.0654)
		( I:0.0693 have:0.0486 not:0.0354 lot:0.0221.:0.1260.:0.1504 I:0.1006 I:0.1484)
		( I:0.0767 have:0.0557 not:0.0415 lot:0.0435.:0.0977.:0.1357 and:0.1279 I:0.1826)
		( I:0.0781 have:0.0486 going:0.0415 lot:0.0566.:0.0933.:0.1465 and:0.1367 I:0.2520)
		( I:0.0791 am:0.0488 going:0.0449 lot:0.0649.:0.0908.:0.1611 I:0.1562 I:0.3223)
		( I:0.0757 am:0.0530 going:0.0471 lot:0.0718.:0.0869.:0.1670 I:0.1748 I:0.3770)
		( I:0.0732 am:0.0522 going:0.0493 lot:0.0742.:0.0840.:0.1729 I:0.1816 I:0.4043)
		( I:0.0698 am:0.0552 going:0.0505 lot:0.0791.:0.0791.:0.1758 I:0.1855 I:0.4043)
		( I:0.0684 am:0.0564 going:0.0525 lot:0.0815 that:0.0801.:0.1787 I:0.1807 I:0.4199)
		( I:0.0635 am:0.0552 going:0.0532 lot:0.0801 that:0.0811.:0.1816 I:0.1816 I:0.4062)
		( I:0.0605 am:0.0586 going:0.0527 lot:0.0796 that:0.0830.:0.1787 but:0.1836 I:0.4082)
		( I:0.0596 am:0.0554 going:0.0527 lot:0.0801 that:0.0820.:0.1768 but:0.1855 I:0.3965)
		( I:0.0596 am:0.0554 going:0.0527 lot:0.0801 that:0.0820.:0.1768 but:0.1855 I:0.3965)
 I am going to say, I am a lot of
800: sample 0: Hello, I'm a language model,
------
		(,:0.1973 the:0.0713�:0.0811 not:0.0669 lot:0.0181,:0.1738 of:0.1523 I:0.0593)
		(,:0.2168 I:0.0898 have:0.0579 not:0.0635 lot:0.0322,:0.1309 of:0.1309 I:0.1348)
		(,:0.2119 I:0.0942 have:0.0693 not:0.0708 lot:0.0544,:0.0962 of:0.1465 I:0.1328)
		(,:0.2061 I:0.0972 have:0.0613 not:0.0640 lot:0.0645,:0.0962.:0.1758 I:0.1328)
		(,:0.1943 I:0.0996 have:0.0605 going:0.0588 lot:0.0718,:0.1040.:0.2070 I:0.1328)
		(,:0.1787 I:0.1001 have:0.0581 going:0.0603 lot:0.0776,:0.1108.:0.2246 I:0.1406)
		(,:0.1611 I:0.1011 have:0.0569 going:0.0613 lot:0.0820,:0.1133.:0.2266 but:0.1504)
		(,:0.1475 I:0.1006 will:0.0605 going:0.0618 lot:0.0830,:0.1118.:0.2344 but:0.1553)
		(,:0.1348 I:0.1001 will:0.0615 going:0.0630 lot:0.0894,:0.1177.:0.2344 but:0.1621)
		(,:0.1206 I:0.1001 will:0.0669 going:0.0649 lot:0.0864,:0.1172.:0.2266 I:0.1602)
		(,:0.1104 I:0.1001 will:0.0698 going:0.0669 lot:0.0889,:0.1182.:0.2295 but:0.1699)
		(,:0.1016 I:0.0977 will:0.0732 going:0.0659 lot:0.0923,:0.1187.:0.2227 I:0.1680)
		(,:0.1016 I:0.0977 will:0.0732 going:0.0659 lot:0.0923,:0.1187.:0.2227 I:0.1680)
 I
------
		( the:0.0713�:0.0811 not:0.0669 lot:0.0181,:0.1738 of:0.1523 I:0.0593 have:0.0496)
		( I:0.0898 have:0.0579 not:0.0635 lot:0.0322,:0.1309 of:0.1309 I:0.1348'm:0.0742)
		( I:0.0942 have:0.0693 not:0.0708 lot:0.0544,:0.0962 of:0.1465 I:0.1328'm:0.1206)
		( I:0.0972 have:0.0613 not:0.0640 lot:0.0645,:0.0962.:0.1758 I:0.1328'm:0.1582)
		( I:0.0996 have:0.0605 going:0.0588 lot:0.0718,:0.1040.:0.2070 I:0.1328'm:0.1875)
		( I:0.1001 have:0.0581 going:0.0603 lot:0.0776,:0.1108.:0.2246 I:0.1406'm:0.2100)
		( I:0.1011 have:0.0569 going:0.0613 lot:0.0820,:0.1133.:0.2266 but:0.1504'm:0.2266)
		( I:0.1006 will:0.0605 going:0.0618 lot:0.0830,:0.1118.:0.2344 but:0.1553'm:0.2354)
		( I:0.1001 will:0.0615 going:0.0630 lot:0.0894,:0.1177.:0.2344 but:0.1621'm:0.2461)
		( I:0.1001 will:0.0669 going:0.0649 lot:0.0864,:0.1172.:0.2266 I:0.1602'm:0.2578)
		( I:0.1001 will:0.0698 going:0.0669 lot:0.0889,:0.1182.:0.2295 but:0.1699'm:0.2617)
		( I:0.0977 will:0.0732 going:0.0659 lot:0.0923,:0.1187.:0.2227 I:0.1680'm:0.2656)
		( I:0.0977 will:0.0732 going:0.0659 lot:0.0923,:0.1187.:0.2227 I:0.1680'm:0.2656)
'm going to know that I'm going to know,
950: sample 0: Hello, I'm a language model,
------
		(,:0.2178 the:0.0767�:0.0830 not:0.1177 few:0.0249,:0.1729,:0.2031 and:0.0835)
		(,:0.1953 I:0.0693�:0.0586 not:0.1494 few:0.0400.:0.1289.:0.1660 but:0.0767)
		(,:0.1553 I:0.0942 have:0.0620 not:0.1631 few:0.0356 of:0.0957 of:0.1973 but:0.1118)
		(,:0.1299 I:0.1030 have:0.0630 not:0.1465 few:0.0322 of:0.1045 of:0.2061 and:0.1621)
		(,:0.1113 I:0.1001 have:0.0618 not:0.1260 lot:0.0342 of:0.1045 of:0.2061 and:0.1768)
		(,:0.0991 I:0.0942 have:0.0562 not:0.1118 lot:0.0369 that:0.1050 of:0.2002 and:0.1855)
		(,:0.0889 I:0.0889 have:0.0559 not:0.1069 lot:0.0396 that:0.1021 of:0.2021 and:0.1875)
		(,:0.0825 I:0.0840 have:0.0532 not:0.0972 lot:0.0427 that:0.0996 of:0.2021 and:0.1826)
		(,:0.0767 I:0.0811've:0.0547 going:0.1016 lot:0.0447 that:0.1001 of:0.1914 and:0.1787)
		(.:0.0762 I:0.0762've:0.0566 going:0.1064 lot:0.0471 that:0.0996 of:0.1943 and:0.1748)
		(.:0.0757 I:0.0742've:0.0591 going:0.1055 lot:0.0481 that:0.1006 of:0.1992 and:0.1611)
		(.:0.0728 I:0.0693've:0.0583 going:0.1104 lot:0.0493 that:0.0952 of:0.2031 and:0.1582)
		(.:0.0728 I:0.0693've:0.0583 going:0.1104 lot:0.0493 that:0.0952 of:0.2031 and:0.1582)
 and
------
		( the:0.0767�:0.0830 not:0.1177 few:0.0249,:0.1729,:0.2031 and:0.0835 the:0.0549)
		( I:0.0693�:0.0586 not:0.1494 few:0.0400.:0.1289.:0.1660 but:0.0767 I:0.1216)
		( I:0.0942 have:0.0620 not:0.1631 few:0.0356 of:0.0957 of:0.1973 but:0.1118 I:0.2344)
		( I:0.1030 have:0.0630 not:0.1465 few:0.0322 of:0.1045 of:0.2061 and:0.1621 I:0.3027)
		( I:0.1001 have:0.0618 not:0.1260 lot:0.0342 of:0.1045 of:0.2061 and:0.1768 I:0.3535)
		( I:0.0942 have:0.0562 not:0.1118 lot:0.0369 that:0.1050 of:0.2002 and:0.1855 I:0.3730)
		( I:0.0889 have:0.0559 not:0.1069 lot:0.0396 that:0.1021 of:0.2021 and:0.1875 I:0.3809)
		( I:0.0840 have:0.0532 not:0.0972 lot:0.0427 that:0.0996 of:0.2021 and:0.1826 I:0.3770)
		( I:0.0811've:0.0547 going:0.1016 lot:0.0447 that:0.1001 of:0.1914 and:0.1787 I:0.3730)
		( I:0.0762've:0.0566 going:0.1064 lot:0.0471 that:0.0996 of:0.1943 and:0.1748 I:0.3594)
		( I:0.0742've:0.0591 going:0.1055 lot:0.0481 that:0.1006 of:0.1992 and:0.1611 I:0.3594)
		( I:0.0693've:0.0583 going:0.1104 lot:0.0493 that:0.0952 of:0.2031 and:0.1582 I:0.3438)
		( I:0.0693've:0.0583 going:0.1104 lot:0.0493 that:0.0952 of:0.2031 and:0.1582 I:0.3438)
 I've got a lot of time. I've got
1100: sample 0: Hello, I'm a language model,
------
		(,:0.2256 the:0.0806�:0.1611 not:0.0640 few:0.0221,:0.2178.:0.1699 and:0.0640)
		(,:0.1475 I:0.1279�:0.1104 not:0.0718 few:0.0410,:0.1328.:0.1572 I:0.1387)
		(,:0.1289 I:0.1875�:0.1187 not:0.1064 few:0.0371 that:0.0908 for:0.1465 I:0.1064)
		(,:0.1133 I:0.2100�:0.1211 not:0.1162 lot:0.0417 that:0.0991 for:0.1650 but:0.1021)
		(,:0.1001 I:0.2178�:0.1196 not:0.1172 lot:0.0427 that:0.0918 for:0.1670 but:0.1221)
		(,:0.0898 I:0.2266�:0.1128 not:0.1108 lot:0.0447 that:0.0859 for:0.1660 but:0.1309)
		( my:0.0898 I:0.2256�:0.1113 not:0.1138 lot:0.0457 that:0.0781 for:0.1641 but:0.1387)
		( my:0.0957 I:0.2344�:0.1128 not:0.1060 lot:0.0459 that:0.0718 for:0.1602 but:0.1396)
		( my:0.0967 I:0.2334�:0.1094 not:0.1055 lot:0.0461 that:0.0659 for:0.1572 but:0.1406)
		( my:0.1006 I:0.2324�:0.1084 not:0.1055 lot:0.0469 that:0.0605 for:0.1553 but:0.1416)
		( my:0.1021 I:0.2432�:0.1069 not:0.1001 lot:0.0461 that:0.0574 for:0.1523 but:0.1426)
		( my:0.1011 I:0.2422�:0.1064 not:0.1001 lot:0.0459 that:0.0527 for:0.1504 but:0.1426)
		( my:0.1011 I:0.2422�:0.1064 not:0.1001 lot:0.0459 that:0.0527 for:0.1504 but:0.1426)
 but
------
		( the:0.0806�:0.1611 not:0.0640 few:0.0221,:0.2178.:0.1699 and:0.0640 I:0.0977)
		( I:0.1279�:0.1104 not:0.0718 few:0.0410,:0.1328.:0.1572 I:0.1387 I:0.1855)
		( I:0.1875�:0.1187 not:0.1064 few:0.0371 that:0.0908 for:0.1465 I:0.1064 I:0.1924)
		( I:0.2100�:0.1211 not:0.1162 lot:0.0417 that:0.0991 for:0.1650 but:0.1021 I:0.2129)
		( I:0.2178�:0.1196 not:0.1172 lot:0.0427 that:0.0918 for:0.1670 but:0.1221 I:0.2363)
		( I:0.2266�:0.1128 not:0.1108 lot:0.0447 that:0.0859 for:0.1660 but:0.1309 I:0.2656)
		( I:0.2256�:0.1113 not:0.1138 lot:0.0457 that:0.0781 for:0.1641 but:0.1387 I:0.2695)
		( I:0.2344�:0.1128 not:0.1060 lot:0.0459 that:0.0718 for:0.1602 but:0.1396 I:0.2715)
		( I:0.2334�:0.1094 not:0.1055 lot:0.0461 that:0.0659 for:0.1572 but:0.1406 I:0.2754)
		( I:0.2324�:0.1084 not:0.1055 lot:0.0469 that:0.0605 for:0.1553 but:0.1416 I:0.2773)
		( I:0.2432�:0.1069 not:0.1001 lot:0.0461 that:0.0574 for:0.1523 but:0.1426 I:0.2773)
		( I:0.2422�:0.1064 not:0.1001 lot:0.0459 that:0.0527 for:0.1504 but:0.1426 I:0.2793)
		( I:0.2422�:0.1064 not:0.1001 lot:0.0459 that:0.0527 for:0.1504 but:0.1426 I:0.2793)
 I'm a language. I'm a language. I
1250: sample 0: Hello, I'm a language model,
------
		(,:0.1709 the:0.0898�:0.1992 not:0.0579 lot:0.0203,:0.1523,:0.1904 the:0.0703)
		(,:0.1406 I:0.1108�:0.1484 not:0.0601 bit:0.0287.:0.1436,:0.1924 I:0.1719)
		(,:0.1289 I:0.1631�:0.2041 not:0.0776 bit:0.0415,:0.0981,:0.1621 I:0.1289)
		(,:0.1196 I:0.1738�:0.2109 not:0.0830 bit:0.0442,:0.0840,:0.1475 and:0.1436)
		(,:0.1104 I:0.1885�:0.1943 not:0.0825 bit:0.0469,:0.0762.:0.1504 and:0.1533)
		(,:0.1035 I:0.1953�:0.1855 not:0.0815 bit:0.0488,:0.0742.:0.1572 but:0.1680)
		(,:0.0986 I:0.2041�:0.1748 not:0.0806 bit:0.0498,:0.0728.:0.1650 but:0.1826)
		(.:0.0942 I:0.2129�:0.1602 not:0.0757 bit:0.0515,:0.0723.:0.1748 but:0.1885)
		(.:0.0967 I:0.2129�:0.1514 not:0.0742 bit:0.0520.:0.0762.:0.1768 but:0.1963)
		(.:0.0972 I:0.2227�:0.1445 not:0.0713 bit:0.0525.:0.0781.:0.1807 but:0.2031)
		(.:0.0977 I:0.2227�:0.1396 not:0.0688 bit:0.0532.:0.0830.:0.1875 but:0.2031)
		(.:0.0986 I:0.2334�:0.1289 not:0.0654 bit:0.0540.:0.0859.:0.1963 but:0.2021)
		(.:0.0986 I:0.2334�:0.1289 not:0.0654 bit:0.0540.:0.0859.:0.1963 but:0.2021)
 but
------
		( the:0.0898�:0.1992 not:0.0579 lot:0.0203,:0.1523,:0.1904 the:0.0703 I:0.0981)
		( I:0.1108�:0.1484 not:0.0601 bit:0.0287.:0.1436,:0.1924 I:0.1719 I:0.2910)
		( I:0.1631�:0.2041 not:0.0776 bit:0.0415,:0.0981,:0.1621 I:0.1289 I:0.3418)
		( I:0.1738�:0.2109 not:0.0830 bit:0.0442,:0.0840,:0.1475 and:0.1436 I:0.3672)
		( I:0.1885�:0.1943 not:0.0825 bit:0.0469,:0.0762.:0.1504 and:0.1533 I:0.3945)
		( I:0.1953�:0.1855 not:0.0815 bit:0.0488,:0.0742.:0.1572 but:0.1680 I:0.4258)
		( I:0.2041�:0.1748 not:0.0806 bit:0.0498,:0.0728.:0.1650 but:0.1826 I:0.4238)
		( I:0.2129�:0.1602 not:0.0757 bit:0.0515,:0.0723.:0.1748 but:0.1885 I:0.4375)
		( I:0.2129�:0.1514 not:0.0742 bit:0.0520.:0.0762.:0.1768 but:0.1963 I:0.4219)
		( I:0.2227�:0.1445 not:0.0713 bit:0.0525.:0.0781.:0.1807 but:0.2031 I:0.4199)
		( I:0.2227�:0.1396 not:0.0688 bit:0.0532.:0.0830.:0.1875 but:0.2031 I:0.4199)
		( I:0.2334�:0.1289 not:0.0654 bit:0.0540.:0.0859.:0.1963 but:0.2021 I:0.4199)
		( I:0.2334�:0.1289 not:0.0654 bit:0.0540.:0.0859.:0.1963 but:0.2021 I:0.4199)
 I'm a language, but I'm a language,
1400: sample 0: Hello, I'm a language model,
------
		(,:0.2148 the:0.0840�:0.1040 not:0.0830 lot:0.0271.:0.1572.:0.1855 and:0.0698)
		(,:0.1982 I:0.1216�:0.0718 not:0.1230 bit:0.0359,:0.1050,:0.1875 I:0.1836)
		(,:0.1758 I:0.1245�:0.1074 not:0.1484 bit:0.0496 that:0.0776.:0.1650 and:0.1309)
		(,:0.1602 I:0.1138�:0.1196 not:0.1396 bit:0.0552 that:0.0811.:0.1660 and:0.1465)
		(,:0.1533 I:0.1104�:0.1250 not:0.1299 bit:0.0581 that:0.0786.:0.1670 and:0.1514)
		(,:0.1436 I:0.1108�:0.1279 not:0.1230 bit:0.0603 that:0.0752.:0.1738 and:0.1504)
		(,:0.1338 I:0.1113�:0.1260 not:0.1177 bit:0.0630 that:0.0723.:0.1729 and:0.1504)
		(,:0.1260 I:0.1152�:0.1270 not:0.1147 bit:0.0645 that:0.0703.:0.1865 and:0.1455)
		(,:0.1157 I:0.1167�:0.1221 not:0.1084 bit:0.0664 that:0.0664.:0.1807 and:0.1406)
		(,:0.1089 I:0.1143�:0.1245 not:0.1064 bit:0.0664 that:0.0645.:0.1885 and:0.1445)
		(,:0.1001 I:0.1157�:0.1216 not:0.1016 bit:0.0669 that:0.0613.:0.1846 and:0.1426)
		(,:0.0918 I:0.1172�:0.1187 not:0.1001 bit:0.0679 that:0.0579.:0.1934 but:0.1484)
		(,:0.0918 I:0.1172�:0.1187 not:0.1001 bit:0.0679 that:0.0579.:0.1934 but:0.1484)
 but
------
		( the:0.0840�:0.1040 not:0.0830 lot:0.0271.:0.1572.:0.1855 and:0.0698 I:0.1504)
		( I:0.1216�:0.0718 not:0.1230 bit:0.0359,:0.1050,:0.1875 I:0.1836 I:0.3027)
		( I:0.1245�:0.1074 not:0.1484 bit:0.0496 that:0.0776.:0.1650 and:0.1309 I:0.3145)
		( I:0.1138�:0.1196 not:0.1396 bit:0.0552 that:0.0811.:0.1660 and:0.1465 I:0.3516)
		( I:0.1104�:0.1250 not:0.1299 bit:0.0581 that:0.0786.:0.1670 and:0.1514 I:0.3613)
		( I:0.1108�:0.1279 not:0.1230 bit:0.0603 that:0.0752.:0.1738 and:0.1504 I:0.3555)
		( I:0.1113�:0.1260 not:0.1177 bit:0.0630 that:0.0723.:0.1729 and:0.1504 I:0.3633)
		( I:0.1152�:0.1270 not:0.1147 bit:0.0645 that:0.0703.:0.1865 and:0.1455 I:0.3613)
		( I:0.1167�:0.1221 not:0.1084 bit:0.0664 that:0.0664.:0.1807 and:0.1406 I:0.3535)
		( I:0.1143�:0.1245 not:0.1064 bit:0.0664 that:0.0645.:0.1885 and:0.1445 I:0.3496)
		( I:0.1157�:0.1216 not:0.1016 bit:0.0669 that:0.0613.:0.1846 and:0.1426 I:0.3457)
		( I:0.1172�:0.1187 not:0.1001 bit:0.0679 that:0.0579.:0.1934 but:0.1484 I:0.3555)
		( I:0.1172�:0.1187 not:0.1001 bit:0.0679 that:0.0579.:0.1934 but:0.1484 I:0.3555)
 I'm a bit like a language, but I'm
1550: sample 0: Hello, I'm a language model,
------
		(,:0.2070 the:0.0884�:0.0796 not:0.0820 lot:0.0291.:0.1787,:0.1787 I:0.1030)
		(,:0.1699 I:0.0820�:0.0581 not:0.0938 lot:0.0381.:0.1338.:0.1689 I:0.1885)
		(,:0.1348 I:0.0781�:0.0679 not:0.0898 lot:0.0369,:0.1035.:0.1514 and:0.1211)
		(,:0.1211 I:0.0723 have:0.0593 sure:0.0918 bit:0.0417,:0.0918.:0.1494 and:0.1387)
		(,:0.1138 I:0.0723 have:0.0630 sure:0.1040 bit:0.0442 of:0.0864.:0.1533 but:0.1475)
		(,:0.1104 I:0.0742 was:0.0649 sure:0.1074 bit:0.0457 of:0.0898.:0.1514 but:0.1758)
		(,:0.1079 I:0.0732 have:0.0679 sure:0.1138 bit:0.0471 of:0.0942.:0.1572 but:0.1973)
		(,:0.1050 I:0.0747 have:0.0688 sure:0.1152 bit:0.0464 of:0.0962.:0.1660 but:0.2227)
		(,:0.1001 I:0.0762 have:0.0674 sure:0.1177 bit:0.0469 of:0.1016.:0.1641 but:0.2285)
		(,:0.0977 I:0.0771 have:0.0669 sure:0.1147 bit:0.0461 of:0.1040.:0.1660 but:0.2461)
		(,:0.0933 I:0.0762 have:0.0679 sure:0.1191 bit:0.0457 of:0.1074.:0.1699 but:0.2559)
		(,:0.0913 I:0.0771 have:0.0688 sure:0.1167 bit:0.0437 of:0.1133 for:0.1768 but:0.2539)
		(,:0.0913 I:0.0771 have:0.0688 sure:0.1167 bit:0.0437 of:0.1133 for:0.1768 but:0.2539)
 but
------
		( the:0.0884�:0.0796 not:0.0820 lot:0.0291.:0.1787,:0.1787 I:0.1030 I:0.2119)
		( I:0.0820�:0.0581 not:0.0938 lot:0.0381.:0.1338.:0.1689 I:0.1885 I:0.3242)
		( I:0.0781�:0.0679 not:0.0898 lot:0.0369,:0.1035.:0.1514 and:0.1211 I:0.3008)
		( I:0.0723 have:0.0593 sure:0.0918 bit:0.0417,:0.0918.:0.1494 and:0.1387 I:0.2988)
		( I:0.0723 have:0.0630 sure:0.1040 bit:0.0442 of:0.0864.:0.1533 but:0.1475 I:0.2988)
		( I:0.0742 was:0.0649 sure:0.1074 bit:0.0457 of:0.0898.:0.1514 but:0.1758 I:0.2969)
		( I:0.0732 have:0.0679 sure:0.1138 bit:0.0471 of:0.0942.:0.1572 but:0.1973 I:0.2930)
		( I:0.0747 have:0.0688 sure:0.1152 bit:0.0464 of:0.0962.:0.1660 but:0.2227 I:0.2773)
		( I:0.0762 have:0.0674 sure:0.1177 bit:0.0469 of:0.1016.:0.1641 but:0.2285 I:0.2734)
		( I:0.0771 have:0.0669 sure:0.1147 bit:0.0461 of:0.1040.:0.1660 but:0.2461 I:0.2578)
		( I:0.0762 have:0.0679 sure:0.1191 bit:0.0457 of:0.1074.:0.1699 but:0.2559 I:0.2422)
		( I:0.0771 have:0.0688 sure:0.1167 bit:0.0437 of:0.1133 for:0.1768 but:0.2539 I:0.2402)
		( I:0.0771 have:0.0688 sure:0.1167 bit:0.0437 of:0.1133 for:0.1768 but:0.2539 I:0.2402)
 I've been able to understand the language, and I
1700: sample 0: Hello, I'm a language model,
------
		(,:0.1060 the:0.0840 am:0.0732 not:0.0757 lot:0.0206.:0.1309.:0.1455 I:0.0952)
		(,:0.1357 I:0.1060 have:0.0830 not:0.1211 bit:0.0459,:0.1162.:0.1699 I:0.2051)
		(,:0.1357 I:0.0889 have:0.0947 not:0.1318 bit:0.0491,:0.1138.:0.1572 and:0.1504)
		(,:0.1377 I:0.0811 have:0.0977 not:0.1157 bit:0.0471,:0.1128.:0.1523 and:0.1562)
		(,:0.1416 I:0.0781 have:0.1016 sure:0.1084 bit:0.0442,:0.1099.:0.1592 and:0.1582)
		(,:0.1475 I:0.0752 have:0.0981 sure:0.1123 bit:0.0410,:0.1079.:0.1621 and:0.1592)
		(,:0.1533 I:0.0747 have:0.0972 sure:0.1138 bit:0.0388,:0.1060.:0.1729 and:0.1621)
		(,:0.1562 I:0.0742 have:0.0981 sure:0.1162 very:0.0361,:0.1045.:0.1846 and:0.1650)
		(,:0.1602 I:0.0713 have:0.1001 sure:0.1138 very:0.0381,:0.1035.:0.1885 and:0.1699)
		(,:0.1631 I:0.0708 have:0.0977 sure:0.1128 very:0.0403,:0.1030.:0.1924 and:0.1650)
		(,:0.1631 I:0.0703 have:0.0957 sure:0.1118 very:0.0415,:0.1025.:0.2002 and:0.1709)
		(,:0.1631 I:0.0698 have:0.0938 sure:0.1060 very:0.0430,:0.1025.:0.2080 and:0.1680)
		(,:0.1631 I:0.0698 have:0.0938 sure:0.1060 very:0.0430,:0.1025.:0.2080 and:0.1680)
 and
------
		( the:0.0840 am:0.0732 not:0.0757 lot:0.0206.:0.1309.:0.1455 I:0.0952 I:0.0796)
		( I:0.1060 have:0.0830 not:0.1211 bit:0.0459,:0.1162.:0.1699 I:0.2051 I:0.1631)
		( I:0.0889 have:0.0947 not:0.1318 bit:0.0491,:0.1138.:0.1572 and:0.1504 I:0.2354)
		( I:0.0811 have:0.0977 not:0.1157 bit:0.0471,:0.1128.:0.1523 and:0.1562 I:0.2656)
		( I:0.0781 have:0.1016 sure:0.1084 bit:0.0442,:0.1099.:0.1592 and:0.1582 I:0.2930)
		( I:0.0752 have:0.0981 sure:0.1123 bit:0.0410,:0.1079.:0.1621 and:0.1592 I:0.3008)
		( I:0.0747 have:0.0972 sure:0.1138 bit:0.0388,:0.1060.:0.1729 and:0.1621 I:0.3008)
		( I:0.0742 have:0.0981 sure:0.1162 very:0.0361,:0.1045.:0.1846 and:0.1650 I:0.3047)
		( I:0.0713 have:0.1001 sure:0.1138 very:0.0381,:0.1035.:0.1885 and:0.1699 I:0.3125)
		( I:0.0708 have:0.0977 sure:0.1128 very:0.0403,:0.1030.:0.1924 and:0.1650 I:0.3066)
		( I:0.0703 have:0.0957 sure:0.1118 very:0.0415,:0.1025.:0.2002 and:0.1709 I:0.3164)
		( I:0.0698 have:0.0938 sure:0.1060 very:0.0430,:0.1025.:0.2080 and:0.1680 I:0.3145)
		( I:0.0698 have:0.0938 sure:0.1060 very:0.0430,:0.1025.:0.2080 and:0.1680 I:0.3145)
 I'm a language model.
The language is a
1850: sample 0: Hello, I'm a language model,
------
		(,:0.2520 I:0.0713�:0.0693 a:0.0850 lot:0.0315,:0.1855,:0.2158 I:0.1523)
		(,:0.1787 I:0.1279�:0.0542 not:0.0962 bit:0.0337,:0.0928.:0.1562 I:0.2021)
		(,:0.1475 I:0.1079�:0.0752 not:0.1064 bit:0.0452 that:0.1064 that:0.1250 I:0.1572)
		(,:0.1348 I:0.0977�:0.0806 not:0.1060 bit:0.0457 that:0.1108 that:0.1455 I:0.1484)
		(,:0.1289 I:0.0938�:0.0845 not:0.1055 bit:0.0454 that:0.1108 that:0.1572 I:0.1494)
		(,:0.1289 I:0.0942�:0.0820 not:0.1040 bit:0.0437 that:0.1108 that:0.1523 I:0.1455)
		(,:0.1260 I:0.0923�:0.0825 not:0.1040 bit:0.0427 that:0.1108 that:0.1553 I:0.1465)
		(,:0.1235 I:0.0908�:0.0801 not:0.0996 bit:0.0422 that:0.1079.:0.1445 I:0.1406)
		(,:0.1216 I:0.0918�:0.0786 not:0.1011 bit:0.0420 that:0.1055.:0.1475 I:0.1436)
		(,:0.1196 I:0.0923�:0.0781 not:0.0977 little:0.0420 that:0.1040.:0.1494 and:0.1387)
		(,:0.1152 I:0.0928�:0.0742 not:0.0952 little:0.0435 that:0.1021.:0.1572 I:0.1426)
		(,:0.1108 I:0.0938�:0.0752 not:0.0981 little:0.0452 that:0.1011.:0.1543 I:0.1396)
		(,:0.1108 I:0.0938�:0.0752 not:0.0981 little:0.0452 that:0.1011.:0.1543 I:0.1396)
 I
------
		( I:0.0713�:0.0693 a:0.0850 lot:0.0315,:0.1855,:0.2158 I:0.1523 am:0.0684)
		( I:0.1279�:0.0542 not:0.0962 bit:0.0337,:0.0928.:0.1562 I:0.2021'm:0.0903)
		( I:0.1079�:0.0752 not:0.1064 bit:0.0452 that:0.1064 that:0.1250 I:0.1572'm:0.2617)
		( I:0.0977�:0.0806 not:0.1060 bit:0.0457 that:0.1108 that:0.1455 I:0.1484'm:0.3555)
		( I:0.0938�:0.0845 not:0.1055 bit:0.0454 that:0.1108 that:0.1572 I:0.1494'm:0.3984)
		( I:0.0942�:0.0820 not:0.1040 bit:0.0437 that:0.1108 that:0.1523 I:0.1455'm:0.4199)
		( I:0.0923�:0.0825 not:0.1040 bit:0.0427 that:0.1108 that:0.1553 I:0.1465'm:0.4199)
		( I:0.0908�:0.0801 not:0.0996 bit:0.0422 that:0.1079.:0.1445 I:0.1406'm:0.4160)
		( I:0.0918�:0.0786 not:0.1011 bit:0.0420 that:0.1055.:0.1475 I:0.1436'm:0.3984)
		( I:0.0923�:0.0781 not:0.0977 little:0.0420 that:0.1040.:0.1494 and:0.1387'm:0.3867)
		( I:0.0928�:0.0742 not:0.0952 little:0.0435 that:0.1021.:0.1572 I:0.1426'm:0.3770)
		( I:0.0938�:0.0752 not:0.0981 little:0.0452 that:0.1011.:0.1543 I:0.1396'm:0.3691)
		( I:0.0938�:0.0752 not:0.0981 little:0.0452 that:0.1011.:0.1543 I:0.1396'm:0.3691)
'm a bit like a bit like a bit like a
2000: sample 0: Hello, I'm a language model,
------
		(,:0.1621 the:0.0591 am:0.0659 going:0.1089 lot:0.0195.:0.1533.:0.2637 I:0.0967)
		(,:0.1504 I:0.1123 have:0.0537 going:0.1226 bit:0.0498.:0.2061.:0.2949 I:0.1953)
		(,:0.1445 I:0.1162 have:0.0588 not:0.1191 bit:0.0623.:0.1250.:0.2217 and:0.1787)
		(,:0.1484 I:0.1172�:0.0625 sure:0.1426 bit:0.0615.:0.0972.:0.1992 and:0.1875)
		(,:0.1504 I:0.1157�:0.0693 sure:0.1484 bit:0.0615.:0.0894.:0.2070 and:0.1934)
		(,:0.1562 I:0.1143�:0.0762 sure:0.1426 bit:0.0579.:0.0845.:0.2070 and:0.2021)
		(,:0.1582 I:0.1133�:0.0801 sure:0.1338 bit:0.0569.:0.0801.:0.2080 and:0.2100)
		(,:0.1611 I:0.1152�:0.0854 not:0.1260 bit:0.0549.:0.0791.:0.2090 and:0.2158)
		(,:0.1611 I:0.1138�:0.0820 not:0.1270 little:0.0520.:0.0776.:0.2031 and:0.2129)
		(,:0.1611 I:0.1152�:0.0845 not:0.1289 little:0.0527.:0.0767.:0.1982 and:0.2188)
		(,:0.1621 I:0.1138�:0.0820 not:0.1245 little:0.0535.:0.0742.:0.2061 and:0.2158)
		(.:0.1641 I:0.1162�:0.0801 not:0.1260 little:0.0547.:0.0737.:0.2041 and:0.2119)
		(.:0.1641 I:0.1162�:0.0801 not:0.1260 little:0.0547.:0.0737.:0.2041 and:0.2119)
 and
------
		( the:0.0591 am:0.0659 going:0.1089 lot:0.0195.:0.1533.:0.2637 I:0.0967 I:0.0977)
		( I:0.1123 have:0.0537 going:0.1226 bit:0.0498.:0.2061.:0.2949 I:0.1953 I:0.2969)
		( I:0.1162 have:0.0588 not:0.1191 bit:0.0623.:0.1250.:0.2217 and:0.1787 I:0.3340)
		( I:0.1172�:0.0625 sure:0.1426 bit:0.0615.:0.0972.:0.1992 and:0.1875 I:0.3750)
		( I:0.1157�:0.0693 sure:0.1484 bit:0.0615.:0.0894.:0.2070 and:0.1934 I:0.4082)
		( I:0.1143�:0.0762 sure:0.1426 bit:0.0579.:0.0845.:0.2070 and:0.2021 I:0.4492)
		( I:0.1133�:0.0801 sure:0.1338 bit:0.0569.:0.0801.:0.2080 and:0.2100 I:0.4629)
		( I:0.1152�:0.0854 not:0.1260 bit:0.0549.:0.0791.:0.2090 and:0.2158 I:0.4766)
		( I:0.1138�:0.0820 not:0.1270 little:0.0520.:0.0776.:0.2031 and:0.2129 I:0.4902)
		( I:0.1152�:0.0845 not:0.1289 little:0.0527.:0.0767.:0.1982 and:0.2188 I:0.4883)
		( I:0.1138�:0.0820 not:0.1245 little:0.0535.:0.0742.:0.2061 and:0.2158 I:0.4863)
		( I:0.1162�:0.0801 not:0.1260 little:0.0547.:0.0737.:0.2041 and:0.2119 I:0.4844)
		( I:0.1162�:0.0801 not:0.1260 little:0.0547.:0.0737.:0.2041 and:0.2119 I:0.4844)
 I'm a bit like to be a language model.
2150: sample 0: Hello, I'm a language model,
------
		(,:0.1621 the:0.0601 have:0.0576 not:0.1611 lot:0.0166.:0.1709.:0.2695 I:0.1406)
		(,:0.1494 I:0.0737 have:0.0752 not:0.2021 lot:0.0189.:0.1318.:0.2061 I:0.1436)
		(,:0.1523 I:0.0757 have:0.0850 not:0.2119 very:0.0217,:0.0879.:0.1475 and:0.2275)
		(,:0.1592 I:0.0747 have:0.0918 not:0.2080 very:0.0227,:0.0649 of:0.1543 and:0.2412)
		(,:0.1670 and:0.0762 have:0.0972 not:0.1846 very:0.0237 that:0.0559 of:0.1445 and:0.2451)
		(,:0.1758 and:0.0854 have:0.1006 not:0.1758 very:0.0240 that:0.0510 of:0.1387 and:0.2393)
		(,:0.1855 and:0.0908 have:0.1016 not:0.1621 great:0.0254 teacher:0.0559 of:0.1357 and:0.2461)
		(,:0.1885 and:0.0991 have:0.1045 not:0.1426 great:0.0270 teacher:0.0579 for:0.1426 and:0.2422)
		(,:0.1963 and:0.1050 have:0.1079 not:0.1328 great:0.0281 teacher:0.0569 for:0.1523 and:0.2500)
		(,:0.1982 and:0.1108 have:0.1060 not:0.1250 great:0.0293 teacher:0.0564 for:0.1523 and:0.2451)
		(,:0.1973 and:0.1138 have:0.1050 not:0.1172 great:0.0306 teacher:0.0562 for:0.1611 and:0.2412)
		(,:0.1963 and:0.1167 have:0.1045 not:0.1094 great:0.0310 teacher:0.0544 for:0.1631 and:0.2373)
		(,:0.1963 and:0.1167 have:0.1045 not:0.1094 great:0.0310 teacher:0.0544 for:0.1631 and:0.2373)
 and
------
		( the:0.0601 have:0.0576 not:0.1611 lot:0.0166.:0.1709.:0.2695 I:0.1406 I:0.1309)
		( I:0.0737 have:0.0752 not:0.2021 lot:0.0189.:0.1318.:0.2061 I:0.1436 I:0.3379)
		( I:0.0757 have:0.0850 not:0.2119 very:0.0217,:0.0879.:0.1475 and:0.2275 I:0.4023)
		( I:0.0747 have:0.0918 not:0.2080 very:0.0227,:0.0649 of:0.1543 and:0.2412 I:0.4355)
		( and:0.0762 have:0.0972 not:0.1846 very:0.0237 that:0.0559 of:0.1445 and:0.2451 I:0.4609)
		( and:0.0854 have:0.1006 not:0.1758 very:0.0240 that:0.0510 of:0.1387 and:0.2393 I:0.4941)
		( and:0.0908 have:0.1016 not:0.1621 great:0.0254 teacher:0.0559 of:0.1357 and:0.2461 I:0.5156)
		( and:0.0991 have:0.1045 not:0.1426 great:0.0270 teacher:0.0579 for:0.1426 and:0.2422 I:0.5391)
		( and:0.1050 have:0.1079 not:0.1328 great:0.0281 teacher:0.0569 for:0.1523 and:0.2500 I:0.5430)
		( and:0.1108 have:0.1060 not:0.1250 great:0.0293 teacher:0.0564 for:0.1523 and:0.2451 I:0.5469)
		( and:0.1138 have:0.1050 not:0.1172 great:0.0306 teacher:0.0562 for:0.1611 and:0.2412 I:0.5508)
		( and:0.1167 have:0.1045 not:0.1094 great:0.0310 teacher:0.0544 for:0.1631 and:0.2373 I:0.5547)
		( and:0.1167 have:0.1045 not:0.1094 great:0.0310 teacher:0.0544 for:0.1631 and:0.2373 I:0.5547)
 I'm a language model.
- The word "
2300: sample 0: Hello, I'm a language model,
------
		(,:0.0996 the:0.0449 have:0.0588 not:0.0889 lot:0.0177.:0.1099.:0.1787 I:0.0996)
		(,:0.0898 I:0.0825 have:0.0591 not:0.1270 bit:0.0205 of:0.1021.:0.1553 I:0.1455)
		(,:0.0864 I:0.0908 have:0.0669 not:0.1113 bit:0.0225 of:0.0923 of:0.1318 I:0.1963)
		(,:0.0903 I:0.0894 have:0.0688 not:0.1079 bit:0.0210 of:0.0776 of:0.1387 I:0.2178)
		(,:0.0928 I:0.0889 have:0.0698 not:0.1040 little:0.0214 of:0.0684 of:0.1338 I:0.2207)
		(,:0.0991 I:0.0879�:0.0718 not:0.0977 little:0.0227 of:0.0640.:0.1318 I:0.2129)
		(,:0.1025 I:0.0869�:0.0801 sure:0.1001 little:0.0237 of:0.0625.:0.1416 I:0.2207)
		(,:0.1069 I:0.0835�:0.0864 sure:0.0972 little:0.0248 of:0.0623.:0.1475 I:0.2266)
		(,:0.1113 I:0.0830�:0.0889 sure:0.0903 little:0.0254 of:0.0645.:0.1514 I:0.2246)
		(,:0.1123 I:0.0845�:0.0967 sure:0.0894 little:0.0251 of:0.0649.:0.1494 I:0.2314)
		(,:0.1138 I:0.0835�:0.1006 sure:0.0889 little:0.0251 of:0.0684.:0.1582 I:0.2412)
		(,:0.1147 I:0.0825�:0.1040 sure:0.0830 little:0.0250 of:0.0698.:0.1562 I:0.2393)
		(,:0.1147 I:0.0825�:0.1040 sure:0.0830 little:0.0250 of:0.0698.:0.1562 I:0.2393)
 I
------
		( the:0.0449 have:0.0588 not:0.0889 lot:0.0177.:0.1099.:0.1787 I:0.0996 think:0.0520)
		( I:0.0825 have:0.0591 not:0.1270 bit:0.0205 of:0.1021.:0.1553 I:0.1455'm:0.1396)
		( I:0.0908 have:0.0669 not:0.1113 bit:0.0225 of:0.0923 of:0.1318 I:0.1963'm:0.3320)
		( I:0.0894 have:0.0688 not:0.1079 bit:0.0210 of:0.0776 of:0.1387 I:0.2178'm:0.3770)
		( I:0.0889 have:0.0698 not:0.1040 little:0.0214 of:0.0684 of:0.1338 I:0.2207'm:0.3730)
		( I:0.0879�:0.0718 not:0.0977 little:0.0227 of:0.0640.:0.1318 I:0.2129'm:0.3633)
		( I:0.0869�:0.0801 sure:0.1001 little:0.0237 of:0.0625.:0.1416 I:0.2207'm:0.3340)
		( I:0.0835�:0.0864 sure:0.0972 little:0.0248 of:0.0623.:0.1475 I:0.2266'm:0.3301)
		( I:0.0830�:0.0889 sure:0.0903 little:0.0254 of:0.0645.:0.1514 I:0.2246'm:0.3145)
		( I:0.0845�:0.0967 sure:0.0894 little:0.0251 of:0.0649.:0.1494 I:0.2314'm:0.2988)
		( I:0.0835�:0.1006 sure:0.0889 little:0.0251 of:0.0684.:0.1582 I:0.2412'm:0.2871)
		( I:0.0825�:0.1040 sure:0.0830 little:0.0250 of:0.0698.:0.1562 I:0.2393'm:0.2754)
		( I:0.0825�:0.1040 sure:0.0830 little:0.0250 of:0.0698.:0.1562 I:0.2393'm:0.2754)
'm a teacher.
The first thing to do is
2450: sample 0: Hello, I'm a language model,
------
		(,:0.1182 the:0.0796 will:0.0503 not:0.1289 lot:0.0148.:0.1309.:0.1670 and:0.1074)
		(,:0.1147 I:0.0840 was:0.0588 not:0.1787 bit:0.0332 of:0.0806 for:0.1318 I:0.2617)
		(,:0.1099 I:0.0874 was:0.0669 not:0.1709 bit:0.0332 of:0.0649 for:0.1484 and:0.2412)
		(,:0.1128 I:0.0840 was:0.0649 not:0.1738 bit:0.0312 of:0.0510 for:0.1533 and:0.2285)
		(,:0.1143 I:0.0811 was:0.0625 not:0.1738 bit:0.0295 of:0.0435 for:0.1602 and:0.2441)
		(,:0.1157 I:0.0767 was:0.0596 not:0.1689 bit:0.0286 of:0.0417 for:0.1641 and:0.2480)
		(,:0.1147 I:0.0723 was:0.0552 not:0.1680 bit:0.0281 teacher:0.0447 for:0.1689 and:0.2520)
		(,:0.1177 and:0.0776 was:0.0549 not:0.1592 student:0.0284 teacher:0.0469 for:0.1768 and:0.2471)
		(,:0.1206 and:0.0854 was:0.0522 not:0.1523 student:0.0309 teacher:0.0483 for:0.1768 and:0.2520)
		(,:0.1201 and:0.0918 was:0.0500 not:0.1475 student:0.0327 teacher:0.0483 for:0.1777 and:0.2461)
		(,:0.1201 and:0.0981 have:0.0515 not:0.1436 student:0.0334 of:0.0486 for:0.1787 and:0.2520)
		(,:0.1201 and:0.1021 have:0.0532 not:0.1406 student:0.0354 of:0.0510 for:0.1807 and:0.2461)
		(,:0.1201 and:0.1021 have:0.0532 not:0.1406 student:0.0354 of:0.0510 for:0.1807 and:0.2461)
 and
------
		( the:0.0796 will:0.0503 not:0.1289 lot:0.0148.:0.1309.:0.1670 and:0.1074 I:0.0913)
		( I:0.0840 was:0.0588 not:0.1787 bit:0.0332 of:0.0806 for:0.1318 I:0.2617 I:0.4766)
		( I:0.0874 was:0.0669 not:0.1709 bit:0.0332 of:0.0649 for:0.1484 and:0.2412 I:0.3691)
		( I:0.0840 was:0.0649 not:0.1738 bit:0.0312 of:0.0510 for:0.1533 and:0.2285 I:0.4375)
		( I:0.0811 was:0.0625 not:0.1738 bit:0.0295 of:0.0435 for:0.1602 and:0.2441 I:0.4805)
		( I:0.0767 was:0.0596 not:0.1689 bit:0.0286 of:0.0417 for:0.1641 and:0.2480 I:0.4961)
		( I:0.0723 was:0.0552 not:0.1680 bit:0.0281 teacher:0.0447 for:0.1689 and:0.2520 I:0.5156)
		( and:0.0776 was:0.0549 not:0.1592 student:0.0284 teacher:0.0469 for:0.1768 and:0.2471 I:0.5156)
		( and:0.0854 was:0.0522 not:0.1523 student:0.0309 teacher:0.0483 for:0.1768 and:0.2520 I:0.5312)
		( and:0.0918 was:0.0500 not:0.1475 student:0.0327 teacher:0.0483 for:0.1777 and:0.2461 I:0.5312)
		( and:0.0981 have:0.0515 not:0.1436 student:0.0334 of:0.0486 for:0.1787 and:0.2520 I:0.5312)
		( and:0.1021 have:0.0532 not:0.1406 student:0.0354 of:0.0510 for:0.1807 and:0.2461 I:0.5312)
		( and:0.1021 have:0.0532 not:0.1406 student:0.0354 of:0.0510 for:0.1807 and:0.2461 I:0.5312)
 I'm a student, and I'm a student,
2600: sample 0: Hello, I'm a language model,
------
		(,:0.0903 the:0.0605�:0.1089 not:0.0649 lot:0.0265.:0.1562.:0.3320 and:0.0996)
		(,:0.0806 the:0.0879�:0.0674 not:0.0913 bit:0.0435.:0.1123.:0.2295 I:0.2002)
		(,:0.0718 I:0.0869�:0.0840 not:0.0928 bit:0.0500,:0.0981.:0.1738 and:0.2559)
		(,:0.0669 I:0.0830�:0.0913 not:0.0972 bit:0.0503,:0.0957.:0.1611 and:0.2393)
		(,:0.0630 I:0.0820�:0.0977 not:0.1006 little:0.0496,:0.0903.:0.1562 and:0.2402)
		(,:0.0598 I:0.0791�:0.0972 not:0.0981 little:0.0532,:0.0894.:0.1533 and:0.2393)
		(,:0.0581 I:0.0786�:0.0942 not:0.0977 little:0.0571,:0.0864.:0.1533 and:0.2373)
		(,:0.0549 I:0.0762�:0.0918 not:0.0952 little:0.0583,:0.0864,:0.1465 and:0.2363)
		(,:0.0515 I:0.0757�:0.0898 not:0.0903 little:0.0608,:0.0864,:0.1484 and:0.2354)
		(,:0.0483 I:0.0757�:0.0840 not:0.0894 little:0.0598,:0.0869,:0.1426 and:0.2324)
		(,:0.0452 I:0.0752�:0.0825 not:0.0854 little:0.0608,:0.0874,:0.1465 and:0.2285)
		(,:0.0420 I:0.0752�:0.0776 not:0.0830 little:0.0603,:0.0884,:0.1484 and:0.2256)
		(,:0.0420 I:0.0752�:0.0776 not:0.0830 little:0.0603,:0.0884,:0.1484 and:0.2256)
 and
------
		( the:0.0605�:0.1089 not:0.0649 lot:0.0265.:0.1562.:0.3320 and:0.0996 I:0.1426)
		( the:0.0879�:0.0674 not:0.0913 bit:0.0435.:0.1123.:0.2295 I:0.2002 I:0.5820)
		( I:0.0869�:0.0840 not:0.0928 bit:0.0500,:0.0981.:0.1738 and:0.2559 I:0.4395)
		( I:0.0830�:0.0913 not:0.0972 bit:0.0503,:0.0957.:0.1611 and:0.2393 I:0.5312)
		( I:0.0820�:0.0977 not:0.1006 little:0.0496,:0.0903.:0.1562 and:0.2402 I:0.5625)
		( I:0.0791�:0.0972 not:0.0981 little:0.0532,:0.0894.:0.1533 and:0.2393 I:0.5938)
		( I:0.0786�:0.0942 not:0.0977 little:0.0571,:0.0864.:0.1533 and:0.2373 I:0.6055)
		( I:0.0762�:0.0918 not:0.0952 little:0.0583,:0.0864,:0.1465 and:0.2363 I:0.5977)
		( I:0.0757�:0.0898 not:0.0903 little:0.0608,:0.0864,:0.1484 and:0.2354 I:0.6055)
		( I:0.0757�:0.0840 not:0.0894 little:0.0598,:0.0869,:0.1426 and:0.2324 I:0.6094)
		( I:0.0752�:0.0825 not:0.0854 little:0.0608,:0.0874,:0.1465 and:0.2285 I:0.6133)
		( I:0.0752�:0.0776 not:0.0830 little:0.0603,:0.0884,:0.1484 and:0.2256 I:0.6172)
		( I:0.0752�:0.0776 not:0.0830 little:0.0603,:0.0884,:0.1484 and:0.2256 I:0.6172)
 I'm a language model, and I'm a language
2750: sample 0: Hello, I'm a language model,
------
		(,:0.0781 the:0.0713�:0.0938 going:0.1040 lot:0.0250 of:0.1553.:0.2715 I:0.2598)
		(,:0.0786 I:0.1118�:0.0737 going:0.1123 lot:0.0244 to:0.0747.:0.1807 I:0.2930)
		(,:0.0791 I:0.1143�:0.0757 going:0.1084 little:0.0352,:0.0620 for:0.1650 I:0.2256)
		(,:0.0791 I:0.1079�:0.0703 going:0.0991 little:0.0466,:0.0635 for:0.1582 I:0.2402)
		(,:0.0796 I:0.1016�:0.0718 not:0.1074 little:0.0574,:0.0608.:0.1455 I:0.2412)
		(,:0.0811 I:0.0977�:0.0718 not:0.1123 little:0.0654,:0.0583.:0.1533 I:0.2432)
		(,:0.0781 I:0.0918�:0.0752 not:0.1177 little:0.0708 teacher:0.0645.:0.1641 I:0.2500)
		(,:0.0776 I:0.0864�:0.0767 not:0.1182 little:0.0771 teacher:0.0703.:0.1680 I:0.2451)
		(,:0.0776 I:0.0845�:0.0781 not:0.1182 little:0.0811 teacher:0.0728.:0.1719 I:0.2500)
		(,:0.0752 and:0.0825�:0.0767 not:0.1250 little:0.0835 teacher:0.0737.:0.1748 I:0.2441)
		(,:0.0728 and:0.0884�:0.0752 not:0.1250 little:0.0854 teacher:0.0747.:0.1787 I:0.2559)
		(,:0.0684 and:0.0923�:0.0786 not:0.1260 little:0.0854 teacher:0.0742.:0.1729 I:0.2539)
		(,:0.0684 and:0.0923�:0.0786 not:0.1260 little:0.0854 teacher:0.0742.:0.1729 I:0.2539)
 I
------
		( the:0.0713�:0.0938 going:0.1040 lot:0.0250 of:0.1553.:0.2715 I:0.2598 am:0.0439)
		( I:0.1118�:0.0737 going:0.1123 lot:0.0244 to:0.0747.:0.1807 I:0.2930'm:0.4570)
		( I:0.1143�:0.0757 going:0.1084 little:0.0352,:0.0620 for:0.1650 I:0.2256'm:0.6523)
		( I:0.1079�:0.0703 going:0.0991 little:0.0466,:0.0635 for:0.1582 I:0.2402'm:0.6406)
		( I:0.1016�:0.0718 not:0.1074 little:0.0574,:0.0608.:0.1455 I:0.2412'm:0.6133)
		( I:0.0977�:0.0718 not:0.1123 little:0.0654,:0.0583.:0.1533 I:0.2432'm:0.5664)
		( I:0.0918�:0.0752 not:0.1177 little:0.0708 teacher:0.0645.:0.1641 I:0.2500'm:0.5273)
		( I:0.0864�:0.0767 not:0.1182 little:0.0771 teacher:0.0703.:0.1680 I:0.2451'm:0.4922)
		( I:0.0845�:0.0781 not:0.1182 little:0.0811 teacher:0.0728.:0.1719 I:0.2500'm:0.4629)
		( and:0.0825�:0.0767 not:0.1250 little:0.0835 teacher:0.0737.:0.1748 I:0.2441'm:0.4375)
		( and:0.0884�:0.0752 not:0.1250 little:0.0854 teacher:0.0747.:0.1787 I:0.2559'm:0.4121)
		( and:0.0923�:0.0786 not:0.1260 little:0.0854 teacher:0.0742.:0.1729 I:0.2539'm:0.3848)
		( and:0.0923�:0.0786 not:0.1260 little:0.0854 teacher:0.0742.:0.1729 I:0.2539'm:0.3848)
'm a language model, I'm a language model,
2900: sample 0: Hello, I'm a language model,
------
		(,:0.0771 the:0.0776 will:0.0693 going:0.1436 lot:0.0248.:0.1494.:0.2715 I:0.1709)
		(,:0.0688 I:0.1235 have:0.0471 going:0.1807 bit:0.0479 of:0.1050.:0.1924 I:0.4082)
		(,:0.0640 I:0.1396'm:0.0557 going:0.1963 bit:0.0530 of:0.0986.:0.1738 I:0.2812)
		(,:0.0620 I:0.1416'm:0.0645 going:0.1953 little:0.0579,:0.0801.:0.1816 I:0.2871)
		(.:0.0645 I:0.1348'm:0.0674 going:0.1973 little:0.0693,:0.0757.:0.1816 I:0.2852)
		(.:0.0659 I:0.1299'm:0.0718 going:0.1875 little:0.0801,:0.0713.:0.1855 I:0.2734)
		(.:0.0674 I:0.1270'm:0.0713 going:0.1914 little:0.0859,:0.0679.:0.1807 I:0.2637)
		(.:0.0688 I:0.1240'm:0.0718 going:0.1904 little:0.0952,:0.0649.:0.1768 I:0.2598)
		(.:0.0688 I:0.1216'm:0.0737 going:0.1807 little:0.1001,:0.0623.:0.1738 I:0.2578)
		(.:0.0664 I:0.1201'm:0.0723 going:0.1797 little:0.0996,:0.0601.:0.1592 I:0.2676)
		(.:0.0645 I:0.1182'm:0.0708 going:0.1807 little:0.1045 teacher:0.0620.:0.1562 I:0.2676)
		(.:0.0625 I:0.1162'm:0.0742 going:0.1729 little:0.1045 teacher:0.0640.:0.1504 I:0.2676)
		(.:0.0625 I:0.1162'm:0.0742 going:0.1729 little:0.1045 teacher:0.0640.:0.1504 I:0.2676)
 I
------
		( the:0.0776 will:0.0693 going:0.1436 lot:0.0248.:0.1494.:0.2715 I:0.1709'm:0.0674)
		( I:0.1235 have:0.0471 going:0.1807 bit:0.0479 of:0.1050.:0.1924 I:0.4082'm:0.4570)
		( I:0.1396'm:0.0557 going:0.1963 bit:0.0530 of:0.0986.:0.1738 I:0.2812'm:0.5938)
		( I:0.1416'm:0.0645 going:0.1953 little:0.0579,:0.0801.:0.1816 I:0.2871'm:0.6328)
		( I:0.1348'm:0.0674 going:0.1973 little:0.0693,:0.0757.:0.1816 I:0.2852'm:0.6406)
		( I:0.1299'm:0.0718 going:0.1875 little:0.0801,:0.0713.:0.1855 I:0.2734'm:0.6211)
		( I:0.1270'm:0.0713 going:0.1914 little:0.0859,:0.0679.:0.1807 I:0.2637'm:0.6172)
		( I:0.1240'm:0.0718 going:0.1904 little:0.0952,:0.0649.:0.1768 I:0.2598'm:0.6016)
		( I:0.1216'm:0.0737 going:0.1807 little:0.1001,:0.0623.:0.1738 I:0.2578'm:0.5898)
		( I:0.1201'm:0.0723 going:0.1797 little:0.0996,:0.0601.:0.1592 I:0.2676'm:0.5742)
		( I:0.1182'm:0.0708 going:0.1807 little:0.1045 teacher:0.0620.:0.1562 I:0.2676'm:0.5664)
		( I:0.1162'm:0.0742 going:0.1729 little:0.1045 teacher:0.0640.:0.1504 I:0.2676'm:0.5508)
		( I:0.1162'm:0.0742 going:0.1729 little:0.1045 teacher:0.0640.:0.1504 I:0.2676'm:0.5508)
'm a language model, I'm a language model,
3050: sample 0: Hello, I'm a language model,
------
		(,:0.0820 the:0.0894 will:0.0603 going:0.0864 lot:0.0253 of:0.1670.:0.2207 I:0.2217)
		(,:0.0776 the:0.0811 have:0.0520 going:0.1128 bit:0.0388 of:0.0815 for:0.1162 I:0.3027)
		(,:0.0757 I:0.0757 have:0.0557 going:0.1367 bit:0.0427 of:0.0532.:0.1128 I:0.1729)
		(,:0.0742 I:0.0786 have:0.0586 going:0.1436 bit:0.0466 of:0.0403.:0.1396 I:0.1572)
		(,:0.0718 I:0.0747 have:0.0605 going:0.1387 bit:0.0500 teacher:0.0471.:0.1533 I:0.1553)
		(,:0.0713 I:0.0713 have:0.0591 going:0.1396 bit:0.0522 teacher:0.0530.:0.1572 I:0.1533)
		(,:0.0713 I:0.0693 have:0.0593 going:0.1436 bit:0.0552 teacher:0.0562.:0.1592 I:0.1543)
		(,:0.0698 I:0.0669 have:0.0608 going:0.1406 bit:0.0569 teacher:0.0579.:0.1582 I:0.1572)
		(,:0.0679 and:0.0688 have:0.0596 going:0.1465 bit:0.0593 teacher:0.0586.:0.1572 I:0.1553)
		(,:0.0664 and:0.0737 have:0.0581 going:0.1455 bit:0.0601 teacher:0.0581.:0.1514 I:0.1592)
		(,:0.0669 and:0.0767 have:0.0574 going:0.1445 bit:0.0610 teacher:0.0579.:0.1465 I:0.1641)
		(,:0.0659 and:0.0815 have:0.0605 going:0.1445 bit:0.0620 teacher:0.0579.:0.1406 I:0.1641)
		(,:0.0659 and:0.0815 have:0.0605 going:0.1445 bit:0.0620 teacher:0.0579.:0.1406 I:0.1641)
 I
------
		( the:0.0894 will:0.0603 going:0.0864 lot:0.0253 of:0.1670.:0.2207 I:0.2217 think:0.0425)
		( the:0.0811 have:0.0520 going:0.1128 bit:0.0388 of:0.0815 for:0.1162 I:0.3027'm:0.3457)
		( I:0.0757 have:0.0557 going:0.1367 bit:0.0427 of:0.0532.:0.1128 I:0.1729'm:0.4805)
		( I:0.0786 have:0.0586 going:0.1436 bit:0.0466 of:0.0403.:0.1396 I:0.1572'm:0.4727)
		( I:0.0747 have:0.0605 going:0.1387 bit:0.0500 teacher:0.0471.:0.1533 I:0.1553'm:0.4531)
		( I:0.0713 have:0.0591 going:0.1396 bit:0.0522 teacher:0.0530.:0.1572 I:0.1533'm:0.4355)
		( I:0.0693 have:0.0593 going:0.1436 bit:0.0552 teacher:0.0562.:0.1592 I:0.1543'm:0.4102)
		( I:0.0669 have:0.0608 going:0.1406 bit:0.0569 teacher:0.0579.:0.1582 I:0.1572'm:0.3906)
		( and:0.0688 have:0.0596 going:0.1465 bit:0.0593 teacher:0.0586.:0.1572 I:0.1553'm:0.3750)
		( and:0.0737 have:0.0581 going:0.1455 bit:0.0601 teacher:0.0581.:0.1514 I:0.1592'm:0.3613)
		( and:0.0767 have:0.0574 going:0.1445 bit:0.0610 teacher:0.0579.:0.1465 I:0.1641'm:0.3340)
		( and:0.0815 have:0.0605 going:0.1445 bit:0.0620 teacher:0.0579.:0.1406 I:0.1641'm:0.3262)
		( and:0.0815 have:0.0605 going:0.1445 bit:0.0620 teacher:0.0579.:0.1406 I:0.1641'm:0.3262)
'm a bit of a bit of a bit of a
3200: sample 0: Hello, I'm a language model,
------
		(,:0.0991 I:0.1040.:0.0493 not:0.1084 lot:0.0304 of:0.1235.:0.2480 I:0.3242)
		(,:0.0879 I:0.0825'm:0.0830 not:0.1216 lot:0.0220 that:0.0679.:0.1484 I:0.3301)
		(,:0.0781 I:0.0693'm:0.1436 not:0.1074 member:0.0303 specialist:0.0400.:0.1426 I:0.2109)
		(,:0.0723 I:0.0635'm:0.1836 not:0.1118 member:0.0342 specialist:0.0566.:0.1650 I:0.1719)
		(,:0.0679 I:0.0605'm:0.2109 not:0.1191 member:0.0359 teacher:0.0674.:0.1660 and:0.1611)
		(,:0.0635 I:0.0588'm:0.2197 not:0.1235 member:0.0371 teacher:0.0737.:0.1660 and:0.1729)
		(.:0.0640 I:0.0576'm:0.2334 not:0.1289 member:0.0366 teacher:0.0771.:0.1602 and:0.1777)
		(.:0.0625 I:0.0564'm:0.2393 not:0.1279 member:0.0364 teacher:0.0767.:0.1494 and:0.1758)
		(.:0.0630 I:0.0557'm:0.2354 not:0.1270 member:0.0364 teacher:0.0762.:0.1426 and:0.1836)
		(.:0.0618 I:0.0549'm:0.2432 not:0.1270 member:0.0361 teacher:0.0732.:0.1299 and:0.1846)
		(.:0.0608 I:0.0525'm:0.2422 not:0.1270 good:0.0352 teacher:0.0693.:0.1187 and:0.1836)
		(.:0.0598 I:0.0520'm:0.2393 not:0.1270 good:0.0364 student:0.0659.:0.1104 and:0.1836)
		(.:0.0598 I:0.0520'm:0.2393 not:0.1270 good:0.0364 student:0.0659.:0.1104 and:0.1836)
 and
------
		( I:0.1040.:0.0493 not:0.1084 lot:0.0304 of:0.1235.:0.2480 I:0.3242 I:0.4844)
		( I:0.0825'm:0.0830 not:0.1216 lot:0.0220 that:0.0679.:0.1484 I:0.3301 I:0.5820)
		( I:0.0693'm:0.1436 not:0.1074 member:0.0303 specialist:0.0400.:0.1426 I:0.2109 I:0.4043)
		( I:0.0635'm:0.1836 not:0.1118 member:0.0342 specialist:0.0566.:0.1650 I:0.1719 I:0.4668)
		( I:0.0605'm:0.2109 not:0.1191 member:0.0359 teacher:0.0674.:0.1660 and:0.1611 I:0.4941)
		( I:0.0588'm:0.2197 not:0.1235 member:0.0371 teacher:0.0737.:0.1660 and:0.1729 I:0.5039)
		( I:0.0576'm:0.2334 not:0.1289 member:0.0366 teacher:0.0771.:0.1602 and:0.1777 I:0.5039)
		( I:0.0564'm:0.2393 not:0.1279 member:0.0364 teacher:0.0767.:0.1494 and:0.1758 I:0.4922)
		( I:0.0557'm:0.2354 not:0.1270 member:0.0364 teacher:0.0762.:0.1426 and:0.1836 I:0.4785)
		( I:0.0549'm:0.2432 not:0.1270 member:0.0361 teacher:0.0732.:0.1299 and:0.1846 I:0.4688)
		( I:0.0525'm:0.2422 not:0.1270 good:0.0352 teacher:0.0693.:0.1187 and:0.1836 I:0.4551)
		( I:0.0520'm:0.2393 not:0.1270 good:0.0364 student:0.0659.:0.1104 and:0.1836 I:0.4453)
		( I:0.0520'm:0.2393 not:0.1270 good:0.0364 student:0.0659.:0.1104 and:0.1836 I:0.4453)
 I'm a good teacher.
The first step is
3350: sample 0: Hello, I'm a language model,
------
		(,:0.1016 I:0.0859.:0.0598 not:0.1128 lot:0.0393 that:0.1089.:0.1982 I:0.3301)
		(,:0.0928 the:0.0991 have:0.0654 not:0.1348 bit:0.0232 that:0.1689.:0.1377 I:0.2949)
		(,:0.0854 I:0.0811 have:0.0728 not:0.1167 little:0.0320 that:0.1406 that:0.1504 and:0.1885)
		(,:0.0801 I:0.0684 have:0.0796 not:0.1182 little:0.0393 that:0.1157 that:0.1494 and:0.2061)
		(,:0.0771 and:0.0645 have:0.0825 not:0.1162 little:0.0449 that:0.0967,:0.1504 and:0.2217)
		(,:0.0732 and:0.0698'm:0.0859 not:0.1123 little:0.0481 that:0.0811,:0.1562 and:0.2168)
		(,:0.0713 and:0.0757'm:0.0918 not:0.1113 little:0.0505 that:0.0742,:0.1553 and:0.2236)
		(,:0.0684 and:0.0815'm:0.0947 not:0.1108 little:0.0518 that:0.0693,:0.1572 and:0.2217)
		(,:0.0669 and:0.0859'm:0.0981 not:0.1045 little:0.0532 that:0.0684,:0.1582 and:0.2197)
		(,:0.0640 and:0.0928'm:0.0977 not:0.0991 little:0.0518 that:0.0654,:0.1514 and:0.2285)
		(,:0.0635 and:0.0952'm:0.1021 not:0.1001 little:0.0515 that:0.0679,:0.1523 and:0.2285)
		(,:0.0605 and:0.1001'm:0.1021 not:0.0952 little:0.0515 that:0.0684,:0.1455 and:0.2285)
		(,:0.0605 and:0.1001'm:0.1021 not:0.0952 little:0.0515 that:0.0684,:0.1455 and:0.2285)
 and
------
		( I:0.0859.:0.0598 not:0.1128 lot:0.0393 that:0.1089.:0.1982 I:0.3301 I:0.4297)
		( the:0.0991 have:0.0654 not:0.1348 bit:0.0232 that:0.1689.:0.1377 I:0.2949 I:0.5234)
		( I:0.0811 have:0.0728 not:0.1167 little:0.0320 that:0.1406 that:0.1504 and:0.1885 I:0.3809)
		( I:0.0684 have:0.0796 not:0.1182 little:0.0393 that:0.1157 that:0.1494 and:0.2061 I:0.4805)
		( and:0.0645 have:0.0825 not:0.1162 little:0.0449 that:0.0967,:0.1504 and:0.2217 I:0.5273)
		( and:0.0698'm:0.0859 not:0.1123 little:0.0481 that:0.0811,:0.1562 and:0.2168 I:0.5508)
		( and:0.0757'm:0.0918 not:0.1113 little:0.0505 that:0.0742,:0.1553 and:0.2236 I:0.5625)
		( and:0.0815'm:0.0947 not:0.1108 little:0.0518 that:0.0693,:0.1572 and:0.2217 I:0.5625)
		( and:0.0859'm:0.0981 not:0.1045 little:0.0532 that:0.0684,:0.1582 and:0.2197 I:0.5469)
		( and:0.0928'm:0.0977 not:0.0991 little:0.0518 that:0.0654,:0.1514 and:0.2285 I:0.5469)
		( and:0.0952'm:0.1021 not:0.1001 little:0.0515 that:0.0679,:0.1523 and:0.2285 I:0.5352)
		( and:0.1001'm:0.1021 not:0.0952 little:0.0515 that:0.0684,:0.1455 and:0.2285 I:0.5234)
		( and:0.1001'm:0.1021 not:0.0952 little:0.0515 that:0.0684,:0.1455 and:0.2285 I:0.5234)
 I'm a little bit more than a little bit of
3500: sample 0: Hello, I'm a language model,
------
		(,:0.0752 I:0.0500�:0.0737 not:0.0708 lot:0.0571,:0.1226.:0.1484 I:0.3359)
		(,:0.0728 the:0.0825�:0.0610 not:0.0845 bit:0.0417 that:0.0986 that:0.1357 I:0.2363)
		(,:0.0693 the:0.0601�:0.0649 sure:0.1167 bit:0.0396 that:0.0547 that:0.1523 I:0.1807)
		(,:0.0664 I:0.0625�:0.0674 sure:0.1279 little:0.0403 teacher:0.0742 that:0.1348 I:0.1797)
		(,:0.0645 I:0.0679�:0.0752 sure:0.1162 little:0.0425 teacher:0.1011.:0.1157 I:0.1641)
		(,:0.0630 I:0.0703�:0.0786 sure:0.1089 little:0.0437 teacher:0.1152.:0.1172 I:0.1523)
		(,:0.0601 I:0.0713�:0.0840 sure:0.1035 little:0.0439 teacher:0.1196.:0.1167 and:0.1514)
		(,:0.0588 I:0.0708�:0.0864 sure:0.0942 little:0.0442 teacher:0.1177.:0.1152 and:0.1592)
		(,:0.0581 I:0.0703�:0.0850 sure:0.0913 little:0.0444 teacher:0.1152.:0.1138 and:0.1592)
		(,:0.0574 I:0.0679�:0.0889 sure:0.0889 little:0.0444 teacher:0.1138.:0.1113 and:0.1680)
		(,:0.0549 I:0.0659�:0.0879 sure:0.0869 little:0.0444 teacher:0.1064.:0.1084 and:0.1689)
		(,:0.0544 I:0.0659�:0.0874 sure:0.0854 little:0.0432 teacher:0.1006 for:0.1069 and:0.1699)
		(,:0.0544 I:0.0659�:0.0874 sure:0.0854 little:0.0432 teacher:0.1006 for:0.1069 and:0.1699)
 and
------
		( I:0.0500�:0.0737 not:0.0708 lot:0.0571,:0.1226.:0.1484 I:0.3359 I:0.4199)
		( the:0.0825�:0.0610 not:0.0845 bit:0.0417 that:0.0986 that:0.1357 I:0.2363 I:0.4277)
		( the:0.0601�:0.0649 sure:0.1167 bit:0.0396 that:0.0547 that:0.1523 I:0.1807 I:0.3594)
		( I:0.0625�:0.0674 sure:0.1279 little:0.0403 teacher:0.0742 that:0.1348 I:0.1797 I:0.4590)
		( I:0.0679�:0.0752 sure:0.1162 little:0.0425 teacher:0.1011.:0.1157 I:0.1641 I:0.5117)
		( I:0.0703�:0.0786 sure:0.1089 little:0.0437 teacher:0.1152.:0.1172 I:0.1523 I:0.5273)
		( I:0.0713�:0.0840 sure:0.1035 little:0.0439 teacher:0.1196.:0.1167 and:0.1514 I:0.5273)
		( I:0.0708�:0.0864 sure:0.0942 little:0.0442 teacher:0.1177.:0.1152 and:0.1592 I:0.5156)
		( I:0.0703�:0.0850 sure:0.0913 little:0.0444 teacher:0.1152.:0.1138 and:0.1592 I:0.5195)
		( I:0.0679�:0.0889 sure:0.0889 little:0.0444 teacher:0.1138.:0.1113 and:0.1680 I:0.5078)
		( I:0.0659�:0.0879 sure:0.0869 little:0.0444 teacher:0.1064.:0.1084 and:0.1689 I:0.4961)
		( I:0.0659�:0.0874 sure:0.0854 little:0.0432 teacher:0.1006 for:0.1069 and:0.1699 I:0.4824)
		( I:0.0659�:0.0874 sure:0.0854 little:0.0432 teacher:0.1006 for:0.1069 and:0.1699 I:0.4824)
 I'm a great teacher. I'm a great teacher
3650: sample 0: Hello, I'm a language model,
------
		(,:0.0762 I:0.0618�:0.0557 not:0.1211 lot:0.0479 that:0.1377.:0.2197 I:0.2119)
		(,:0.0708 the:0.0854�:0.0723 not:0.1006 bit:0.0247 that:0.1387.:0.1768 I:0.1885)
		(,:0.0654 the:0.0698�:0.0728 going:0.1299 bit:0.0203 that:0.0791.:0.1484 and:0.1621)
		(,:0.0610 the:0.0588 have:0.0776 going:0.1328 little:0.0232 teacher:0.0615.:0.1357 and:0.1572)
		(,:0.0593 the:0.0574 have:0.0815 going:0.1377 little:0.0266 teacher:0.0830.:0.1289 and:0.1543)
		(,:0.0564 the:0.0564'm:0.0894 going:0.1396 good:0.0297 teacher:0.0981.:0.1299 and:0.1504)
		(,:0.0540 the:0.0571'm:0.0952 going:0.1426 good:0.0322 teacher:0.1050.:0.1279 and:0.1484)
		(,:0.0515 the:0.0601'm:0.0981 going:0.1475 good:0.0339 teacher:0.1074.:0.1260 and:0.1475)
		(,:0.0508 the:0.0596'm:0.0962 going:0.1455 good:0.0349 teacher:0.1074.:0.1240 but:0.1504)
		(,:0.0488 the:0.0608'm:0.1006 going:0.1445 good:0.0359 teacher:0.1055.:0.1221 but:0.1504)
		(,:0.0481 the:0.0603'm:0.1001 going:0.1436 good:0.0356 teacher:0.1006 for:0.1240 but:0.1504)
		(,:0.0464 the:0.0615'm:0.0991 going:0.1426 good:0.0366 teacher:0.0991 for:0.1226 but:0.1504)
		(,:0.0464 the:0.0615'm:0.0991 going:0.1426 good:0.0366 teacher:0.0991 for:0.1226 but:0.1504)
 but
------
		( I:0.0618�:0.0557 not:0.1211 lot:0.0479 that:0.1377.:0.2197 I:0.2119 I:0.5664)
		( the:0.0854�:0.0723 not:0.1006 bit:0.0247 that:0.1387.:0.1768 I:0.1885 I:0.4668)
		( the:0.0698�:0.0728 going:0.1299 bit:0.0203 that:0.0791.:0.1484 and:0.1621 I:0.3496)
		( the:0.0588 have:0.0776 going:0.1328 little:0.0232 teacher:0.0615.:0.1357 and:0.1572 I:0.3359)
		( the:0.0574 have:0.0815 going:0.1377 little:0.0266 teacher:0.0830.:0.1289 and:0.1543 I:0.3418)
		( the:0.0564'm:0.0894 going:0.1396 good:0.0297 teacher:0.0981.:0.1299 and:0.1504 I:0.3281)
		( the:0.0571'm:0.0952 going:0.1426 good:0.0322 teacher:0.1050.:0.1279 and:0.1484 I:0.3145)
		( the:0.0601'm:0.0981 going:0.1475 good:0.0339 teacher:0.1074.:0.1260 and:0.1475 I:0.3008)
		( the:0.0596'm:0.0962 going:0.1455 good:0.0349 teacher:0.1074.:0.1240 but:0.1504 I:0.2891)
		( the:0.0608'm:0.1006 going:0.1445 good:0.0359 teacher:0.1055.:0.1221 but:0.1504 I:0.2891)
		( the:0.0603'm:0.1001 going:0.1436 good:0.0356 teacher:0.1006 for:0.1240 but:0.1504 I:0.2773)
		( the:0.0615'm:0.0991 going:0.1426 good:0.0366 teacher:0.0991 for:0.1226 but:0.1504 I:0.2773)
		( the:0.0615'm:0.0991 going:0.1426 good:0.0366 teacher:0.0991 for:0.1226 but:0.1504 I:0.2773)
 I'm not a language model. I'm a language
3800: sample 0: Hello, I'm a language model,
------
		(,:0.0791 and:0.0520 have:0.0505 not:0.0898 lot:0.0334.:0.1226.:0.2129 I:0.2676)
		(,:0.0732 and:0.0742 have:0.0613 a:0.0781 bit:0.0403 that:0.1094 that:0.1514 I:0.2080)
		(,:0.0693 the:0.0645 have:0.0659 sure:0.0889 bit:0.0417 of:0.0425 that:0.1406 and:0.2158)
		(,:0.0645 and:0.0640 have:0.0713 sure:0.0981 little:0.0386 teacher:0.0737.:0.1201 and:0.2070)
		(,:0.0630 and:0.0674 have:0.0742 not:0.0908 little:0.0415 teacher:0.0957.:0.1240 and:0.2002)
		(,:0.0613 and:0.0693 have:0.0762 not:0.1035 little:0.0408 teacher:0.1055.:0.1240 and:0.1973)
		(,:0.0583 and:0.0698 have:0.0767 not:0.1123 little:0.0408 teacher:0.1108.:0.1240 and:0.1953)
		(,:0.0576 and:0.0708 have:0.0786 not:0.1157 little:0.0396 teacher:0.1162.:0.1206 and:0.1953)
		(,:0.0569 and:0.0718 have:0.0771 not:0.1196 little:0.0383 teacher:0.1157.:0.1177 and:0.1953)
		(,:0.0544 and:0.0703 have:0.0762 not:0.1250 little:0.0383 teacher:0.1138.:0.1143 and:0.1953)
		(,:0.0540 and:0.0718 have:0.0752 not:0.1299 bit:0.0386 teacher:0.1123.:0.1108 and:0.1875)
		(,:0.0535 and:0.0732 have:0.0747 not:0.1289 bit:0.0388 teacher:0.1104.:0.1079 and:0.1885)
		(,:0.0535 and:0.0732 have:0.0747 not:0.1289 bit:0.0388 teacher:0.1104.:0.1079 and:0.1885)
 and
------
		( and:0.0520 have:0.0505 not:0.0898 lot:0.0334.:0.1226.:0.2129 I:0.2676 I:0.5156)
		( and:0.0742 have:0.0613 a:0.0781 bit:0.0403 that:0.1094 that:0.1514 I:0.2080 I:0.4629)
		( the:0.0645 have:0.0659 sure:0.0889 bit:0.0417 of:0.0425 that:0.1406 and:0.2158 I:0.3633)
		( and:0.0640 have:0.0713 sure:0.0981 little:0.0386 teacher:0.0737.:0.1201 and:0.2070 I:0.3984)
		( and:0.0674 have:0.0742 not:0.0908 little:0.0415 teacher:0.0957.:0.1240 and:0.2002 I:0.4180)
		( and:0.0693 have:0.0762 not:0.1035 little:0.0408 teacher:0.1055.:0.1240 and:0.1973 I:0.4219)
		( and:0.0698 have:0.0767 not:0.1123 little:0.0408 teacher:0.1108.:0.1240 and:0.1953 I:0.4102)
		( and:0.0708 have:0.0786 not:0.1157 little:0.0396 teacher:0.1162.:0.1206 and:0.1953 I:0.3965)
		( and:0.0718 have:0.0771 not:0.1196 little:0.0383 teacher:0.1157.:0.1177 and:0.1953 I:0.3867)
		( and:0.0703 have:0.0762 not:0.1250 little:0.0383 teacher:0.1138.:0.1143 and:0.1953 I:0.3750)
		( and:0.0718 have:0.0752 not:0.1299 bit:0.0386 teacher:0.1123.:0.1108 and:0.1875 I:0.3633)
		( and:0.0732 have:0.0747 not:0.1289 bit:0.0388 teacher:0.1104.:0.1079 and:0.1885 I:0.3652)
		( and:0.0732 have:0.0747 not:0.1289 bit:0.0388 teacher:0.1104.:0.1079 and:0.1885 I:0.3652)
 I'm a language model. I'm a language model
3950: sample 0: Hello, I'm a language model,
------
		(,:0.0791 I:0.0508 have:0.0459 not:0.1152 lot:0.0330 that:0.0972.:0.1758 I:0.3594)
		(,:0.0737 I:0.0791 have:0.0442 not:0.1069 bit:0.0184 that:0.0593.:0.1631 I:0.3340)
		(,:0.0698 I:0.0913 have:0.0500 not:0.0894 good:0.0273 of:0.0405 for:0.1562 and:0.1797)
		(,:0.0649 I:0.0923 have:0.0527 not:0.0952 good:0.0364 of:0.0359 for:0.1641 and:0.1592)
		(,:0.0630 I:0.0898 have:0.0559 not:0.1060 good:0.0420 teacher:0.0417 for:0.1797 and:0.1475)
		(,:0.0601 I:0.0845 have:0.0576 not:0.1138 good:0.0471 teacher:0.0500 for:0.1885 and:0.1475)
		(,:0.0588 I:0.0806 have:0.0625 not:0.1167 good:0.0498 teacher:0.0544 for:0.1982 and:0.1406)
		(,:0.0579 I:0.0747 have:0.0610 not:0.1143 good:0.0527 teacher:0.0576 for:0.2012 and:0.1396)
		(,:0.0554 I:0.0723 have:0.0635 not:0.1133 good:0.0557 teacher:0.0583 for:0.2031 and:0.1377)
		(,:0.0549 I:0.0693 have:0.0630 not:0.1113 good:0.0571 teacher:0.0579 for:0.2051 and:0.1367)
		(,:0.0542 I:0.0654 have:0.0625 not:0.1108 good:0.0586 teacher:0.0566 for:0.2080 and:0.1367)
		(.:0.0537 I:0.0630 have:0.0625 not:0.1099 good:0.0601 teacher:0.0554 for:0.2100 and:0.1357)
		(.:0.0537 I:0.0630 have:0.0625 not:0.1099 good:0.0601 teacher:0.0554 for:0.2100 and:0.1357)
 and
------
		( I:0.0508 have:0.0459 not:0.1152 lot:0.0330 that:0.0972.:0.1758 I:0.3594 I:0.4707)
		( I:0.0791 have:0.0442 not:0.1069 bit:0.0184 that:0.0593.:0.1631 I:0.3340 I:0.6875)
		( I:0.0913 have:0.0500 not:0.0894 good:0.0273 of:0.0405 for:0.1562 and:0.1797 I:0.4980)
		( I:0.0923 have:0.0527 not:0.0952 good:0.0364 of:0.0359 for:0.1641 and:0.1592 I:0.5469)
		( I:0.0898 have:0.0559 not:0.1060 good:0.0420 teacher:0.0417 for:0.1797 and:0.1475 I:0.5391)
		( I:0.0845 have:0.0576 not:0.1138 good:0.0471 teacher:0.0500 for:0.1885 and:0.1475 I:0.5195)
		( I:0.0806 have:0.0625 not:0.1167 good:0.0498 teacher:0.0544 for:0.1982 and:0.1406 I:0.4902)
		( I:0.0747 have:0.0610 not:0.1143 good:0.0527 teacher:0.0576 for:0.2012 and:0.1396 I:0.4609)
		( I:0.0723 have:0.0635 not:0.1133 good:0.0557 teacher:0.0583 for:0.2031 and:0.1377 I:0.4473)
		( I:0.0693 have:0.0630 not:0.1113 good:0.0571 teacher:0.0579 for:0.2051 and:0.1367 I:0.4199)
		( I:0.0654 have:0.0625 not:0.1108 good:0.0586 teacher:0.0566 for:0.2080 and:0.1367 I:0.4082)
		( I:0.0630 have:0.0625 not:0.1099 good:0.0601 teacher:0.0554 for:0.2100 and:0.1357 I:0.3945)
		( I:0.0630 have:0.0625 not:0.1099 good:0.0601 teacher:0.0554 for:0.2100 and:0.1357 I:0.3945)
 I'm a language model.
I'm a language
4100: sample 0: Hello, I'm a language model,
------
		(,:0.0742 I:0.0728 have:0.0654 not:0.0767 lot:0.0391.:0.1187.:0.1875 I:0.3965)
		(,:0.0664 I:0.1030 have:0.0850 not:0.0811 bit:0.0249 that:0.0752 for:0.1797 I:0.2090)
		(,:0.0591 I:0.1187 have:0.0977 not:0.0757 very:0.0272,:0.0442 for:0.1748 and:0.2539)
		(,:0.0554 I:0.1279 have:0.1040 not:0.0879 little:0.0295 teacher:0.0398 for:0.1729 and:0.2344)
		(,:0.0520 I:0.1270 have:0.1025 not:0.0986 little:0.0334 teacher:0.0605 for:0.1680 and:0.2227)
		(,:0.0493 I:0.1250 have:0.1035 not:0.1045 little:0.0349 teacher:0.0752 for:0.1611 and:0.2305)
		(,:0.0483 I:0.1240 have:0.0996 not:0.1069 little:0.0374 teacher:0.0845 for:0.1572 and:0.2285)
		(,:0.0464 I:0.1162 have:0.1025 not:0.1089 little:0.0374 teacher:0.0894 for:0.1494 and:0.2305)
		(,:0.0442 I:0.1123 have:0.1006 not:0.1084 little:0.0386 teacher:0.0923 for:0.1445 and:0.2354)
		(,:0.0437 I:0.1084 have:0.0991 not:0.1079 little:0.0386 teacher:0.0913 for:0.1396 and:0.2373)
		(,:0.0420 I:0.1050 have:0.0981 not:0.1069 little:0.0386 teacher:0.0913 for:0.1377 and:0.2393)
		(,:0.0415 I:0.1016 have:0.0972 not:0.1064 little:0.0396 teacher:0.0894 for:0.1328 and:0.2402)
		(,:0.0415 I:0.1016 have:0.0972 not:0.1064 little:0.0396 teacher:0.0894 for:0.1328 and:0.2402)
 and
------
		( I:0.0728 have:0.0654 not:0.0767 lot:0.0391.:0.1187.:0.1875 I:0.3965 I:0.5703)
		( I:0.1030 have:0.0850 not:0.0811 bit:0.0249 that:0.0752 for:0.1797 I:0.2090 I:0.5078)
		( I:0.1187 have:0.0977 not:0.0757 very:0.0272,:0.0442 for:0.1748 and:0.2539 I:0.3965)
		( I:0.1279 have:0.1040 not:0.0879 little:0.0295 teacher:0.0398 for:0.1729 and:0.2344 I:0.4434)
		( I:0.1270 have:0.1025 not:0.0986 little:0.0334 teacher:0.0605 for:0.1680 and:0.2227 I:0.4512)
		( I:0.1250 have:0.1035 not:0.1045 little:0.0349 teacher:0.0752 for:0.1611 and:0.2305 I:0.4395)
		( I:0.1240 have:0.0996 not:0.1069 little:0.0374 teacher:0.0845 for:0.1572 and:0.2285 I:0.4297)
		( I:0.1162 have:0.1025 not:0.1089 little:0.0374 teacher:0.0894 for:0.1494 and:0.2305 I:0.4199)
		( I:0.1123 have:0.1006 not:0.1084 little:0.0386 teacher:0.0923 for:0.1445 and:0.2354 I:0.3945)
		( I:0.1084 have:0.0991 not:0.1079 little:0.0386 teacher:0.0913 for:0.1396 and:0.2373 I:0.3848)
		( I:0.1050 have:0.0981 not:0.1069 little:0.0386 teacher:0.0913 for:0.1377 and:0.2393 I:0.3730)
		( I:0.1016 have:0.0972 not:0.1064 little:0.0396 teacher:0.0894 for:0.1328 and:0.2402 I:0.3594)
		( I:0.1016 have:0.0972 not:0.1064 little:0.0396 teacher:0.0894 for:0.1328 and:0.2402 I:0.3594)
 I'm a language model. I'm a language model
