1: sample 0: Hello, I'm a language model,
		(Hello:0.0006,:0.0017 I:0.0005'm:0.0006 a:0.0004 language:0.0006 model:0.0006,:0.0015)
		( program:0.0002,:0.0006 I:0.0002,:0.0002 Murray:0.0002pps:0.0002,:0.0002,:0.0008)
		( program:0.0002,:0.0004,:0.0003,:0.0003 Murray:0.0002,:0.0002,:0.0002,:0.0006)
		( Murray:0.0002,:0.0004,:0.0003,:0.0003,:0.0002,:0.0003,:0.0003,:0.0005)
		( Murray:0.0002,:0.0004,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005)
		( Murray:0.0002,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005)
		( Murray:0.0002,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0004)
		(,:0.0002,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0004)
		(,:0.0002,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0004)
		(,:0.0002,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0004)
		(,:0.0002,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0004)
		(,:0.0003,:0.0003,:0.0004,:0.0003,:0.0003,:0.0003,:0.0003,:0.0004)
Sweet
50: sample 0: Hello, I'm a language model,
		( the:0.0262 the:0.0317 the:0.0273 the:0.0233 the:0.0295 the:0.0249 the:0.0280 the:0.0306)
		( the:0.0287 the:0.0325 the:0.0293 the:0.0271 the:0.0304 the:0.0276 the:0.0297 the:0.0315)
		( the:0.0297 the:0.0325 the:0.0294 the:0.0280 the:0.0315 the:0.0286 the:0.0305 the:0.0315)
		( the:0.0297 the:0.0325 the:0.0295 the:0.0288 the:0.0315 the:0.0287 the:0.0306 the:0.0315)
		( the:0.0297 the:0.0315 the:0.0295 the:0.0288 the:0.0315 the:0.0287 the:0.0306 the:0.0315)
		( the:0.0306 the:0.0317 the:0.0305 the:0.0298 the:0.0306 the:0.0297 the:0.0306 the:0.0315)
		( the:0.0306 the:0.0317 the:0.0305 the:0.0298 the:0.0306 the:0.0297 the:0.0306 the:0.0315)
		( the:0.0306 the:0.0317 the:0.0306 the:0.0298 the:0.0306 the:0.0297 the:0.0306 the:0.0317)
		( the:0.0306 the:0.0317 the:0.0306 the:0.0298 the:0.0306 the:0.0297 the:0.0308 the:0.0317)
		( the:0.0306 the:0.0317 the:0.0306 the:0.0298 the:0.0306 the:0.0298 the:0.0308 the:0.0317)
		( the:0.0308 the:0.0317 the:0.0306 the:0.0298 the:0.0306 the:0.0298 the:0.0308 the:0.0317)
		( the:0.0308 the:0.0317 the:0.0306 the:0.0298 the:0.0306 the:0.0298 the:0.0308 the:0.0317)
).
550: sample 0: Hello, I'm a language model,
		( a:0.0100 the:0.0366 the:0.1069 a:0.1050 different:0.0581.:0.1523 of:0.3457 the:0.0786)
		( a:0.0242 the:0.1025�:0.0776 a:0.1050 different:0.0466.:0.1328 of:0.2539 the:0.1074)
		( the:0.0381 the:0.1387�:0.1191 a:0.0947 different:0.0317.:0.1299 of:0.2021 the:0.0981)
		( the:0.0737 the:0.1416�:0.1240 a:0.0869 different:0.0195.:0.1299 of:0.1631 the:0.0815)
		( the:0.0918 the:0.1270,:0.1167 a:0.0815 new:0.0165.:0.1436 of:0.1426 and:0.1050)
		( the:0.0962 the:0.1128,:0.1289 a:0.0781 new:0.0155.:0.1543.:0.1309 and:0.1235)
		( the:0.0952 the:0.0991,:0.1396 a:0.0742 new:0.0143.:0.1582.:0.1357 and:0.1416)
		( the:0.0903 the:0.0874,:0.1416 a:0.0693 new:0.0135.:0.1680.:0.1455 and:0.1602)
		( the:0.0830 the:0.0776,:0.1426 a:0.0659 few:0.0161.:0.1768.:0.1465 and:0.1689)
		( the:0.0762 and:0.0894,:0.1357 a:0.0623 few:0.0199.:0.1748.:0.1465 and:0.1777)
		( the:0.0703 and:0.0981,:0.1289 a:0.0581 few:0.0229.:0.1836.:0.1553 and:0.1855)
		( the:0.0615 and:0.1064,:0.1226 a:0.0542 few:0.0266.:0.1807.:0.1533 and:0.1943)
 and
1050: sample 0: Hello, I'm a language model,
		( use:0.0115 the:0.1289 use:0.0330 the:0.0659 new:0.0115
:0.0781 of:0.0762 the:0.1504)
		( use:0.0119 the:0.0540 use:0.0237 the:0.0214 �:0.0074 and:0.0374,:0.0503 the:0.0427)
		( the:0.0115 the:0.0265,:0.0209.:0.0143 �:0.0053,:0.0280,:0.0491 the:0.0258)
		( the:0.0131 the:0.0267,:0.0308.:0.0271
:0.0055,:0.0361,:0.0635 the:0.0339)
		( the:0.0164 the:0.0430,:0.0437.:0.0559 number:0.0079,:0.0520,:0.0747 the:0.0486)
		( the:0.0215 the:0.0603 have:0.0603.:0.0903 number:0.0145,:0.0732,:0.0903 the:0.0476)
		( the:0.0278 the:0.0591 have:0.0889 not:0.1719 few:0.0176,:0.1006,:0.1221 and:0.0540)
		( the:0.0349 the:0.0535 have:0.1074 not:0.2598 lot:0.0247,:0.1226,:0.1475 I:0.0830)
		( the:0.0408 the:0.0474 have:0.1108 not:0.3242 lot:0.0327,:0.1357,:0.1533 I:0.1484)
		( the:0.0452 and:0.0422 have:0.1064 not:0.3516 lot:0.0388,:0.1387,:0.1553 I:0.1826)
		( the:0.0464 and:0.0461 have:0.1001 not:0.3809 lot:0.0400,:0.1387,:0.1465 I:0.1738)
		( the:0.0461 and:0.0474 have:0.0874 not:0.3789 lot:0.0403,:0.1289,:0.1338 I:0.1504)
 I
1550: sample 0: Hello, I'm a language model,
		( use:0.0029 and:0.0082 all:0.0190,:0.0977 more:0.0120
:0.0889 and:0.0605 and:0.0304)
		( a:0.0027 and:0.0057 first:0.0086,:0.0388 more:0.0064
:0.0276 of:0.0220 and:0.0099)
		( the:0.0028 and:0.0076,:0.0096,:0.0425 more:0.0064
:0.0200 of:0.0172 and:0.0154)
		( the:0.0045 and:0.0139,:0.0152,:0.0542 more:0.0096
:0.0201 of:0.0232 and:0.0278)
		( the:0.0073 the:0.0253,:0.0217,:0.0520 more:0.0105 and:0.0226 of:0.0330 and:0.0547)
		( the:0.0114 the:0.0464,:0.0304,:0.0466 very:0.0143 and:0.0277 of:0.0520 and:0.0889)
		( the:0.0167 the:0.0679,:0.0371 the:0.0471 very:0.0164 and:0.0371 of:0.0767 and:0.1221)
		( the:0.0229 the:0.0791 have:0.0505 not:0.0425 good:0.0197,:0.0510.:0.1079 and:0.1396)
		( the:0.0288 the:0.0811 have:0.0610 not:0.0488 good:0.0264,:0.0610.:0.1436 and:0.1436)
		( the:0.0352 the:0.0757 have:0.0693 going:0.0742 good:0.0305 that:0.0688.:0.1777 but:0.1641)
		( the:0.0396 the:0.0713 have:0.0742 going:0.0962 good:0.0330 that:0.0825.:0.2012 but:0.1875)
		( the:0.0439 and:0.0698 have:0.0752 going:0.1084 good:0.0325 that:0.0894.:0.2197 but:0.1934)
 but
2050: sample 0: Hello, I'm a language model,
		( know:0.0014 only:0.0028 all:0.0153 and:0.0913 more:0.0099 and:0.1396 and:0.1230 and:0.0137)
		( a:0.0016 and:0.0045 and:0.0082 and:0.0275 more:0.0056 and:0.0452 and:0.0432 and:0.0074)
		( the:0.0026 and:0.0099 and:0.0091 and:0.0265 more:0.0070 and:0.0311 and:0.0275 and:0.0154)
		( the:0.0048 and:0.0181 and:0.0115,:0.0261 very:0.0089 and:0.0354 and:0.0271 and:0.0210)
		( the:0.0079 and:0.0306 and:0.0151 the:0.0461 very:0.0177 and:0.0393,:0.0369 and:0.0645)
		( the:0.0123 and:0.0425 and:0.0183 the:0.0659 very:0.0256 and:0.0405,:0.0598 and:0.1064)
		( the:0.0177 and:0.0510 was:0.0302 the:0.0781 very:0.0342 of:0.0481,:0.0991 and:0.1631)
		( the:0.0223 and:0.0566 was:0.0444 not:0.1025 very:0.0388 of:0.0713,:0.1328 and:0.1846)
		( the:0.0283 and:0.0605 have:0.0537 not:0.1177 very:0.0408 of:0.0918,:0.1504 and:0.1924)
		( the:0.0332 and:0.0674 have:0.0576 not:0.1128 very:0.0415 of:0.1099 of:0.1660 and:0.1836)
		( the:0.0369 and:0.0728 have:0.0532 not:0.0898 very:0.0408 of:0.1162 of:0.1670 and:0.1699)
		( the:0.0405 and:0.0820 have:0.0488 not:0.0713 very:0.0393 of:0.1104 of:0.1484 and:0.1650)
 and
2550: sample 0: Hello, I'm a language model,
		( present:0.0013 leading:0.0059 and:0.0500 and:0.1104 more:0.0107 and:0.0459 and:0.0422 and:0.0085)
		( present:0.0015 and:0.0049 and:0.0206 and:0.0354 more:0.0072 and:0.0193,:0.0259 and:0.0059)
		( the:0.0021 and:0.0084 and:0.0190-:0.0298 more:0.0085 and:0.0168 of:0.0366 and:0.0096)
		( the:0.0041 and:0.0139 and:0.0157-:0.0176 more:0.0101 and:0.0161 of:0.0522 I:0.0122)
		( the:0.0069 and:0.0229 and:0.0198 not:0.0222 very:0.0143 and:0.0181 of:0.0859 and:0.0366)
		( the:0.0107 and:0.0361 have:0.0201 not:0.0544 very:0.0199,:0.0258 of:0.1216 and:0.0654)
		( the:0.0149 and:0.0483�:0.0310 not:0.1045 very:0.0237,:0.0383 of:0.1504 and:0.0991)
		( the:0.0194 and:0.0596�:0.0466 not:0.1582 very:0.0278 of:0.0649 of:0.1602 and:0.1367)
		( the:0.0233 and:0.0747�:0.0610 not:0.2002 very:0.0339 of:0.0991 of:0.1680 and:0.1611)
		( the:0.0272 and:0.0889�:0.0698 not:0.2021 very:0.0369 of:0.1338 of:0.1738 and:0.1797)
		( the:0.0303 and:0.1030�:0.0703 not:0.1816 very:0.0388 of:0.1592 of:0.1602 and:0.2002)
		( the:0.0334 and:0.1182�:0.0684 not:0.1562 very:0.0398 of:0.1602 of:0.1396 and:0.2227)
 and
3050: sample 0: Hello, I'm a language model,
		( answer:0.0007 and:0.0208 and:0.0461 and:0.1211 new:0.0125 and:0.0562 and:0.0270 and:0.0151)
		( a:0.0008 and:0.0125 and:0.0259 and:0.0554 new:0.0114
:0.0293,:0.0139 and:0.0137)
		( the:0.0020 and:0.0165 and:0.0225 and:0.0422 new:0.0144
:0.0320,:0.0168 and:0.0217)
		( the:0.0042 and:0.0183 and:0.0176 and:0.0237 new:0.0177 and:0.0200,:0.0281 and:0.0247)
		( the:0.0074 and:0.0186 and:0.0288 not:0.0175 number:0.0172,:0.0197,:0.0640 and:0.0762)
		( the:0.0115 and:0.0210 and:0.0209 not:0.0284 number:0.0186,:0.0272,:0.0898 and:0.0913)
		( the:0.0160 and:0.0221�:0.0269 not:0.0408 new:0.0199,:0.0415,:0.1118 and:0.1104)
		( the:0.0203 the:0.0312�:0.0304 not:0.0564 new:0.0203,:0.0579,:0.1250 and:0.1196)
		( the:0.0248 the:0.0425 have:0.0325 not:0.0698 very:0.0217,:0.0669,:0.1299 and:0.1128)
		( the:0.0278 the:0.0498 have:0.0376 not:0.0757 very:0.0242 of:0.0732,:0.1387 and:0.1055)
		( the:0.0309 and:0.0552 have:0.0417 not:0.0708 little:0.0258 of:0.0762,:0.1279 and:0.1064)
		(,:0.0349 and:0.0669 have:0.0439 going:0.0815 little:0.0320 of:0.0703 for:0.1279 and:0.1138)
 and
3550: sample 0: Hello, I'm a language model,
		( answer:0.0006 and:0.0067 and:0.0142 and:0.0684 more:0.0080 and:0.0236,:0.0352 and:0.0137)
		( the:0.0006 and:0.0074 and:0.0132 and:0.0312 more:0.0063 and:0.0148,:0.0239 and:0.0128)
		( the:0.0017 and:0.0128 and:0.0182 and:0.0238 number:0.0108 and:0.0143,:0.0295 and:0.0197)
		( the:0.0037 and:0.0154 and:0.0137 and:0.0142 number:0.0165,:0.0164 of:0.0564 and:0.0201)
		( the:0.0067 and:0.0177 and:0.0187 not:0.0161 good:0.0219,:0.0219 of:0.0850 and:0.0447)
		( the:0.0106 and:0.0220.:0.0300 not:0.0361 good:0.0294,:0.0287 of:0.1138 and:0.0767)
		( the:0.0153 which:0.0327.:0.0474 not:0.0625 good:0.0344 of:0.0454 of:0.1279 and:0.1206)
		( the:0.0203 which:0.0427.:0.0615 not:0.0972 good:0.0371 of:0.0654.:0.1709 and:0.1572)
		( the:0.0261 the:0.0469.:0.0728 not:0.1348 good:0.0378 of:0.0820.:0.2021 and:0.1787)
		( the:0.0308 the:0.0535.:0.0767 not:0.1533 good:0.0386 of:0.0840.:0.2178 and:0.1719)
		( the:0.0344 and:0.0645.:0.0757 not:0.1494 good:0.0400 that:0.0767.:0.2041 and:0.1602)
		( the:0.0381 and:0.0728.:0.0688 not:0.1367 good:0.0364 professor:0.0713.:0.1797 and:0.1504)
 and
4050: sample 0: Hello, I'm a language model,
		( mean:0.0005 and:0.0041 and:0.0104 and:0.0435 more:0.0040 and:0.0159,:0.0264 and:0.0078)
		( mean:0.0004 and:0.0058 and:0.0107 and:0.0219 new:0.0071 and:0.0101,:0.0201 and:0.0096)
		( the:0.0013 and:0.0109 and:0.0159 and:0.0176 number:0.0106 and:0.0090 of:0.0276 and:0.0188)
		( the:0.0031 and:0.0156 and:0.0164 the:0.0198 number:0.0171,:0.0103 of:0.0503 and:0.0216)
		( the:0.0059 and:0.0188 and:0.0215 the:0.0320 number:0.0186,:0.0130 of:0.0698 and:0.0425)
		( the:0.0100 and:0.0233 was:0.0266 the:0.0366 great:0.0172,:0.0184 of:0.0820 and:0.0928)
		( the:0.0148 the:0.0286 was:0.0400 the:0.0425 great:0.0237,:0.0267.:0.0918 and:0.1533)
		( the:0.0204 the:0.0381 was:0.0525 a:0.0513 great:0.0264 that:0.0439.:0.1250 and:0.2051)
		( the:0.0253 the:0.0464 was:0.0591 a:0.0610 great:0.0277 that:0.0688.:0.1543 and:0.2363)
		( the:0.0297 the:0.0527�:0.0615 a:0.0654 great:0.0261 that:0.0918.:0.1787 and:0.2490)
		( the:0.0342 the:0.0583�:0.0630 a:0.0679 great:0.0233 that:0.0967.:0.1934 and:0.2422)
		( the:0.0376 the:0.0630�:0.0640 a:0.0659 great:0.0199 that:0.0913.:0.1992 and:0.2236)
 and
4550: sample 0: Hello, I'm a language model,
		( swearing:0.0005 and:0.0047 and:0.0087 and:0.0305 more:0.0067 and:0.0198,:0.0278 and:0.0094)
		( present:0.0005 and:0.0062 and:0.0109 and:0.0179 more:0.0090 and:0.0127,:0.0197 and:0.0104)
		( the:0.0013 and:0.0130 and:0.0148 and:0.0186 more:0.0148 and:0.0140,:0.0266 and:0.0190)
		( the:0.0028 and:0.0160 and:0.0168 the:0.0247 more:0.0150 and:0.0149,:0.0320 and:0.0187)
		( the:0.0052 and:0.0215�:0.0210 not:0.0330 new:0.0133 of:0.0151 of:0.0488 and:0.0264)
		( the:0.0087 and:0.0322�:0.0305 not:0.0510 good:0.0134 of:0.0258 of:0.0605 and:0.0605)
		( the:0.0128 and:0.0398�:0.0391 not:0.0620 good:0.0139 of:0.0415 of:0.0613 and:0.1064)
		( the:0.0175 and:0.0461�:0.0479 not:0.0625 very:0.0151 of:0.0583 for:0.0747 and:0.1729)
		( the:0.0225 and:0.0552�:0.0566 not:0.0615 bit:0.0172 of:0.0645 for:0.0972 and:0.2285)
		( the:0.0265 and:0.0654�:0.0605 going:0.0640 bit:0.0186 of:0.0547 for:0.1016 and:0.2598)
		( the:0.0315 and:0.0757�:0.0625 going:0.0923 professor:0.0236 professor:0.0737 for:0.0864 and:0.2852)
		( the:0.0347 and:0.0869�:0.0679 going:0.1152 professor:0.0294 professor:0.0967 expert:0.0693 and:0.2852)
 and
5050: sample 0: Hello, I'm a language model,
		( mock:0.0007 only:0.0039 and:0.0066 and:0.0237 more:0.0041 and:0.0182,:0.0162 and:0.0077)
		( mock:0.0005 and:0.0046 and:0.0093 and:0.0194 new:0.0069 and:0.0101,:0.0111 and:0.0109)
		( the:0.0011 the:0.0083 and:0.0145 and:0.0239 new:0.0102 and:0.0102,:0.0182 and:0.0215)
		( the:0.0024 the:0.0129 and:0.0189 not:0.0273 new:0.0137 and:0.0134 of:0.0408 and:0.0203)
		( the:0.0046 the:0.0190 and:0.0250 not:0.0586 new:0.0149 of:0.0194 of:0.0747 and:0.0283)
		( the:0.0074 the:0.0284 and:0.0284 not:0.0938 good:0.0167 of:0.0405 of:0.1025 and:0.0569)
		( the:0.0112 the:0.0425 was:0.0281 not:0.1133 good:0.0217 of:0.0771 for:0.1104 and:0.0986)
		( the:0.0153 the:0.0579 was:0.0378 not:0.1094 good:0.0265 of:0.1167 for:0.1445 and:0.1455)
		( the:0.0199 the:0.0708 have:0.0469 not:0.1035 very:0.0327 of:0.1436 for:0.1758 and:0.1895)
		( the:0.0239 the:0.0791 have:0.0618 not:0.0796 very:0.0361 of:0.1387 for:0.1836 and:0.2188)
		( the:0.0278 the:0.0854 have:0.0703 not:0.0635 very:0.0327 of:0.1133 for:0.1768 and:0.2393)
		( the:0.0306 the:0.0879 have:0.0796 going:0.0598 little:0.0281 for:0.0879 for:0.1543 and:0.2480)
 and
5550: sample 0: Hello, I'm a language model,
		( cry:0.0004 and:0.0076 hope:0.0026 and:0.0425 great:0.0041 and:0.0242 and:0.0131 and:0.0099)
		( use:0.0004 and:0.0073 and:0.0059 and:0.0240 new:0.0065 and:0.0168,:0.0114 and:0.0110)
		( the:0.0010 and:0.0135 and:0.0109 and:0.0215 new:0.0143 and:0.0172 of:0.0298 and:0.0203)
		( the:0.0024 and:0.0165 and:0.0188 not:0.0292 new:0.0193 and:0.0188 of:0.0928 and:0.0226)
		( the:0.0046 and:0.0205�:0.0231 not:0.0540 little:0.0186 and:0.0167 of:0.1572 and:0.0361)
		( the:0.0077 the:0.0283�:0.0483 not:0.0737 little:0.0280 of:0.0286 of:0.1816 and:0.0552)
		( the:0.0118 the:0.0398�:0.0879 not:0.0898 little:0.0317 of:0.0432 of:0.1768 and:0.0796)
		( the:0.0164 the:0.0522�:0.1260 not:0.1030 little:0.0325 of:0.0562 of:0.1738 and:0.1147)
		( the:0.0211 the:0.0583�:0.1426 not:0.0972 little:0.0295 that:0.0635 of:0.1621 and:0.1396)
		( the:0.0258 and:0.0703�:0.1318 going:0.1172 professor:0.0522 that:0.0649 of:0.1348 and:0.1504)
		( the:0.0295 and:0.0811�:0.1206 going:0.1318 professor:0.0854-:0.0630.:0.1050 and:0.1582)
		(,:0.0344 and:0.0918�:0.1128 going:0.1289 professor:0.1191 teacher:0.0767.:0.1006 I:0.1699)
 I
6050: sample 0: Hello, I'm a language model,
		( shoot:0.0004 and:0.0051 use:0.0031 and:0.0349 more:0.0029 and:0.0120,:0.0104 and:0.0028)
		(�:0.0004 and:0.0067 and:0.0066 and:0.0186 more:0.0051 and:0.0087,:0.0096 and:0.0056)
		( the:0.0009 and:0.0127 and:0.0135 and:0.0193 number:0.0103 and:0.0088 of:0.0147 and:0.0115)
		( the:0.0020 and:0.0156 and:0.0206 not:0.0173 number:0.0170 of:0.0114 of:0.0381 and:0.0112)
		( the:0.0038 and:0.0198 and:0.0189 not:0.0304 new:0.0115 of:0.0215 of:0.0771 and:0.0164)
		( the:0.0066 and:0.0219 was:0.0315 not:0.0378 good:0.0173 of:0.0405 of:0.1016 and:0.0309)
		( the:0.0101 and:0.0237 was:0.0491 not:0.0449 good:0.0250 of:0.0688 of:0.1089 and:0.0508)
		( the:0.0142 and:0.0281 was:0.0645 not:0.0525 good:0.0352 of:0.1011 of:0.1074 and:0.0845)
		( the:0.0186 and:0.0369 was:0.0698 not:0.0579 good:0.0500 of:0.1245 of:0.1104 and:0.1177)
		( the:0.0232 and:0.0471 was:0.0615 going:0.0669 good:0.0610 of:0.1260 for:0.1318 and:0.1270)
		(,:0.0282 and:0.0562 found:0.0618 going:0.0845 good:0.0664 that:0.1172 for:0.1631 and:0.1309)
		(,:0.0354 and:0.0649 found:0.0635 going:0.0938 good:0.0649 that:0.1006 for:0.1855 I:0.1445)
 I
6550: sample 0: Hello, I'm a language model,
		( plural:0.0004 only:0.0030 and:0.0032 and:0.0320 new:0.0040 and:0.0148,:0.0085 and:0.0026)
		(�:0.0006 and:0.0054 and:0.0056 and:0.0208 new:0.0082 and:0.0115,:0.0099 and:0.0066)
		(�:0.0010 and:0.0085 and:0.0098 and:0.0216 new:0.0117 and:0.0112 of:0.0199 and:0.0101)
		( the:0.0018 and:0.0101 and:0.0119 not:0.0195 new:0.0121,:0.0118 of:0.0481 and:0.0088)
		( the:0.0034 and:0.0137 was:0.0151 not:0.0332 further:0.0110 of:0.0168 of:0.0742 and:0.0103)
		( the:0.0059 and:0.0176 was:0.0205 not:0.0439 little:0.0149 of:0.0282 of:0.0923 which:0.0178)
		( the:0.0092 and:0.0216 was:0.0256 not:0.0540 little:0.0206 of:0.0447 of:0.1162 which:0.0332)
		( the:0.0135 the:0.0277 was:0.0315 not:0.0737 little:0.0305 of:0.0635 of:0.1377 and:0.0596)
		( the:0.0183 and:0.0383 was:0.0391 not:0.1055 little:0.0388 of:0.0820 of:0.1494 and:0.0913)
		( the:0.0237 and:0.0515.:0.0562 not:0.1196 little:0.0417 that:0.1089 of:0.1445 I:0.1055)
		( the:0.0292 and:0.0635.:0.0981 not:0.1108 bit:0.0442 that:0.1167.:0.1396 I:0.1836)
		( the:0.0334 and:0.0713.:0.1445 going:0.1079 bit:0.0537 that:0.0991.:0.1494 I:0.2871)
 I
7050: sample 0: Hello, I'm a language model,
		( shoot:0.0008 only:0.0056 and:0.0052 and:0.0131 more:0.0052 and:0.0106,:0.0134 and:0.0026)
		(�:0.0008 and:0.0067 and:0.0079 and:0.0102 more:0.0066 and:0.0088,:0.0110 and:0.0092)
		(�:0.0012 and:0.0107 and:0.0117 and:0.0129 more:0.0086 and:0.0110,:0.0189 and:0.0107)
		(�:0.0016 and:0.0131 and:0.0139 not:0.0245 good:0.0114 and:0.0131 of:0.0293 and:0.0091)
		( the:0.0028 and:0.0170 was:0.0239 not:0.0361 good:0.0178 of:0.0187 of:0.0505 and:0.0135)
		( the:0.0049 and:0.0212�:0.0393 not:0.0493 little:0.0374 of:0.0325 of:0.0630 and:0.0356)
		( the:0.0078 and:0.0278�:0.0630 not:0.0635 little:0.0723 of:0.0510 of:0.0781 and:0.0806)
		( the:0.0117 and:0.0378�:0.0815 not:0.0786 little:0.1035 of:0.0742 of:0.0942 and:0.1387)
		( the:0.0157 and:0.0503�:0.0864 not:0.0864 little:0.1030 of:0.0894.:0.1079 and:0.1699)
		( the:0.0206 and:0.0615�:0.0840 not:0.0820 little:0.0952 of:0.0850.:0.1387 and:0.1748)
		(,:0.0280 and:0.0708�:0.0796 going:0.0903 little:0.0845 therapist:0.1177.:0.1582 and:0.1670)
		(,:0.0364 and:0.0796�:0.0820 going:0.0952 little:0.0781 therapist:0.1436.:0.1758 and:0.1592)
 and
7550: sample 0: Hello, I'm a language model,
		(�:0.0005 only:0.0023 and:0.0026 and:0.0095 more:0.0059 and:0.0090 and:0.0115 and:0.0019)
		(�:0.0009 and:0.0033 and:0.0063 and:0.0076 more:0.0091 and:0.0089,:0.0083 and:0.0063)
		(�:0.0014 and:0.0070 and:0.0140 not:0.0170 more:0.0148 and:0.0095,:0.0133 and:0.0105)
		(�:0.0019 and:0.0111 and:0.0182 not:0.0417 more:0.0126 and:0.0101 of:0.0270 and:0.0086)
		( the:0.0034 and:0.0157 and:0.0172 not:0.0562 little:0.0128 and:0.0119 of:0.0371 and:0.0113)
		( the:0.0058 and:0.0190.:0.0204 not:0.0703 little:0.0203 of:0.0157 for:0.0447 and:0.0237)
		( the:0.0095 and:0.0243.:0.0315 not:0.0894 little:0.0260 of:0.0255 for:0.0654 and:0.0544)
		( the:0.0140 and:0.0317.:0.0488 not:0.1050 great:0.0315 of:0.0398 for:0.0923 and:0.1167)
		( the:0.0192 and:0.0422.:0.0757 going:0.1260 great:0.0383 that:0.0623 for:0.1177 and:0.1631)
		( the:0.0245 and:0.0542.:0.1069 going:0.1553 great:0.0425 that:0.0688 for:0.1270 and:0.1699)
		( the:0.0300 and:0.0654.:0.1445 going:0.1631 great:0.0408 teacher:0.1260 for:0.1191 and:0.1592)
		(,:0.0376 and:0.0723.:0.1699 going:0.1465 great:0.0366 teacher:0.2500,:0.1152 I:0.1738)
 I
8050: sample 0: Hello, I'm a language model,
		( flipped:0.0006 only:0.0022 see:0.0036 and:0.0030 further:0.0028 and:0.0053,:0.0096 and:0.0017)
		(�:0.0006 to:0.0023 and:0.0051 and:0.0045 more:0.0039 and:0.0039,:0.0059 and:0.0039)
		(�:0.0010 to:0.0043 and:0.0084 and:0.0084 further:0.0081 and:0.0047,:0.0123 and:0.0067)
		(�:0.0014 and:0.0071 have:0.0127 just:0.0089 further:0.0113 of:0.0049 of:0.0298 to:0.0076)
		( the:0.0027 the:0.0096 have:0.0168 just:0.0128 good:0.0127 of:0.0101 of:0.0557 to:0.0101)
		( the:0.0049 the:0.0151�:0.0302 just:0.0187 little:0.0214 of:0.0234 of:0.0796 and:0.0155)
		( the:0.0079 the:0.0251�:0.0439 just:0.0284 little:0.0376 of:0.0459 of:0.0972 and:0.0364)
		( the:0.0122 the:0.0408�:0.0540 just:0.0396 little:0.0537 of:0.0742 of:0.1157 and:0.0825)
		( the:0.0173 the:0.0591 was:0.0564 just:0.0503 little:0.0649 that:0.1099 of:0.1338 and:0.1299)
		( the:0.0229 the:0.0723 was:0.0603 just:0.0530 little:0.0698 that:0.1396 of:0.1475 and:0.1553)
		( the:0.0291 the:0.0806 have:0.0623 just:0.0481 bit:0.0771 that:0.1436 of:0.1465 but:0.1650)
		( the:0.0344 the:0.0869 have:0.0654 have:0.0513 bit:0.0923 that:0.1289 of:0.1387 and:0.1582)
 and
8550: sample 0: Hello, I'm a language model,
		( flipped:0.0006 only:0.0019 also:0.0022 and:0.0053 further:0.0025 and:0.0038,:0.0096 right:0.0015)
		(�:0.0009 and:0.0033 use:0.0031 and:0.0056 more:0.0033 and:0.0039,:0.0071 and:0.0040)
		(�:0.0013 and:0.0065.:0.0045 not:0.0112 further:0.0047 and:0.0052,:0.0131 and:0.0067)
		(�:0.0019 and:0.0097 have:0.0072 not:0.0214 further:0.0070 and:0.0060 of:0.0231 and:0.0050)
		(�:0.0024 and:0.0123 have:0.0106 not:0.0228 little:0.0095 of:0.0090 of:0.0332 and:0.0065)
		( the:0.0044 and:0.0140 am:0.0153 going:0.0320 little:0.0215 of:0.0166 for:0.0459 and:0.0182)
		( the:0.0071 and:0.0194 am:0.0278 going:0.0649 little:0.0413 that:0.0354 for:0.0684 and:0.0649)
		( the:0.0107 and:0.0289 am:0.0457 going:0.1152 little:0.0608 that:0.0752,:0.0874 and:0.1641)
		( the:0.0153 and:0.0432 am:0.0654 going:0.1641 little:0.0752 that:0.1309,:0.1250 and:0.2617)
		( the:0.0206 and:0.0596 am:0.0850 going:0.1934 little:0.0825 that:0.1670.:0.1631 and:0.2715)
		( the:0.0255 and:0.0742 am:0.0908 going:0.1885 little:0.0801 that:0.1553.:0.1875 and:0.2393)
		(,:0.0315 and:0.0801 am:0.0869 going:0.1562 little:0.0757 that:0.1138.:0.1924 and:0.2168)
 and
9050: sample 0: Hello, I'm a language model,
		( frown:0.0004 only:0.0018 and:0.0052 and:0.0098 further:0.0027 and:0.0036 and:0.0071 and:0.0020)
		(�:0.0007 and:0.0027 and:0.0057 and:0.0079 later:0.0034 and:0.0034 work:0.0050 and:0.0034)
		(�:0.0010 and:0.0038 have:0.0078 and:0.0104 later:0.0041 and:0.0040,:0.0058 and:0.0056)
		(�:0.0014 and:0.0052 have:0.0134 not:0.0187 new:0.0049 and:0.0044 of:0.0123 and:0.0047)
		( the:0.0025 and:0.0068 have:0.0194 not:0.0245 good:0.0059 of:0.0054 of:0.0205 and:0.0055)
		( the:0.0044 and:0.0068 have:0.0266 going:0.0276 good:0.0102 of:0.0095 of:0.0270 and:0.0102)
		( the:0.0072 and:0.0092�:0.0396 going:0.0405 good:0.0168 of:0.0160 for:0.0361 and:0.0233)
		( the:0.0112 the:0.0148�:0.0525 going:0.0552 good:0.0217 of:0.0270 for:0.0510 and:0.0505)
		( the:0.0157 the:0.0275�:0.0669 going:0.0698 good:0.0282 of:0.0437,:0.0742 and:0.0884)
		( the:0.0210 the:0.0415�:0.0815 going:0.0835 good:0.0320 of:0.0630.:0.1030 and:0.1177)
		( the:0.0266 and:0.0569�:0.0967 going:0.0903 good:0.0327 of:0.0747.:0.1279 I:0.1416)
		( the:0.0322 and:0.0737�:0.1113 going:0.0879 good:0.0297 teacher:0.1465.:0.1299 I:0.1680)
 I
9550: sample 0: Hello, I'm a language model,
		( frown:0.0006 only:0.0017 and:0.0040 and:0.0039 further:0.0025 and:0.0025 work:0.0040 only:0.0014)
		(�:0.0007 only:0.0019 and:0.0052 and:0.0053 new:0.0031 and:0.0023 work:0.0038 and:0.0025)
		(�:0.0010 and:0.0025 and:0.0072 and:0.0095 new:0.0049 and:0.0029 of:0.0062 and:0.0041)
		(�:0.0014 and:0.0047 was:0.0086 not:0.0146 new:0.0065 and:0.0028 of:0.0125 and:0.0034)
		( the:0.0021 and:0.0052 was:0.0131 not:0.0161 new:0.0075 of:0.0046 for:0.0168 which:0.0054)
		( the:0.0037 and:0.0078 was:0.0190 going:0.0229 little:0.0121 that:0.0100 for:0.0240 I:0.0113)
		( the:0.0062 and:0.0107 was:0.0287 going:0.0439 little:0.0212 that:0.0248 that:0.0430 and:0.0264)
		( the:0.0096 the:0.0198 am:0.0427 going:0.0679 little:0.0347 that:0.0569 that:0.0732 and:0.0713)
		( the:0.0140 the:0.0352 am:0.0566 going:0.0977 little:0.0483 that:0.0991 that:0.1079 and:0.1299)
		( the:0.0187 and:0.0596 am:0.0640 going:0.1318 little:0.0581 that:0.1270 that:0.1309 and:0.1592)
		( the:0.0239 and:0.0854 am:0.0649 going:0.1641 little:0.0608 that:0.1201 that:0.1260 and:0.1748)
		( the:0.0292 and:0.1011 am:0.0623 going:0.1748 little:0.0593 teacher:0.1924 that:0.0991 and:0.1904)
 and
10050: sample 0: Hello, I'm a language model,
		( frown:0.0007 only:0.0015 present:0.0032 and:0.0029 further:0.0014 and:0.0036,:0.0059 record:0.0010)
		(�:0.0007 and:0.0022 use:0.0039 and:0.0043 further:0.0022 and:0.0024,:0.0044 and:0.0026)
		(�:0.0011 and:0.0052 have:0.0064 and:0.0070 new:0.0032 and:0.0029,:0.0071 and:0.0032)
		(�:0.0015 and:0.0087 have:0.0110 just:0.0084 new:0.0044 review:0.0038 of:0.0134 and:0.0029)
		( the:0.0020 and:0.0120 have:0.0153 just:0.0131 little:0.0070 arts:0.0067 of:0.0227 so:0.0042)
		( the:0.0036 and:0.0140 have:0.0210 going:0.0182 little:0.0153 arts:0.0093 of:0.0325 and:0.0096)
		( the:0.0060 and:0.0211 have:0.0291 going:0.0289 little:0.0267 of:0.0128 of:0.0483 and:0.0356)
		( the:0.0093 and:0.0334 have:0.0430 going:0.0471 little:0.0361 that:0.0216 of:0.0713 and:0.1128)
		( the:0.0135 and:0.0549 am:0.0645 going:0.0679 little:0.0396 that:0.0415 of:0.1035 and:0.2148)
		( the:0.0178 and:0.0815 am:0.1099 going:0.0850 very:0.0371 that:0.0613 of:0.1206 and:0.2393)
		(,:0.0250 and:0.0991 am:0.1416 going:0.0913 very:0.0356 that:0.0703.:0.1279 and:0.2158)
		(,:0.0344 and:0.1060 am:0.1523 going:0.0894 professor:0.0322 that:0.0625.:0.1426 and:0.1875)
 and
10550: sample 0: Hello, I'm a language model,
		( frown:0.0005 only:0.0019 and:0.0018 and:0.0086 further:0.0020 medium:0.0023 work:0.0033 rest:0.0010)
		(�:0.0007 only:0.0016 and:0.0023 and:0.0050 further:0.0020 medium:0.0025 work:0.0031 and:0.0014)
		(�:0.0010 and:0.0039 and:0.0042 not:0.0096 little:0.0038 medium:0.0046,:0.0062 and:0.0037)
		(�:0.0013 and:0.0072 have:0.0066 not:0.0131 little:0.0081 and:0.0060 of:0.0156 and:0.0051)
		( the:0.0017 and:0.0104 have:0.0100 not:0.0167 little:0.0164 and:0.0075 of:0.0249 and:0.0084)
		( the:0.0031 and:0.0128 have:0.0153 going:0.0240 little:0.0275 and:0.0087,:0.0322 and:0.0159)
		( the:0.0053 and:0.0189 have:0.0245 going:0.0374 little:0.0505 of:0.0134,:0.0540 and:0.0459)
		( the:0.0084 and:0.0312 have:0.0408 going:0.0508 little:0.0664 of:0.0204,:0.0942 and:0.1318)
		( the:0.0124 and:0.0552 have:0.0649 going:0.0654 little:0.0664 of:0.0289,:0.1445 and:0.2246)
		( the:0.0172 and:0.0850 have:0.0845 going:0.0708 little:0.0554 teacher:0.0388,:0.1738 and:0.2256)
		(,:0.0228 and:0.1045 have:0.0938 going:0.0645 little:0.0420 teacher:0.1338,:0.1787 and:0.1914)
		(,:0.0317 and:0.1133 have:0.0942 not:0.0537 little:0.0332 teacher:0.3301,:0.1777 and:0.1709)
 and
11050: sample 0: Hello, I'm a language model,
		(�:0.0005 only:0.0021 use:0.0030 and:0.0049 further:0.0017 and:0.0015 work:0.0027 right:0.0008)
		(�:0.0009 only:0.0017 use:0.0031 and:0.0032 further:0.0017 work:0.0017 work:0.0034 and:0.0013)
		(�:0.0013 to:0.0032,:0.0049 not:0.0085 new:0.0033,:0.0025 of:0.0052 and:0.0029)
		(�:0.0016 and:0.0043 have:0.0061 not:0.0179 new:0.0050,:0.0032 of:0.0151 and:0.0034)
		(�:0.0020 and:0.0061 have:0.0087 going:0.0283 little:0.0078 of:0.0062 of:0.0264 and:0.0058)
		( the:0.0036 and:0.0080 will:0.0138 going:0.0608 little:0.0190 of:0.0125 of:0.0366 and:0.0134)
		( the:0.0060 and:0.0135 have:0.0231 going:0.0972 little:0.0493 of:0.0215 of:0.0496 and:0.0432)
		( the:0.0096 and:0.0245 have:0.0381 going:0.1260 little:0.0830 of:0.0315 of:0.0679 and:0.1016)
		( the:0.0143 and:0.0437 have:0.0574 going:0.1338 little:0.1089 that:0.0498 of:0.0898 and:0.1494)
		( the:0.0197 and:0.0674 have:0.0723 going:0.1230 little:0.1201 that:0.0618 of:0.1055 and:0.1602)
		(,:0.0269 and:0.0874 have:0.0850 not:0.1138 little:0.1235 teacher:0.0679 of:0.1069 and:0.1582)
		(,:0.0369 and:0.0996 have:0.0918 not:0.1157 little:0.1182 teacher:0.1475 of:0.0986 and:0.1611)
 and
11550: sample 0: Hello, I'm a language model,
		(�:0.0009 only:0.0015 use:0.0019 and:0.0022 further:0.0012 medium:0.0024 work:0.0029 only:0.0008)
		(�:0.0014 then:0.0023 use:0.0029 and:0.0019 further:0.0015 medium:0.0022 work:0.0026 and:0.0013)
		(�:0.0020 to:0.0033 use:0.0040 not:0.0046 further:0.0022 medium:0.0034 of:0.0048 and:0.0020)
		(�:0.0027 then:0.0042 have:0.0042 not:0.0079 little:0.0044 medium:0.0034 of:0.0142 such:0.0021)
		(�:0.0034 and:0.0050�:0.0089 not:0.0129 little:0.0085 of:0.0038 of:0.0276 such:0.0034)
		(�:0.0041 and:0.0073�:0.0210 not:0.0232 little:0.0150 of:0.0085 of:0.0481 which:0.0092)
		( the:0.0049 and:0.0110�:0.0422 going:0.0417 little:0.0262 of:0.0172 of:0.0781 and:0.0244)
		( the:0.0079 the:0.0190�:0.0669 going:0.0630 little:0.0361 of:0.0309 of:0.1182 and:0.0684)
		( the:0.0120 the:0.0364�:0.0854 going:0.0840 little:0.0449 that:0.0569 of:0.1572 and:0.1250)
		( the:0.0173 the:0.0527�:0.0986 going:0.0977 little:0.0474 that:0.0806 of:0.1816 and:0.1436)
		( the:0.0231 the:0.0654�:0.1060 going:0.1025 little:0.0457 that:0.0864 of:0.1719 and:0.1396)
		(,:0.0312 and:0.0820�:0.1064 going:0.1006 little:0.0405 that:0.0693 of:0.1436 I:0.1777)
 I
12050: sample 0: Hello, I'm a language model,
		(�:0.0006 only:0.0011 use:0.0015 and:0.0029 new:0.0006 medium:0.0023 work:0.0049 following:0.0008)
		(�:0.0010 following:0.0016 and:0.0024 and:0.0032 new:0.0015 medium:0.0027 work:0.0045 following:0.0013)
		(�:0.0013 to:0.0025 and:0.0042 not:0.0056 new:0.0039 medium:0.0048 of:0.0058 following:0.0018)
		(�:0.0017 and:0.0032 have:0.0074 not:0.0131 new:0.0068 medium:0.0043 of:0.0164 to:0.0022)
		(�:0.0021 the:0.0044�:0.0142 not:0.0222 little:0.0085 of:0.0098 of:0.0300 and:0.0045)
		( the:0.0025 the:0.0065�:0.0254 not:0.0383 little:0.0190 of:0.0189 of:0.0449 and:0.0145)
		( the:0.0044 the:0.0120�:0.0479 not:0.0544 little:0.0471 of:0.0327 of:0.0608 and:0.0520)
		( the:0.0071 the:0.0256�:0.0718 going:0.0771 little:0.0747 that:0.0654,:0.0986 and:0.1318)
		( the:0.0110 the:0.0454�:0.0879 going:0.1064 little:0.1079 that:0.1157,:0.1436 and:0.1895)
		( the:0.0160 the:0.0654 have:0.0942 going:0.1260 little:0.1318 that:0.1514,:0.1855 and:0.1963)
		( the:0.0217 the:0.0728 have:0.1016 going:0.1309 little:0.1426 that:0.1445,:0.2188 and:0.1914)
		( the:0.0278 the:0.0776 have:0.0991 not:0.1279 little:0.1436 that:0.1094,:0.2197 and:0.1855)
 and
12550: sample 0: Hello, I'm a language model,
		(�:0.0007 only:0.0010 use:0.0018 and:0.0063 further:0.0007 rest:0.0013 and:0.0037 only:0.0007)
		(�:0.0011 only:0.0012 use:0.0030 and:0.0047 further:0.0009 work:0.0016 work:0.0034 only:0.0010)
		(�:0.0015 and:0.0018 use:0.0045 and:0.0073 further:0.0016 work:0.0018 of:0.0039 and:0.0017)
		(�:0.0020 and:0.0031 use:0.0049 not:0.0104 particular:0.0028 arts:0.0029 of:0.0081 and:0.0021)
		(�:0.0024 and:0.0042 highly:0.0067 going:0.0195 little:0.0066 arts:0.0056 of:0.0119 and:0.0026)
		(�:0.0028 and:0.0054�:0.0118 going:0.0479 little:0.0172 of:0.0109 for:0.0167 which:0.0065)
		( the:0.0048 and:0.0090�:0.0236 going:0.0845 little:0.0381 of:0.0190 for:0.0297 which:0.0182)
		( the:0.0081 and:0.0162�:0.0371 going:0.1309 little:0.0679 that:0.0386 for:0.0566 and:0.0593)
		( the:0.0125 the:0.0334�:0.0439 going:0.1660 little:0.1108 that:0.0737 for:0.0952 and:0.1309)
		( the:0.0182 the:0.0547�:0.0483 going:0.1787 little:0.1436 that:0.1001 for:0.1245 and:0.1689)
		( the:0.0253 and:0.0640�:0.0500 going:0.1719 little:0.1621 that:0.0952 for:0.1270 and:0.1787)
		( the:0.0322 and:0.0762�:0.0518 going:0.1553 little:0.1641 teacher:0.1138,:0.1113 and:0.1826)
 and
13050: sample 0: Hello, I'm a language model,
		(�:0.0007 only:0.0008 present:0.0009 and:0.0009 further:0.0006 medium:0.0009 work:0.0016 dark:0.0004)
		(�:0.0010 only:0.0010 use:0.0014 and:0.0015 further:0.0010 search:0.0010 call:0.0014 bottom:0.0007)
		(�:0.0014 only:0.0014 have:0.0028 not:0.0050 further:0.0016 search:0.0018 of:0.0026 following:0.0011)
		(�:0.0019 and:0.0027 have:0.0066 not:0.0117 new:0.0025 search:0.0026 of:0.0070 and:0.0018)
		(�:0.0023 and:0.0038 have:0.0103 going:0.0178 little:0.0043 of:0.0057 of:0.0139 and:0.0037)
		(�:0.0028 and:0.0049 have:0.0155 going:0.0327 little:0.0092 of:0.0113 of:0.0214 and:0.0082)
		( the:0.0038 and:0.0074 have:0.0233 going:0.0566 little:0.0175 of:0.0214 of:0.0349 and:0.0223)
		( the:0.0065 and:0.0141 have:0.0369 going:0.1021 little:0.0288 of:0.0371 for:0.0620 and:0.0591)
		( the:0.0106 and:0.0292 have:0.0530 going:0.1641 little:0.0425 that:0.0664 that:0.0898 and:0.1108)
		( the:0.0155 and:0.0527 have:0.0615 going:0.2070 little:0.0474 that:0.0903 for:0.1089 and:0.1260)
		( the:0.0220 and:0.0781 think:0.0723 going:0.2090 little:0.0464 that:0.0840 of:0.1162 I:0.1348)
		( the:0.0283 and:0.0957 think:0.0693 going:0.1709 little:0.0413 professor:0.1177 of:0.1177 I:0.1768)
 I
13550: sample 0: Hello, I'm a language model,
		(�:0.0008 only:0.0010 see:0.0014 and:0.0009 similar:0.0005 medium:0.0010 and:0.0018 however:0.0005)
		(�:0.0013 only:0.0009 see:0.0011 going:0.0016 similar:0.0008 and:0.0013,:0.0014 pre:0.0006)
		(�:0.0018 two:0.0014 and:0.0023 going:0.0052 particular:0.0014 medium:0.0022,:0.0025 and:0.0011)
		(�:0.0023 and:0.0026 was:0.0029 going:0.0159 particular:0.0034 search:0.0031 of:0.0049 and:0.0016)
		(�:0.0028 and:0.0042�:0.0042 going:0.0264 sure:0.0072 arts:0.0038 of:0.0070 and:0.0031)
		(�:0.0034 and:0.0058�:0.0076 going:0.0437 sure:0.0147 arts:0.0057 of:0.0098 and:0.0094)
		(�:0.0039 and:0.0105�:0.0129 going:0.0581 very:0.0140 that:0.0077,:0.0190 and:0.0306)
		( the:0.0056 and:0.0217�:0.0204 sure:0.0742 very:0.0255 that:0.0152,:0.0442 and:0.0986)
		( the:0.0091 and:0.0437�:0.0295 sure:0.0889 very:0.0354 that:0.0254,:0.0913 and:0.1729)
		( the:0.0139 and:0.0757 think:0.0579 sure:0.0981 very:0.0398 that:0.0349,:0.1426 and:0.1924)
		( the:0.0198 and:0.1089 think:0.0850 sure:0.0986 very:0.0391 teacher:0.0752,:0.1660 and:0.1807)
		(,:0.0273 and:0.1289 think:0.0879 sure:0.0879 great:0.0403 teacher:0.1621.:0.1611 and:0.1582)
 and
14050: sample 0: Hello, I'm a language model,
		(�:0.0006 type:0.0006 see:0.0008 and:0.0012yll:0.0004 medium:0.0012 work:0.0009 medium:0.0003)
		(�:0.0010 type:0.0008 use:0.0014 and:0.0013 appropriate:0.0006 medium:0.0014 work:0.0010 project:0.0005)
		(�:0.0014 to:0.0012ct:0.0023 and:0.0022 particular:0.0015 medium:0.0023 of:0.0019 and:0.0009)
		(�:0.0018 and:0.0022 have:0.0033 going:0.0056 particular:0.0032 search:0.0037 of:0.0053 and:0.0014)
		(�:0.0023 and:0.0035 have:0.0052 going:0.0103 particular:0.0047 search:0.0049 of:0.0093 which:0.0018)
		(�:0.0027 and:0.0045 have:0.0095 going:0.0214 sure:0.0066 of:0.0053 of:0.0171 which:0.0043)
		(�:0.0031 and:0.0067 have:0.0183 going:0.0371 little:0.0156 that:0.0102 of:0.0272 and:0.0121)
		( the:0.0050 the:0.0121 have:0.0332 going:0.0557 little:0.0325 that:0.0229 of:0.0461 and:0.0486)
		( the:0.0086 the:0.0292 have:0.0505 going:0.0693 little:0.0439 that:0.0461 of:0.0742 but:0.1123)
		( the:0.0135 the:0.0591 have:0.0654 going:0.0737 little:0.0483 that:0.0732 of:0.1001 but:0.1729)
		( the:0.0197 the:0.0791 have:0.0713 not:0.0776 little:0.0454 that:0.0767 of:0.1152 but:0.1836)
		(,:0.0291 the:0.0845 have:0.0703 not:0.0830 little:0.0396 teacher:0.0825 of:0.1133 but:0.1699)
 but
14550: sample 0: Hello, I'm a language model,
		(�:0.0008 only:0.0008 present:0.0007 and:0.0007 href:0.0005 change:0.0011 and:0.0018 wo:0.0003)
		(�:0.0013 only:0.0009ys:0.0008ness:0.0006 appropriate:0.0005 call:0.0013 call:0.0013 experiment:0.0005)
		(�:0.0018 to:0.0014ys:0.0017 not:0.0022 particular:0.0014 call:0.0018 of:0.0030 and:0.0011)
		(�:0.0023 and:0.0023 was:0.0030 going:0.0047 particular:0.0035 of:0.0021 of:0.0064 and:0.0016)
		(�:0.0029 and:0.0035�:0.0052 going:0.0124 particular:0.0046 of:0.0052 of:0.0103 and:0.0031)
		(�:0.0034 and:0.0047�:0.0099 going:0.0383 new:0.0051 of:0.0113 of:0.0171 and:0.0081)
		(�:0.0040 and:0.0078 have:0.0175 going:0.0791 very:0.0089 of:0.0189 of:0.0269 and:0.0266)
		( the:0.0058 and:0.0162 have:0.0315 going:0.1191 very:0.0168 that:0.0376 that:0.0574 and:0.0767)
		( the:0.0100 the:0.0312 have:0.0461 going:0.1367 very:0.0237 that:0.0713 that:0.1069 but:0.1396)
		( the:0.0156 the:0.0571 am:0.0598 going:0.1299 little:0.0327 that:0.1021 that:0.1396 but:0.1973)
		( the:0.0229 and:0.0820 am:0.0674 going:0.1089 little:0.0400 that:0.1069 that:0.1416 but:0.2178)
		( the:0.0311 and:0.0981 was:0.0728 going:0.0840 little:0.0422 therapist:0.1260 that:0.1152 but:0.2158)
 but
15050: sample 0: Hello, I'm a language model,
		(�:0.0008 type:0.0007igs:0.0009 time:0.0005yll:0.0006 medium:0.0006 work:0.0010 bottom:0.0003)
		(�:0.0012 type:0.0008ct:0.0014 time:0.0008 particular:0.0005 medium:0.0008 work:0.0011 bottom:0.0005)
		(�:0.0016 type:0.0009ct:0.0018 not:0.0028 particular:0.0016 medium:0.0017 of:0.0028 and:0.0006)
		(�:0.0022 while:0.0012 have:0.0031 going:0.0069 particular:0.0035 and:0.0020 of:0.0089 to:0.0010)
		(�:0.0027 while:0.0017 have:0.0053 going:0.0168 particular:0.0051 and:0.0031 of:0.0141 and:0.0018)
		(�:0.0032 while:0.0023�:0.0117 going:0.0339 particular:0.0063 of:0.0056 of:0.0198 which:0.0049)
		(�:0.0037 and:0.0034 have:0.0225 sure:0.0527 very:0.0132 of:0.0103 of:0.0315 and:0.0146)
		( the:0.0052 and:0.0071 have:0.0383 going:0.0693 very:0.0258 of:0.0184 of:0.0559 and:0.0544)
		( the:0.0090 and:0.0151 have:0.0518 going:0.0840 very:0.0376 of:0.0304,:0.0962 and:0.1143)
		( the:0.0145 and:0.0327 have:0.0593 going:0.0874 very:0.0425 teacher:0.0466.:0.1445 and:0.1436)
		(,:0.0219 and:0.0615 have:0.0649 going:0.0767 little:0.0471 teacher:0.1426.:0.1680 and:0.1611)
		(,:0.0334 and:0.0776 am:0.0703 not:0.0698 little:0.0483 teacher:0.3066.:0.1484 and:0.1592)
 and
15550: sample 0: Hello, I'm a language model,
		(�:0.0006 only:0.0005ct:0.0008 associated:0.0004 occasion:0.0004 medium:0.0011,:0.0009 inspiration:0.0003)
		(�:0.0009
:0.0007ct:0.0015 failed:0.0005itude:0.0005 medium:0.0011 of:0.0007 bottom:0.0004)
		(�:0.0013
:0.0011ct:0.0023 going:0.0013 new:0.0010 medium:0.0020 of:0.0027 bottom:0.0006)
		(�:0.0017 the:0.0011ct:0.0031 going:0.0038 new:0.0019 medium:0.0019 of:0.0074 to:0.0009)
		(�:0.0022 and:0.0015ct:0.0034 going:0.0082 new:0.0029 of:0.0027 of:0.0116 and:0.0016)
		(�:0.0026 and:0.0022�:0.0056 going:0.0184 very:0.0048 of:0.0049 of:0.0153 and:0.0036)
		(�:0.0031 the:0.0034�:0.0099 going:0.0330 very:0.0092 of:0.0084 of:0.0237 and:0.0115)
		( the:0.0041 the:0.0077 have:0.0178 going:0.0469 little:0.0154 that:0.0199.:0.0383 and:0.0391)
		( the:0.0074 the:0.0171 have:0.0312 going:0.0559 little:0.0237 that:0.0391.:0.0854 and:0.1089)
		( the:0.0125 the:0.0311 am:0.0457 a:0.0654 little:0.0272 that:0.0581.:0.1553 and:0.1660)
		( the:0.0190 and:0.0513 am:0.0791 a:0.0918 little:0.0272 that:0.0605.:0.1924 and:0.2012)
		(,:0.0293 and:0.0698 am:0.1030 a:0.1045 bit:0.0388 teacher:0.0557.:0.1855 and:0.2129)
 and
16050: sample 0: Hello, I'm a language model,
		(�:0.0006 weight:0.0005 present:0.0007 associated:0.0004yll:0.0006 outcome:0.0006 work:0.0012 immediate:0.0003)
		(�:0.0010
:0.0005ys:0.0008 associated:0.0004yll:0.0006illion:0.0006 work:0.0011 growing:0.0004)
		(�:0.0015 only:0.0007�:0.0012 not:0.0023 new:0.0008 medium:0.0015 of:0.0028 and:0.0008)
		(�:0.0020 and:0.0013�:0.0035 not:0.0060 new:0.0015 search:0.0018 of:0.0063 and:0.0010)
		(�:0.0027 and:0.0018�:0.0084 not:0.0112 sure:0.0033 of:0.0036 of:0.0097 and:0.0020)
		(�:0.0034 and:0.0023�:0.0179 sure:0.0253 very:0.0051 of:0.0065 of:0.0112 and:0.0039)
		(�:0.0041 and:0.0035�:0.0317 sure:0.0410 very:0.0101 of:0.0106 for:0.0162 and:0.0122)
		( the:0.0048 and:0.0071�:0.0483 sure:0.0552 very:0.0187 of:0.0153,:0.0305 and:0.0569)
		( the:0.0087 and:0.0175�:0.0654 not:0.0654 very:0.0259 of:0.0216,:0.0640 and:0.1475)
		( the:0.0147 and:0.0417�:0.0884 not:0.0806 bit:0.0383 teacher:0.0361,:0.1040 and:0.2188)
		(,:0.0231 and:0.0781�:0.1206 not:0.0884 bit:0.0454 teacher:0.0898,:0.1250 and:0.2656)
		(,:0.0361 and:0.0996�:0.1572 a:0.1025 bit:0.0479 teacher:0.1768,:0.1235 and:0.2637)
 and
16550: sample 0: Hello, I'm a language model,
		(�:0.0007 type:0.0005ets:0.0009 associated:0.0004 Paragu:0.0005quez:0.0009 work:0.0009 inspiration:0.0004)
		(�:0.0011 however:0.0006ets:0.0011ned:0.0004 particular:0.0005illion:0.0017 work:0.0008 following:0.0003)
		(�:0.0015 however:0.0009ys:0.0016 and:0.0011 particular:0.0013illion:0.0018 of:0.0014 to:0.0005)
		(�:0.0021 however:0.0013ys:0.0021 going:0.0016 particular:0.0026illion:0.0017 of:0.0045 and:0.0009)
		(�:0.0027 to:0.0015.:0.0039 going:0.0041 particular:0.0036 of:0.0028 of:0.0093 and:0.0015)
		(�:0.0033 the:0.0027�:0.0063 going:0.0137 few:0.0051 of:0.0057 of:0.0159 and:0.0040)
		(�:0.0039 the:0.0051�:0.0098 going:0.0339 few:0.0085 of:0.0085 of:0.0238 and:0.0123)
		(�:0.0045 the:0.0112�:0.0159 going:0.0693 little:0.0162 of:0.0118 of:0.0439 and:0.0464)
		( the:0.0082 the:0.0248 have:0.0248 going:0.1216 very:0.0266 that:0.0189 of:0.0806 and:0.1235)
		( the:0.0145 the:0.0471 have:0.0400 going:0.1660 little:0.0364 that:0.0272 of:0.1191 and:0.1855)
		( the:0.0226 the:0.0674 am:0.0518 going:0.1895 little:0.0439 teacher:0.0713 of:0.1279 and:0.2314)
		(.:0.0325 and:0.0771 am:0.0591 going:0.1777 little:0.0469 teacher:0.2041 teacher:0.1196 and:0.2480)
 and
17050: sample 0: Hello, I'm a language model,
		(�:0.0005 however:0.0005ets:0.0008 associated:0.0004 Paragu:0.0004 medium:0.0006pei:0.0008 discontin:0.0003)
		(�:0.0008 however:0.0006ct:0.0013hered:0.0007 halluc:0.0004illion:0.0007pei:0.0005 bottom:0.0003)
		(�:0.0011 however:0.0009ct:0.0019hered:0.0013 particular:0.0006 medium:0.0010 of:0.0012 and:0.0006)
		(�:0.0015 and:0.0015 have:0.0028 not:0.0023 particular:0.0012 medium:0.0014 of:0.0035 and:0.0011)
		(�:0.0019 and:0.0023 have:0.0043 going:0.0065 new:0.0017 arts:0.0023 of:0.0054 and:0.0014)
		(�:0.0023 and:0.0033 have:0.0069 going:0.0187 few:0.0026 arts:0.0036 of:0.0079 which:0.0030)
		(�:0.0027 and:0.0045 have:0.0122 going:0.0420 little:0.0054 arts:0.0052 of:0.0130 which:0.0080)
		( the:0.0036 and:0.0074 have:0.0217 going:0.0747 little:0.0130 of:0.0075 of:0.0259 which:0.0227)
		( the:0.0071 the:0.0156 have:0.0376 going:0.1113 little:0.0253 that:0.0131 of:0.0479 and:0.0654)
		( the:0.0128 the:0.0337 have:0.0505 going:0.1367 little:0.0371 teacher:0.0311.:0.0767 and:0.1133)
		( the:0.0205 the:0.0559 have:0.0576 going:0.1357 little:0.0439 teacher:0.0903.:0.0972 and:0.1484)
		(,:0.0332 and:0.0664 have:0.0564 going:0.1162 little:0.0413 teacher:0.2012 teacher:0.0854 and:0.1543)
 and
17550: sample 0: Hello, I'm a language model,
		(�:0.0005 medium:0.0006zzo:0.0006uel:0.0004itude:0.0004 medium:0.0008 call:0.0005sonian:0.0004)
		(�:0.0008 medium:0.0006igs:0.0008ological:0.0005itude:0.0006 medium:0.0009 call:0.0005 topp:0.0003)
		(�:0.0012 medium:0.0008 have:0.0008 not:0.0012itude:0.0008 medium:0.0022 of:0.0012 and:0.0004)
		(�:0.0017 medium:0.0009 have:0.0021 not:0.0036 particular:0.0012 search:0.0024 of:0.0040 and:0.0010)
		(�:0.0023 and:0.0018 have:0.0038 not:0.0063 particular:0.0022 search:0.0033 of:0.0071 and:0.0022)
		(�:0.0029 and:0.0029 have:0.0072 sure:0.0152 very:0.0054 of:0.0035 of:0.0104 and:0.0047)
		(�:0.0036 and:0.0047 have:0.0125 sure:0.0234 very:0.0102 of:0.0052 of:0.0143 and:0.0146)
		(�:0.0042 the:0.0103 have:0.0225 going:0.0269 very:0.0173 of:0.0081.:0.0243 and:0.0530)
		( the:0.0058 and:0.0237 have:0.0403 going:0.0371 very:0.0261 that:0.0141.:0.0505 and:0.1367)
		( the:0.0109 and:0.0554 have:0.0625 going:0.0488 little:0.0415 that:0.0283.:0.0903 and:0.1992)
		( the:0.0182 and:0.0938 am:0.0845 a:0.0654 little:0.0591 teacher:0.0625.:0.1157 and:0.2354)
		( the:0.0273 and:0.1045 am:0.1064 a:0.0820 little:0.0645 teacher:0.1670.:0.0986 and:0.2490)
 and
18050: sample 0: Hello, I'm a language model,
		(�:0.0005 medium:0.0005igs:0.0008uel:0.0006 Paragu:0.0004 medium:0.0012 matters:0.0005sonian:0.0003)
		(�:0.0008 medium:0.0005ct:0.0013 associated:0.0006uthor:0.0007 medium:0.0009 work:0.0005sonian:0.0003)
		(�:0.0011 ahead:0.0008ct:0.0018 associated:0.0011uthor:0.0007 medium:0.0019,:0.0016 and:0.0003)
		(�:0.0015 and:0.0009ct:0.0019 not:0.0023 particular:0.0012 medium:0.0020,:0.0037 and:0.0006)
		(�:0.0020 and:0.0018 have:0.0029 sure:0.0078 sure:0.0020 of:0.0038,:0.0059 which:0.0013)
		(�:0.0025 and:0.0023 have:0.0051 sure:0.0238 sure:0.0064 of:0.0063,:0.0073 which:0.0028)
		(�:0.0031 and:0.0030 have:0.0089 sure:0.0408 sure:0.0088 of:0.0091,:0.0103 which:0.0059)
		(�:0.0035 the:0.0055 have:0.0155 sure:0.0525 bit:0.0097 of:0.0134,:0.0195 and:0.0192)
		( the:0.0056 the:0.0121 have:0.0267 going:0.0608 bit:0.0197 of:0.0188,:0.0378 and:0.0552)
		( the:0.0106 the:0.0271 have:0.0400 going:0.0918 bit:0.0393 that:0.0303,:0.0625 and:0.0991)
		( the:0.0182 and:0.0564 have:0.0530 going:0.1196 bit:0.0713 teacher:0.0405 of:0.0894 and:0.1406)
		(,:0.0293 and:0.0835 am:0.0610 going:0.1279 bit:0.1050 teacher:0.1001 of:0.0928 I:0.1895)
 I
18550: sample 0: Hello, I'm a language model,
		(�:0.0006 Seoul:0.0004ets:0.0009uel:0.0007calling:0.0004less:0.0007 work:0.0004uitous:0.0003)
		(�:0.0009
:0.0004ys:0.0012uel:0.0007ARS:0.0004illion:0.0007 Created:0.0005ARS:0.0003)
		(�:0.0012
:0.0006ys:0.0016 not:0.0022ys:0.0006 search:0.0016 of:0.0016
:0.0005)
		(�:0.0017 and:0.0008ys:0.0018 not:0.0058 particular:0.0012 search:0.0034 of:0.0042 and:0.0007)
		(�:0.0022 and:0.0016�:0.0025 not:0.0096 sure:0.0037 search:0.0045.:0.0074 and:0.0017)
		(�:0.0028 and:0.0021�:0.0049 going:0.0217 sure:0.0094 search:0.0043.:0.0119 but:0.0058)
		(�:0.0034 and:0.0033�:0.0092 going:0.0369 sure:0.0097 that:0.0074.:0.0194 but:0.0198)
		(�:0.0041 and:0.0061�:0.0151 going:0.0588 little:0.0165 that:0.0156.:0.0322 but:0.0552)
		( the:0.0049 and:0.0143 am:0.0258 going:0.0830 little:0.0249 that:0.0327 that:0.0549 and:0.1221)
		( the:0.0094 and:0.0393 am:0.0540 going:0.1064 little:0.0322 that:0.0613 that:0.0923 and:0.1943)
		( the:0.0167 and:0.0796 am:0.0898 going:0.1138 little:0.0361 that:0.0854 that:0.1177 and:0.2363)
		( the:0.0265 and:0.0986 am:0.1191 going:0.1123 little:0.0349 teacher:0.1060 that:0.1118 and:0.2471)
 and
19050: sample 0: Hello, I'm a language model,
		(�:0.0006prop:0.0004ets:0.0006 Reserved:0.0004aphael:0.0004 medium:0.0006 need:0.0005 PG:0.0002)
		(�:0.0009 type:0.0006ys:0.0008 notation:0.0006bees:0.0005 medium:0.0005 need:0.0004ban:0.0003)
		(�:0.0013 type:0.0008ys:0.0012 and:0.0007 particular:0.0005 medium:0.0011 of:0.0009ban:0.0005)
		(�:0.0017 type:0.0009ys:0.0014 not:0.0017 particular:0.0011 search:0.0017 of:0.0021 I:0.0005)
		(�:0.0024 and:0.0009 hope:0.0016 going:0.0035 particular:0.0017 search:0.0027 of:0.0036 I:0.0009)
		(�:0.0030 and:0.0012�:0.0032 going:0.0098 sure:0.0030 barrier:0.0042 of:0.0051 but:0.0019)
		(�:0.0037 and:0.0018�:0.0067 sure:0.0192 very:0.0043 that:0.0067 of:0.0073 but:0.0056)
		(�:0.0044 and:0.0031�:0.0127 sure:0.0292 very:0.0075 that:0.0132 of:0.0109 but:0.0150)
		(�:0.0050 the:0.0082�:0.0211 going:0.0400 little:0.0122 that:0.0266 of:0.0176 but:0.0374)
		( the:0.0087 the:0.0216�:0.0320 going:0.0535 little:0.0170 that:0.0522 for:0.0332 but:0.0679)
		( the:0.0153 the:0.0469�:0.0518 going:0.0654 little:0.0215 that:0.0889 for:0.0566 and:0.0913)
		( the:0.0250 and:0.0718�:0.0801 going:0.0713 little:0.0238 that:0.1040 for:0.0664 and:0.1260)
 and
19550: sample 0: Hello, I'm a language model,
		(�:0.0005prop:0.0009ets:0.0017kins:0.0004calling:0.0007 trem:0.0007obyl:0.0005prop:0.0005)
		(�:0.0008prop:0.0006ets:0.0025kins:0.0005itude:0.0005 trem:0.0006obyl:0.0008prop:0.0004)
		(�:0.0011 type:0.0005ets:0.0022 not:0.0006ys:0.0006
:0.0009 and:0.0007 however:0.0004)
		(�:0.0015 to:0.0007zz:0.0018 not:0.0021 particular:0.0009 and:0.0012 of:0.0017 and:0.0006)
		(�:0.0020 and:0.0011�:0.0029 going:0.0049 sure:0.0023 and:0.0019 of:0.0026 and:0.0012)
		(�:0.0025 the:0.0017�:0.0054 going:0.0120 sure:0.0050 of:0.0033 for:0.0041 but:0.0035)
		(�:0.0031 the:0.0032�:0.0096 sure:0.0275 bit:0.0051 of:0.0051 for:0.0066 but:0.0085)
		(�:0.0036 the:0.0070 have:0.0164 sure:0.0542 bit:0.0092 that:0.0089 for:0.0144 but:0.0247)
		( the:0.0064 the:0.0183 have:0.0292 sure:0.0698 bit:0.0147 that:0.0162,:0.0294 and:0.0547)
		( the:0.0127 the:0.0430 have:0.0449 going:0.0742 bit:0.0219 that:0.0293,:0.0544 and:0.0933)
		( the:0.0216 the:0.0708 am:0.0603 a:0.0894 bit:0.0286 teacher:0.0664,:0.0757 and:0.1299)
		( the:0.0342 and:0.0864�:0.0645 a:0.1147 bit:0.0322 teacher:0.1523,:0.0664 and:0.1533)
 and
20050: sample 0: Hello, I'm a language model,
		(�:0.0005 term:0.0004ets:0.0010uel:0.0004itude:0.0006obyl:0.0007obyl:0.0008obyl:0.0003)
		(�:0.0008
:0.0008ets:0.0010 familiar:0.0004itude:0.0008obyl:0.0008obyl:0.0011obyl:0.0003)
		(�:0.0011
:0.0010ys:0.0012 not:0.0012itude:0.0013 medium:0.0010 of:0.0017
:0.0003)
		(�:0.0015
:0.0011 am:0.0025 not:0.0026 new:0.0015
:0.0013 of:0.0063 I:0.0006)
		(�:0.0019 and:0.0017 am:0.0054 not:0.0045 sure:0.0033.:0.0016 of:0.0115 I:0.0012)
		(�:0.0025 and:0.0027 am:0.0098 going:0.0104 sure:0.0079.:0.0023 of:0.0173 but:0.0048)
		(�:0.0031 and:0.0039�:0.0175 going:0.0157 very:0.0110 that:0.0038 of:0.0254 but:0.0125)
		(�:0.0035 and:0.0071�:0.0297 going:0.0280 very:0.0208 that:0.0084 of:0.0476 but:0.0352)
		( the:0.0050 and:0.0166 am:0.0493 going:0.0479 very:0.0322 that:0.0197 of:0.0938 and:0.0845)
		( the:0.0099 and:0.0417 am:0.0771 going:0.0708 very:0.0413 that:0.0425 of:0.1455 and:0.1426)
		( the:0.0173 and:0.0786 am:0.0947 going:0.0845 bit:0.0444 that:0.0625 of:0.1777 and:0.1963)
		(,:0.0275 and:0.1006 am:0.0933 going:0.0918 bit:0.0552 teacher:0.0850.:0.1807 and:0.2197)
 and
20550: sample 0: Hello, I'm a language model,
		(�:0.0005 term:0.0003 jun:0.0007 jun:0.0004 jun:0.0005lessness:0.0004obyl:0.0004 jun:0.0004)
		(�:0.0007 reserv:0.0005ys:0.0007kins:0.0005 jun:0.0004lessness:0.0004obyl:0.0006 inco:0.0004)
		(�:0.0011
:0.0005ys:0.0009 and:0.0008ys:0.0006 Lo:0.0007 of:0.0010 inco:0.0004)
		(�:0.0014 and:0.0011ys:0.0010 going:0.0025pt:0.0009 Lo:0.0011 of:0.0035 and:0.0010)
		(�:0.0019 and:0.0022 was:0.0016 going:0.0081.:0.0011 of:0.0021 of:0.0068 and:0.0021)
		(�:0.0024 and:0.0034 was:0.0026 going:0.0197 sure:0.0018 of:0.0038 of:0.0110 and:0.0040)
		(�:0.0030 and:0.0052 have:0.0052 going:0.0337 sure:0.0024 of:0.0058 of:0.0192 and:0.0106)
		(�:0.0036 and:0.0096 have:0.0110 going:0.0505 little:0.0042 of:0.0080 of:0.0354 and:0.0315)
		( the:0.0056 and:0.0238 have:0.0242 going:0.0767 little:0.0083 manager:0.0149 of:0.0664 and:0.0811)
		( the:0.0111 and:0.0583 have:0.0454 going:0.1196 student:0.0153 professor:0.0278 of:0.1138 and:0.1377)
		( the:0.0195 and:0.1108 have:0.0620 going:0.1455 student:0.0233 professor:0.0586 of:0.1426 and:0.1807)
		(,:0.0309 and:0.1328 have:0.0640 going:0.1270 student:0.0286 professor:0.1016 of:0.1099 and:0.2129)
 and
21050: sample 0: Hello, I'm a language model,
		(�:0.0006 tongue:0.0005 jun:0.0008uel:0.0007 jun:0.0003 trem:0.0006 jun:0.0003 inspiration:0.0003)
		(�:0.0008
:0.0006ys:0.0007uel:0.0007itude:0.0005illion:0.0008ned:0.0004 Cunningham:0.0003)
		(�:0.0012 various:0.0008ys:0.0009als:0.0009itude:0.0007illion:0.0012.:0.0006ados:0.0005)
		(�:0.0016 various:0.0010 am:0.0022 going:0.0015.:0.0013illion:0.0018.:0.0023 I:0.0008)
		(�:0.0021 and:0.0016 am:0.0043 going:0.0048.:0.0029 and:0.0027.:0.0059 I:0.0016)
		(�:0.0027 and:0.0024 am:0.0082 going:0.0109 sure:0.0054 and:0.0033.:0.0093 I:0.0022)
		(�:0.0033 and:0.0038 am:0.0167 going:0.0261 sure:0.0094-:0.0051.:0.0145 and:0.0051)
		(�:0.0038 and:0.0074 am:0.0322 going:0.0464 little:0.0131-:0.0081.:0.0334 and:0.0234)
		( the:0.0064 the:0.0188 am:0.0576 going:0.0679 little:0.0269-:0.0155.:0.0781 and:0.0762)
		( the:0.0123 and:0.0459 am:0.0947 going:0.0898 little:0.0417-:0.0337.:0.1484 and:0.1309)
		(.:0.0214 and:0.0840 am:0.1299 going:0.1035 little:0.0579 teacher:0.1001.:0.1885 and:0.1631)
		(.:0.0337 and:0.1016 am:0.1309 going:0.0991 little:0.0603 teacher:0.2715,:0.1797 and:0.1924)
 and
21550: sample 0: Hello, I'm a language model,
		(�:0.0005 term:0.0006 jun:0.0009 jun:0.0007itude:0.0004less:0.0008 cos:0.0005blogspot:0.0003)
		(�:0.0008
:0.0005 jun:0.0007 familiar:0.0006itude:0.0007less:0.0009 cos:0.0004blogspot:0.0003)
		(�:0.0010
:0.0008ys:0.0006 familiar:0.0010itude:0.0009less:0.0014,:0.0012 coordination:0.0003)
		(�:0.0014
:0.0011 was:0.0011 going:0.0021 new:0.0013less:0.0020,:0.0030 which:0.0006)
		(�:0.0018 and:0.0015 was:0.0022 going:0.0051 new:0.0018 search:0.0020,:0.0050 which:0.0015)
		(�:0.0022 and:0.0020 was:0.0041 sure:0.0162 sure:0.0023 of:0.0028.:0.0081 which:0.0042)
		(�:0.0028 the:0.0032 was:0.0070 sure:0.0405 sure:0.0041 of:0.0046.:0.0112 which:0.0073)
		(�:0.0032 the:0.0075 was:0.0123 sure:0.0850 sure:0.0077 of:0.0080,:0.0228 and:0.0194)
		( the:0.0043 the:0.0194 would:0.0229 sure:0.1387 little:0.0192 that:0.0203,:0.0610 and:0.0674)
		(.:0.0088 the:0.0442 would:0.0327 sure:0.1699 little:0.0381 that:0.0491,:0.1235 and:0.1162)
		(,:0.0161 and:0.0747 think:0.0491 sure:0.1572 little:0.0532 that:0.0825,:0.1758 and:0.1455)
		(,:0.0287 and:0.0933 think:0.0581 sure:0.1279 little:0.0583 that:0.0767,:0.1689 and:0.1729)
 and
22050: sample 0: Hello, I'm a language model,
		(�:0.0005google:0.0005 jun:0.0009ory:0.0004 Reserved:0.0004keley:0.0006 need:0.0003prop:0.0003)
		(�:0.0007
:0.0005 jun:0.0006 familiar:0.0004itude:0.0004bent:0.0008cer:0.0006 Seventh:0.0004)
		(�:0.0010
:0.0006ci:0.0007 not:0.0012 mention:0.0006
:0.0008
:0.0011
:0.0004)
		(�:0.0013
:0.0007
:0.0012 not:0.0049 mention:0.0007
:0.0016
:0.0027
:0.0006)
		(�:0.0017 the:0.0010 have:0.0021 not:0.0106.:0.0010.:0.0019.:0.0053�:0.0010)
		(�:0.0022 the:0.0015�:0.0042 going:0.0198 sure:0.0032 of:0.0033 of:0.0098�:0.0020)
		(�:0.0026 the:0.0027�:0.0070 going:0.0306 little:0.0062 of:0.0067 of:0.0179 but:0.0041)
		(�:0.0031 the:0.0063 have:0.0125 going:0.0447 little:0.0128 of:0.0132 of:0.0352 but:0.0123)
		( the:0.0053 the:0.0166 have:0.0254 going:0.0635 little:0.0260 of:0.0250 of:0.0718 and:0.0391)
		( the:0.0103 the:0.0383 have:0.0518 going:0.0825 little:0.0366 of:0.0422 of:0.1279 and:0.0952)
		(,:0.0192 and:0.0664 have:0.0796 going:0.0815 little:0.0400-:0.0684 of:0.1553 and:0.1396)
		(,:0.0332 and:0.0918 have:0.0845 a:0.0947 great:0.0369-:0.0898 of:0.1245 and:0.1582)
 and
22550: sample 0: Hello, I'm a language model,
		(�:0.0005 tongue:0.0006 jun:0.0006rait:0.0005enezuel:0.0005quez:0.0006 need:0.0004 inspiration:0.0003)
		(�:0.0008
:0.0005ets:0.0006 familiar:0.0005itude:0.0005quez:0.0007cer:0.0004liner:0.0004)
		(�:0.0011 to:0.0005ck:0.0007 familiar:0.0011ces:0.0008less:0.0012 of:0.0012
:0.0004)
		(�:0.0014 to:0.0007ck:0.0011 familiar:0.0020ces:0.0011
:0.0022,:0.0030
:0.0007)
		(�:0.0019 the:0.0013�:0.0018 sure:0.0049 little:0.0010
:0.0027,:0.0050 and:0.0009)
		(�:0.0024 the:0.0020�:0.0042 sure:0.0205 sure:0.0041 of:0.0046,:0.0075 and:0.0020)
		(�:0.0029 the:0.0034�:0.0078 sure:0.0315 little:0.0051 of:0.0069,:0.0109 and:0.0061)
		(�:0.0035 the:0.0077�:0.0141 sure:0.0466 little:0.0099-:0.0108,:0.0227 and:0.0226)
		( the:0.0053 the:0.0187�:0.0229 sure:0.0508 little:0.0166-:0.0256,:0.0486 and:0.0874)
		( the:0.0104 the:0.0396�:0.0354 sure:0.0532 little:0.0283-:0.0586,:0.0898 and:0.1943)
		(,:0.0188 and:0.0693�:0.0522 not:0.0786 little:0.0427-:0.1133 that:0.1367 and:0.2598)
		(,:0.0322 and:0.0952�:0.0625 not:0.0938 little:0.0454-:0.1260 that:0.1289 and:0.2734)
 and
23050: sample 0: Hello, I'm a language model,
		(�:0.0006 term:0.0004 jun:0.0006ly:0.0004 href:0.0004keley:0.0005pei:0.0003tex:0.0003)
		(�:0.0008
:0.0003 jun:0.0006ly:0.0006itude:0.0006cled:0.0005cer:0.0003liner:0.0004)
		(�:0.0011 inter:0.0005xt:0.0008als:0.0009itude:0.0007
:0.0009,:0.0012 coordination:0.0004)
		(�:0.0015 and:0.0007xt:0.0009als:0.0011itude:0.0007
:0.0018.:0.0023 coordination:0.0006)
		(�:0.0019 and:0.0013 am:0.0014 going:0.0023 specific:0.0009.:0.0025.:0.0042 and:0.0007)
		(�:0.0025 and:0.0019 am:0.0019 going:0.0064 new:0.0010.:0.0033.:0.0055 and:0.0012)
		(�:0.0031 and:0.0031 was:0.0029 going:0.0136 sure:0.0022.:0.0043.:0.0090 and:0.0028)
		(�:0.0036 and:0.0053 was:0.0055 going:0.0271 little:0.0053 that:0.0095.:0.0189 and:0.0114)
		( the:0.0071 the:0.0146 have:0.0125 going:0.0439 little:0.0120 that:0.0250,:0.0598 and:0.0420)
		( the:0.0136 the:0.0410 have:0.0276 going:0.0679 little:0.0243 that:0.0588,:0.1299 and:0.0947)
		( the:0.0234 the:0.0649�:0.0503 going:0.0850 little:0.0427 that:0.0879,:0.1631 and:0.1226)
		(,:0.0366 and:0.0796�:0.0698 a:0.0957 little:0.0522 that:0.0703.:0.1562 and:0.1318)
 and
23550: sample 0: Hello, I'm a language model,
		(�:0.0004 dopamine:0.0007zzo:0.0004uel:0.0003nown:0.0004keley:0.0007 and:0.0005rals:0.0003)
		(�:0.0006
:0.0005adows:0.0005
:0.0004itude:0.0006by:0.0006
:0.0006rals:0.0006)
		(�:0.0009 type:0.0007onic:0.0009 not:0.0011itude:0.0007
:0.0011
:0.0020rals:0.0003)
		(�:0.0012 to:0.0008onic:0.0016 not:0.0023 new:0.0008
:0.0017.:0.0038 esp:0.0005)
		(�:0.0015 and:0.0014 am:0.0028 going:0.0038 new:0.0014.:0.0021.:0.0071 which:0.0009)
		(�:0.0020 and:0.0016 am:0.0043 going:0.0083 new:0.0018.:0.0028.:0.0104 which:0.0026)
		(�:0.0025 and:0.0027 have:0.0063 going:0.0136 very:0.0025 that:0.0038.:0.0127 which:0.0054)
		(�:0.0029 and:0.0055 have:0.0123 going:0.0283 very:0.0067 that:0.0099.:0.0226 but:0.0183)
		( the:0.0060 and:0.0135 have:0.0219 going:0.0479 very:0.0157 that:0.0271 that:0.0525 but:0.0576)
		(.:0.0115 and:0.0364 have:0.0393 going:0.0781 very:0.0292 that:0.0664 that:0.1074 but:0.1069)
		(,:0.0209 and:0.0776 am:0.0603 going:0.1094 very:0.0410 that:0.1216 for:0.1504 but:0.1338)
		(,:0.0354 and:0.1045 am:0.0806 sure:0.1260 great:0.0413 that:0.1396 for:0.1865 but:0.1445)
 but
