1: sample 0: Hello, I'm a language model,
------
		( grades:0.0002,:0.0003Minimum:0.0001'm:0.0002andal:0.0002 Work:0.0002 model:0.0002,:0.0005)
		( grades:0.0002Wonder:0.0002 Pir:0.0002True:0.0002andal:0.0002 Work:0.0002883:0.0001 processing:0.0002)
		( grades:0.0002 Christian:0.0002 Pir:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 processing:0.0002)
		(acked:0.0002 Christian:0.0002 Pir:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Nigeria:0.0002 sun:0.0002 debris:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002 tightly:0.0001Donnell:0.0002 Nigeria:0.0002 sun:0.0002 debris:0.0002)
		(acked:0.0002 Christian:0.0002 aggression:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002)
		( closer:0.0002 Christian:0.0002 aggression:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002)
		( closer:0.0002 Christian:0.0002Index:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002)
		( closer:0.0002 Christian:0.0002Index:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002dates:0.0002)
		( closer:0.0002 Christian:0.0002Index:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002)
 bearded
------
		(,:0.0003Minimum:0.0001'm:0.0002andal:0.0002 Work:0.0002 model:0.0002,:0.0005 bearded:0.0003)
		(Wonder:0.0002 Pir:0.0002True:0.0002andal:0.0002 Work:0.0002883:0.0001 processing:0.0002 bearded:0.0002)
		( Christian:0.0002 Pir:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 processing:0.0002 bearded:0.0002)
		( Christian:0.0002 Pir:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Work:0.0002 sun:0.0002 Planetary:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002True:0.0002Donnell:0.0002 Nigeria:0.0002 sun:0.0002 debris:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002 tightly:0.0001Donnell:0.0002 Nigeria:0.0002 sun:0.0002 debris:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002dates:0.0002)
		( Christian:0.0002 aggression:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002dates:0.0002)
		( Christian:0.0002Index:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002dates:0.0002)
		( Christian:0.0002Index:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002dates:0.0002dates:0.0002)
		( Christian:0.0002Index:0.0002 tightly:0.0002Index:0.0002 Nigeria:0.0002 sun:0.0002 bearded:0.0002dates:0.0002)
datesdatesdates231 suing231231 Quartreal231231
50: sample 0: Hello, I'm a language model,
------
		( a:0.0005,:0.0530 I:0.0175,:0.0090 a:0.0781 and:0.0133 and:0.0165,:0.0630)
		( a:0.0013,:0.0393 and:0.0193,:0.0160 a:0.0615 and:0.0194 and:0.0267,:0.0581)
		( a:0.0025,:0.0342 and:0.0229,:0.0201 a:0.0510,:0.0249 and:0.0322,:0.0542)
		( a:0.0039,:0.0317 and:0.0249,:0.0232 a:0.0464,:0.0293 and:0.0347,:0.0508)
		( a:0.0053,:0.0304 and:0.0262,:0.0250 a:0.0422,:0.0327 and:0.0354,:0.0493)
		( a:0.0065,:0.0292 and:0.0269,:0.0271 a:0.0396,:0.0344 and:0.0361,:0.0479)
		( a:0.0079,:0.0289,:0.0267,:0.0286 a:0.0383,:0.0352 and:0.0359,:0.0466)
		( a:0.0089 the:0.0305,:0.0275,:0.0293 a:0.0359,:0.0361,:0.0347,:0.0454)
		( a:0.0098 the:0.0312,:0.0282,:0.0300 a:0.0349,:0.0374,:0.0344,:0.0442)
		( the:0.0114 the:0.0322,:0.0291,:0.0308 a:0.0337,:0.0371,:0.0356,:0.0442)
		( the:0.0124 the:0.0330,:0.0299,:0.0306 a:0.0327,:0.0383,:0.0356,:0.0430)
		( the:0.0139 the:0.0339,:0.0298,:0.0315 a:0.0317,:0.0383,:0.0356,:0.0432)
		( the:0.0124 the:0.0330,:0.0298,:0.0307 a:0.0327,:0.0362,:0.0356,:0.0581)
,
------
		(,:0.0530 I:0.0175,:0.0090 a:0.0781 and:0.0133 and:0.0165,:0.0630,:0.0767)
		(,:0.0393 and:0.0193,:0.0160 a:0.0615 and:0.0194 and:0.0267,:0.0581,:0.0635)
		(,:0.0342 and:0.0229,:0.0201 a:0.0510,:0.0249 and:0.0322,:0.0542,:0.0579)
		(,:0.0317 and:0.0249,:0.0232 a:0.0464,:0.0293 and:0.0347,:0.0508,:0.0530)
		(,:0.0304 and:0.0262,:0.0250 a:0.0422,:0.0327 and:0.0354,:0.0493,:0.0500)
		(,:0.0292 and:0.0269,:0.0271 a:0.0396,:0.0344 and:0.0361,:0.0479,:0.0486)
		(,:0.0289,:0.0267,:0.0286 a:0.0383,:0.0352 and:0.0359,:0.0466,:0.0459)
		( the:0.0305,:0.0275,:0.0293 a:0.0359,:0.0361,:0.0347,:0.0454,:0.0449)
		( the:0.0312,:0.0282,:0.0300 a:0.0349,:0.0374,:0.0344,:0.0442,:0.0449)
		( the:0.0322,:0.0291,:0.0308 a:0.0337,:0.0371,:0.0356,:0.0442,:0.0437)
		( the:0.0330,:0.0299,:0.0306 a:0.0327,:0.0383,:0.0356,:0.0430,:0.0425)
		( the:0.0339,:0.0298,:0.0315 a:0.0317,:0.0383,:0.0356,:0.0432,:0.0427)
		( the:0.0330,:0.0298,:0.0307 a:0.0327,:0.0382 and:0.0346,:0.0430,:0.0425)
,,,,,,,,,,,
200: sample 0: Hello, I'm a language model,
------
		(-:0.0079,:0.1055 I:0.0996,:0.0211 a:0.0835,:0.0659,:0.0708 and:0.0732)
		(-:0.0126,:0.0664 I:0.0452 the:0.0271 a:0.0454,:0.0791,:0.0820 and:0.0815)
		(-:0.0150,:0.0535 I:0.0271 the:0.0334 a:0.0327,:0.0845,:0.0879 and:0.0850)
		(-:0.0162 the:0.0505,:0.0280 the:0.0366 a:0.0260,:0.0854,:0.0903 and:0.0869)
		(-:0.0167 the:0.0503,:0.0295 the:0.0381 a:0.0215,:0.0859,:0.0908 and:0.0854)
		( the:0.0187 the:0.0510,:0.0310 the:0.0383 a:0.0187,:0.0864,:0.0918 and:0.0835)
		( the:0.0197 the:0.0500,:0.0315 the:0.0378 a:0.0166,:0.0845.:0.0933 and:0.0786)
		( the:0.0205 the:0.0491,:0.0320 the:0.0376 a:0.0147,:0.0845.:0.0918 and:0.0752)
		( the:0.0214 the:0.0481,:0.0325 the:0.0359.:0.0134,:0.0820,:0.0874 and:0.0703)
		( the:0.0215 the:0.0469,:0.0327 the:0.0352.:0.0130,:0.0820,:0.0859 and:0.0674)
		( the:0.0216 the:0.0457,:0.0332 the:0.0344.:0.0126,:0.0796,:0.0840 and:0.0625)
		( the:0.0225 the:0.0447,:0.0325 the:0.0337,:0.0121,:0.0771,:0.0820 and:0.0593)
		( the:0.0217 the:0.0492 I:0.0271 the:0.0345.:0.0126,:0.0822,:0.0822 and:0.0624)
 and
------
		(,:0.1055 I:0.0996,:0.0211 a:0.0835,:0.0659,:0.0708 and:0.0732 and:0.0591)
		(,:0.0664 I:0.0452 the:0.0271 a:0.0454,:0.0791,:0.0820 and:0.0815 the:0.0518)
		(,:0.0535 I:0.0271 the:0.0334 a:0.0327,:0.0845,:0.0879 and:0.0850 the:0.0559)
		( the:0.0505,:0.0280 the:0.0366 a:0.0260,:0.0854,:0.0903 and:0.0869 the:0.0583)
		( the:0.0503,:0.0295 the:0.0381 a:0.0215,:0.0859,:0.0908 and:0.0854 the:0.0601)
		( the:0.0510,:0.0310 the:0.0383 a:0.0187,:0.0864,:0.0918 and:0.0835 the:0.0596)
		( the:0.0500,:0.0315 the:0.0378 a:0.0166,:0.0845.:0.0933 and:0.0786 the:0.0586)
		( the:0.0491,:0.0320 the:0.0376 a:0.0147,:0.0845.:0.0918 and:0.0752 the:0.0557)
		( the:0.0481,:0.0325 the:0.0359.:0.0134,:0.0820,:0.0874 and:0.0703 the:0.0544)
		( the:0.0469,:0.0327 the:0.0352.:0.0130,:0.0820,:0.0859 and:0.0674 the:0.0515)
		( the:0.0457,:0.0332 the:0.0344.:0.0126,:0.0796,:0.0840 and:0.0625 the:0.0503)
		( the:0.0447,:0.0325 the:0.0337,:0.0121,:0.0771,:0.0820 and:0.0593 the:0.0488)
		( the:0.0458,:0.0331 the:0.0382.:0.0126,:0.0791,:0.0367 and:0.0833 the:0.0503)
 the.
-.
-.
-.
350: sample 0: Hello, I'm a language model,
------
		(,:0.0068,:0.1279 I:0.0830,:0.0210 a:0.0820,:0.1055,:0.1104,:0.0698)
		(,:0.0142,:0.0889 I:0.0388,:0.0315 a:0.0420,:0.1216,:0.1162 and:0.0598)
		(,:0.0209,:0.0732,:0.0356,:0.0374 a:0.0303,:0.1250,:0.1162 and:0.0640)
		(,:0.0255,:0.0654,:0.0393,:0.0405 a:0.0248,:0.1221,:0.1133 and:0.0645)
		(,:0.0282,:0.0613,:0.0413,:0.0413 a:0.0211,:0.1172 of:0.1133 and:0.0635)
		(,:0.0309,:0.0566,:0.0432,:0.0413 a:0.0187,:0.1123 of:0.1099 and:0.0615)
		(,:0.0315,:0.0535,:0.0435,:0.0410 a:0.0170,:0.1079 of:0.1069 and:0.0576)
		(,:0.0317,:0.0505,:0.0427,:0.0393 a:0.0156,:0.1030 of:0.1006 and:0.0540)
		(,:0.0320,:0.0476,:0.0430,:0.0386.:0.0150,:0.1011 of:0.0967 the:0.0515)
		(,:0.0312,:0.0461,:0.0420,:0.0378.:0.0150,:0.0962.:0.0928 the:0.0491)
		(,:0.0305,:0.0432,:0.0422,:0.0359.:0.0148.:0.0942.:0.0918 the:0.0481)
		(,:0.0306,:0.0417,:0.0413,:0.0352.:0.0144.:0.0918.:0.0874 the:0.0469)
		(,:0.0306,:0.1279,:0.0422,:0.0360.:0.0148 language:0.1661,:0.0836 the:0.0515)
 the
------
		(,:0.1279 I:0.0830,:0.0210 a:0.0820,:0.1055,:0.1104,:0.0698 the:0.0454)
		(,:0.0889 I:0.0388,:0.0315 a:0.0420,:0.1216,:0.1162 and:0.0598 the:0.0231)
		(,:0.0732,:0.0356,:0.0374 a:0.0303,:0.1250,:0.1162 and:0.0640 the:0.0165)
		(,:0.0654,:0.0393,:0.0405 a:0.0248,:0.1221,:0.1133 and:0.0645 the:0.0139)
		(,:0.0613,:0.0413,:0.0413 a:0.0211,:0.1172 of:0.1133 and:0.0635 the:0.0123)
		(,:0.0566,:0.0432,:0.0413 a:0.0187,:0.1123 of:0.1099 and:0.0615 the:0.0111)
		(,:0.0535,:0.0435,:0.0410 a:0.0170,:0.1079 of:0.1069 and:0.0576 the:0.0103)
		(,:0.0505,:0.0427,:0.0393 a:0.0156,:0.1030 of:0.1006 and:0.0540.:0.0099)
		(,:0.0476,:0.0430,:0.0386.:0.0150,:0.1011 of:0.0967 the:0.0515.:0.0105)
		(,:0.0461,:0.0420,:0.0378.:0.0150,:0.0962.:0.0928 the:0.0491.:0.0110)
		(,:0.0432,:0.0422,:0.0359.:0.0148.:0.0942.:0.0918 the:0.0481.:0.0112)
		(,:0.0417,:0.0413,:0.0352.:0.0144.:0.0918.:0.0874 the:0.0469.:0.0115)
		(,:0.3869,:0.0422,:0.0360.:0.0148,:0.1214,:0.0836 the:0.0482.:0.0112)
.
The first.
-19.
-
500: sample 0: Hello, I'm a language model,
------
		(,:0.0051,:0.0962 I:0.1279 not:0.0247 a:0.0757,:0.0923,:0.0864,:0.0566)
		(,:0.0114,:0.0708 I:0.0630 not:0.0254 a:0.0374,:0.1040,:0.0933 and:0.0513)
		(,:0.0172,:0.0603 I:0.0417,:0.0305 a:0.0269,:0.1108,:0.0967 and:0.0554)
		(,:0.0217,:0.0552,:0.0359,:0.0359 a:0.0227,:0.1133,:0.0991 and:0.0583)
		(,:0.0247,:0.0520,:0.0396,:0.0396 a:0.0203,:0.1104,:0.1001 and:0.0598)
		(,:0.0267,:0.0491,:0.0403,:0.0410 a:0.0187.:0.1172.:0.1040 and:0.0601)
		(,:0.0273,:0.0466,:0.0422,:0.0410 a:0.0172.:0.1235.:0.1040 and:0.0581)
		(,:0.0277,:0.0439,:0.0425,:0.0417 a:0.0160.:0.1260.:0.1060 and:0.0557)
		(,:0.0275,:0.0420,:0.0415,:0.0410 a:0.0151.:0.1279.:0.1055 and:0.0530)
		(,:0.0271,:0.0405,:0.0415,:0.0400 new:0.0149.:0.1289.:0.1035 and:0.0500)
		(,:0.0266,:0.0383,:0.0403,:0.0391 new:0.0149.:0.1270.:0.1016 and:0.0474)
		(,:0.0258,:0.0369,:0.0403,:0.0393 new:0.0146.:0.1240.:0.0991 and:0.0439)
		(,:0.0266,:0.0384,:0.0415,:0.0395 new:0.0149.:0.1268,:0.0723 and:0.0585)
 and
------
		(,:0.0962 I:0.1279 not:0.0247 a:0.0757,:0.0923,:0.0864,:0.0566 the:0.0515)
		(,:0.0708 I:0.0630 not:0.0254 a:0.0374,:0.1040,:0.0933 and:0.0513 the:0.0503)
		(,:0.0603 I:0.0417,:0.0305 a:0.0269,:0.1108,:0.0967 and:0.0554 the:0.0520)
		(,:0.0552,:0.0359,:0.0359 a:0.0227,:0.1133,:0.0991 and:0.0583 the:0.0544)
		(,:0.0520,:0.0396,:0.0396 a:0.0203,:0.1104,:0.1001 and:0.0598 the:0.0542)
		(,:0.0491,:0.0403,:0.0410 a:0.0187.:0.1172.:0.1040 and:0.0601 the:0.0547)
		(,:0.0466,:0.0422,:0.0410 a:0.0172.:0.1235.:0.1040 and:0.0581 the:0.0535)
		(,:0.0439,:0.0425,:0.0417 a:0.0160.:0.1260.:0.1060 and:0.0557 the:0.0535)
		(,:0.0420,:0.0415,:0.0410 a:0.0151.:0.1279.:0.1055 and:0.0530 the:0.0518)
		(,:0.0405,:0.0415,:0.0400 new:0.0149.:0.1289.:0.1035 and:0.0500 the:0.0500)
		(,:0.0383,:0.0403,:0.0391 new:0.0149.:0.1270.:0.1016 and:0.0474 the:0.0483)
		(,:0.0369,:0.0403,:0.0393 new:0.0146.:0.1240.:0.0991 and:0.0439 the:0.0466)
		(,:0.0384,:0.0404,:0.0391 new:0.0149.:0.1257.:0.1015 and:0.0473 the:0.0482)
 the same time, and the same same time, and
650: sample 0: Hello, I'm a language model,
------
		(,:0.0063,:0.0952 I:0.1699 not:0.0253 a:0.0806,:0.0854,:0.0815,:0.0540)
		(,:0.0136,:0.0723 I:0.0786 not:0.0248 a:0.0408,:0.1006,:0.0967 and:0.0498)
		(,:0.0209,:0.0654 I:0.0496,:0.0311 a:0.0304,:0.1118,:0.1079 and:0.0542)
		(,:0.0270,:0.0610,:0.0410,:0.0374 a:0.0261,:0.1201,:0.1143 and:0.0591)
		(,:0.0317,:0.0581,:0.0452,:0.0413 a:0.0232,:0.1250,:0.1206 and:0.0630)
		(,:0.0347,:0.0559,:0.0488,:0.0439 a:0.0215,:0.1289,:0.1221 and:0.0654)
		(,:0.0371,:0.0544,:0.0508,:0.0461 a:0.0200,:0.1279,:0.1260 and:0.0659)
		(,:0.0381,:0.0518,:0.0522,:0.0471 a:0.0189,:0.1299,:0.1250 and:0.0659)
		(,:0.0386,:0.0505,:0.0525,:0.0471 a:0.0177,:0.1289,:0.1245 and:0.0654)
		(,:0.0391,:0.0491,:0.0527,:0.0469 a:0.0166,:0.1260,:0.1226 and:0.0635)
		(,:0.0386,:0.0474,:0.0520,:0.0464 a:0.0156,:0.1279,:0.1235 and:0.0615)
		(,:0.0381,:0.0457,:0.0510,:0.0459 a:0.0148,:0.1245,:0.1206 and:0.0593)
		(,:0.0387,:0.0610 I:0.1698,:0.0439 a:0.0407,:0.1287,:0.1223 and:0.0615)
 and
------
		(,:0.0952 I:0.1699 not:0.0253 a:0.0806,:0.0854,:0.0815,:0.0540 the:0.0491)
		(,:0.0723 I:0.0786 not:0.0248 a:0.0408,:0.1006,:0.0967 and:0.0498 the:0.0486)
		(,:0.0654 I:0.0496,:0.0311 a:0.0304,:0.1118,:0.1079 and:0.0542 the:0.0518)
		(,:0.0610,:0.0410,:0.0374 a:0.0261,:0.1201,:0.1143 and:0.0591 the:0.0540)
		(,:0.0581,:0.0452,:0.0413 a:0.0232,:0.1250,:0.1206 and:0.0630 the:0.0554)
		(,:0.0559,:0.0488,:0.0439 a:0.0215,:0.1289,:0.1221 and:0.0654 the:0.0569)
		(,:0.0544,:0.0508,:0.0461 a:0.0200,:0.1279,:0.1260 and:0.0659 the:0.0569)
		(,:0.0518,:0.0522,:0.0471 a:0.0189,:0.1299,:0.1250 and:0.0659 the:0.0566)
		(,:0.0505,:0.0525,:0.0471 a:0.0177,:0.1289,:0.1245 and:0.0654 the:0.0552)
		(,:0.0491,:0.0527,:0.0469 a:0.0166,:0.1260,:0.1226 and:0.0635 the:0.0540)
		(,:0.0474,:0.0520,:0.0464 a:0.0156,:0.1279,:0.1235 and:0.0615 the:0.0525)
		(,:0.0457,:0.0510,:0.0459 a:0.0148,:0.1245,:0.1206 and:0.0593 the:0.0510)
		(,:0.0474,:0.0519,:0.0465 a:0.0157,:0.1275,:0.1234 and:0.0543 the:0.0525)
 the same time, and the same time, and and
800: sample 0: Hello, I'm a language model,
------
		( the:0.0063,:0.0972 I:0.2344 not:0.0293 a:0.0908,:0.0898,:0.0864,:0.0603)
		(,:0.0127,:0.0767 I:0.1172 not:0.0332 a:0.0464,:0.1104,:0.1113,:0.0437)
		(,:0.0194,:0.0703 I:0.0757 not:0.0344 a:0.0344,:0.1289,:0.1289 and:0.0471)
		(,:0.0255,:0.0669 I:0.0569 not:0.0344 a:0.0294,:0.1436,:0.1396 and:0.0520)
		(,:0.0303,:0.0645,:0.0481,:0.0356 a:0.0260,:0.1504,:0.1465 and:0.0564)
		(,:0.0337,:0.0625,:0.0522,:0.0386 a:0.0239,:0.1533,:0.1475 and:0.0596)
		(,:0.0364,:0.0603,:0.0552,:0.0405 a:0.0216,:0.1572,:0.1504 and:0.0618)
		(,:0.0381,:0.0586,:0.0566,:0.0422 a:0.0200,:0.1553,:0.1494 and:0.0625)
		(,:0.0396,:0.0571,:0.0566,:0.0432 a:0.0186,:0.1562,:0.1465 and:0.0630)
		(,:0.0400,:0.0554,:0.0566,:0.0437 a:0.0173,:0.1494,:0.1436 and:0.0620)
		(,:0.0403,:0.0535,:0.0564,:0.0437 the:0.0164,:0.1465,:0.1406 and:0.0608)
		(,:0.0403,:0.0518,:0.0559,:0.0442 the:0.0156,:0.1426,:0.1406 and:0.0596)
		(,:0.0402,:0.0536,:0.0481,:0.0437 a:0.0463,:0.1536,:0.0862 and:0.0608)
 and
------
		(,:0.0972 I:0.2344 not:0.0293 a:0.0908,:0.0898,:0.0864,:0.0603 the:0.0488)
		(,:0.0767 I:0.1172 not:0.0332 a:0.0464,:0.1104,:0.1113,:0.0437 the:0.0520)
		(,:0.0703 I:0.0757 not:0.0344 a:0.0344,:0.1289,:0.1289 and:0.0471 the:0.0574)
		(,:0.0669 I:0.0569 not:0.0344 a:0.0294,:0.1436,:0.1396 and:0.0520 the:0.0625)
		(,:0.0645,:0.0481,:0.0356 a:0.0260,:0.1504,:0.1465 and:0.0564 the:0.0664)
		(,:0.0625,:0.0522,:0.0386 a:0.0239,:0.1533,:0.1475 and:0.0596 the:0.0684)
		(,:0.0603,:0.0552,:0.0405 a:0.0216,:0.1572,:0.1504 and:0.0618 the:0.0698)
		(,:0.0586,:0.0566,:0.0422 a:0.0200,:0.1553,:0.1494 and:0.0625 the:0.0708)
		(,:0.0571,:0.0566,:0.0432 a:0.0186,:0.1562,:0.1465 and:0.0630 the:0.0693)
		(,:0.0554,:0.0566,:0.0437 a:0.0173,:0.1494,:0.1436 and:0.0620 the:0.0688)
		(,:0.0535,:0.0564,:0.0437 the:0.0164,:0.1465,:0.1406 and:0.0608 the:0.0669)
		(,:0.0518,:0.0559,:0.0442 the:0.0156,:0.1426,:0.1406 and:0.0596 the:0.0654)
		(,:0.0972,:0.0551,:0.0437 the:0.0163,:0.1435,:0.1468 and:0.0608 the:0.0670)
 the the the the the the the the the the the
950: sample 0: Hello, I'm a language model,
------
		(,:0.0055,:0.0801 I:0.1953 not:0.0332 a:0.0840 language:0.0947,:0.0864,:0.0640)
		(,:0.0113,:0.0640 I:0.0933 not:0.0422 a:0.0449,:0.0874,:0.1074 and:0.0493)
		(,:0.0173,:0.0591 I:0.0625 not:0.0476 a:0.0342,:0.0981,:0.1191 and:0.0542)
		(,:0.0229,:0.0566 I:0.0481 not:0.0488 a:0.0295,:0.1064,:0.1270 and:0.0603)
		(,:0.0272,:0.0544 I:0.0398 not:0.0481 a:0.0266.:0.1118,:0.1309 and:0.0659)
		(,:0.0308 and:0.0540,:0.0415 not:0.0457 a:0.0245.:0.1240,:0.1318 and:0.0693)
		(,:0.0337 and:0.0554,:0.0432 not:0.0425 a:0.0227.:0.1318,:0.1299 and:0.0718)
		(,:0.0354 and:0.0562,:0.0437 not:0.0398 a:0.0209.:0.1357,:0.1289 and:0.0728)
		(,:0.0369 and:0.0562,:0.0439 not:0.0364 a:0.0194.:0.1367,:0.1270 and:0.0737)
		(,:0.0376 and:0.0559,:0.0437 not:0.0337 a:0.0179.:0.1357,:0.1245 and:0.0723)
		(,:0.0378 and:0.0554,:0.0427 not:0.0311 a:0.0166.:0.1338,:0.1216 and:0.0703)
		(,:0.0378 and:0.0537,:0.0417 the:0.0287 a:0.0154.:0.1299,:0.1182 and:0.0674)
		(,:0.0336 and:0.0538,:0.0439 not:0.0425 a:0.0840.:0.1354,:0.1318 and:0.0704)
 and
------
		(,:0.0801 I:0.1953 not:0.0332 a:0.0840 language:0.0947,:0.0864,:0.0640 the:0.0398)
		(,:0.0640 I:0.0933 not:0.0422 a:0.0449,:0.0874,:0.1074 and:0.0493 the:0.0454)
		(,:0.0591 I:0.0625 not:0.0476 a:0.0342,:0.0981,:0.1191 and:0.0542 the:0.0535)
		(,:0.0566 I:0.0481 not:0.0488 a:0.0295,:0.1064,:0.1270 and:0.0603 the:0.0596)
		(,:0.0544 I:0.0398 not:0.0481 a:0.0266.:0.1118,:0.1309 and:0.0659 the:0.0640)
		( and:0.0540,:0.0415 not:0.0457 a:0.0245.:0.1240,:0.1318 and:0.0693 the:0.0674)
		( and:0.0554,:0.0432 not:0.0425 a:0.0227.:0.1318,:0.1299 and:0.0718 the:0.0693)
		( and:0.0562,:0.0437 not:0.0398 a:0.0209.:0.1357,:0.1289 and:0.0728 the:0.0698)
		( and:0.0562,:0.0439 not:0.0364 a:0.0194.:0.1367,:0.1270 and:0.0737 the:0.0698)
		( and:0.0559,:0.0437 not:0.0337 a:0.0179.:0.1357,:0.1245 and:0.0723 the:0.0684)
		( and:0.0554,:0.0427 not:0.0311 a:0.0166.:0.1338,:0.1216 and:0.0703 the:0.0684)
		( and:0.0537,:0.0417 the:0.0287 a:0.0154.:0.1299,:0.1182 and:0.0674 the:0.0669)
		(,:0.2548,:0.0431 not:0.0311 a:0.0166.:0.1238,:0.1318 and:0.0704 the:0.0681)
 the
The first, and the the the the the
1100: sample 0: Hello, I'm a language model,
------
		( you:0.0068,:0.0713 I:0.2178 not:0.0299 a:0.0942 language:0.0854,:0.0767,:0.0693)
		(,:0.0114,:0.0586 I:0.1084 not:0.0435 a:0.0515,:0.0830,:0.1006 and:0.0464)
		(,:0.0175,:0.0554 I:0.0752 not:0.0542 a:0.0405,:0.0923,:0.1152 and:0.0483)
		(,:0.0234,:0.0537 I:0.0613 not:0.0593 a:0.0356,:0.1006,:0.1221 and:0.0520)
		(,:0.0282,:0.0530 I:0.0530 not:0.0610 a:0.0330.:0.1094,:0.1250 and:0.0559)
		(,:0.0322,:0.0518 I:0.0471 not:0.0593 a:0.0304.:0.1172,:0.1270 and:0.0593)
		(,:0.0354 and:0.0540,:0.0481 not:0.0569 a:0.0286.:0.1230,:0.1270 and:0.0618)
		(,:0.0376 and:0.0557,:0.0486 not:0.0540 a:0.0265.:0.1279,:0.1260 and:0.0630)
		(,:0.0396 and:0.0566,:0.0496 not:0.0503 a:0.0247.:0.1279,:0.1226 and:0.0635)
		(,:0.0403 and:0.0564,:0.0493 not:0.0474 a:0.0229.:0.1270,:0.1201 and:0.0635)
		(,:0.0410 and:0.0562,:0.0496 not:0.0437 a:0.0212.:0.1270,:0.1191 and:0.0623)
		(,:0.0410 and:0.0554,:0.0483 not:0.0410 a:0.0198.:0.1250,:0.1162 and:0.0613)
		(,:0.0410,:0.0585,:0.0496 not:0.0437 a:0.0329.:0.1269,:0.1259 and:0.0623)
 and
------
		(,:0.0713 I:0.2178 not:0.0299 a:0.0942 language:0.0854,:0.0767,:0.0693 and:0.0330)
		(,:0.0586 I:0.1084 not:0.0435 a:0.0515,:0.0830,:0.1006 and:0.0464 the:0.0383)
		(,:0.0554 I:0.0752 not:0.0542 a:0.0405,:0.0923,:0.1152 and:0.0483 the:0.0464)
		(,:0.0537 I:0.0613 not:0.0593 a:0.0356,:0.1006,:0.1221 and:0.0520 the:0.0535)
		(,:0.0530 I:0.0530 not:0.0610 a:0.0330.:0.1094,:0.1250 and:0.0559 the:0.0591)
		(,:0.0518 I:0.0471 not:0.0593 a:0.0304.:0.1172,:0.1270 and:0.0593 the:0.0635)
		( and:0.0540,:0.0481 not:0.0569 a:0.0286.:0.1230,:0.1270 and:0.0618 the:0.0664)
		( and:0.0557,:0.0486 not:0.0540 a:0.0265.:0.1279,:0.1260 and:0.0630 the:0.0684)
		( and:0.0566,:0.0496 not:0.0503 a:0.0247.:0.1279,:0.1226 and:0.0635 the:0.0693)
		( and:0.0564,:0.0493 not:0.0474 a:0.0229.:0.1270,:0.1201 and:0.0635 the:0.0703)
		( and:0.0562,:0.0496 not:0.0437 a:0.0212.:0.1270,:0.1191 and:0.0623 the:0.0703)
		( and:0.0554,:0.0483 not:0.0410 a:0.0198.:0.1250,:0.1162 and:0.0613 the:0.0693)
		( and:0.0561 I:0.7100 not:0.0298 a:0.0213.:0.1269,:0.1270 and:0.0484 the:0.0702)
 the the the the the the the the the the the
1250: sample 0: Hello, I'm a language model,
------
		( you:0.0054,:0.0586 I:0.2227 not:0.0231 a:0.0898 language:0.1025,:0.0674,:0.0732)
		(,:0.0091,:0.0483 I:0.1064 not:0.0330 a:0.0483,:0.0703,:0.0884 and:0.0483)
		(,:0.0145,:0.0466 I:0.0737 not:0.0400 a:0.0376,:0.0771,:0.0986 and:0.0483)
		(,:0.0197,:0.0459 I:0.0605 not:0.0437 a:0.0332,:0.0825,:0.1025 and:0.0503)
		(,:0.0240,:0.0452 I:0.0532 not:0.0442 a:0.0302,:0.0869,:0.1035 and:0.0532)
		(,:0.0277,:0.0444�:0.0525 not:0.0430 a:0.0277.:0.0933,:0.1021 and:0.0562)
		(,:0.0306 and:0.0461�:0.0542 not:0.0403 a:0.0255.:0.0967,:0.1011 and:0.0581)
		(,:0.0330 and:0.0479�:0.0549 not:0.0376 a:0.0236.:0.0991,:0.0986 and:0.0591)
		(,:0.0344 and:0.0488�:0.0552 not:0.0347 a:0.0217.:0.1001,:0.0967 and:0.0598)
		(,:0.0354 and:0.0493�:0.0557 not:0.0317 a:0.0199.:0.1006,:0.0938 and:0.0596)
		(,:0.0361 and:0.0493�:0.0547 not:0.0294 a:0.0184.:0.1001,:0.0908 and:0.0588)
		(,:0.0364 and:0.0488�:0.0542 not:0.0273 good:0.0176.:0.0996,:0.0884 and:0.0576)
		(,:0.0360 and:0.0492�:0.0547 not:0.0294 a:0.0184 language:0.6020,:0.1025 and:0.0588)
 and
------
		(,:0.0586 I:0.2227 not:0.0231 a:0.0898 language:0.1025,:0.0674,:0.0732 the:0.0344)
		(,:0.0483 I:0.1064 not:0.0330 a:0.0483,:0.0703,:0.0884 and:0.0483 the:0.0391)
		(,:0.0466 I:0.0737 not:0.0400 a:0.0376,:0.0771,:0.0986 and:0.0483 the:0.0459)
		(,:0.0459 I:0.0605 not:0.0437 a:0.0332,:0.0825,:0.1025 and:0.0503 the:0.0522)
		(,:0.0452 I:0.0532 not:0.0442 a:0.0302,:0.0869,:0.1035 and:0.0532 the:0.0574)
		(,:0.0444�:0.0525 not:0.0430 a:0.0277.:0.0933,:0.1021 and:0.0562 the:0.0608)
		( and:0.0461�:0.0542 not:0.0403 a:0.0255.:0.0967,:0.1011 and:0.0581 the:0.0625)
		( and:0.0479�:0.0549 not:0.0376 a:0.0236.:0.0991,:0.0986 and:0.0591 the:0.0645)
		( and:0.0488�:0.0552 not:0.0347 a:0.0217.:0.1001,:0.0967 and:0.0598 the:0.0649)
		( and:0.0493�:0.0557 not:0.0317 a:0.0199.:0.1006,:0.0938 and:0.0596 the:0.0645)
		( and:0.0493�:0.0547 not:0.0294 a:0.0184.:0.1001,:0.0908 and:0.0588 the:0.0635)
		( and:0.0488�:0.0542 not:0.0273 good:0.0176.:0.0996,:0.0884 and:0.0576 the:0.0625)
		(,:0.0453 I:0.7504 not:0.0294 a:0.0184 language:0.1028,:0.0673 and:0.0588 the:0.0636)
 the the way to the way to the time, and
