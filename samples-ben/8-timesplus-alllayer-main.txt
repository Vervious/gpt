1: sample 0: Hello, I'm a language model,
------
		( abound:0.0001 Demon:0.0002pers:0.0002ird:0.0002 Gilmore:0.0002miss:0.0001 Sector:0.0002etus:0.0001)
		( Well:0.0003 protested:0.0001 gin:0.0002Aaron:0.0002 fab:0.0002 eluc:0.0002INK:0.0002 Historical:0.0002)
		( assigned:0.0002 definitive:0.0002 Dent:0.0002 Pixar:0.0002FactoryReloaded:0.0001 stigma:0.0001D:0.0001––:0.0001)
		( Credit:0.0001 derivative:0.0001 narrowed:0.0002urb:0.0001Quant:0.0001 Shadows:0.0001 trump:0.0001Ill:0.0000)
		(Brazil:0.0002term:0.0001 separ:0.0001hens:0.0001 invasive:0.0000Lyn:0.0000Random:0.0000 bullet:0.0000)
		( short:0.0001 audition:0.0002 Eddie:0.0001 Hath:0.0001 Hindus:0.0000 flung:0.0000,:0.0000,:0.0000)
		( introductory:0.0002 mont:0.0001frames:0.0001 meas:0.0000 McK:0.0000,:0.0000,:0.0000,:0.0000)
		( democr:0.0002Sax:0.0001773:0.0001Ign:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( Brazil:0.0002 Asc:0.0002ACE:0.0001 the:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( insurers:0.0002 violet:0.0001luck:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( Jeremy:0.0002 stones:0.0002 basil:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		(sector:0.0002 peg:0.0001 disappointing:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		(sector:0.0002 peg:0.0001 disappointing:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
,
------
		( Demon:0.0002pers:0.0002ird:0.0002 Gilmore:0.0002miss:0.0001 Sector:0.0002etus:0.0001catching:0.0001)
		( protested:0.0001 gin:0.0002Aaron:0.0002 fab:0.0002 eluc:0.0002INK:0.0002 Historical:0.0002 chi:0.0001)
		( definitive:0.0002 Dent:0.0002 Pixar:0.0002FactoryReloaded:0.0001 stigma:0.0001D:0.0001––:0.0001152:0.0001)
		( derivative:0.0001 narrowed:0.0002urb:0.0001Quant:0.0001 Shadows:0.0001 trump:0.0001Ill:0.0000 km:0.0000)
		(term:0.0001 separ:0.0001hens:0.0001 invasive:0.0000Lyn:0.0000Random:0.0000 bullet:0.0000 chill:0.0000)
		( audition:0.0002 Eddie:0.0001 Hath:0.0001 Hindus:0.0000 flung:0.0000,:0.0000,:0.0000,:0.0000)
		( mont:0.0001frames:0.0001 meas:0.0000 McK:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		(Sax:0.0001773:0.0001Ign:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( Asc:0.0002ACE:0.0001 the:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( violet:0.0001luck:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( stones:0.0002 basil:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( peg:0.0001 disappointing:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
		( peg:0.0001 disappointing:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000,:0.0000)
,,,,,,,,,,,
50: sample 0: Hello, I'm a language model,
------
		(.:0.0815 and:0.0825 the:0.0708,:0.0659 the:0.0239.:0.0486.:0.0825 and:0.0825)
		( the:0.0442 the:0.0737 the:0.1309.:0.0415 the:0.0569.:0.0439.:0.0500 the:0.0908)
		( the:0.0610 the:0.0598 the:0.0791 the:0.0513 the:0.0491 the:0.0535 the:0.0508 the:0.0610)
		( the:0.0640 the:0.0603 the:0.0640 the:0.0603 the:0.0605 the:0.0603 the:0.0620 the:0.0603)
		( the:0.0623 the:0.0623 the:0.0623 the:0.0620 the:0.0601 the:0.0620 the:0.0620 the:0.0623)
		( the:0.0625 the:0.0625 the:0.0623 the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0623)
		( the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623)
		( the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0623 the:0.0625 the:0.0623)
		( the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623)
		( the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0623)
		( the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623)
		( the:0.0625 the:0.0623 the:0.0623 the:0.0625 the:0.0625 the:0.0623 the:0.0625 the:0.0623)
		( the:0.0625 the:0.0623 the:0.0623 the:0.0625 the:0.0625 the:0.0623 the:0.0625 the:0.0623)
 the
------
		( and:0.0825 the:0.0708,:0.0659 the:0.0239.:0.0486.:0.0825 and:0.0825 �:0.0079)
		( the:0.0737 the:0.1309.:0.0415 the:0.0569.:0.0439.:0.0500 the:0.0908 the:0.0723)
		( the:0.0598 the:0.0791 the:0.0513 the:0.0491 the:0.0535 the:0.0508 the:0.0610 the:0.0630)
		( the:0.0603 the:0.0640 the:0.0603 the:0.0605 the:0.0603 the:0.0620 the:0.0603 the:0.0601)
		( the:0.0623 the:0.0623 the:0.0620 the:0.0601 the:0.0620 the:0.0620 the:0.0623 the:0.0603)
		( the:0.0625 the:0.0623 the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0623 the:0.0623)
		( the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623)
		( the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0623 the:0.0625 the:0.0623 the:0.0625)
		( the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623)
		( the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0625 the:0.0623 the:0.0625)
		( the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623 the:0.0623)
		( the:0.0623 the:0.0623 the:0.0625 the:0.0625 the:0.0623 the:0.0625 the:0.0623 the:0.0623)
		( the:0.0623 the:0.0623 the:0.0625 the:0.0625 the:0.0623 the:0.0625 the:0.0623 the:0.0623)
 the the the the the the the the the the the
200: sample 0: Hello, I'm a language model,
------
		(,:0.1348 and:0.1001�:0.0437 not:0.0830 few:0.0170.:0.0879 of:0.1514 and:0.1045)
		(,:0.1914 and:0.1079�:0.0479 not:0.0854 few:0.0167.:0.1416 of:0.1475 and:0.1069)
		(,:0.2002 and:0.1099�:0.0540 not:0.0835 few:0.0164.:0.1553.:0.1387 and:0.1045)
		(,:0.2051 and:0.1094�:0.0498 not:0.0801 few:0.0151.:0.1631.:0.1533 and:0.1050)
		(,:0.1914 and:0.1006 can:0.0491 not:0.0752 few:0.0145.:0.1484.:0.1475 and:0.0996)
		(,:0.1855 and:0.0947 can:0.0530 a:0.0728 few:0.0131.:0.1387.:0.1436 and:0.0952)
		(,:0.1748 and:0.0864 can:0.0566 a:0.0703 few:0.0117.:0.1299.:0.1377 and:0.0903)
		(,:0.1631 and:0.0786 can:0.0603 a:0.0718 few:0.0102.:0.1250.:0.1357 and:0.0850)
		(,:0.1504 and:0.0698 can:0.0623 a:0.0723 of:0.0104.:0.1201.:0.1348 and:0.0801)
		(,:0.1484 and:0.0618 can:0.0645 a:0.0693 of:0.0118.:0.1147.:0.1328 and:0.0757)
		(,:0.1367 and:0.0532 can:0.0674 a:0.0698 of:0.0135.:0.1147.:0.1377 the:0.0757)
		(,:0.1338 and:0.0447 can:0.0679 a:0.0664 of:0.0148.:0.1084.:0.1348 the:0.0742)
		(,:0.1338 and:0.0447 can:0.0679 a:0.0664 of:0.0148.:0.1084.:0.1348 the:0.0742)
 the
------
		( and:0.1001�:0.0437 not:0.0830 few:0.0170.:0.0879 of:0.1514 and:0.1045 first:0.0081)
		( and:0.1079�:0.0479 not:0.0854 few:0.0167.:0.1416 of:0.1475 and:0.1069 same:0.0106)
		( and:0.1099�:0.0540 not:0.0835 few:0.0164.:0.1553.:0.1387 and:0.1045 same:0.0107)
		( and:0.1094�:0.0498 not:0.0801 few:0.0151.:0.1631.:0.1533 and:0.1050 same:0.0109)
		( and:0.1006 can:0.0491 not:0.0752 few:0.0145.:0.1484.:0.1475 and:0.0996 same:0.0112)
		( and:0.0947 can:0.0530 a:0.0728 few:0.0131.:0.1387.:0.1436 and:0.0952 same:0.0112)
		( and:0.0864 can:0.0566 a:0.0703 few:0.0117.:0.1299.:0.1377 and:0.0903 same:0.0115)
		( and:0.0786 can:0.0603 a:0.0718 few:0.0102.:0.1250.:0.1357 and:0.0850 same:0.0113)
		( and:0.0698 can:0.0623 a:0.0723 of:0.0104.:0.1201.:0.1348 and:0.0801 time:0.0123)
		( and:0.0618 can:0.0645 a:0.0693 of:0.0118.:0.1147.:0.1328 and:0.0757 time:0.0133)
		( and:0.0532 can:0.0674 a:0.0698 of:0.0135.:0.1147.:0.1377 the:0.0757 time:0.0140)
		( and:0.0447 can:0.0679 a:0.0664 of:0.0148.:0.1084.:0.1348 the:0.0742 time:0.0152)
		( and:0.0447 can:0.0679 a:0.0664 of:0.0148.:0.1084.:0.1348 the:0.0742 time:0.0152)
 time, the time, the time, the time.
350: sample 0: Hello, I'm a language model,
------
		(,:0.1855 and:0.1025�:0.0613 not:0.0566 new:0.0187,:0.1543,:0.1235 the:0.0845)
		(,:0.3770 and:0.1572�:0.0796 not:0.0835 new:0.0194,:0.1807,:0.1797 and:0.1177)
		(,:0.3418 and:0.1562�:0.0801 not:0.0933 great:0.0215,:0.1846,:0.1963 and:0.1299)
		(,:0.3125 and:0.1455�:0.0869 not:0.0850 great:0.0210,:0.1738,:0.1885 and:0.1416)
		(,:0.2734 and:0.1328�:0.0879 not:0.0757 great:0.0206,:0.1797,:0.1895 and:0.1494)
		(,:0.2490 and:0.1196�:0.0815 not:0.0649 great:0.0209,:0.1748,:0.1895 and:0.1504)
		(,:0.2363 and:0.1123�:0.0732 not:0.0552 great:0.0214,:0.1787,:0.1895 and:0.1504)
		(,:0.2334 and:0.1069�:0.0654 not:0.0476 great:0.0214,:0.1738,:0.1816 and:0.1514)
		(,:0.2295 and:0.1040�:0.0569 not:0.0405 great:0.0219,:0.1709,:0.1768 and:0.1455)
		(,:0.2285 and:0.1016�:0.0496 not:0.0347 great:0.0219,:0.1699,:0.1719 and:0.1416)
		(,:0.2373 and:0.1025�:0.0425 not:0.0289 great:0.0210,:0.1631,:0.1582 and:0.1377)
		(,:0.2373 and:0.1040�:0.0374 a:0.0244 great:0.0204,:0.1572,:0.1543 and:0.1309)
		(,:0.2373 and:0.1040�:0.0374 a:0.0244 great:0.0204,:0.1572,:0.1543 and:0.1309)
 and
------
		( and:0.1025�:0.0613 not:0.0566 new:0.0187,:0.1543,:0.1235 the:0.0845 the:0.0845)
		( and:0.1572�:0.0796 not:0.0835 new:0.0194,:0.1807,:0.1797 and:0.1177 the:0.0381)
		( and:0.1562�:0.0801 not:0.0933 great:0.0215,:0.1846,:0.1963 and:0.1299 the:0.0342)
		( and:0.1455�:0.0869 not:0.0850 great:0.0210,:0.1738,:0.1885 and:0.1416 the:0.0337)
		( and:0.1328�:0.0879 not:0.0757 great:0.0206,:0.1797,:0.1895 and:0.1494 the:0.0334)
		( and:0.1196�:0.0815 not:0.0649 great:0.0209,:0.1748,:0.1895 and:0.1504 the:0.0342)
		( and:0.1123�:0.0732 not:0.0552 great:0.0214,:0.1787,:0.1895 and:0.1504 the:0.0347)
		( and:0.1069�:0.0654 not:0.0476 great:0.0214,:0.1738,:0.1816 and:0.1514 the:0.0352)
		( and:0.1040�:0.0569 not:0.0405 great:0.0219,:0.1709,:0.1768 and:0.1455 the:0.0339)
		( and:0.1016�:0.0496 not:0.0347 great:0.0219,:0.1699,:0.1719 and:0.1416 the:0.0327)
		( and:0.1025�:0.0425 not:0.0289 great:0.0210,:0.1631,:0.1582 and:0.1377 the:0.0310)
		( and:0.1040�:0.0374 a:0.0244 great:0.0204,:0.1572,:0.1543 and:0.1309 the:0.0294)
		( and:0.1040�:0.0374 a:0.0244 great:0.0204,:0.1572,:0.1543 and:0.1309 the:0.0294)
 the world.
The first of the world.

500: sample 0: Hello, I'm a language model,
------
		(,:0.0913 and:0.0986�:0.0645 not:0.0635 lot:0.0228,:0.1514 of:0.1157 and:0.0796)
		(,:0.1611 and:0.1069�:0.0771 not:0.0598 few:0.0261,:0.2891,:0.2139 and:0.1030)
		(,:0.1465 and:0.0820�:0.0752 not:0.0645 few:0.0311,:0.2061,:0.1826 I:0.1104)
		(,:0.1426 and:0.0684�:0.0713 not:0.0630 few:0.0327,:0.1875,:0.1611 I:0.1216)
		(,:0.1328 and:0.0586�:0.0732 not:0.0591 few:0.0339,:0.1758,:0.1562 I:0.1157)
		(,:0.1211 and:0.0515�:0.0698 not:0.0542 few:0.0366,:0.1748,:0.1533 I:0.1113)
		(,:0.1104 the:0.0493�:0.0654 not:0.0481 few:0.0386,:0.1641,:0.1494 I:0.0996)
		(,:0.1006 the:0.0493�:0.0635 going:0.0442 few:0.0398,:0.1621,:0.1543 I:0.0889)
		(,:0.0942 the:0.0481�:0.0630 going:0.0403 few:0.0396,:0.1689,:0.1602 I:0.0776)
		(,:0.0859 the:0.0459�:0.0569 going:0.0364 few:0.0383,:0.1689,:0.1592 and:0.0796)
		(.:0.0859 the:0.0422�:0.0549 going:0.0334 few:0.0354,:0.1689,:0.1689 and:0.0850)
		(.:0.0898 the:0.0391�:0.0522 a:0.0297 few:0.0317,:0.1816,:0.1699 and:0.0889)
		(.:0.0898 the:0.0391�:0.0522 a:0.0297 few:0.0317,:0.1816,:0.1699 and:0.0889)
 and
------
		( and:0.0986�:0.0645 not:0.0635 lot:0.0228,:0.1514 of:0.1157 and:0.0796 the:0.0776)
		( and:0.1069�:0.0771 not:0.0598 few:0.0261,:0.2891,:0.2139 and:0.1030 the:0.0356)
		( and:0.0820�:0.0752 not:0.0645 few:0.0311,:0.2061,:0.1826 I:0.1104 I:0.0579)
		( and:0.0684�:0.0713 not:0.0630 few:0.0327,:0.1875,:0.1611 I:0.1216 I:0.0593)
		( and:0.0586�:0.0732 not:0.0591 few:0.0339,:0.1758,:0.1562 I:0.1157 I:0.0537)
		( and:0.0515�:0.0698 not:0.0542 few:0.0366,:0.1748,:0.1533 I:0.1113 I:0.0496)
		( the:0.0493�:0.0654 not:0.0481 few:0.0386,:0.1641,:0.1494 I:0.0996 the:0.0464)
		( the:0.0493�:0.0635 going:0.0442 few:0.0398,:0.1621,:0.1543 I:0.0889 the:0.0476)
		( the:0.0481�:0.0630 going:0.0403 few:0.0396,:0.1689,:0.1602 I:0.0776 the:0.0493)
		( the:0.0459�:0.0569 going:0.0364 few:0.0383,:0.1689,:0.1592 and:0.0796 the:0.0515)
		( the:0.0422�:0.0549 going:0.0334 few:0.0354,:0.1689,:0.1689 and:0.0850 the:0.0520)
		( the:0.0391�:0.0522 a:0.0297 few:0.0317,:0.1816,:0.1699 and:0.0889 the:0.0532)
		( the:0.0391�:0.0522 a:0.0297 few:0.0317,:0.1816,:0.1699 and:0.0889 the:0.0532)
 the same way of the same way of the same way
650: sample 0: Hello, I'm a language model,
------
		(,:0.0898 and:0.0854�:0.0957 not:0.0271 good:0.0170,:0.1138 of:0.1162 and:0.0923)
		(,:0.1396 and:0.1055�:0.0938 not:0.0403 few:0.0175,:0.1924,:0.1445 and:0.1787)
		(,:0.1934 and:0.0938�:0.0962 not:0.0549 few:0.0250,:0.1797,:0.1533 and:0.2021)
		(,:0.2070 and:0.0796�:0.0869 not:0.0547 few:0.0278,:0.1748,:0.1650 and:0.1904)
		(,:0.2129 and:0.0659�:0.0757 not:0.0537 few:0.0308,:0.1797,:0.1592 and:0.1807)
		(,:0.2109 and:0.0586�:0.0664 not:0.0518 good:0.0344,:0.1758,:0.1484 and:0.1621)
		(,:0.2061 and:0.0562 am:0.0664 not:0.0483 good:0.0369,:0.1660,:0.1396 and:0.1494)
		(,:0.1992 and:0.0552 am:0.0630 not:0.0452 good:0.0391,:0.1680,:0.1348 and:0.1416)
		(,:0.1934 and:0.0540 am:0.0586 going:0.0432 good:0.0378,:0.1621,:0.1250 and:0.1396)
		(,:0.1787 and:0.0535 am:0.0525 going:0.0413 good:0.0376,:0.1504,:0.1167 and:0.1318)
		(,:0.1660 and:0.0505 am:0.0439 going:0.0391 good:0.0347,:0.1484,:0.1099 and:0.1260)
		(,:0.1494 and:0.0469 am:0.0352 going:0.0369 good:0.0322,:0.1436,:0.0991 and:0.1216)
		(,:0.1494 and:0.0469 am:0.0352 going:0.0369 good:0.0322,:0.1436,:0.0991 and:0.1216)
 and
------
		( and:0.0854�:0.0957 not:0.0271 good:0.0170,:0.1138 of:0.1162 and:0.0923 the:0.0393)
		( and:0.1055�:0.0938 not:0.0403 few:0.0175,:0.1924,:0.1445 and:0.1787 I:0.0400)
		( and:0.0938�:0.0962 not:0.0549 few:0.0250,:0.1797,:0.1533 and:0.2021 I:0.0640)
		( and:0.0796�:0.0869 not:0.0547 few:0.0278,:0.1748,:0.1650 and:0.1904 I:0.0747)
		( and:0.0659�:0.0757 not:0.0537 few:0.0308,:0.1797,:0.1592 and:0.1807 I:0.0840)
		( and:0.0586�:0.0664 not:0.0518 good:0.0344,:0.1758,:0.1484 and:0.1621 I:0.0840)
		( and:0.0562 am:0.0664 not:0.0483 good:0.0369,:0.1660,:0.1396 and:0.1494 I:0.0791)
		( and:0.0552 am:0.0630 not:0.0452 good:0.0391,:0.1680,:0.1348 and:0.1416 I:0.0718)
		( and:0.0540 am:0.0586 going:0.0432 good:0.0378,:0.1621,:0.1250 and:0.1396 I:0.0618)
		( and:0.0535 am:0.0525 going:0.0413 good:0.0376,:0.1504,:0.1167 and:0.1318 I:0.0522)
		( and:0.0505 am:0.0439 going:0.0391 good:0.0347,:0.1484,:0.1099 and:0.1260 I:0.0422)
		( and:0.0469 am:0.0352 going:0.0369 good:0.0322,:0.1436,:0.0991 and:0.1216 it:0.0361)
		( and:0.0469 am:0.0352 going:0.0369 good:0.0322,:0.1436,:0.0991 and:0.1216 it:0.0361)
 it's not to be able to be able to be
800: sample 0: Hello, I'm a language model,
------
		(,:0.1045 and:0.0649�:0.0708 not:0.0396 few:0.0146,:0.1582 of:0.1455 and:0.0747)
		(,:0.1250 and:0.0376 was:0.0630 not:0.0835 lot:0.0179,:0.2061,:0.1562 I:0.0820)
		(,:0.1855 I:0.0439�:0.0630 not:0.0996 lot:0.0306,:0.1768,:0.1377 I:0.1475)
		(,:0.2100 I:0.0601�:0.0679 not:0.0884 lot:0.0342,:0.1406,:0.1104 I:0.1709)
		(,:0.2402 I:0.0752�:0.0732 not:0.0742 good:0.0383,:0.1299 that:0.1182 I:0.1748)
		(,:0.2520 I:0.0840�:0.0771 not:0.0669 good:0.0425,:0.1235 that:0.1245 I:0.1592)
		(,:0.2656 I:0.0854�:0.0776 not:0.0598 good:0.0466,:0.1250 that:0.1250 I:0.1514)
		(,:0.2637 I:0.0854�:0.0747 sure:0.0571 good:0.0479,:0.1270 that:0.1260 I:0.1494)
		(,:0.2676 I:0.0850�:0.0693 sure:0.0544 good:0.0464,:0.1279.:0.1279 I:0.1416)
		(,:0.2656 I:0.0806�:0.0623 sure:0.0508 good:0.0444,:0.1338.:0.1299 I:0.1416)
		(,:0.2598 I:0.0776�:0.0557 sure:0.0466 good:0.0396,:0.1348.:0.1338 I:0.1357)
		(,:0.2578 I:0.0752�:0.0474 sure:0.0415 good:0.0344,:0.1406.:0.1318 I:0.1309)
		(,:0.2578 I:0.0752�:0.0474 sure:0.0415 good:0.0344,:0.1406.:0.1318 I:0.1309)
 I
------
		( and:0.0649�:0.0708 not:0.0396 few:0.0146,:0.1582 of:0.1455 and:0.0747 have:0.0476)
		( and:0.0376 was:0.0630 not:0.0835 lot:0.0179,:0.2061,:0.1562 I:0.0820�:0.0522)
		( I:0.0439�:0.0630 not:0.0996 lot:0.0306,:0.1768,:0.1377 I:0.1475�:0.0510)
		( I:0.0601�:0.0679 not:0.0884 lot:0.0342,:0.1406,:0.1104 I:0.1709�:0.0664)
		( I:0.0752�:0.0732 not:0.0742 good:0.0383,:0.1299 that:0.1182 I:0.1748�:0.0811)
		( I:0.0840�:0.0771 not:0.0669 good:0.0425,:0.1235 that:0.1245 I:0.1592�:0.0957)
		( I:0.0854�:0.0776 not:0.0598 good:0.0466,:0.1250 that:0.1250 I:0.1514�:0.1016)
		( I:0.0854�:0.0747 sure:0.0571 good:0.0479,:0.1270 that:0.1260 I:0.1494�:0.1069)
		( I:0.0850�:0.0693 sure:0.0544 good:0.0464,:0.1279.:0.1279 I:0.1416�:0.1099)
		( I:0.0806�:0.0623 sure:0.0508 good:0.0444,:0.1338.:0.1299 I:0.1416�:0.1157)
		( I:0.0776�:0.0557 sure:0.0466 good:0.0396,:0.1348.:0.1338 I:0.1357�:0.1123)
		( I:0.0752�:0.0474 sure:0.0415 good:0.0344,:0.1406.:0.1318 I:0.1309�:0.1167)
		( I:0.0752�:0.0474 sure:0.0415 good:0.0344,:0.1406.:0.1318 I:0.1309�:0.1167)
’m not going to do.
I�
950: sample 0: Hello, I'm a language model,
------
		(,:0.0688 and:0.0571�:0.0471 not:0.0586 few:0.0211,:0.1631 of:0.1631 and:0.0569)
		(,:0.0972 and:0.0630�:0.0708 not:0.1104 good:0.0200,:0.1816 of:0.2520 and:0.1035)
		(,:0.1445 and:0.0649�:0.0544 not:0.1543 good:0.0298,:0.1797 of:0.1924 I:0.1211)
		(,:0.1631 I:0.0693 am:0.0615 not:0.1436 good:0.0403,:0.1514 of:0.2246 but:0.1455)
		(,:0.1787 the:0.0728 am:0.0728 not:0.1436 good:0.0479,:0.1357 of:0.2695 but:0.1982)
		(,:0.1855 the:0.0752 am:0.0781 not:0.1367 good:0.0483,:0.1348 of:0.2949 but:0.2129)
		(,:0.1992 the:0.0781 am:0.0806 not:0.1348 good:0.0466,:0.1367 of:0.3184 but:0.2188)
		(,:0.2051 the:0.0786 am:0.0820 not:0.1226 good:0.0425,:0.1475 of:0.3262 but:0.2188)
		(,:0.2148 the:0.0781 am:0.0850 not:0.1138 good:0.0381,:0.1533 of:0.3379 but:0.2109)
		(,:0.2197 the:0.0776 am:0.0845 not:0.1055 good:0.0342,:0.1611 of:0.3379 but:0.1963)
		(,:0.2197 the:0.0757 am:0.0830 not:0.0928 good:0.0298,:0.1699 of:0.3262 but:0.1826)
		(,:0.2217 the:0.0737 am:0.0825 not:0.0791 good:0.0259,:0.1699 of:0.3281 but:0.1650)
		(,:0.2217 the:0.0737 am:0.0825 not:0.0791 good:0.0259,:0.1699 of:0.3281 but:0.1650)
 but
------
		( and:0.0571�:0.0471 not:0.0586 few:0.0211,:0.1631 of:0.1631 and:0.0569 it:0.0522)
		( and:0.0630�:0.0708 not:0.1104 good:0.0200,:0.1816 of:0.2520 and:0.1035 I:0.1484)
		( and:0.0649�:0.0544 not:0.1543 good:0.0298,:0.1797 of:0.1924 I:0.1211 I:0.2373)
		( I:0.0693 am:0.0615 not:0.1436 good:0.0403,:0.1514 of:0.2246 but:0.1455 I:0.2676)
		( the:0.0728 am:0.0728 not:0.1436 good:0.0479,:0.1357 of:0.2695 but:0.1982 I:0.2793)
		( the:0.0752 am:0.0781 not:0.1367 good:0.0483,:0.1348 of:0.2949 but:0.2129 I:0.2715)
		( the:0.0781 am:0.0806 not:0.1348 good:0.0466,:0.1367 of:0.3184 but:0.2188 I:0.2715)
		( the:0.0786 am:0.0820 not:0.1226 good:0.0425,:0.1475 of:0.3262 but:0.2188 I:0.2656)
		( the:0.0781 am:0.0850 not:0.1138 good:0.0381,:0.1533 of:0.3379 but:0.2109 I:0.2715)
		( the:0.0776 am:0.0845 not:0.1055 good:0.0342,:0.1611 of:0.3379 but:0.1963 I:0.2695)
		( the:0.0757 am:0.0830 not:0.0928 good:0.0298,:0.1699 of:0.3262 but:0.1826 I:0.2656)
		( the:0.0737 am:0.0825 not:0.0791 good:0.0259,:0.1699 of:0.3281 but:0.1650 I:0.2656)
		( the:0.0737 am:0.0825 not:0.0791 good:0.0259,:0.1699 of:0.3281 but:0.1650 I:0.2656)
 I think it's a lot of the world.

1100: sample 0: Hello, I'm a language model,
------
		(,:0.0574 the:0.0613�:0.0791 not:0.0588 lot:0.0325,:0.1602 of:0.1328 the:0.0549)
		(,:0.0796 the:0.0654�:0.1455 not:0.0918 lot:0.0204,:0.0938,:0.1455 I:0.0786)
		(,:0.1328 I:0.0898 am:0.1309 not:0.1816 great:0.0256,:0.1084,:0.1396 but:0.1211)
		(,:0.1504 I:0.0957 am:0.1465 not:0.1729 good:0.0364 that:0.1128 that:0.1670 but:0.1611)
		(,:0.1777 I:0.0913 am:0.1553 not:0.1680 good:0.0391 that:0.1021 that:0.1582 but:0.1719)
		(,:0.1846 I:0.0835 am:0.1582 not:0.1631 good:0.0366 that:0.0977 that:0.1484 but:0.1768)
		(,:0.1846 I:0.0796 am:0.1709 not:0.1514 good:0.0339 that:0.0913 of:0.1406 but:0.1689)
		(,:0.1787 I:0.0752 am:0.1719 not:0.1357 good:0.0320 that:0.0845 of:0.1455 but:0.1631)
		(,:0.1709 I:0.0708 am:0.1826 not:0.1221 good:0.0281,:0.0771 of:0.1445 but:0.1553)
		(,:0.1631 I:0.0659 am:0.1758 not:0.1104 good:0.0253,:0.0796 of:0.1406 but:0.1475)
		(,:0.1465 I:0.0610 am:0.1699 not:0.0947 good:0.0217,:0.0806 of:0.1377 but:0.1416)
		(,:0.1318 I:0.0552 am:0.1641 not:0.0781 good:0.0187,:0.0786 of:0.1348 but:0.1328)
		(,:0.1318 I:0.0552 am:0.1641 not:0.0781 good:0.0187,:0.0786 of:0.1348 but:0.1328)
 but
------
		( the:0.0613�:0.0791 not:0.0588 lot:0.0325,:0.1602 of:0.1328 the:0.0549 it:0.0688)
		( the:0.0654�:0.1455 not:0.0918 lot:0.0204,:0.0938,:0.1455 I:0.0786 I:0.1768)
		( I:0.0898 am:0.1309 not:0.1816 great:0.0256,:0.1084,:0.1396 but:0.1211 I:0.2793)
		( I:0.0957 am:0.1465 not:0.1729 good:0.0364 that:0.1128 that:0.1670 but:0.1611 I:0.3379)
		( I:0.0913 am:0.1553 not:0.1680 good:0.0391 that:0.1021 that:0.1582 but:0.1719 I:0.3359)
		( I:0.0835 am:0.1582 not:0.1631 good:0.0366 that:0.0977 that:0.1484 but:0.1768 I:0.3320)
		( I:0.0796 am:0.1709 not:0.1514 good:0.0339 that:0.0913 of:0.1406 but:0.1689 I:0.3223)
		( I:0.0752 am:0.1719 not:0.1357 good:0.0320 that:0.0845 of:0.1455 but:0.1631 I:0.3301)
		( I:0.0708 am:0.1826 not:0.1221 good:0.0281,:0.0771 of:0.1445 but:0.1553 I:0.3398)
		( I:0.0659 am:0.1758 not:0.1104 good:0.0253,:0.0796 of:0.1406 but:0.1475 I:0.3379)
		( I:0.0610 am:0.1699 not:0.0947 good:0.0217,:0.0806 of:0.1377 but:0.1416 I:0.3359)
		( I:0.0552 am:0.1641 not:0.0781 good:0.0187,:0.0786 of:0.1348 but:0.1328 I:0.3359)
		( I:0.0552 am:0.1641 not:0.0781 good:0.0187,:0.0786 of:0.1348 but:0.1328 I:0.3359)
 I'm not sure to use it. I'm not
1250: sample 0: Hello, I'm a language model,
------
		(,:0.0549 the:0.0493�:0.0957 not:0.0549 lot:0.0211.:0.1270 of:0.1123 and:0.0630)
		(,:0.0542 the:0.0613�:0.2852 not:0.0586 great:0.0266,:0.1094 of:0.1631 and:0.1079)
		(,:0.0723 I:0.0767�:0.2002 not:0.0967 great:0.0466 that:0.0806 of:0.1963 and:0.1245)
		(,:0.1045 I:0.0786�:0.2520 not:0.0977 great:0.0454 that:0.0835 of:0.1836 but:0.1641)
		(,:0.1318 the:0.0732�:0.2715 not:0.1040 great:0.0417 that:0.0786 of:0.1992 but:0.1572)
		(,:0.1494 the:0.0762�:0.2949 not:0.1001 great:0.0391 that:0.0728 of:0.2080 but:0.1484)
		(,:0.1592 the:0.0791�:0.3164 not:0.0952 great:0.0359,:0.0757 of:0.2109 and:0.1406)
		(,:0.1758 the:0.0825�:0.3418 not:0.0913 great:0.0332,:0.0845 of:0.2148 and:0.1436)
		(,:0.1846 the:0.0864�:0.3672 not:0.0854 great:0.0315,:0.0913 of:0.2188 and:0.1475)
		(,:0.1943 the:0.0884�:0.3789 not:0.0776 great:0.0298,:0.0962 of:0.2139 and:0.1514)
		(,:0.2002 the:0.0923�:0.4043 not:0.0718 great:0.0281,:0.1016 of:0.2090 and:0.1523)
		(,:0.2051 the:0.0947�:0.4141 not:0.0649 great:0.0264,:0.1074 of:0.2031 and:0.1572)
		(,:0.2051 the:0.0947�:0.4141 not:0.0649 great:0.0264,:0.1074 of:0.2031 and:0.1572)
 and
------
		( the:0.0493�:0.0957 not:0.0549 lot:0.0211.:0.1270 of:0.1123 and:0.0630 the:0.0371)
		( the:0.0613�:0.2852 not:0.0586 great:0.0266,:0.1094 of:0.1631 and:0.1079 the:0.0669)
		( I:0.0767�:0.2002 not:0.0967 great:0.0466 that:0.0806 of:0.1963 and:0.1245 I:0.1641)
		( I:0.0786�:0.2520 not:0.0977 great:0.0454 that:0.0835 of:0.1836 but:0.1641 I:0.1709)
		( the:0.0732�:0.2715 not:0.1040 great:0.0417 that:0.0786 of:0.1992 but:0.1572 I:0.1777)
		( the:0.0762�:0.2949 not:0.1001 great:0.0391 that:0.0728 of:0.2080 but:0.1484 I:0.1689)
		( the:0.0791�:0.3164 not:0.0952 great:0.0359,:0.0757 of:0.2109 and:0.1406 I:0.1777)
		( the:0.0825�:0.3418 not:0.0913 great:0.0332,:0.0845 of:0.2148 and:0.1436 I:0.1719)
		( the:0.0864�:0.3672 not:0.0854 great:0.0315,:0.0913 of:0.2188 and:0.1475 I:0.1758)
		( the:0.0884�:0.3789 not:0.0776 great:0.0298,:0.0962 of:0.2139 and:0.1514 I:0.1797)
		( the:0.0923�:0.4043 not:0.0718 great:0.0281,:0.1016 of:0.2090 and:0.1523 I:0.1846)
		( the:0.0947�:0.4141 not:0.0649 great:0.0264,:0.1074 of:0.2031 and:0.1572 I:0.1816)
		( the:0.0947�:0.4141 not:0.0649 great:0.0264,:0.1074 of:0.2031 and:0.1572 I:0.1816)
 I'm not a very different language. I'm not
1400: sample 0: Hello, I'm a language model,
------
		(,:0.0410 the:0.0596�:0.0732 not:0.0527 lot:0.0197.:0.1206 of:0.0864 and:0.0654)
		(,:0.0457 the:0.0454�:0.2129 a:0.0625 good:0.0199,:0.0908.:0.1406 and:0.0859)
		(,:0.0447 you:0.0659�:0.1650 sure:0.0869 good:0.0275 that:0.0884 that:0.1475 but:0.1533)
		(,:0.0903 you:0.0757�:0.1982 sure:0.1807 good:0.0415 that:0.0977 that:0.1914 but:0.1807)
		(,:0.1118 you:0.0825�:0.1963 sure:0.1709 good:0.0493 that:0.0957 that:0.1855 but:0.1865)
		(,:0.1211 you:0.0825�:0.2129 sure:0.1787 good:0.0522 that:0.0894 that:0.1758 but:0.1777)
		(,:0.1240 you:0.0815�:0.2275 sure:0.1768 good:0.0540 that:0.0864 that:0.1729 but:0.1768)
		(,:0.1279 you:0.0830�:0.2441 sure:0.1846 good:0.0540 that:0.0825 that:0.1611 but:0.1660)
		(,:0.1289 you:0.0825�:0.2637 sure:0.1865 good:0.0525 that:0.0796 that:0.1582 but:0.1670)
		(,:0.1270 you:0.0801�:0.2734 sure:0.1865 good:0.0525 that:0.0762,:0.1660 but:0.1582)
		(,:0.1216 you:0.0796�:0.2812 sure:0.1777 good:0.0505,:0.0757,:0.1768 but:0.1602)
		(,:0.1162 you:0.0752�:0.2793 sure:0.1787 good:0.0488,:0.0776,:0.1875 but:0.1572)
		(,:0.1162 you:0.0752�:0.2793 sure:0.1787 good:0.0488,:0.0776,:0.1875 but:0.1572)
 but
------
		( the:0.0596�:0.0732 not:0.0527 lot:0.0197.:0.1206 of:0.0864 and:0.0654 I:0.0767)
		( the:0.0454�:0.2129 a:0.0625 good:0.0199,:0.0908.:0.1406 and:0.0859 I:0.1235)
		( you:0.0659�:0.1650 sure:0.0869 good:0.0275 that:0.0884 that:0.1475 but:0.1533 I:0.2100)
		( you:0.0757�:0.1982 sure:0.1807 good:0.0415 that:0.0977 that:0.1914 but:0.1807 I:0.2188)
		( you:0.0825�:0.1963 sure:0.1709 good:0.0493 that:0.0957 that:0.1855 but:0.1865 I:0.2012)
		( you:0.0825�:0.2129 sure:0.1787 good:0.0522 that:0.0894 that:0.1758 but:0.1777 I:0.1885)
		( you:0.0815�:0.2275 sure:0.1768 good:0.0540 that:0.0864 that:0.1729 but:0.1768 I:0.1797)
		( you:0.0830�:0.2441 sure:0.1846 good:0.0540 that:0.0825 that:0.1611 but:0.1660 I:0.1807)
		( you:0.0825�:0.2637 sure:0.1865 good:0.0525 that:0.0796 that:0.1582 but:0.1670 it:0.1846)
		( you:0.0801�:0.2734 sure:0.1865 good:0.0525 that:0.0762,:0.1660 but:0.1582 it:0.1875)
		( you:0.0796�:0.2812 sure:0.1777 good:0.0505,:0.0757,:0.1768 but:0.1602 it:0.1904)
		( you:0.0752�:0.2793 sure:0.1787 good:0.0488,:0.0776,:0.1875 but:0.1572 it:0.1953)
		( you:0.0752�:0.2793 sure:0.1787 good:0.0488,:0.0776,:0.1875 but:0.1572 it:0.1953)
 it's a lot of time to learn.
The
1550: sample 0: Hello, I'm a language model,
------
		(,:0.1064 the:0.0996�:0.0535 not:0.0471 lot:0.0234.:0.1270.:0.1191 the:0.0820)
		(,:0.0613 the:0.0708�:0.1514 not:0.0496 few:0.0212,:0.0928.:0.1475 but:0.1187)
		(,:0.0574 I:0.0991�:0.1484 sure:0.1611 few:0.0254 that:0.1475 that:0.1396 but:0.1982)
		(,:0.1035 I:0.1045�:0.1650 sure:0.2695 good:0.0378 that:0.1357.:0.1436 but:0.2324)
		(,:0.1396 I:0.1235�:0.1328 sure:0.2617 good:0.0483 that:0.1260.:0.1660 but:0.2314)
		(,:0.1504 I:0.1260�:0.1338 sure:0.2500 good:0.0491 that:0.1133.:0.1699 but:0.2148)
		(,:0.1572 I:0.1250�:0.1318 sure:0.2480 good:0.0483 that:0.1108.:0.1719 but:0.2002)
		(,:0.1660 I:0.1279�:0.1387 sure:0.2471 good:0.0464 that:0.1055.:0.1748 and:0.2061)
		(,:0.1738 I:0.1270�:0.1396 sure:0.2354 good:0.0444 that:0.1011.:0.1768 and:0.2041)
		(,:0.1738 I:0.1299�:0.1387 sure:0.2344 good:0.0427,:0.1001.:0.1758 and:0.2109)
		(,:0.1777 I:0.1318�:0.1396 sure:0.2217 good:0.0408,:0.1016.:0.1777 and:0.2178)
		(,:0.1729 I:0.1309�:0.1406 sure:0.2197 good:0.0398,:0.1016.:0.1816 and:0.2246)
		(,:0.1729 I:0.1309�:0.1406 sure:0.2197 good:0.0398,:0.1016.:0.1816 and:0.2246)
 and
------
		( the:0.0996�:0.0535 not:0.0471 lot:0.0234.:0.1270.:0.1191 the:0.0820 the:0.0576)
		( the:0.0708�:0.1514 not:0.0496 few:0.0212,:0.0928.:0.1475 but:0.1187 I:0.0933)
		( I:0.0991�:0.1484 sure:0.1611 few:0.0254 that:0.1475 that:0.1396 but:0.1982 I:0.1992)
		( I:0.1045�:0.1650 sure:0.2695 good:0.0378 that:0.1357.:0.1436 but:0.2324 I:0.2754)
		( I:0.1235�:0.1328 sure:0.2617 good:0.0483 that:0.1260.:0.1660 but:0.2314 I:0.2393)
		( I:0.1260�:0.1338 sure:0.2500 good:0.0491 that:0.1133.:0.1699 but:0.2148 I:0.2246)
		( I:0.1250�:0.1318 sure:0.2480 good:0.0483 that:0.1108.:0.1719 but:0.2002 I:0.2080)
		( I:0.1279�:0.1387 sure:0.2471 good:0.0464 that:0.1055.:0.1748 and:0.2061 I:0.2021)
		( I:0.1270�:0.1396 sure:0.2354 good:0.0444 that:0.1011.:0.1768 and:0.2041 I:0.1963)
		( I:0.1299�:0.1387 sure:0.2344 good:0.0427,:0.1001.:0.1758 and:0.2109 I:0.1914)
		( I:0.1318�:0.1396 sure:0.2217 good:0.0408,:0.1016.:0.1777 and:0.2178 I:0.1777)
		( I:0.1309�:0.1406 sure:0.2197 good:0.0398,:0.1016.:0.1816 and:0.2246 I:0.1738)
		( I:0.1309�:0.1406 sure:0.2197 good:0.0398,:0.1016.:0.1816 and:0.2246 I:0.1738)
 I have a language to use the language.
The
1700: sample 0: Hello, I'm a language model,
------
		(,:0.1094 the:0.1001�:0.0383 not:0.0659 lot:0.0179,:0.1406.:0.1504 the:0.0625)
		(,:0.0557 you:0.0967�:0.0723 not:0.0894 few:0.0251,:0.0928.:0.1709 and:0.0986)
		(,:0.0483 I:0.1494 will:0.0713 not:0.0972 bit:0.0315,:0.1016.:0.1846 and:0.1895)
		(,:0.1079 I:0.1465 have:0.0713 sure:0.0791 bit:0.0408,:0.1152,:0.1670 and:0.2129)
		(,:0.1338 I:0.1445 am:0.0674 sure:0.0737 bit:0.0461,:0.1226,:0.1855 and:0.2061)
		(,:0.1348 I:0.1367 am:0.0669 going:0.0713 bit:0.0476,:0.1289,:0.1963 and:0.2119)
		(,:0.1357 I:0.1318 am:0.0688 going:0.0718 bit:0.0457,:0.1338,:0.1973 and:0.2021)
		(,:0.1357 I:0.1270 am:0.0703 going:0.0723 bit:0.0452,:0.1357,:0.2080 and:0.2021)
		(,:0.1338 I:0.1201 am:0.0688 going:0.0723 bit:0.0432,:0.1426,:0.2188 and:0.1934)
		(,:0.1309 I:0.1157 am:0.0713 going:0.0723 bit:0.0425,:0.1406,:0.2197 and:0.1934)
		(,:0.1260 I:0.1089�:0.0703 going:0.0728 bit:0.0405,:0.1445,:0.2314 and:0.1855)
		(,:0.1196 I:0.1025�:0.0737 going:0.0703 bit:0.0396,:0.1396,:0.2344 and:0.1777)
		(,:0.1196 I:0.1025�:0.0737 going:0.0703 bit:0.0396,:0.1396,:0.2344 and:0.1777)
 and
------
		( the:0.1001�:0.0383 not:0.0659 lot:0.0179,:0.1406.:0.1504 the:0.0625 the:0.0649)
		( you:0.0967�:0.0723 not:0.0894 few:0.0251,:0.0928.:0.1709 and:0.0986 I:0.1621)
		( I:0.1494 will:0.0713 not:0.0972 bit:0.0315,:0.1016.:0.1846 and:0.1895 I:0.3242)
		( I:0.1465 have:0.0713 sure:0.0791 bit:0.0408,:0.1152,:0.1670 and:0.2129 I:0.4082)
		( I:0.1445 am:0.0674 sure:0.0737 bit:0.0461,:0.1226,:0.1855 and:0.2061 I:0.3965)
		( I:0.1367 am:0.0669 going:0.0713 bit:0.0476,:0.1289,:0.1963 and:0.2119 I:0.3789)
		( I:0.1318 am:0.0688 going:0.0718 bit:0.0457,:0.1338,:0.1973 and:0.2021 I:0.3730)
		( I:0.1270 am:0.0703 going:0.0723 bit:0.0452,:0.1357,:0.2080 and:0.2021 I:0.3613)
		( I:0.1201 am:0.0688 going:0.0723 bit:0.0432,:0.1426,:0.2188 and:0.1934 I:0.3555)
		( I:0.1157 am:0.0713 going:0.0723 bit:0.0425,:0.1406,:0.2197 and:0.1934 I:0.3477)
		( I:0.1089�:0.0703 going:0.0728 bit:0.0405,:0.1445,:0.2314 and:0.1855 I:0.3301)
		( I:0.1025�:0.0737 going:0.0703 bit:0.0396,:0.1396,:0.2344 and:0.1777 I:0.3125)
		( I:0.1025�:0.0737 going:0.0703 bit:0.0396,:0.1396,:0.2344 and:0.1777 I:0.3125)
 I'm a very different from the language.
I
1850: sample 0: Hello, I'm a language model,
------
		(,:0.0796 you:0.0908�:0.0425 sure:0.0369 lot:0.0215,:0.1069.:0.1846 the:0.0869)
		( the:0.0449 you:0.1104�:0.1494 a:0.0552 great:0.0294 that:0.1113.:0.2637 but:0.0752)
		( the:0.0388 I:0.1182�:0.1719 a:0.0566 good:0.0398 that:0.1104.:0.2930 but:0.1377)
		(,:0.0767 I:0.1338�:0.1650 a:0.0742 good:0.0439 that:0.0894.:0.1914 but:0.1357)
		(,:0.0933 I:0.1416�:0.1523 a:0.0757 good:0.0474 that:0.0815.:0.1895 but:0.1455)
		(,:0.0957 I:0.1436�:0.1631 a:0.0786 good:0.0483 that:0.0767.:0.1855 but:0.1416)
		(,:0.1011 I:0.1445�:0.1689 a:0.0815 good:0.0486 that:0.0737.:0.1895 but:0.1377)
		(,:0.0996 I:0.1523�:0.1758 a:0.0864 good:0.0488 that:0.0728.:0.1875 and:0.1309)
		(,:0.1025 I:0.1553�:0.1846 a:0.0869 good:0.0491 that:0.0718.:0.1875 and:0.1235)
		(,:0.1011 I:0.1562�:0.1943 a:0.0894 good:0.0491 that:0.0693.:0.1865 and:0.1250)
		(,:0.1016 I:0.1582�:0.2031 a:0.0894 good:0.0493 that:0.0684.:0.1875 and:0.1206)
		(,:0.0991 I:0.1602�:0.2031 a:0.0874 good:0.0479 that:0.0679.:0.1875 and:0.1167)
		(,:0.0991 I:0.1602�:0.2031 a:0.0874 good:0.0479 that:0.0679.:0.1875 and:0.1167)
 and
------
		( you:0.0908�:0.0425 sure:0.0369 lot:0.0215,:0.1069.:0.1846 the:0.0869 the:0.0884)
		( you:0.1104�:0.1494 a:0.0552 great:0.0294 that:0.1113.:0.2637 but:0.0752 I:0.1396)
		( I:0.1182�:0.1719 a:0.0566 good:0.0398 that:0.1104.:0.2930 but:0.1377 I:0.3770)
		( I:0.1338�:0.1650 a:0.0742 good:0.0439 that:0.0894.:0.1914 but:0.1357 I:0.3926)
		( I:0.1416�:0.1523 a:0.0757 good:0.0474 that:0.0815.:0.1895 but:0.1455 I:0.3691)
		( I:0.1436�:0.1631 a:0.0786 good:0.0483 that:0.0767.:0.1855 but:0.1416 I:0.3672)
		( I:0.1445�:0.1689 a:0.0815 good:0.0486 that:0.0737.:0.1895 but:0.1377 I:0.3730)
		( I:0.1523�:0.1758 a:0.0864 good:0.0488 that:0.0728.:0.1875 and:0.1309 I:0.3770)
		( I:0.1553�:0.1846 a:0.0869 good:0.0491 that:0.0718.:0.1875 and:0.1235 I:0.3809)
		( I:0.1562�:0.1943 a:0.0894 good:0.0491 that:0.0693.:0.1865 and:0.1250 I:0.3848)
		( I:0.1582�:0.2031 a:0.0894 good:0.0493 that:0.0684.:0.1875 and:0.1206 I:0.3887)
		( I:0.1602�:0.2031 a:0.0874 good:0.0479 that:0.0679.:0.1875 and:0.1167 I:0.3926)
		( I:0.1602�:0.2031 a:0.0874 good:0.0479 that:0.0679.:0.1875 and:0.1167 I:0.3926)
 I'm a language-based.
- The language
2000: sample 0: Hello, I'm a language model,
------
		(,:0.0830 you:0.1191�:0.0659 not:0.0845 lot:0.0559,:0.0854.:0.1973 the:0.0669)
		( the:0.0376 you:0.1172�:0.1650 not:0.0918 little:0.0623 that:0.0708.:0.2812 I:0.1108)
		( the:0.0243 you:0.1099�:0.1650 sure:0.1035 little:0.0825 that:0.0938.:0.2871 and:0.1230)
		(,:0.0588 I:0.1133�:0.1797 sure:0.0972 little:0.1143 that:0.0850.:0.1943 and:0.1562)
		(,:0.0737 I:0.1226�:0.1650 sure:0.0938 little:0.0996,:0.0742,:0.1973 and:0.1611)
		(,:0.0732 I:0.1250�:0.1758 sure:0.0972 little:0.0967,:0.0732,:0.1973 and:0.1738)
		(,:0.0679 I:0.1289�:0.1689 sure:0.0962 little:0.0957,:0.0718,:0.1982 and:0.1670)
		(,:0.0674 I:0.1338�:0.1807 sure:0.1021 little:0.0952,:0.0723,:0.1982 and:0.1660)
		(,:0.0645 I:0.1348�:0.1758 sure:0.1025 little:0.0947,:0.0703,:0.2002 and:0.1680)
		(,:0.0635 I:0.1406�:0.1797 sure:0.1030 little:0.0947,:0.0703,:0.1982 and:0.1670)
		(,:0.0608 I:0.1406�:0.1846 sure:0.1040 little:0.0942,:0.0708,:0.2002 and:0.1680)
		(,:0.0576 I:0.1436�:0.1895 sure:0.1055 little:0.0938,:0.0693,:0.2021 and:0.1689)
		(,:0.0576 I:0.1436�:0.1895 sure:0.1055 little:0.0938,:0.0693,:0.2021 and:0.1689)
 and
------
		( you:0.1191�:0.0659 not:0.0845 lot:0.0559,:0.0854.:0.1973 the:0.0669 you:0.0649)
		( you:0.1172�:0.1650 not:0.0918 little:0.0623 that:0.0708.:0.2812 I:0.1108 I:0.3242)
		( you:0.1099�:0.1650 sure:0.1035 little:0.0825 that:0.0938.:0.2871 and:0.1230 I:0.5117)
		( I:0.1133�:0.1797 sure:0.0972 little:0.1143 that:0.0850.:0.1943 and:0.1562 I:0.4941)
		( I:0.1226�:0.1650 sure:0.0938 little:0.0996,:0.0742,:0.1973 and:0.1611 I:0.4473)
		( I:0.1250�:0.1758 sure:0.0972 little:0.0967,:0.0732,:0.1973 and:0.1738 I:0.4570)
		( I:0.1289�:0.1689 sure:0.0962 little:0.0957,:0.0718,:0.1982 and:0.1670 I:0.4609)
		( I:0.1338�:0.1807 sure:0.1021 little:0.0952,:0.0723,:0.1982 and:0.1660 I:0.4727)
		( I:0.1348�:0.1758 sure:0.1025 little:0.0947,:0.0703,:0.2002 and:0.1680 I:0.4746)
		( I:0.1406�:0.1797 sure:0.1030 little:0.0947,:0.0703,:0.1982 and:0.1670 I:0.4727)
		( I:0.1406�:0.1846 sure:0.1040 little:0.0942,:0.0708,:0.2002 and:0.1680 I:0.4727)
		( I:0.1436�:0.1895 sure:0.1055 little:0.0938,:0.0693,:0.2021 and:0.1689 I:0.4883)
		( I:0.1436�:0.1895 sure:0.1055 little:0.0938,:0.0693,:0.2021 and:0.1689 I:0.4883)
 I'm a little bit more.
I'm a
2150: sample 0: Hello, I'm a language model,
------
		( and:0.0393 you:0.1455�:0.0532 sure:0.1040 lot:0.0332,:0.0942,:0.1504 the:0.0796)
		( the:0.0457 you:0.1309�:0.0903 not:0.1953 great:0.0354 that:0.1299.:0.2109 I:0.1396)
		( the:0.0327 you:0.1582�:0.1436 not:0.1035 good:0.0386 that:0.1338.:0.2891 but:0.1729)
		( the:0.0522 you:0.1396�:0.1514 sure:0.1226 good:0.0378 that:0.1396.:0.2422 but:0.1924)
		(,:0.0605 you:0.1367�:0.1348 sure:0.1104 good:0.0393 that:0.1328.:0.2305 but:0.2266)
		(,:0.0598 you:0.1338�:0.1406 sure:0.1162 bit:0.0400 that:0.1289.:0.2324 but:0.2109)
		(,:0.0554 you:0.1309�:0.1406 sure:0.1123 bit:0.0410 that:0.1250.:0.2344 but:0.2070)
		(,:0.0540 you:0.1299�:0.1396 sure:0.1133 bit:0.0422 that:0.1221.:0.2383 but:0.1973)
		(,:0.0513 I:0.1250�:0.1396 sure:0.1157 bit:0.0417 that:0.1187.:0.2285 but:0.2002)
		(,:0.0498 I:0.1299�:0.1396 a:0.1118 bit:0.0430 that:0.1157.:0.2324 but:0.1914)
		(,:0.0471 I:0.1328�:0.1406 a:0.1143 bit:0.0439 that:0.1128.:0.2363 but:0.1855)
		(,:0.0454 I:0.1387�:0.1406 a:0.1182 bit:0.0437 I:0.1074.:0.2402 but:0.1777)
		(,:0.0454 I:0.1387�:0.1406 a:0.1182 bit:0.0437 I:0.1074.:0.2402 but:0.1777)
 but
------
		( you:0.1455�:0.0532 sure:0.1040 lot:0.0332,:0.0942,:0.1504 the:0.0796 I:0.1191)
		( you:0.1309�:0.0903 not:0.1953 great:0.0354 that:0.1299.:0.2109 I:0.1396 I:0.3594)
		( you:0.1582�:0.1436 not:0.1035 good:0.0386 that:0.1338.:0.2891 but:0.1729 I:0.3672)
		( you:0.1396�:0.1514 sure:0.1226 good:0.0378 that:0.1396.:0.2422 but:0.1924 I:0.3691)
		( you:0.1367�:0.1348 sure:0.1104 good:0.0393 that:0.1328.:0.2305 but:0.2266 I:0.3613)
		( you:0.1338�:0.1406 sure:0.1162 bit:0.0400 that:0.1289.:0.2324 but:0.2109 I:0.3750)
		( you:0.1309�:0.1406 sure:0.1123 bit:0.0410 that:0.1250.:0.2344 but:0.2070 I:0.3789)
		( you:0.1299�:0.1396 sure:0.1133 bit:0.0422 that:0.1221.:0.2383 but:0.1973 I:0.3789)
		( I:0.1250�:0.1396 sure:0.1157 bit:0.0417 that:0.1187.:0.2285 but:0.2002 I:0.3828)
		( I:0.1299�:0.1396 a:0.1118 bit:0.0430 that:0.1157.:0.2324 but:0.1914 I:0.3848)
		( I:0.1328�:0.1406 a:0.1143 bit:0.0439 that:0.1128.:0.2363 but:0.1855 I:0.3867)
		( I:0.1387�:0.1406 a:0.1182 bit:0.0437 I:0.1074.:0.2402 but:0.1777 I:0.3906)
		( I:0.1387�:0.1406 a:0.1182 bit:0.0437 I:0.1074.:0.2402 but:0.1777 I:0.3906)
 I think it is a lot of a lot of people
2300: sample 0: Hello, I'm a language model,
------
		( and:0.0486 you:0.1064�:0.0593 going:0.0679 good:0.0312,:0.0747.:0.1572 the:0.1006)
		( the:0.0391 you:0.1387�:0.0869 not:0.1680 little:0.0415 that:0.0835.:0.2617 I:0.1729)
		( the:0.0369 you:0.1924�:0.1226 sure:0.1196 good:0.0374 for:0.1143.:0.3184 but:0.1250)
		(,:0.0562 you:0.2314�:0.1484 sure:0.0996 good:0.0469 for:0.1011.:0.2109 but:0.1455)
		(,:0.0610 you:0.2324�:0.1445 not:0.0894 good:0.0498 for:0.0981.:0.2080 but:0.1641)
		(,:0.0593 you:0.2275�:0.1455 sure:0.0933 good:0.0510 for:0.0972.:0.2070 but:0.1562)
		(,:0.0583 you:0.2256�:0.1465 sure:0.1001 good:0.0493 for:0.0962.:0.2061 but:0.1523)
		(,:0.0574 you:0.2227�:0.1484 sure:0.1001 good:0.0491 for:0.0928.:0.2051 but:0.1436)
		(,:0.0564 you:0.2217�:0.1504 sure:0.1074 good:0.0491 for:0.0923.:0.1963 but:0.1416)
		(,:0.0566 you:0.2295�:0.1455 sure:0.1079 good:0.0488 for:0.0894.:0.1953 but:0.1387)
		(,:0.0569 you:0.2168�:0.1494 sure:0.1157 good:0.0488 for:0.0889.:0.1963 but:0.1367)
		(,:0.0569 you:0.2148�:0.1455 sure:0.1167 good:0.0486 for:0.0859.:0.1973 but:0.1348)
		(,:0.0569 you:0.2148�:0.1455 sure:0.1167 good:0.0486 for:0.0859.:0.1973 but:0.1348)
 but
------
		( you:0.1064�:0.0593 going:0.0679 good:0.0312,:0.0747.:0.1572 the:0.1006 I:0.1426)
		( you:0.1387�:0.0869 not:0.1680 little:0.0415 that:0.0835.:0.2617 I:0.1729 I:0.4258)
		( you:0.1924�:0.1226 sure:0.1196 good:0.0374 for:0.1143.:0.3184 but:0.1250 I:0.3848)
		( you:0.2314�:0.1484 sure:0.0996 good:0.0469 for:0.1011.:0.2109 but:0.1455 I:0.3730)
		( you:0.2324�:0.1445 not:0.0894 good:0.0498 for:0.0981.:0.2080 but:0.1641 I:0.3672)
		( you:0.2275�:0.1455 sure:0.0933 good:0.0510 for:0.0972.:0.2070 but:0.1562 I:0.3633)
		( you:0.2256�:0.1465 sure:0.1001 good:0.0493 for:0.0962.:0.2061 but:0.1523 I:0.3652)
		( you:0.2227�:0.1484 sure:0.1001 good:0.0491 for:0.0928.:0.2051 but:0.1436 I:0.3672)
		( you:0.2217�:0.1504 sure:0.1074 good:0.0491 for:0.0923.:0.1963 but:0.1416 I:0.3691)
		( you:0.2295�:0.1455 sure:0.1079 good:0.0488 for:0.0894.:0.1953 but:0.1387 I:0.3691)
		( you:0.2168�:0.1494 sure:0.1157 good:0.0488 for:0.0889.:0.1963 but:0.1367 I:0.3711)
		( you:0.2148�:0.1455 sure:0.1167 good:0.0486 for:0.0859.:0.1973 but:0.1348 I:0.3711)
		( you:0.2148�:0.1455 sure:0.1167 good:0.0486 for:0.0859.:0.1973 but:0.1348 I:0.3711)
 I think it's a good idea.
I think
2450: sample 0: Hello, I'm a language model,
------
		(-:0.0364 I:0.1523�:0.0527 not:0.1172 great:0.0275,:0.1069,:0.2158 the:0.1631)
		( the:0.0327 the:0.1006 was:0.0518 not:0.2852 little:0.0417 for:0.0498,:0.1885 I:0.1680)
		( the:0.0366 you:0.1006�:0.0605 not:0.1699 little:0.0461 of:0.0742,:0.1621 and:0.0967)
		(,:0.0537 you:0.0923�:0.0659 not:0.0952 bit:0.0537 of:0.0613.:0.1211 but:0.1074)
		(,:0.0569 you:0.0928�:0.0615 not:0.0928 bit:0.0596 of:0.0557.:0.1152 but:0.1182)
		(,:0.0540 you:0.0947�:0.0620 not:0.0923 bit:0.0598 of:0.0540.:0.1152 but:0.1108)
		(,:0.0518 you:0.0977�:0.0591 not:0.0928 bit:0.0596 of:0.0525,:0.1118 but:0.1064)
		(,:0.0508 you:0.1006 am:0.0635 not:0.0884 bit:0.0596 that:0.0525,:0.1094 but:0.1045)
		(,:0.0483 you:0.1011 am:0.0640 not:0.0894 bit:0.0591 that:0.0513,:0.1104 and:0.1006)
		(.:0.0503 you:0.1016 am:0.0649 not:0.0850 bit:0.0605 that:0.0513,:0.1079 and:0.1021)
		(.:0.0503 you:0.1021 am:0.0659 not:0.0840 bit:0.0583 that:0.0498,:0.1060 and:0.0977)
		(.:0.0503 you:0.1030 am:0.0674 not:0.0811 bit:0.0581 that:0.0486,:0.1064 and:0.0991)
		(.:0.0503 you:0.1030 am:0.0674 not:0.0811 bit:0.0581 that:0.0486,:0.1064 and:0.0991)
 and
------
		( I:0.1523�:0.0527 not:0.1172 great:0.0275,:0.1069,:0.2158 the:0.1631 the:0.1270)
		( the:0.1006 was:0.0518 not:0.2852 little:0.0417 for:0.0498,:0.1885 I:0.1680 I:0.3887)
		( you:0.1006�:0.0605 not:0.1699 little:0.0461 of:0.0742,:0.1621 and:0.0967 I:0.2441)
		( you:0.0923�:0.0659 not:0.0952 bit:0.0537 of:0.0613.:0.1211 but:0.1074 I:0.2656)
		( you:0.0928�:0.0615 not:0.0928 bit:0.0596 of:0.0557.:0.1152 but:0.1182 I:0.2598)
		( you:0.0947�:0.0620 not:0.0923 bit:0.0598 of:0.0540.:0.1152 but:0.1108 I:0.2676)
		( you:0.0977�:0.0591 not:0.0928 bit:0.0596 of:0.0525,:0.1118 but:0.1064 I:0.2695)
		( you:0.1006 am:0.0635 not:0.0884 bit:0.0596 that:0.0525,:0.1094 but:0.1045 I:0.2812)
		( you:0.1011 am:0.0640 not:0.0894 bit:0.0591 that:0.0513,:0.1104 and:0.1006 I:0.2949)
		( you:0.1016 am:0.0649 not:0.0850 bit:0.0605 that:0.0513,:0.1079 and:0.1021 I:0.3086)
		( you:0.1021 am:0.0659 not:0.0840 bit:0.0583 that:0.0498,:0.1060 and:0.0977 I:0.3066)
		( you:0.1030 am:0.0674 not:0.0811 bit:0.0581 that:0.0486,:0.1064 and:0.0991 I:0.3203)
		( you:0.1030 am:0.0674 not:0.0811 bit:0.0581 that:0.0486,:0.1064 and:0.0991 I:0.3203)
 I'm a language model.
The language model is
2600: sample 0: Hello, I'm a language model,
------
		( and:0.0253 I:0.1543�:0.1445 not:0.0593 lot:0.0344 that:0.0854,:0.2090 the:0.0967)
		(.:0.0359 I:0.0972�:0.1475 not:0.1572 little:0.0698 that:0.0972.:0.2295 I:0.2061)
		(.:0.0312 you:0.1133�:0.1963 not:0.1167 little:0.0776 that:0.1270.:0.2305 and:0.1050)
		(.:0.0442 I:0.1060�:0.2451 a:0.1523 little:0.0889 that:0.1289.:0.2090 but:0.1279)
		(.:0.0410 I:0.1064�:0.2217 a:0.1465 little:0.0869 that:0.1230.:0.2070 but:0.1377)
		(.:0.0391 I:0.1045�:0.2148 a:0.1543 little:0.0874 that:0.1191.:0.2080 but:0.1270)
		(.:0.0398 we:0.1094�:0.2080 a:0.1465 little:0.0835 that:0.1133.:0.2090 but:0.1196)
		(.:0.0410 we:0.1118�:0.2031 a:0.1475 little:0.0835 that:0.1064.:0.2002 and:0.1177)
		(.:0.0420 we:0.1182�:0.1875 a:0.1484 little:0.0830 that:0.1035.:0.2031 and:0.1143)
		(.:0.0427 we:0.1245�:0.1826 a:0.1494 little:0.0830 that:0.0972.:0.1992 and:0.1133)
		(.:0.0432 we:0.1299�:0.1797 a:0.1426 little:0.0781 that:0.0938.:0.1963 and:0.1089)
		(.:0.0435 we:0.1338�:0.1758 a:0.1367 little:0.0781 I:0.0938.:0.1973 and:0.1069)
		(.:0.0435 we:0.1338�:0.1758 a:0.1367 little:0.0781 I:0.0938.:0.1973 and:0.1069)
 and
------
		( I:0.1543�:0.1445 not:0.0593 lot:0.0344 that:0.0854,:0.2090 the:0.0967 you:0.1060)
		( I:0.0972�:0.1475 not:0.1572 little:0.0698 that:0.0972.:0.2295 I:0.2061 I:0.4062)
		( you:0.1133�:0.1963 not:0.1167 little:0.0776 that:0.1270.:0.2305 and:0.1050 I:0.3438)
		( I:0.1060�:0.2451 a:0.1523 little:0.0889 that:0.1289.:0.2090 but:0.1279 I:0.3711)
		( I:0.1064�:0.2217 a:0.1465 little:0.0869 that:0.1230.:0.2070 but:0.1377 I:0.3496)
		( I:0.1045�:0.2148 a:0.1543 little:0.0874 that:0.1191.:0.2080 but:0.1270 I:0.3477)
		( we:0.1094�:0.2080 a:0.1465 little:0.0835 that:0.1133.:0.2090 but:0.1196 I:0.3398)
		( we:0.1118�:0.2031 a:0.1475 little:0.0835 that:0.1064.:0.2002 and:0.1177 I:0.3418)
		( we:0.1182�:0.1875 a:0.1484 little:0.0830 that:0.1035.:0.2031 and:0.1143 I:0.3438)
		( we:0.1245�:0.1826 a:0.1494 little:0.0830 that:0.0972.:0.1992 and:0.1133 I:0.3457)
		( we:0.1299�:0.1797 a:0.1426 little:0.0781 that:0.0938.:0.1963 and:0.1089 I:0.3457)
		( we:0.1338�:0.1758 a:0.1367 little:0.0781 I:0.0938.:0.1973 and:0.1069 I:0.3477)
		( we:0.1338�:0.1758 a:0.1367 little:0.0781 I:0.0938.:0.1973 and:0.1069 I:0.3477)
 I am a language model. I am a language model
2750: sample 0: Hello, I'm a language model,
------
		(,:0.0283 I:0.2148�:0.1187 not:0.0776 great:0.0684,:0.1133,:0.1807 you:0.1006)
		(.:0.0369 I:0.1279�:0.1226 not:0.1602 great:0.0620 that:0.0747.:0.2344 I:0.1738)
		( the:0.0391 you:0.1445�:0.1357 not:0.1416 little:0.0718 that:0.0708.:0.2285 and:0.0947)
		(,:0.0498 you:0.1484�:0.1855 a:0.1206 little:0.0825 that:0.0688.:0.1973 I:0.1279)
		(,:0.0525 you:0.1484�:0.1699 a:0.1260 little:0.0801 that:0.0669.:0.1943 but:0.1318)
		(,:0.0500 you:0.1455�:0.1680 a:0.1240 little:0.0776 that:0.0649.:0.1934 I:0.1270)
		(,:0.0520 you:0.1445�:0.1582 a:0.1250 little:0.0757,:0.0613.:0.1963 I:0.1270)
		(,:0.0525 you:0.1426�:0.1553 a:0.1328 little:0.0713,:0.0598.:0.1924 I:0.1318)
		(,:0.0544 you:0.1426�:0.1475 a:0.1328 little:0.0693,:0.0601.:0.1895 I:0.1338)
		(,:0.0547 you:0.1416�:0.1377 a:0.1338 little:0.0654,:0.0586.:0.1895 I:0.1357)
		(,:0.0559 you:0.1406�:0.1367 a:0.1279 little:0.0635,:0.0571.:0.1865 I:0.1426)
		(,:0.0569 you:0.1406�:0.1289 a:0.1299 little:0.0601,:0.0537.:0.1826 I:0.1445)
		(,:0.0569 you:0.1406�:0.1289 a:0.1299 little:0.0601,:0.0537.:0.1826 I:0.1445)
 I
------
		( I:0.2148�:0.1187 not:0.0776 great:0.0684,:0.1133,:0.1807 you:0.1006�:0.0703)
		( I:0.1279�:0.1226 not:0.1602 great:0.0620 that:0.0747.:0.2344 I:0.1738'm:0.3359)
		( you:0.1445�:0.1357 not:0.1416 little:0.0718 that:0.0708.:0.2285 and:0.0947'm:0.3340)
		( you:0.1484�:0.1855 a:0.1206 little:0.0825 that:0.0688.:0.1973 I:0.1279'm:0.2500)
		( you:0.1484�:0.1699 a:0.1260 little:0.0801 that:0.0669.:0.1943 but:0.1318'm:0.2559)
		( you:0.1455�:0.1680 a:0.1240 little:0.0776 that:0.0649.:0.1934 I:0.1270'm:0.2500)
		( you:0.1445�:0.1582 a:0.1250 little:0.0757,:0.0613.:0.1963 I:0.1270'm:0.2471)
		( you:0.1426�:0.1553 a:0.1328 little:0.0713,:0.0598.:0.1924 I:0.1318'm:0.2441)
		( you:0.1426�:0.1475 a:0.1328 little:0.0693,:0.0601.:0.1895 I:0.1338'm:0.2520)
		( you:0.1416�:0.1377 a:0.1338 little:0.0654,:0.0586.:0.1895 I:0.1357'm:0.2490)
		( you:0.1406�:0.1367 a:0.1279 little:0.0635,:0.0571.:0.1865 I:0.1426'm:0.2451)
		( you:0.1406�:0.1289 a:0.1299 little:0.0601,:0.0537.:0.1826 I:0.1445'm:0.2539)
		( you:0.1406�:0.1289 a:0.1299 little:0.0601,:0.0537.:0.1826 I:0.1445'm:0.2539)
'm a bit more familiar with the language. I'm
2900: sample 0: Hello, I'm a language model,
------
		(-:0.0227 I:0.1758�:0.0820 going:0.0859 good:0.0354,:0.0864.:0.2383 you:0.0820)
		(.:0.0248 I:0.1543�:0.0903 going:0.1309 little:0.0481.:0.0908.:0.2793 I:0.1914)
		( the:0.0168 you:0.1377 am:0.0879 not:0.1211 little:0.0640 that:0.1201.:0.2676 I:0.1182)
		(,:0.0364 you:0.1699�:0.0967 a:0.1040 little:0.0972 that:0.1328.:0.2412 I:0.1797)
		(,:0.0454 you:0.1719�:0.0928 not:0.1079 little:0.0957 that:0.1357.:0.2412 I:0.1758)
		(,:0.0444 you:0.1768�:0.0933 going:0.1123 little:0.0947 that:0.1348.:0.2402 I:0.1846)
		(,:0.0442 you:0.1797�:0.0942 going:0.1211 little:0.0908 that:0.1357.:0.2295 I:0.1875)
		(,:0.0439 you:0.1855�:0.0952 going:0.1206 little:0.0889 that:0.1328.:0.2295 I:0.1895)
		(,:0.0461 you:0.1943�:0.0967 going:0.1206 little:0.0854 that:0.1309.:0.2217 I:0.1943)
		(,:0.0466 you:0.2012�:0.0981 going:0.1279 little:0.0815 that:0.1309.:0.2227 I:0.1963)
		(,:0.0481 you:0.1992�:0.0991 going:0.1289 little:0.0781 that:0.1289.:0.2246 I:0.1895)
		(,:0.0508 you:0.2080�:0.0952 going:0.1299 little:0.0747 that:0.1260.:0.2148 I:0.1904)
		(,:0.0508 you:0.2080�:0.0952 going:0.1299 little:0.0747 that:0.1260.:0.2148 I:0.1904)
 I
------
		( I:0.1758�:0.0820 going:0.0859 good:0.0354,:0.0864.:0.2383 you:0.0820'm:0.0601)
		( I:0.1543�:0.0903 going:0.1309 little:0.0481.:0.0908.:0.2793 I:0.1914'm:0.2754)
		( you:0.1377 am:0.0879 not:0.1211 little:0.0640 that:0.1201.:0.2676 I:0.1182'm:0.2832)
		( you:0.1699�:0.0967 a:0.1040 little:0.0972 that:0.1328.:0.2412 I:0.1797'm:0.2471)
		( you:0.1719�:0.0928 not:0.1079 little:0.0957 that:0.1357.:0.2412 I:0.1758'm:0.2578)
		( you:0.1768�:0.0933 going:0.1123 little:0.0947 that:0.1348.:0.2402 I:0.1846'm:0.2432)
		( you:0.1797�:0.0942 going:0.1211 little:0.0908 that:0.1357.:0.2295 I:0.1875'm:0.2441)
		( you:0.1855�:0.0952 going:0.1206 little:0.0889 that:0.1328.:0.2295 I:0.1895'm:0.2441)
		( you:0.1943�:0.0967 going:0.1206 little:0.0854 that:0.1309.:0.2217 I:0.1943'm:0.2324)
		( you:0.2012�:0.0981 going:0.1279 little:0.0815 that:0.1309.:0.2227 I:0.1963'm:0.2344)
		( you:0.1992�:0.0991 going:0.1289 little:0.0781 that:0.1289.:0.2246 I:0.1895'm:0.2334)
		( you:0.2080�:0.0952 going:0.1299 little:0.0747 that:0.1260.:0.2148 I:0.1904'm:0.2236)
		( you:0.2080�:0.0952 going:0.1299 little:0.0747 that:0.1260.:0.2148 I:0.1904'm:0.2236)
'm a language model, I'm a language model,
