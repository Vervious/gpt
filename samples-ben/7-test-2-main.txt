1: sample 0: Hello, I'm a language model,
------
		(Hello:0.4902,:0.6562 I:0.4590'm:0.5977 a:0.1953 language:0.4277 model:0.4434,:0.5234)
		(Hello:0.0008,:0.0027 I:0.0005'm:0.0009 a:0.0005 language:0.0008 model:0.0008,:0.0021)
		(Hello:0.0002,:0.0009,:0.0002,:0.0002 Murray:0.0003 splendid:0.0002).:0.0002,:0.0012)
		( Often:0.0002,:0.0005,:0.0003,:0.0003 Murray:0.0003,:0.0002).:0.0003,:0.0008)
		( Murray:0.0002,:0.0004,:0.0003,:0.0003 Murray:0.0003,:0.0003).:0.0003,:0.0007)
		( Murray:0.0002,:0.0003,:0.0003,:0.0003,:0.0002,:0.0003).:0.0003,:0.0006)
		( Murray:0.0002,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005)
		( Murray:0.0002 the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005)
		( the:0.0002 the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005)
		( the:0.0002 the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005)
		( the:0.0002 the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005)
		( the:0.0003 the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0004)
		( the:0.0003 the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0004)
,
------
		(,:0.6562 I:0.4590'm:0.5977 a:0.1953 language:0.4277 model:0.4434,:0.5234,:0.5820)
		(,:0.0027 I:0.0005'm:0.0009 a:0.0005 language:0.0008 model:0.0008,:0.0021,:0.0027)
		(,:0.0009,:0.0002,:0.0002 Murray:0.0003 splendid:0.0002).:0.0002,:0.0012,:0.0011)
		(,:0.0005,:0.0003,:0.0003 Murray:0.0003,:0.0002).:0.0003,:0.0008,:0.0007)
		(,:0.0004,:0.0003,:0.0003 Murray:0.0003,:0.0003).:0.0003,:0.0007,:0.0006)
		(,:0.0003,:0.0003,:0.0003,:0.0002,:0.0003).:0.0003,:0.0006,:0.0005)
		(,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005,:0.0005)
		( the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005,:0.0005)
		( the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005,:0.0005)
		( the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005,:0.0004)
		( the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0005,:0.0004)
		( the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0004,:0.0004)
		( the:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0003,:0.0004,:0.0004)
,,,,,,,,,,,
50: sample 0: Hello, I'm a language model,
------
		(Hello:0.3711,:0.9883 I:0.8398'm:0.5703 a:0.5898 language:0.5547 model:0.4160,:0.9688)
		(-:0.0309 and:0.0356 a:0.0176,:0.0659 a:0.0120 to:0.0496,:0.0688 and:0.0554)
		(-:0.0337 and:0.0231 a:0.0178,:0.0684 a:0.0104,:0.0466,:0.0698 and:0.0378)
		(-:0.0352 the:0.0215 the:0.0198,:0.0708 a:0.0101,:0.0515,:0.0728 the:0.0376)
		(-:0.0386 the:0.0248 the:0.0228,:0.0713 the:0.0110,:0.0530,:0.0728 the:0.0422)
		(-:0.0410 the:0.0277 the:0.0247,:0.0718 the:0.0119,:0.0549,:0.0728 the:0.0461)
		(-:0.0437 the:0.0310 the:0.0267,:0.0718 the:0.0129,:0.0566,:0.0728 the:0.0474)
		(-:0.0464 the:0.0327 the:0.0282,:0.0723 the:0.0136,:0.0566,:0.0732 the:0.0500)
		(-:0.0493 the:0.0354 the:0.0298,:0.0723 the:0.0143,:0.0586,:0.0732 the:0.0515)
		(-:0.0522 the:0.0364 the:0.0315,:0.0723 the:0.0152,:0.0586,:0.0732 the:0.0513)
		(-:0.0552 the:0.0383 the:0.0322,:0.0728 the:0.0156,:0.0605,:0.0732 the:0.0530)
		(-:0.0569 the:0.0405 the:0.0332,:0.0728 the:0.0165,:0.0605,:0.0732 the:0.0542)
		(-:0.0603 the:0.0415 the:0.0349,:0.0728 the:0.0168,:0.0608,:0.0732 the:0.0542)
 the
------
		(,:0.9883 I:0.8398'm:0.5703 a:0.5898 language:0.5547 model:0.4160,:0.9688 the:0.9805)
		( and:0.0356 a:0.0176,:0.0659 a:0.0120 to:0.0496,:0.0688 and:0.0554 a:0.0128)
		( and:0.0231 a:0.0178,:0.0684 a:0.0104,:0.0466,:0.0698 and:0.0378 a:0.0114)
		( the:0.0215 the:0.0198,:0.0708 a:0.0101,:0.0515,:0.0728 the:0.0376 a:0.0112)
		( the:0.0248 the:0.0228,:0.0713 the:0.0110,:0.0530,:0.0728 the:0.0422 the:0.0121)
		( the:0.0277 the:0.0247,:0.0718 the:0.0119,:0.0549,:0.0728 the:0.0461 the:0.0131)
		( the:0.0310 the:0.0267,:0.0718 the:0.0129,:0.0566,:0.0728 the:0.0474 the:0.0138)
		( the:0.0327 the:0.0282,:0.0723 the:0.0136,:0.0566,:0.0732 the:0.0500 the:0.0150)
		( the:0.0354 the:0.0298,:0.0723 the:0.0143,:0.0586,:0.0732 the:0.0515 the:0.0157)
		( the:0.0364 the:0.0315,:0.0723 the:0.0152,:0.0586,:0.0732 the:0.0513 the:0.0161)
		( the:0.0383 the:0.0322,:0.0728 the:0.0156,:0.0605,:0.0732 the:0.0530 the:0.0171)
		( the:0.0405 the:0.0332,:0.0728 the:0.0165,:0.0605,:0.0732 the:0.0542 the:0.0181)
		( the:0.0415 the:0.0349,:0.0728 the:0.0168,:0.0608,:0.0732 the:0.0542 the:0.0186)
 the the the the the the the the the the the
200: sample 0: Hello, I'm a language model,
------
		(Hello:0.0630,:0.9961 I:0.8633'm:0.4355 a:0.7109 language:0.3066 model:0.4570,:0.9883)
		( of:0.0223 the:0.0598 of:0.0996 not:0.0684�:0.0120.:0.1245.:0.1211 the:0.0835)
		( of:0.1543 the:0.0576.:0.1021 not:0.0859 few:0.0140.:0.1245.:0.1216 the:0.0820)
		( of:0.1187 the:0.0591.:0.1113 not:0.0884 few:0.0151.:0.1318.:0.1177 the:0.0771)
		( of:0.0942 the:0.0591.:0.1357 not:0.0854 few:0.0160.:0.1270.:0.1196 the:0.0732)
		( of:0.0801 the:0.0588.:0.1582 not:0.0830 few:0.0170.:0.1279.:0.1157 the:0.0723)
		( of:0.0698 the:0.0588.:0.1729 not:0.0801 few:0.0179.:0.1299.:0.1177 the:0.0708)
		( of:0.0620 the:0.0571.:0.1943 not:0.0728 few:0.0178.:0.1309.:0.1128 the:0.0684)
		( of:0.0579 the:0.0571.:0.2061 not:0.0698 few:0.0184.:0.1260.:0.1152 the:0.0679)
		( of:0.0540 the:0.0571.:0.2168 not:0.0669 few:0.0189.:0.1279.:0.1104 the:0.0674)
		( of:0.0500 the:0.0571.:0.2275 not:0.0605 few:0.0189.:0.1289.:0.1123 the:0.0669)
		( of:0.0476 the:0.0571.:0.2383 not:0.0579 few:0.0189,:0.1235.:0.1079 the:0.0664)
		( of:0.0452 the:0.0571.:0.2373 not:0.0552 few:0.0189.:0.1260.:0.1089 the:0.0664)
 the
------
		(,:0.9961 I:0.8633'm:0.4355 a:0.7109 language:0.3066 model:0.4570,:0.9883 the:0.9766)
		( the:0.0598 of:0.0996 not:0.0684�:0.0120.:0.1245.:0.1211 the:0.0835 other:0.0078)
		( the:0.0576.:0.1021 not:0.0859 few:0.0140.:0.1245.:0.1216 the:0.0820 same:0.0086)
		( the:0.0591.:0.1113 not:0.0884 few:0.0151.:0.1318.:0.1177 the:0.0771 same:0.0093)
		( the:0.0591.:0.1357 not:0.0854 few:0.0160.:0.1270.:0.1196 the:0.0732 same:0.0095)
		( the:0.0588.:0.1582 not:0.0830 few:0.0170.:0.1279.:0.1157 the:0.0723 same:0.0095)
		( the:0.0588.:0.1729 not:0.0801 few:0.0179.:0.1299.:0.1177 the:0.0708 same:0.0095)
		( the:0.0571.:0.1943 not:0.0728 few:0.0178.:0.1309.:0.1128 the:0.0684 same:0.0095)
		( the:0.0571.:0.2061 not:0.0698 few:0.0184.:0.1260.:0.1152 the:0.0679 same:0.0095)
		( the:0.0571.:0.2168 not:0.0669 few:0.0189.:0.1279.:0.1104 the:0.0674 same:0.0095)
		( the:0.0571.:0.2275 not:0.0605 few:0.0189.:0.1289.:0.1123 the:0.0669 same:0.0095)
		( the:0.0571.:0.2383 not:0.0579 few:0.0189,:0.1235.:0.1079 the:0.0664 same:0.0095)
		( the:0.0571.:0.2373 not:0.0552 few:0.0189.:0.1260.:0.1089 the:0.0664 same:0.0096)
 same of the same, the same of the time of
350: sample 0: Hello, I'm a language model,
------
		(Hello:0.0145,:0.9922 I:0.6484'm:0.0430 a:0.7969 language:0.2422 model:0.5195,:0.9961)
		(,:0.0723 the:0.0869.:0.2266 not:0.1279�:0.0654,:0.2578,:0.1572 and:0.1079)
		(,:0.0635 and:0.1143.:0.1084 not:0.1406�:0.0850,:0.2617,:0.1602 and:0.1108)
		(,:0.0508 and:0.1387.:0.0613 not:0.1221�:0.0728,:0.2676,:0.1670 and:0.1113)
		(
:0.0520 and:0.1465.:0.0435 not:0.1094�:0.0623,:0.2637,:0.1758 and:0.1099)
		(
:0.0525 and:0.1475 think:0.0471 not:0.0962�:0.0544,:0.2617,:0.1768 and:0.1089)
		(
:0.0530 and:0.1475 think:0.0530 not:0.0879�:0.0491,:0.2578,:0.1777 and:0.1084)
		(
:0.0530 and:0.1484 think:0.0579 not:0.0850 lot:0.0483,:0.2578,:0.1738 and:0.1055)
		(
:0.0513 and:0.1484 think:0.0596 not:0.0767 lot:0.0491,:0.2451,:0.1689 and:0.1050)
		(
:0.0496 and:0.1406 think:0.0635 not:0.0732 lot:0.0498,:0.2441,:0.1738 and:0.1016)
		(
:0.0481 and:0.1416 think:0.0654 not:0.0698 lot:0.0503,:0.2314,:0.1719 and:0.1016)
		(
:0.0464 and:0.1416 think:0.0659 not:0.0664 lot:0.0493,:0.2324,:0.1680 and:0.0986)
		(
:0.0464 and:0.1338 think:0.0684 not:0.0649 lot:0.0498,:0.2197,:0.1660 and:0.0986)
 and
------
		(,:0.9922 I:0.6484'm:0.0430 a:0.7969 language:0.2422 model:0.5195,:0.9961 and:0.9961)
		( the:0.0869.:0.2266 not:0.1279�:0.0654,:0.2578,:0.1572 and:0.1079 the:0.0718)
		( and:0.1143.:0.1084 not:0.1406�:0.0850,:0.2617,:0.1602 and:0.1108 the:0.0664)
		( and:0.1387.:0.0613 not:0.1221�:0.0728,:0.2676,:0.1670 and:0.1113 the:0.0603)
		( and:0.1465.:0.0435 not:0.1094�:0.0623,:0.2637,:0.1758 and:0.1099 the:0.0571)
		( and:0.1475 think:0.0471 not:0.0962�:0.0544,:0.2617,:0.1768 and:0.1089 the:0.0544)
		( and:0.1475 think:0.0530 not:0.0879�:0.0491,:0.2578,:0.1777 and:0.1084 the:0.0537)
		( and:0.1484 think:0.0579 not:0.0850 lot:0.0483,:0.2578,:0.1738 and:0.1055 the:0.0515)
		( and:0.1484 think:0.0596 not:0.0767 lot:0.0491,:0.2451,:0.1689 and:0.1050 the:0.0510)
		( and:0.1406 think:0.0635 not:0.0732 lot:0.0498,:0.2441,:0.1738 and:0.1016 the:0.0505)
		( and:0.1416 think:0.0654 not:0.0698 lot:0.0503,:0.2314,:0.1719 and:0.1016 the:0.0500)
		( and:0.1416 think:0.0659 not:0.0664 lot:0.0493,:0.2324,:0.1680 and:0.0986 the:0.0496)
		( and:0.1338 think:0.0684 not:0.0649 lot:0.0498,:0.2197,:0.1660 and:0.0986 the:0.0479)
 the same, and the same, and the same,
500: sample 0: Hello, I'm a language model,
------
		(Hello:0.0060,:0.9883 I:0.7617'm:0.0295 a:0.8672 language:0.4277 model:0.7539,:1.0000)
		(.:0.0420 and:0.1245.:0.2539 not:0.1060�:0.0242,:0.1680 of:0.1680 and:0.1226)
		(.:0.0505 and:0.1270.:0.1875 not:0.1187�:0.0225,:0.2012,:0.1729 I:0.0972)
		(.:0.0474 and:0.1211.:0.1367 not:0.0991 bit:0.0243,:0.2119,:0.1885 I:0.1836)
		(.:0.0505 and:0.1147.:0.1030 not:0.0903 bit:0.0258,:0.2070,:0.1807 I:0.2383)
		(,:0.0559 and:0.1079.:0.0767 not:0.0894 bit:0.0266,:0.2041,:0.1816 I:0.2656)
		(,:0.0618 and:0.1011.:0.0635 not:0.0884 bit:0.0267,:0.2002,:0.1797 I:0.2734)
		(,:0.0664 and:0.0981.:0.0525 not:0.0903 bit:0.0261,:0.1982,:0.1777 I:0.2793)
		(,:0.0718 and:0.0952 have:0.0559 not:0.0981 bit:0.0255,:0.2070,:0.1865 I:0.2734)
		(,:0.0757 and:0.0942 have:0.0596 not:0.1001 good:0.0258,:0.2061,:0.1836 I:0.2695)
		(,:0.0776 and:0.0913 have:0.0640 not:0.1030 good:0.0261,:0.2021,:0.1924 I:0.2656)
		(,:0.0801 and:0.0884 have:0.0684 not:0.1055 good:0.0273,:0.2119,:0.1914 I:0.2617)
		(,:0.0825 and:0.0884 have:0.0698 not:0.1084 good:0.0278,:0.2119,:0.1914 I:0.2451)
 I
------
		(,:0.9883 I:0.7617'm:0.0295 a:0.8672 language:0.4277 model:0.7539,:1.0000 I:1.0000)
		( and:0.1245.:0.2539 not:0.1060�:0.0242,:0.1680 of:0.1680 and:0.1226 have:0.0608)
		( and:0.1270.:0.1875 not:0.1187�:0.0225,:0.2012,:0.1729 I:0.0972 am:0.0500)
		( and:0.1211.:0.1367 not:0.0991 bit:0.0243,:0.2119,:0.1885 I:0.1836 am:0.0527)
		( and:0.1147.:0.1030 not:0.0903 bit:0.0258,:0.2070,:0.1807 I:0.2383 am:0.0510)
		( and:0.1079.:0.0767 not:0.0894 bit:0.0266,:0.2041,:0.1816 I:0.2656 am:0.0474)
		( and:0.1011.:0.0635 not:0.0884 bit:0.0267,:0.2002,:0.1797 I:0.2734 have:0.0442)
		( and:0.0981.:0.0525 not:0.0903 bit:0.0261,:0.1982,:0.1777 I:0.2793 have:0.0469)
		( and:0.0952 have:0.0559 not:0.0981 bit:0.0255,:0.2070,:0.1865 I:0.2734 have:0.0474)
		( and:0.0942 have:0.0596 not:0.1001 good:0.0258,:0.2061,:0.1836 I:0.2695 have:0.0481)
		( and:0.0913 have:0.0640 not:0.1030 good:0.0261,:0.2021,:0.1924 I:0.2656 can:0.0520)
		( and:0.0884 have:0.0684 not:0.1055 good:0.0273,:0.2119,:0.1914 I:0.2617 have:0.0532)
		( and:0.0884 have:0.0698 not:0.1084 good:0.0278,:0.2119,:0.1914 I:0.2451 can:0.0549)
 can be a good. I am not a good.
650: sample 0: Hello, I'm a language model,
------
		(Hello:0.0076,:0.9883 I:0.8203'm:0.0266 a:0.9492 language:0.5664 model:0.8125,:1.0000)
		(,:0.0491 the:0.1260.:0.1514 not:0.0586 lot:0.0166,:0.1177 of:0.1924 the:0.0579)
		(.:0.0737 the:0.1147.:0.1973 not:0.0679 bit:0.0281.:0.1709 of:0.1406 I:0.1055)
		(.:0.1050 the:0.0850.:0.1582 not:0.0684 bit:0.0347.:0.1816.:0.1387 I:0.1416)
		(.:0.1133 the:0.0713.:0.1250 not:0.0698 bit:0.0359.:0.1875.:0.1436 I:0.1279)
		(.:0.1167 the:0.0635.:0.1030 not:0.0742 bit:0.0356,:0.1729.:0.1484 and:0.1147)
		(.:0.1167 and:0.0625.:0.0854 not:0.0806 bit:0.0344,:0.1738.:0.1416 and:0.1260)
		(.:0.1147 and:0.0598 have:0.0923 not:0.0830 few:0.0337,:0.1758.:0.1357 and:0.1245)
		(.:0.1099 and:0.0588 have:0.1055 not:0.0859 few:0.0337,:0.1787.:0.1396 and:0.1299)
		(.:0.1084 and:0.0581 have:0.1147 not:0.0869 few:0.0342,:0.1816.:0.1348 and:0.1299)
		(.:0.1035 and:0.0588 have:0.1182 not:0.0884 few:0.0337,:0.1748.:0.1299 and:0.1299)
		(.:0.1025 and:0.0579 have:0.1226 not:0.0898 few:0.0332,:0.1768.:0.1260 and:0.1299)
		(.:0.0977 and:0.0569 have:0.1270 not:0.0894 few:0.0339,:0.1689.:0.1289 and:0.1309)
 and
------
		(,:0.9883 I:0.8203'm:0.0266 a:0.9492 language:0.5664 model:0.8125,:1.0000 and:0.9961)
		( the:0.1260.:0.1514 not:0.0586 lot:0.0166,:0.1177 of:0.1924 the:0.0579 the:0.0757)
		( the:0.1147.:0.1973 not:0.0679 bit:0.0281.:0.1709 of:0.1406 I:0.1055 I:0.1113)
		( the:0.0850.:0.1582 not:0.0684 bit:0.0347.:0.1816.:0.1387 I:0.1416 I:0.1279)
		( the:0.0713.:0.1250 not:0.0698 bit:0.0359.:0.1875.:0.1436 I:0.1279 I:0.0981)
		( the:0.0635.:0.1030 not:0.0742 bit:0.0356,:0.1729.:0.1484 and:0.1147 I:0.0728)
		( and:0.0625.:0.0854 not:0.0806 bit:0.0344,:0.1738.:0.1416 and:0.1260 I:0.0601)
		( and:0.0598 have:0.0923 not:0.0830 few:0.0337,:0.1758.:0.1357 and:0.1245 I:0.0500)
		( and:0.0588 have:0.1055 not:0.0859 few:0.0337,:0.1787.:0.1396 and:0.1299 I:0.0447)
		( and:0.0581 have:0.1147 not:0.0869 few:0.0342,:0.1816.:0.1348 and:0.1299 I:0.0415)
		( and:0.0588 have:0.1182 not:0.0884 few:0.0337,:0.1748.:0.1299 and:0.1299 I:0.0386)
		( and:0.0579 have:0.1226 not:0.0898 few:0.0332,:0.1768.:0.1260 and:0.1299 I:0.0371)
		( and:0.0569 have:0.1270 not:0.0894 few:0.0339,:0.1689.:0.1289 and:0.1309 I:0.0359)
 I have been able to be able to be able to
800: sample 0: Hello, I'm a language model,
------
		(Hello:0.0047,:0.9883 I:0.9102'm:0.0293 a:0.9688 language:0.7812 model:0.9219,:1.0000)
		(,:0.0894 the:0.0996.:0.0957 not:0.0659 lot:0.0305,:0.1533 of:0.1592 I:0.0742)
		(,:0.0713 the:0.0889.:0.1074 not:0.1182 bit:0.0483.:0.1118,:0.1260 I:0.1621)
		(,:0.0723 the:0.0879 have:0.0908 not:0.1201 bit:0.0549.:0.1050.:0.1235 I:0.1963)
		(,:0.0630 the:0.0815 have:0.0859 not:0.1318 bit:0.0557.:0.1084.:0.1465 I:0.1836)
		(,:0.0613 the:0.0767 have:0.0903 not:0.1445 bit:0.0559.:0.1104.:0.1533 I:0.1768)
		(,:0.0596 the:0.0713 have:0.0884 not:0.1602 bit:0.0522,:0.1069.:0.1650 I:0.1846)
		(,:0.0586 the:0.0674 have:0.0879 not:0.1641 bit:0.0486,:0.1133.:0.1650 I:0.1855)
		(,:0.0596 the:0.0640 have:0.0845 not:0.1768 bit:0.0454,:0.1118.:0.1562 I:0.1924)
		(,:0.0588 the:0.0608 have:0.0864 not:0.1738 bit:0.0417,:0.1177.:0.1572 I:0.1904)
		(,:0.0581 the:0.0581 have:0.0845 not:0.1816 bit:0.0376,:0.1172.:0.1504 I:0.2002)
		(,:0.0571 I:0.0610 have:0.0825 not:0.1797 bit:0.0349,:0.1113.:0.1445 I:0.2012)
		(,:0.0564 I:0.0620 have:0.0815 not:0.1787 bit:0.0325,:0.1113.:0.1455 I:0.2031)
 I
------
		(,:0.9883 I:0.9102'm:0.0293 a:0.9688 language:0.7812 model:0.9219,:1.0000 I:1.0000)
		( the:0.0996.:0.0957 not:0.0659 lot:0.0305,:0.1533 of:0.1592 I:0.0742 have:0.0732)
		( the:0.0889.:0.1074 not:0.1182 bit:0.0483.:0.1118,:0.1260 I:0.1621 have:0.0649)
		( the:0.0879 have:0.0908 not:0.1201 bit:0.0549.:0.1050.:0.1235 I:0.1963�:0.0669)
		( the:0.0815 have:0.0859 not:0.1318 bit:0.0557.:0.1084.:0.1465 I:0.1836�:0.0623)
		( the:0.0767 have:0.0903 not:0.1445 bit:0.0559.:0.1104.:0.1533 I:0.1768 have:0.0605)
		( the:0.0713 have:0.0884 not:0.1602 bit:0.0522,:0.1069.:0.1650 I:0.1846 have:0.0613)
		( the:0.0674 have:0.0879 not:0.1641 bit:0.0486,:0.1133.:0.1650 I:0.1855 have:0.0654)
		( the:0.0640 have:0.0845 not:0.1768 bit:0.0454,:0.1118.:0.1562 I:0.1924 have:0.0664)
		( the:0.0608 have:0.0864 not:0.1738 bit:0.0417,:0.1177.:0.1572 I:0.1904 have:0.0684)
		( the:0.0581 have:0.0845 not:0.1816 bit:0.0376,:0.1172.:0.1504 I:0.2002 have:0.0674)
		( I:0.0610 have:0.0825 not:0.1797 bit:0.0349,:0.1113.:0.1445 I:0.2012 have:0.0664)
		( I:0.0620 have:0.0815 not:0.1787 bit:0.0325,:0.1113.:0.1455 I:0.2031 have:0.0698)
 have a few-to-to-to-to
950: sample 0: Hello, I'm a language model,
------
		(Hello:0.0038,:0.9883 I:0.9375'm:0.0098 a:0.9688 language:0.9023 model:0.9766,:1.0000)
		(,:0.0708 the:0.1011.:0.3047 not:0.0947 lot:0.0493,:0.1167,:0.1025 the:0.0645)
		(.:0.0815 the:0.0610.:0.2949 not:0.1504 lot:0.0505,:0.1196,:0.1289 and:0.0874)
		(.:0.0801 and:0.0811.:0.1602 not:0.1611 lot:0.0488 of:0.1021.:0.1426 I:0.1035)
		(,:0.0723 and:0.0850.:0.1035 not:0.1719 lot:0.0449 of:0.1040.:0.1768 and:0.1260)
		(,:0.0771 and:0.0889.:0.0742 not:0.1895 lot:0.0400 of:0.1050.:0.1963 and:0.1504)
		(,:0.0791 and:0.0894 have:0.0703 not:0.2041 few:0.0381.:0.1060.:0.2158 and:0.1631)
		(,:0.0825 and:0.0903 have:0.0708 not:0.2129 few:0.0391.:0.1084.:0.2178 and:0.1787)
		(,:0.0840 and:0.0928 have:0.0679 not:0.2139 few:0.0396.:0.1089.:0.2236 and:0.1865)
		(,:0.0835 and:0.0923 have:0.0664 not:0.2168 few:0.0400.:0.1099.:0.2295 and:0.1855)
		(,:0.0835 and:0.0928 have:0.0659 not:0.2109 few:0.0398.:0.1152.:0.2266 and:0.1943)
		(,:0.0835 and:0.0933 have:0.0635 not:0.2168 few:0.0398.:0.1128.:0.2354 and:0.1934)
		(,:0.0835 and:0.0938 have:0.0654 not:0.2129 few:0.0396.:0.1123.:0.2334 and:0.1934)
 and
------
		(,:0.9883 I:0.9375'm:0.0098 a:0.9688 language:0.9023 model:0.9766,:1.0000 and:0.9961)
		( the:0.1011.:0.3047 not:0.0947 lot:0.0493,:0.1167,:0.1025 the:0.0645 the:0.0908)
		( the:0.0610.:0.2949 not:0.1504 lot:0.0505,:0.1196,:0.1289 and:0.0874 I:0.1289)
		( and:0.0811.:0.1602 not:0.1611 lot:0.0488 of:0.1021.:0.1426 I:0.1035 I:0.2227)
		( and:0.0850.:0.1035 not:0.1719 lot:0.0449 of:0.1040.:0.1768 and:0.1260 I:0.1904)
		( and:0.0889.:0.0742 not:0.1895 lot:0.0400 of:0.1050.:0.1963 and:0.1504 I:0.1768)
		( and:0.0894 have:0.0703 not:0.2041 few:0.0381.:0.1060.:0.2158 and:0.1631 I:0.1592)
		( and:0.0903 have:0.0708 not:0.2129 few:0.0391.:0.1084.:0.2178 and:0.1787 I:0.1543)
		( and:0.0928 have:0.0679 not:0.2139 few:0.0396.:0.1089.:0.2236 and:0.1865 I:0.1514)
		( and:0.0923 have:0.0664 not:0.2168 few:0.0400.:0.1099.:0.2295 and:0.1855 I:0.1494)
		( and:0.0928 have:0.0659 not:0.2109 few:0.0398.:0.1152.:0.2266 and:0.1943 I:0.1484)
		( and:0.0933 have:0.0635 not:0.2168 few:0.0398.:0.1128.:0.2354 and:0.1934 I:0.1553)
		( and:0.0938 have:0.0654 not:0.2129 few:0.0396.:0.1123.:0.2334 and:0.1934 I:0.1543)
 I can be a lot of the language.
The
1100: sample 0: Hello, I'm a language model,
------
		(Hello:0.0045,:0.9922 I:0.9688'm:0.0062 a:0.9805 language:0.9336 model:0.9844,:1.0000)
		(,:0.0977 the:0.1011�:0.1035 a:0.0447 lot:0.0371 of:0.0918 of:0.1133 the:0.0630)
		(,:0.0684 you:0.0586.:0.0850 not:0.0835 few:0.0452,:0.1025,:0.1260 but:0.0923)
		(,:0.0879 you:0.0698�:0.0574 not:0.1011 few:0.0554,:0.1211,:0.1484 but:0.1187)
		(,:0.0767 you:0.0762 am:0.0630 not:0.1138 few:0.0552,:0.1387,:0.1709 but:0.1250)
		(,:0.0737 you:0.0796 am:0.0635 not:0.1216 few:0.0505,:0.1426,:0.1924 but:0.1191)
		(,:0.0698 you:0.0791 am:0.0623 not:0.1270 few:0.0461,:0.1514,:0.2090 and:0.1162)
		(,:0.0688 you:0.0771 have:0.0630 not:0.1289 good:0.0430,:0.1475,:0.2197 and:0.1216)
		(,:0.0659 you:0.0762 have:0.0630 not:0.1318 good:0.0457,:0.1445,:0.2295 and:0.1279)
		(,:0.0635 you:0.0757 have:0.0645 not:0.1289 good:0.0461,:0.1426,:0.2305 and:0.1289)
		(,:0.0635 you:0.0732 have:0.0659 not:0.1338 good:0.0466,:0.1406,:0.2422 and:0.1338)
		(,:0.0613 you:0.0708 have:0.0674 not:0.1328 good:0.0474,:0.1396,:0.2432 and:0.1357)
		(,:0.0593 you:0.0688 have:0.0659 not:0.1309 good:0.0469,:0.1328,:0.2432 and:0.1367)
 and
------
		(,:0.9922 I:0.9688'm:0.0062 a:0.9805 language:0.9336 model:0.9844,:1.0000 and:1.0000)
		( the:0.1011�:0.1035 a:0.0447 lot:0.0371 of:0.0918 of:0.1133 the:0.0630 the:0.1250)
		( you:0.0586.:0.0850 not:0.0835 few:0.0452,:0.1025,:0.1260 but:0.0923 I:0.0938)
		( you:0.0698�:0.0574 not:0.1011 few:0.0554,:0.1211,:0.1484 but:0.1187 I:0.0981)
		( you:0.0762 am:0.0630 not:0.1138 few:0.0552,:0.1387,:0.1709 but:0.1250 I:0.0898)
		( you:0.0796 am:0.0635 not:0.1216 few:0.0505,:0.1426,:0.1924 but:0.1191 I:0.0854)
		( you:0.0791 am:0.0623 not:0.1270 few:0.0461,:0.1514,:0.2090 and:0.1162 I:0.0840)
		( you:0.0771 have:0.0630 not:0.1289 good:0.0430,:0.1475,:0.2197 and:0.1216 I:0.0811)
		( you:0.0762 have:0.0630 not:0.1318 good:0.0457,:0.1445,:0.2295 and:0.1279 I:0.0811)
		( you:0.0757 have:0.0645 not:0.1289 good:0.0461,:0.1426,:0.2305 and:0.1289 I:0.0796)
		( you:0.0732 have:0.0659 not:0.1338 good:0.0466,:0.1406,:0.2422 and:0.1338 I:0.0781)
		( you:0.0708 have:0.0674 not:0.1328 good:0.0474,:0.1396,:0.2432 and:0.1357 I:0.0771)
		( you:0.0688 have:0.0659 not:0.1309 good:0.0469,:0.1328,:0.2432 and:0.1367 I:0.0767)
 I can’t know what you can’
1250: sample 0: Hello, I'm a language model,
------
		(Hello:0.0058,:0.9922 I:0.9883 Dragonbound:0.0047 a:0.9844 language:0.9883 model:0.9922,:1.0000)
		(,:0.0613 the:0.0718�:0.1475 not:0.0209 lot:0.0977 of:0.0986 of:0.1187 the:0.0669)
		(,:0.0566 it:0.0684�:0.1040 not:0.0554 lot:0.0659 that:0.1157,:0.1260 I:0.1270)
		(,:0.0645 it:0.0601�:0.0928 not:0.0737 bit:0.0566 that:0.1387,:0.1377 I:0.1914)
		(,:0.0601 it:0.0564�:0.0884 not:0.0903 bit:0.0557 that:0.1523,:0.1406 I:0.2090)
		(,:0.0591 it:0.0562�:0.0854 not:0.1069 bit:0.0520 that:0.1631,:0.1455 I:0.2285)
		(,:0.0571 it:0.0557�:0.0859 not:0.1162 bit:0.0498 that:0.1582.:0.1494 I:0.2285)
		(,:0.0557 it:0.0562�:0.0840 not:0.1279 bit:0.0454 that:0.1631.:0.1572 I:0.2402)
		(,:0.0544 it:0.0557�:0.0835 not:0.1357 bit:0.0430 that:0.1611.:0.1562 I:0.2520)
		(,:0.0537 it:0.0552�:0.0894 not:0.1377 bit:0.0408 that:0.1592.:0.1572 I:0.2520)
		(,:0.0532 it:0.0552�:0.0869 not:0.1406 bit:0.0378 that:0.1670.:0.1582 I:0.2539)
		(,:0.0527 it:0.0552�:0.0889 not:0.1445 bit:0.0361 that:0.1572.:0.1602 I:0.2539)
		(�:0.0525 it:0.0554�:0.0918 not:0.1484 bit:0.0347 that:0.1562.:0.1543 I:0.2676)
 I
------
		(,:0.9922 I:0.9883 Dragonbound:0.0047 a:0.9844 language:0.9883 model:0.9922,:1.0000 I:1.0000)
		( the:0.0718�:0.1475 not:0.0209 lot:0.0977 of:0.0986 of:0.1187 the:0.0669�:0.0977)
		( it:0.0684�:0.1040 not:0.0554 lot:0.0659 that:0.1157,:0.1260 I:0.1270�:0.0889)
		( it:0.0601�:0.0928 not:0.0737 bit:0.0566 that:0.1387,:0.1377 I:0.1914�:0.1230)
		( it:0.0564�:0.0884 not:0.0903 bit:0.0557 that:0.1523,:0.1406 I:0.2090�:0.1396)
		( it:0.0562�:0.0854 not:0.1069 bit:0.0520 that:0.1631,:0.1455 I:0.2285�:0.1396)
		( it:0.0557�:0.0859 not:0.1162 bit:0.0498 that:0.1582.:0.1494 I:0.2285�:0.1426)
		( it:0.0562�:0.0840 not:0.1279 bit:0.0454 that:0.1631.:0.1572 I:0.2402�:0.1387)
		( it:0.0557�:0.0835 not:0.1357 bit:0.0430 that:0.1611.:0.1562 I:0.2520�:0.1367)
		( it:0.0552�:0.0894 not:0.1377 bit:0.0408 that:0.1592.:0.1572 I:0.2520�:0.1348)
		( it:0.0552�:0.0869 not:0.1406 bit:0.0378 that:0.1670.:0.1582 I:0.2539�:0.1338)
		( it:0.0552�:0.0889 not:0.1445 bit:0.0361 that:0.1572.:0.1602 I:0.2539�:0.1250)
		( it:0.0554�:0.0918 not:0.1484 bit:0.0347 that:0.1562.:0.1543 I:0.2676�:0.1245)
’ll be a language that is a language.
1400: sample 0: Hello, I'm a language model,
------
		(Hello:0.0034,:0.9961 I:0.9922 Dragonbound:0.0051 a:0.9883 language:0.9922 model:0.9961,:1.0000)
		(,:0.0420 the:0.0625�:0.1650 not:0.0305 lot:0.0664 that:0.0952,:0.1816 and:0.0806)
		(,:0.0649 you:0.1045�:0.1367 not:0.0598 bit:0.0659 that:0.1279,:0.1621 I:0.1309)
		(,:0.0669 you:0.1128�:0.1167 not:0.0801 bit:0.0791 that:0.1602,:0.1738 I:0.1318)
		(,:0.0635 you:0.1147�:0.1104 not:0.1030 bit:0.0806 that:0.1660,:0.1758 I:0.1216)
		(,:0.0596 you:0.1108�:0.1099 not:0.1211 bit:0.0811 that:0.1670,:0.1748 I:0.1167)
		(,:0.0562 you:0.1069�:0.1079 not:0.1426 bit:0.0786 that:0.1709,:0.1709 and:0.1113)
		(,:0.0552 you:0.1011�:0.1074 not:0.1572 bit:0.0771 that:0.1680,:0.1748 and:0.1152)
		(,:0.0527 you:0.0996�:0.1035 not:0.1670 bit:0.0762 that:0.1758,:0.1738 and:0.1191)
		(,:0.0505 you:0.0957�:0.1064 not:0.1787 bit:0.0732 that:0.1748,:0.1738 and:0.1221)
		(,:0.0500 you:0.0898�:0.1045 not:0.1816 bit:0.0728 that:0.1748,:0.1650 and:0.1226)
		(,:0.0481 you:0.0869�:0.1030 not:0.1973 bit:0.0723 that:0.1758,:0.1670 and:0.1221)
		(,:0.0479 you:0.0840�:0.1021 not:0.2031 bit:0.0723 that:0.1758,:0.1680 and:0.1221)
 and
------
		(,:0.9961 I:0.9922 Dragonbound:0.0051 a:0.9883 language:0.9922 model:0.9961,:1.0000 and:1.0000)
		( the:0.0625�:0.1650 not:0.0305 lot:0.0664 that:0.0952,:0.1816 and:0.0806 the:0.0771)
		( you:0.1045�:0.1367 not:0.0598 bit:0.0659 that:0.1279,:0.1621 I:0.1309 I:0.1963)
		( you:0.1128�:0.1167 not:0.0801 bit:0.0791 that:0.1602,:0.1738 I:0.1318 I:0.2275)
		( you:0.1147�:0.1104 not:0.1030 bit:0.0806 that:0.1660,:0.1758 I:0.1216 I:0.2275)
		( you:0.1108�:0.1099 not:0.1211 bit:0.0811 that:0.1670,:0.1748 I:0.1167 I:0.2305)
		( you:0.1069�:0.1079 not:0.1426 bit:0.0786 that:0.1709,:0.1709 and:0.1113 I:0.2490)
		( you:0.1011�:0.1074 not:0.1572 bit:0.0771 that:0.1680,:0.1748 and:0.1152 I:0.2461)
		( you:0.0996�:0.1035 not:0.1670 bit:0.0762 that:0.1758,:0.1738 and:0.1191 I:0.2539)
		( you:0.0957�:0.1064 not:0.1787 bit:0.0732 that:0.1748,:0.1738 and:0.1221 I:0.2539)
		( you:0.0898�:0.1045 not:0.1816 bit:0.0728 that:0.1748,:0.1650 and:0.1226 I:0.2656)
		( you:0.0869�:0.1030 not:0.1973 bit:0.0723 that:0.1758,:0.1670 and:0.1221 I:0.2656)
		( you:0.0840�:0.1021 not:0.2031 bit:0.0723 that:0.1758,:0.1680 and:0.1221 I:0.2656)
 I’ll be a language that is a language
1550: sample 0: Hello, I'm a language model,
------
		(}):0.0026,:0.9961 I:0.9961 Dragonbound:0.0050 a:0.9922 language:0.9961 model:1.0000,:1.0000)
		(,:0.1191 the:0.0549�:0.1035 sure:0.0271 lot:0.0315 of:0.1279,:0.1670 and:0.1562)
		(,:0.1172 and:0.0771�:0.0898 sure:0.0520 bit:0.0315 that:0.1206.:0.2334 I:0.1514)
		(,:0.1260 and:0.1001�:0.0840 sure:0.0603 bit:0.0359 that:0.1250.:0.2178 and:0.1387)
		(,:0.1182 and:0.1030�:0.0776 sure:0.0635 bit:0.0369 that:0.1172.:0.2148 and:0.1338)
		(,:0.1152 and:0.1030�:0.0728 sure:0.0635 bit:0.0369 that:0.1074.:0.2139 and:0.1309)
		(,:0.1133 and:0.1021�:0.0669 sure:0.0630 bit:0.0364 that:0.0996.:0.2158 and:0.1279)
		(,:0.1118 and:0.1001�:0.0664 sure:0.0598 bit:0.0361 that:0.0952.:0.2129 and:0.1260)
		(,:0.1074 and:0.1016�:0.0640 sure:0.0576 bit:0.0364 that:0.0938.:0.2119 and:0.1245)
		(,:0.1035 and:0.1011�:0.0645 going:0.0542 bit:0.0366 that:0.0898.:0.2100 and:0.1226)
		(,:0.0996 and:0.1006�:0.0645 going:0.0544 bit:0.0371 that:0.0894.:0.2119 and:0.1206)
		(,:0.0962 and:0.1030�:0.0649 going:0.0552 bit:0.0376 that:0.0884.:0.2109 and:0.1191)
		(,:0.0952 and:0.1035�:0.0654 going:0.0562 bit:0.0383 that:0.0879.:0.2129 and:0.1143)
 and
------
		(,:0.9961 I:0.9961 Dragonbound:0.0050 a:0.9922 language:0.9961 model:1.0000,:1.0000 and:1.0000)
		( the:0.0549�:0.1035 sure:0.0271 lot:0.0315 of:0.1279,:0.1670 and:0.1562 I:0.1050)
		( and:0.0771�:0.0898 sure:0.0520 bit:0.0315 that:0.1206.:0.2334 I:0.1514 I:0.4043)
		( and:0.1001�:0.0840 sure:0.0603 bit:0.0359 that:0.1250.:0.2178 and:0.1387 I:0.4023)
		( and:0.1030�:0.0776 sure:0.0635 bit:0.0369 that:0.1172.:0.2148 and:0.1338 I:0.3672)
		( and:0.1030�:0.0728 sure:0.0635 bit:0.0369 that:0.1074.:0.2139 and:0.1309 I:0.3633)
		( and:0.1021�:0.0669 sure:0.0630 bit:0.0364 that:0.0996.:0.2158 and:0.1279 I:0.3516)
		( and:0.1001�:0.0664 sure:0.0598 bit:0.0361 that:0.0952.:0.2129 and:0.1260 I:0.3457)
		( and:0.1016�:0.0640 sure:0.0576 bit:0.0364 that:0.0938.:0.2119 and:0.1245 I:0.3574)
		( and:0.1011�:0.0645 going:0.0542 bit:0.0366 that:0.0898.:0.2100 and:0.1226 I:0.3555)
		( and:0.1006�:0.0645 going:0.0544 bit:0.0371 that:0.0894.:0.2119 and:0.1206 I:0.3672)
		( and:0.1030�:0.0649 going:0.0552 bit:0.0376 that:0.0884.:0.2109 and:0.1191 I:0.3809)
		( and:0.1035�:0.0654 going:0.0562 bit:0.0383 that:0.0879.:0.2129 and:0.1143 I:0.3789)
 I can be used to be used to be used to
1700: sample 0: Hello, I'm a language model,
------
		(Hello:0.0041,:0.9961 I:1.0000 respawn:0.0048 a:0.9922 language:1.0000 model:1.0000,:1.0000)
		(,:0.0515 you:0.0425�:0.1030 not:0.0483 lot:0.0325 of:0.2217.:0.1953 and:0.1270)
		(,:0.0493 and:0.0327 will:0.0806 not:0.0588 lot:0.0437 of:0.1582.:0.2402 and:0.1201)
		(,:0.0486 the:0.0376 will:0.0786 not:0.0718 lot:0.0386 of:0.1504.:0.2266 which:0.1318)
		(,:0.0479 the:0.0432 will:0.0742 not:0.0786 bit:0.0408 that:0.1582.:0.2363 which:0.1387)
		(,:0.0493 the:0.0459 will:0.0713 not:0.0840 bit:0.0400 that:0.1533.:0.2383 which:0.1377)
		(,:0.0483 the:0.0498 will:0.0688 not:0.0864 bit:0.0398 that:0.1602.:0.2383 which:0.1338)
		(,:0.0476 the:0.0515 will:0.0674 not:0.0864 bit:0.0386 that:0.1572.:0.2432 which:0.1309)
		(,:0.0471 and:0.0537 will:0.0645 not:0.0830 bit:0.0388 that:0.1484.:0.2383 and:0.1240)
		(,:0.0469 and:0.0564'm:0.0645 not:0.0806 bit:0.0381 that:0.1465.:0.2373 and:0.1216)
		(,:0.0466 and:0.0610'm:0.0640 not:0.0796 bit:0.0386 that:0.1475.:0.2344 and:0.1230)
		(,:0.0466 and:0.0625'm:0.0645 not:0.0781 bit:0.0391 that:0.1396.:0.2354 and:0.1211)
		(,:0.0457 and:0.0659'm:0.0649 not:0.0776 bit:0.0386 that:0.1387.:0.2363 and:0.1201)
 and
------
		(,:0.9961 I:1.0000 respawn:0.0048 a:0.9922 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( you:0.0425�:0.1030 not:0.0483 lot:0.0325 of:0.2217.:0.1953 and:0.1270 I:0.1030)
		( and:0.0327 will:0.0806 not:0.0588 lot:0.0437 of:0.1582.:0.2402 and:0.1201 I:0.1455)
		( the:0.0376 will:0.0786 not:0.0718 lot:0.0386 of:0.1504.:0.2266 which:0.1318 I:0.1328)
		( the:0.0432 will:0.0742 not:0.0786 bit:0.0408 that:0.1582.:0.2363 which:0.1387 I:0.1348)
		( the:0.0459 will:0.0713 not:0.0840 bit:0.0400 that:0.1533.:0.2383 which:0.1377 I:0.1533)
		( the:0.0498 will:0.0688 not:0.0864 bit:0.0398 that:0.1602.:0.2383 which:0.1338 I:0.1943)
		( the:0.0515 will:0.0674 not:0.0864 bit:0.0386 that:0.1572.:0.2432 which:0.1309 I:0.2324)
		( and:0.0537 will:0.0645 not:0.0830 bit:0.0388 that:0.1484.:0.2383 and:0.1240 I:0.2656)
		( and:0.0564'm:0.0645 not:0.0806 bit:0.0381 that:0.1465.:0.2373 and:0.1216 I:0.3027)
		( and:0.0610'm:0.0640 not:0.0796 bit:0.0386 that:0.1475.:0.2344 and:0.1230 I:0.3281)
		( and:0.0625'm:0.0645 not:0.0781 bit:0.0391 that:0.1396.:0.2354 and:0.1211 I:0.3555)
		( and:0.0659'm:0.0649 not:0.0776 bit:0.0386 that:0.1387.:0.2363 and:0.1201 I:0.3711)
 I'm a language of the language.
The language
1850: sample 0: Hello, I'm a language model,
------
		(Hello:0.0032,:0.9961 I:1.0000 respawn:0.0049 a:0.9922 language:1.0000 model:1.0000,:1.0000)
		(,:0.0410 the:0.0515�:0.1572 I:0.0227 lot:0.0283 that:0.1455.:0.1846 I:0.1592)
		(,:0.0437 I:0.0588 am:0.0986 now:0.0231 lot:0.0337 that:0.1953.:0.1885 and:0.1250)
		(,:0.0510 I:0.0562 am:0.0806 not:0.0359 little:0.0386 that:0.1865,:0.1787 and:0.1543)
		(,:0.0608 it:0.0535�:0.0698 not:0.0503 little:0.0437 that:0.1758,:0.1836 and:0.1729)
		(,:0.0708 it:0.0603 have:0.0708 not:0.0630 little:0.0476 that:0.1670,:0.1787 and:0.1816)
		(,:0.0806 it:0.0635�:0.0752 not:0.0737 little:0.0496 that:0.1582,:0.1855 and:0.1836)
		(,:0.0874 it:0.0654�:0.0781 not:0.0820 little:0.0503 that:0.1504,:0.1846 and:0.1846)
		(,:0.0947 it:0.0679�:0.0815 not:0.0903 little:0.0520 that:0.1426,:0.1826 and:0.1895)
		(,:0.1006 it:0.0688�:0.0815 not:0.0996 little:0.0537 that:0.1396,:0.1826 and:0.1895)
		(,:0.1069 it:0.0693�:0.0820 not:0.1045 little:0.0540 that:0.1328,:0.1924 and:0.1885)
		(,:0.1108 it:0.0698�:0.0820 not:0.1099 little:0.0547 that:0.1260,:0.1934 and:0.1885)
		(,:0.1118 it:0.0684�:0.0825 not:0.1196 little:0.0540 that:0.1230,:0.1924 and:0.1865)
 and
------
		(,:0.9961 I:1.0000 respawn:0.0049 a:0.9922 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0515�:0.1572 I:0.0227 lot:0.0283 that:0.1455.:0.1846 I:0.1592 I:0.1318)
		( I:0.0588 am:0.0986 now:0.0231 lot:0.0337 that:0.1953.:0.1885 and:0.1250 I:0.3203)
		( I:0.0562 am:0.0806 not:0.0359 little:0.0386 that:0.1865,:0.1787 and:0.1543 I:0.2812)
		( it:0.0535�:0.0698 not:0.0503 little:0.0437 that:0.1758,:0.1836 and:0.1729 I:0.2754)
		( it:0.0603 have:0.0708 not:0.0630 little:0.0476 that:0.1670,:0.1787 and:0.1816 I:0.3047)
		( it:0.0635�:0.0752 not:0.0737 little:0.0496 that:0.1582,:0.1855 and:0.1836 I:0.3379)
		( it:0.0654�:0.0781 not:0.0820 little:0.0503 that:0.1504,:0.1846 and:0.1846 I:0.3613)
		( it:0.0679�:0.0815 not:0.0903 little:0.0520 that:0.1426,:0.1826 and:0.1895 I:0.3867)
		( it:0.0688�:0.0815 not:0.0996 little:0.0537 that:0.1396,:0.1826 and:0.1895 I:0.3984)
		( it:0.0693�:0.0820 not:0.1045 little:0.0540 that:0.1328,:0.1924 and:0.1885 I:0.4102)
		( it:0.0698�:0.0820 not:0.1099 little:0.0547 that:0.1260,:0.1934 and:0.1885 I:0.4082)
		( it:0.0684�:0.0825 not:0.1196 little:0.0540 that:0.1230,:0.1924 and:0.1865 I:0.4082)
 I'm a language teacher. I'm a language teacher
2000: sample 0: Hello, I'm a language model,
------
		( WWE:0.0025,:0.9961 I:1.0000 Dragonbound:0.0046 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0315
:0.0564�:0.2109 not:0.0369 lot:0.0442 that:0.1338.:0.2041 I:0.1416)
		(,:0.0405 it:0.0547�:0.0732 not:0.0811 bit:0.0493 that:0.1660.:0.2393 and:0.1377)
		(,:0.0464 it:0.0608 have:0.0688 not:0.0938 bit:0.0432 that:0.1445.:0.2578 and:0.1797)
		(,:0.0513 it:0.0664 have:0.0703 not:0.1040 bit:0.0388 that:0.1206.:0.2559 and:0.2148)
		(,:0.0554 it:0.0684 have:0.0757 not:0.1138 little:0.0388 that:0.0996.:0.2695 and:0.2227)
		(,:0.0586 it:0.0708 have:0.0781 not:0.1157 little:0.0427 teacher:0.0898.:0.2695 and:0.2295)
		(,:0.0623 it:0.0708 have:0.0771 not:0.1191 little:0.0459 teacher:0.1162.:0.2734 and:0.2256)
		(,:0.0640 and:0.0713 have:0.0767 not:0.1230 little:0.0496 teacher:0.1377.:0.2793 and:0.2227)
		(,:0.0664 and:0.0723 have:0.0767 not:0.1279 little:0.0520 teacher:0.1572.:0.2793 and:0.2197)
		(,:0.0693 and:0.0728 have:0.0811 not:0.1260 little:0.0564 teacher:0.1748.:0.2852 and:0.2178)
		(,:0.0698 and:0.0737 have:0.0811 not:0.1250 little:0.0579 teacher:0.1836.:0.2871 and:0.2275)
		(,:0.0728 and:0.0742 have:0.0820 not:0.1309 little:0.0610 teacher:0.1934.:0.2891 and:0.2266)
 and
------
		(,:0.9961 I:1.0000 Dragonbound:0.0046 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		(
:0.0564�:0.2109 not:0.0369 lot:0.0442 that:0.1338.:0.2041 I:0.1416 I:0.1143)
		( it:0.0547�:0.0732 not:0.0811 bit:0.0493 that:0.1660.:0.2393 and:0.1377 I:0.2852)
		( it:0.0608 have:0.0688 not:0.0938 bit:0.0432 that:0.1445.:0.2578 and:0.1797 I:0.2871)
		( it:0.0664 have:0.0703 not:0.1040 bit:0.0388 that:0.1206.:0.2559 and:0.2148 I:0.3301)
		( it:0.0684 have:0.0757 not:0.1138 little:0.0388 that:0.0996.:0.2695 and:0.2227 I:0.3594)
		( it:0.0708 have:0.0781 not:0.1157 little:0.0427 teacher:0.0898.:0.2695 and:0.2295 I:0.3672)
		( it:0.0708 have:0.0771 not:0.1191 little:0.0459 teacher:0.1162.:0.2734 and:0.2256 I:0.3633)
		( and:0.0713 have:0.0767 not:0.1230 little:0.0496 teacher:0.1377.:0.2793 and:0.2227 I:0.3594)
		( and:0.0723 have:0.0767 not:0.1279 little:0.0520 teacher:0.1572.:0.2793 and:0.2197 I:0.3457)
		( and:0.0728 have:0.0811 not:0.1260 little:0.0564 teacher:0.1748.:0.2852 and:0.2178 I:0.3164)
		( and:0.0737 have:0.0811 not:0.1250 little:0.0579 teacher:0.1836.:0.2871 and:0.2275 I:0.3047)
		( and:0.0742 have:0.0820 not:0.1309 little:0.0610 teacher:0.1934.:0.2891 and:0.2266 I:0.2910)
 I'm a language teacher.
- I'm a
2150: sample 0: Hello, I'm a language model,
------
		( WWE:0.0023,:0.9961 I:1.0000 respawn:0.0053 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0253 and:0.0708�:0.1699 not:0.0388 great:0.0272 that:0.1494.:0.2559 I:0.1865)
		(,:0.0342 I:0.0586 am:0.1167 not:0.1064 great:0.0277 that:0.1357.:0.2402 and:0.1309)
		(,:0.0366 I:0.0544 have:0.1226 not:0.1348 great:0.0237 that:0.1069.:0.2354 and:0.1348)
		(,:0.0396 and:0.0510 have:0.1279 not:0.1484 teacher:0.0239 that:0.0923.:0.2207 and:0.1328)
		(,:0.0405 and:0.0576 have:0.1270 not:0.1660 teacher:0.0228 teacher:0.0820.:0.2148 and:0.1299)
		(,:0.0417 and:0.0618 have:0.1226 not:0.1699 good:0.0216 teacher:0.1143.:0.2168 and:0.1235)
		(,:0.0417 and:0.0659 have:0.1201 not:0.1670 good:0.0220 teacher:0.1455.:0.2070 I:0.1279)
		(,:0.0435 and:0.0669 have:0.1191 not:0.1748 good:0.0220 teacher:0.1719.:0.2080 I:0.1348)
		(,:0.0439 and:0.0698 have:0.1191 not:0.1660 little:0.0228 teacher:0.1924.:0.2100 I:0.1377)
		(,:0.0432 and:0.0708 have:0.1196 not:0.1660 little:0.0231 teacher:0.2139.:0.2012 I:0.1455)
		(,:0.0437 and:0.0718 have:0.1133 not:0.1670 little:0.0242 teacher:0.2256.:0.2021 I:0.1455)
		(,:0.0444 and:0.0723 have:0.1143 not:0.1680 little:0.0248 teacher:0.2363.:0.2061 I:0.1494)
 I
------
		(,:0.9961 I:1.0000 respawn:0.0053 a:0.9961 language:1.0000 model:1.0000,:1.0000 I:1.0000)
		( and:0.0708�:0.1699 not:0.0388 great:0.0272 that:0.1494.:0.2559 I:0.1865 will:0.0728)
		( I:0.0586 am:0.1167 not:0.1064 great:0.0277 that:0.1357.:0.2402 and:0.1309'm:0.1748)
		( I:0.0544 have:0.1226 not:0.1348 great:0.0237 that:0.1069.:0.2354 and:0.1348'm:0.2217)
		( and:0.0510 have:0.1279 not:0.1484 teacher:0.0239 that:0.0923.:0.2207 and:0.1328'm:0.2227)
		( and:0.0576 have:0.1270 not:0.1660 teacher:0.0228 teacher:0.0820.:0.2148 and:0.1299'm:0.2168)
		( and:0.0618 have:0.1226 not:0.1699 good:0.0216 teacher:0.1143.:0.2168 and:0.1235'm:0.2168)
		( and:0.0659 have:0.1201 not:0.1670 good:0.0220 teacher:0.1455.:0.2070 I:0.1279'm:0.2051)
		( and:0.0669 have:0.1191 not:0.1748 good:0.0220 teacher:0.1719.:0.2080 I:0.1348'm:0.1953)
		( and:0.0698 have:0.1191 not:0.1660 little:0.0228 teacher:0.1924.:0.2100 I:0.1377'm:0.1875)
		( and:0.0708 have:0.1196 not:0.1660 little:0.0231 teacher:0.2139.:0.2012 I:0.1455'm:0.1768)
		( and:0.0718 have:0.1133 not:0.1670 little:0.0242 teacher:0.2256.:0.2021 I:0.1455'm:0.1777)
		( and:0.0723 have:0.1143 not:0.1680 little:0.0248 teacher:0.2363.:0.2061 I:0.1494'm:0.1689)
'm a language teacher, I'm a language teacher,
2300: sample 0: Hello, I'm a language model,
------
		(Hello:0.0030,:1.0000 I:1.0000'm:0.0075 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0305 and:0.1084�:0.2266 I:0.0508 great:0.0244-:0.1084.:0.2832 I:0.2256)
		(,:0.0393 the:0.0588�:0.0933 not:0.1211 good:0.0288 that:0.1040.:0.2969 and:0.1270)
		(,:0.0447 the:0.0737 have:0.0732 not:0.1641 good:0.0253 of:0.1055.:0.2676 and:0.1426)
		(,:0.0481 the:0.0747 have:0.0801 not:0.1689 good:0.0228 of:0.0986.:0.2393 and:0.1514)
		(,:0.0525 the:0.0767 have:0.0850 not:0.1709 good:0.0221 of:0.0835.:0.2217 and:0.1592)
		(,:0.0540 the:0.0771 have:0.0879 not:0.1621 good:0.0216 teacher:0.0908.:0.2100 and:0.1602)
		(,:0.0576 the:0.0781 have:0.0864 not:0.1631 good:0.0211 teacher:0.1050.:0.2070 and:0.1631)
		(,:0.0579 the:0.0791 have:0.0913 not:0.1582 good:0.0208 teacher:0.1182 for:0.2090 and:0.1621)
		(,:0.0603 the:0.0796 have:0.0908 not:0.1553 good:0.0204 teacher:0.1289 for:0.2070 and:0.1709)
		(,:0.0613 the:0.0806 have:0.0908 not:0.1445 good:0.0201 teacher:0.1338.:0.1973 and:0.1699)
		(,:0.0620 the:0.0791 have:0.0913 not:0.1426 good:0.0199 teacher:0.1455.:0.1982 and:0.1709)
		(,:0.0630 the:0.0796 have:0.0918 not:0.1416 good:0.0197 teacher:0.1514,:0.1982 and:0.1719)
 and
------
		(,:1.0000 I:1.0000'm:0.0075 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( and:0.1084�:0.2266 I:0.0508 great:0.0244-:0.1084.:0.2832 I:0.2256 I:0.1357)
		( the:0.0588�:0.0933 not:0.1211 good:0.0288 that:0.1040.:0.2969 and:0.1270 I:0.2119)
		( the:0.0737 have:0.0732 not:0.1641 good:0.0253 of:0.1055.:0.2676 and:0.1426 I:0.2119)
		( the:0.0747 have:0.0801 not:0.1689 good:0.0228 of:0.0986.:0.2393 and:0.1514 I:0.2598)
		( the:0.0767 have:0.0850 not:0.1709 good:0.0221 of:0.0835.:0.2217 and:0.1592 I:0.2930)
		( the:0.0771 have:0.0879 not:0.1621 good:0.0216 teacher:0.0908.:0.2100 and:0.1602 I:0.2891)
		( the:0.0781 have:0.0864 not:0.1631 good:0.0211 teacher:0.1050.:0.2070 and:0.1631 I:0.2871)
		( the:0.0791 have:0.0913 not:0.1582 good:0.0208 teacher:0.1182 for:0.2090 and:0.1621 I:0.2734)
		( the:0.0796 have:0.0908 not:0.1553 good:0.0204 teacher:0.1289 for:0.2070 and:0.1709 I:0.2617)
		( the:0.0806 have:0.0908 not:0.1445 good:0.0201 teacher:0.1338.:0.1973 and:0.1699 I:0.2383)
		( the:0.0791 have:0.0913 not:0.1426 good:0.0199 teacher:0.1455.:0.1982 and:0.1709 I:0.2275)
		( the:0.0796 have:0.0918 not:0.1416 good:0.0197 teacher:0.1514,:0.1982 and:0.1719 I:0.2168)
 I'm a language teacher. I'm a language teacher
2450: sample 0: Hello, I'm a language model,
------
		(Hello:0.0037,:1.0000 I:1.0000'm:0.0233 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(.:0.0282 I:0.0413�:0.1108 not:0.0557 time:0.0281 that:0.1196.:0.2383 I:0.1357)
		(.:0.0253 I:0.0593 have:0.0908 not:0.1807 bit:0.0188 that:0.1357.:0.2334 and:0.1152)
		(,:0.0245 I:0.0520 have:0.0923 not:0.2217 little:0.0193 that:0.1260.:0.2236 and:0.1426)
		(,:0.0253 and:0.0549 have:0.0894 not:0.2500 little:0.0225 that:0.1021.:0.1992 and:0.1650)
		(,:0.0254 and:0.0679 have:0.0869 not:0.2617 little:0.0254 of:0.0894.:0.1982 and:0.1738)
		(,:0.0255 and:0.0762 have:0.0845 not:0.2637 little:0.0277 of:0.0835.:0.1875 and:0.1836)
		(,:0.0250 and:0.0781 have:0.0825 not:0.2559 little:0.0298 of:0.0796.:0.1787 and:0.1797)
		(,:0.0245 and:0.0806 have:0.0806 not:0.2617 little:0.0312 of:0.0752.:0.1807 and:0.1777)
		(,:0.0240 and:0.0806 have:0.0791 not:0.2559 little:0.0322 of:0.0708.:0.1729 and:0.1846)
		(,:0.0237 and:0.0806 have:0.0776 not:0.2539 little:0.0334 of:0.0688.:0.1748 and:0.1826)
		(,:0.0233 and:0.0806 have:0.0762 not:0.2490 little:0.0347 of:0.0669.:0.1680 and:0.1807)
		(,:0.0229 and:0.0811 have:0.0752 not:0.2344 little:0.0352 of:0.0649.:0.1689 and:0.1807)
 and
------
		(,:1.0000 I:1.0000'm:0.0233 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.0413�:0.1108 not:0.0557 time:0.0281 that:0.1196.:0.2383 I:0.1357 I:0.1338)
		( I:0.0593 have:0.0908 not:0.1807 bit:0.0188 that:0.1357.:0.2334 and:0.1152 I:0.1973)
		( I:0.0520 have:0.0923 not:0.2217 little:0.0193 that:0.1260.:0.2236 and:0.1426 I:0.1699)
		( and:0.0549 have:0.0894 not:0.2500 little:0.0225 that:0.1021.:0.1992 and:0.1650 I:0.1982)
		( and:0.0679 have:0.0869 not:0.2617 little:0.0254 of:0.0894.:0.1982 and:0.1738 I:0.2178)
		( and:0.0762 have:0.0845 not:0.2637 little:0.0277 of:0.0835.:0.1875 and:0.1836 I:0.2334)
		( and:0.0781 have:0.0825 not:0.2559 little:0.0298 of:0.0796.:0.1787 and:0.1797 I:0.2275)
		( and:0.0806 have:0.0806 not:0.2617 little:0.0312 of:0.0752.:0.1807 and:0.1777 I:0.2363)
		( and:0.0806 have:0.0791 not:0.2559 little:0.0322 of:0.0708.:0.1729 and:0.1846 I:0.2334)
		( and:0.0806 have:0.0776 not:0.2539 little:0.0334 of:0.0688.:0.1748 and:0.1826 I:0.2207)
		( and:0.0806 have:0.0762 not:0.2490 little:0.0347 of:0.0669.:0.1680 and:0.1807 I:0.2197)
		( and:0.0811 have:0.0752 not:0.2344 little:0.0352 of:0.0649.:0.1689 and:0.1807 I:0.2188)
 I've been able to see how the language of the
2600: sample 0: Hello, I'm a language model,
------
		(Hello:0.0041,:1.0000 I:1.0000'm:0.0583 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(.:0.0277 the:0.0403�:0.1855 I:0.0220 great:0.0344 that:0.1660.:0.3262 I:0.2061)
		(.:0.0295 I:0.0374 am:0.0913 not:0.0383 bit:0.0332 that:0.2051.:0.3145 and:0.1245)
		(.:0.0291 and:0.0352 am:0.0815 not:0.0569 great:0.0289 that:0.1582.:0.2852 and:0.1416)
		(.:0.0277 and:0.0432 am:0.0781 not:0.0664 great:0.0272 that:0.1387.:0.2754 and:0.1396)
		(.:0.0266 and:0.0474 am:0.0752 not:0.0718 great:0.0258 that:0.1191.:0.2637 and:0.1396)
		(.:0.0248 and:0.0505 am:0.0728 not:0.0723 little:0.0261.:0.1064.:0.2637 and:0.1416)
		(.:0.0239 and:0.0520 have:0.0703 not:0.0718 little:0.0272.:0.1074.:0.2754 and:0.1396)
		(.:0.0231 and:0.0522 have:0.0669 not:0.0718 little:0.0276.:0.1074.:0.2773 and:0.1426)
		(.:0.0217 and:0.0527 have:0.0684 not:0.0723 little:0.0280.:0.1108.:0.2773 and:0.1416)
		(.:0.0203 and:0.0515 have:0.0693 not:0.0708 little:0.0284.:0.1113.:0.2891 and:0.1416)
		(.:0.0197 and:0.0515 have:0.0703 not:0.0698 little:0.0291.:0.1147.:0.2910 and:0.1445)
		(.:0.0184 and:0.0503�:0.0713 not:0.0669 little:0.0287.:0.1147.:0.3027 and:0.1445)
 and
------
		(,:1.0000 I:1.0000'm:0.0583 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0403�:0.1855 I:0.0220 great:0.0344 that:0.1660.:0.3262 I:0.2061 I:0.1250)
		( I:0.0374 am:0.0913 not:0.0383 bit:0.0332 that:0.2051.:0.3145 and:0.1245 I:0.2539)
		( and:0.0352 am:0.0815 not:0.0569 great:0.0289 that:0.1582.:0.2852 and:0.1416 I:0.2734)
		( and:0.0432 am:0.0781 not:0.0664 great:0.0272 that:0.1387.:0.2754 and:0.1396 I:0.3340)
		( and:0.0474 am:0.0752 not:0.0718 great:0.0258 that:0.1191.:0.2637 and:0.1396 I:0.3613)
		( and:0.0505 am:0.0728 not:0.0723 little:0.0261.:0.1064.:0.2637 and:0.1416 I:0.3750)
		( and:0.0520 have:0.0703 not:0.0718 little:0.0272.:0.1074.:0.2754 and:0.1396 I:0.3770)
		( and:0.0522 have:0.0669 not:0.0718 little:0.0276.:0.1074.:0.2773 and:0.1426 I:0.3770)
		( and:0.0527 have:0.0684 not:0.0723 little:0.0280.:0.1108.:0.2773 and:0.1416 I:0.3770)
		( and:0.0515 have:0.0693 not:0.0708 little:0.0284.:0.1113.:0.2891 and:0.1416 I:0.3770)
		( and:0.0515 have:0.0703 not:0.0698 little:0.0291.:0.1147.:0.2910 and:0.1445 I:0.3652)
		( and:0.0503�:0.0713 not:0.0669 little:0.0287.:0.1147.:0.3027 and:0.1445 I:0.3652)
 I'm a language model. I'm a language model
2750: sample 0: Hello, I'm a language model,
------
		(Hello:0.0034,:1.0000 I:1.0000'm:0.1357 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(.:0.0410 and:0.1167�:0.1758 I:0.0415 very:0.0304.:0.1138.:0.2988 I:0.2676)
		(.:0.0432 I:0.0654 can:0.1147 not:0.0571 great:0.0300-:0.1240.:0.2871 I:0.1572)
		(.:0.0432 I:0.0757 can:0.1143 not:0.0752 great:0.0280-:0.1221.:0.2344 I:0.1406)
		(.:0.0437 and:0.0796 can:0.1011 not:0.0811 great:0.0261-:0.1147.:0.2344 I:0.1514)
		(.:0.0439 and:0.0894 can:0.0894 not:0.0830 great:0.0258-:0.1011.:0.2188 I:0.1523)
		(.:0.0432 and:0.0967 can:0.0830 not:0.0850 great:0.0248-:0.0918.:0.2168 and:0.1514)
		(,:0.0427 and:0.1045 can:0.0796 not:0.0859 little:0.0255-:0.0874.:0.2070 and:0.1631)
		(,:0.0435 and:0.1089�:0.0776 not:0.0879 little:0.0264 of:0.0854.:0.2070 and:0.1680)
		(,:0.0430 and:0.1133�:0.0811 a:0.0879 little:0.0265 of:0.0850.:0.2002 and:0.1738)
		(,:0.0437 and:0.1177�:0.0850 not:0.0884 little:0.0267 teacher:0.0869.:0.2021 and:0.1719)
		(,:0.0435 and:0.1221�:0.0845 not:0.0869 little:0.0271 teacher:0.0869.:0.2041 and:0.1797)
		(,:0.0430 and:0.1226�:0.0889 not:0.0879 little:0.0266 teacher:0.0889.:0.2070 and:0.1787)
 and
------
		(,:1.0000 I:1.0000'm:0.1357 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( and:0.1167�:0.1758 I:0.0415 very:0.0304.:0.1138.:0.2988 I:0.2676 I:0.2061)
		( I:0.0654 can:0.1147 not:0.0571 great:0.0300-:0.1240.:0.2871 I:0.1572 I:0.4336)
		( I:0.0757 can:0.1143 not:0.0752 great:0.0280-:0.1221.:0.2344 I:0.1406 I:0.4609)
		( and:0.0796 can:0.1011 not:0.0811 great:0.0261-:0.1147.:0.2344 I:0.1514 I:0.5117)
		( and:0.0894 can:0.0894 not:0.0830 great:0.0258-:0.1011.:0.2188 I:0.1523 I:0.5352)
		( and:0.0967 can:0.0830 not:0.0850 great:0.0248-:0.0918.:0.2168 and:0.1514 I:0.5195)
		( and:0.1045 can:0.0796 not:0.0859 little:0.0255-:0.0874.:0.2070 and:0.1631 I:0.5117)
		( and:0.1089�:0.0776 not:0.0879 little:0.0264 of:0.0854.:0.2070 and:0.1680 I:0.5039)
		( and:0.1133�:0.0811 a:0.0879 little:0.0265 of:0.0850.:0.2002 and:0.1738 I:0.5039)
		( and:0.1177�:0.0850 not:0.0884 little:0.0267 teacher:0.0869.:0.2021 and:0.1719 I:0.4980)
		( and:0.1221�:0.0845 not:0.0869 little:0.0271 teacher:0.0869.:0.2041 and:0.1797 I:0.4824)
		( and:0.1226�:0.0889 not:0.0879 little:0.0266 teacher:0.0889.:0.2070 and:0.1787 I:0.4805)
 I'm a language model. I'm a language model
2900: sample 0: Hello, I'm a language model,
------
		(Hello:0.0034,:1.0000 I:1.0000'm:0.2754 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(.:0.0471 and:0.0693�:0.0957 going:0.0520 very:0.0435 that:0.2109.:0.2471 I:0.1865)
		(.:0.0510 the:0.0669 can:0.0688 going:0.1001 little:0.0410 that:0.2109.:0.2520 and:0.1650)
		(.:0.0505 the:0.0747 don:0.0703 going:0.1260 little:0.0398 that:0.1592.:0.2324 and:0.1895)
		(,:0.0505 the:0.0752 don:0.0640 going:0.1270 little:0.0413 that:0.1416.:0.2305 and:0.1738)
		(,:0.0540 the:0.0771 don:0.0635 going:0.1299 little:0.0420 that:0.1167.:0.2275 and:0.1748)
		(,:0.0562 the:0.0767 don:0.0596 not:0.1230 little:0.0430 that:0.0972.:0.2178 and:0.1797)
		(,:0.0569 the:0.0781 don:0.0557 not:0.1270 little:0.0432 that:0.0830.:0.2100 and:0.1787)
		(,:0.0579 the:0.0796 don:0.0554 not:0.1245 little:0.0435 teacher:0.0752.:0.2148 and:0.1787)
		(,:0.0588 the:0.0781�:0.0520 not:0.1299 little:0.0439 teacher:0.0801.:0.2070 and:0.1885)
		(,:0.0583 the:0.0791�:0.0520 not:0.1289 little:0.0447 teacher:0.0820.:0.2021 and:0.1895)
		(,:0.0596 the:0.0796�:0.0552 not:0.1279 little:0.0439 teacher:0.0845.:0.1953 and:0.1904)
		(,:0.0588 the:0.0806�:0.0552 not:0.1289 little:0.0435 teacher:0.0874.:0.1904 and:0.1914)
 and
------
		(,:1.0000 I:1.0000'm:0.2754 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( and:0.0693�:0.0957 going:0.0520 very:0.0435 that:0.2109.:0.2471 I:0.1865 I:0.1138)
		( the:0.0669 can:0.0688 going:0.1001 little:0.0410 that:0.2109.:0.2520 and:0.1650 I:0.3203)
		( the:0.0747 don:0.0703 going:0.1260 little:0.0398 that:0.1592.:0.2324 and:0.1895 I:0.3320)
		( the:0.0752 don:0.0640 going:0.1270 little:0.0413 that:0.1416.:0.2305 and:0.1738 I:0.3340)
		( the:0.0771 don:0.0635 going:0.1299 little:0.0420 that:0.1167.:0.2275 and:0.1748 I:0.3145)
		( the:0.0767 don:0.0596 not:0.1230 little:0.0430 that:0.0972.:0.2178 and:0.1797 I:0.2852)
		( the:0.0781 don:0.0557 not:0.1270 little:0.0432 that:0.0830.:0.2100 and:0.1787 I:0.2637)
		( the:0.0796 don:0.0554 not:0.1245 little:0.0435 teacher:0.0752.:0.2148 and:0.1787 I:0.2412)
		( the:0.0781�:0.0520 not:0.1299 little:0.0439 teacher:0.0801.:0.2070 and:0.1885 I:0.2227)
		( the:0.0791�:0.0520 not:0.1289 little:0.0447 teacher:0.0820.:0.2021 and:0.1895 I:0.2129)
		( the:0.0796�:0.0552 not:0.1279 little:0.0439 teacher:0.0845.:0.1953 and:0.1904 I:0.1953)
		( the:0.0806�:0.0552 not:0.1289 little:0.0435 teacher:0.0874.:0.1904 and:0.1914 I:0.1875)
 I'm a language model.
I'm a language
3050: sample 0: Hello, I'm a language model,
------
		(Hello:0.0050,:1.0000 I:1.0000'm:0.3789 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(.:0.0408 and:0.0598 have:0.0991 sure:0.0742 bit:0.0398 that:0.1299.:0.2285 I:0.1318)
		(.:0.0410 I:0.0742 can:0.1084 sure:0.1250 bit:0.0525 that:0.1445.:0.2041 which:0.1963)
		(,:0.0417 the:0.0635 can:0.0923 sure:0.1875 bit:0.0413 of:0.1025.:0.1953 which:0.1543)
		(,:0.0444 the:0.0649 can:0.0820 sure:0.2090 bit:0.0383 of:0.1104.:0.2021 and:0.1348)
		(,:0.0461 the:0.0645 can:0.0742 sure:0.2119 bit:0.0369 of:0.1064.:0.2061 and:0.1377)
		(,:0.0466 the:0.0654 have:0.0713 sure:0.2070 bit:0.0361 of:0.1030.:0.2012 and:0.1357)
		(,:0.0471 the:0.0645 have:0.0693 sure:0.2061 bit:0.0347 teacher:0.1035.:0.2070 and:0.1377)
		(,:0.0479 the:0.0654 have:0.0664 sure:0.1953 bit:0.0349 teacher:0.1084.:0.2021 and:0.1387)
		(,:0.0488 and:0.0684 have:0.0679 sure:0.1846 bit:0.0342 teacher:0.1108.:0.2061 and:0.1416)
		(,:0.0498 and:0.0688 have:0.0645 sure:0.1748 bit:0.0347 teacher:0.1133.:0.2002 and:0.1396)
		(,:0.0493 and:0.0698 have:0.0654 sure:0.1670 bit:0.0342 teacher:0.1133.:0.2041 and:0.1436)
		(,:0.0488 and:0.0723 have:0.0625 sure:0.1582 bit:0.0349 teacher:0.1138.:0.2070 and:0.1406)
 and
------
		(,:1.0000 I:1.0000'm:0.3789 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( and:0.0598 have:0.0991 sure:0.0742 bit:0.0398 that:0.1299.:0.2285 I:0.1318 I:0.1904)
		( I:0.0742 can:0.1084 sure:0.1250 bit:0.0525 that:0.1445.:0.2041 which:0.1963 I:0.2754)
		( the:0.0635 can:0.0923 sure:0.1875 bit:0.0413 of:0.1025.:0.1953 which:0.1543 I:0.3652)
		( the:0.0649 can:0.0820 sure:0.2090 bit:0.0383 of:0.1104.:0.2021 and:0.1348 I:0.3809)
		( the:0.0645 can:0.0742 sure:0.2119 bit:0.0369 of:0.1064.:0.2061 and:0.1377 I:0.3613)
		( the:0.0654 have:0.0713 sure:0.2070 bit:0.0361 of:0.1030.:0.2012 and:0.1357 I:0.3477)
		( the:0.0645 have:0.0693 sure:0.2061 bit:0.0347 teacher:0.1035.:0.2070 and:0.1377 I:0.3203)
		( the:0.0654 have:0.0664 sure:0.1953 bit:0.0349 teacher:0.1084.:0.2021 and:0.1387 I:0.2969)
		( and:0.0684 have:0.0679 sure:0.1846 bit:0.0342 teacher:0.1108.:0.2061 and:0.1416 I:0.2852)
		( and:0.0688 have:0.0645 sure:0.1748 bit:0.0347 teacher:0.1133.:0.2002 and:0.1396 I:0.2754)
		( and:0.0698 have:0.0654 sure:0.1670 bit:0.0342 teacher:0.1133.:0.2041 and:0.1436 I:0.2656)
		( and:0.0723 have:0.0625 sure:0.1582 bit:0.0349 teacher:0.1138.:0.2070 and:0.1406 I:0.2559)
 I'm a language model.
I'm a language
3200: sample 0: Hello, I'm a language model,
------
		(Hello:0.0039,:1.0000 I:1.0000'm:0.6719 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(.:0.0447 I:0.0923 have:0.0796 not:0.0630 very:0.0271 that:0.1592.:0.2363 I:0.2168)
		(.:0.0518 I:0.1230 have:0.0898 not:0.1523 very:0.0278-:0.0967.:0.2051 I:0.1309)
		(.:0.0540 I:0.1094 have:0.0928 not:0.1836 professor:0.0267 teacher:0.0771.:0.1943 and:0.1230)
		(.:0.0552 I:0.0889 have:0.0898 not:0.1768 member:0.0284 teacher:0.0933.:0.1973 and:0.1226)
		(.:0.0552 I:0.0752 have:0.0889 not:0.1699 member:0.0300 teacher:0.1040.:0.1904 and:0.1309)
		(.:0.0557 I:0.0649 have:0.0869 not:0.1689 member:0.0299 teacher:0.1064.:0.1934 and:0.1377)
		(.:0.0547 I:0.0574 have:0.0889 not:0.1621 member:0.0297 teacher:0.1089.:0.1855 and:0.1455)
		(.:0.0554 I:0.0520 have:0.0850 not:0.1582 member:0.0288 teacher:0.1069.:0.1885 and:0.1562)
		(.:0.0544 the:0.0498 have:0.0859 not:0.1543 member:0.0275 teacher:0.1064.:0.1904 and:0.1553)
		(.:0.0554 the:0.0508 have:0.0820 not:0.1523 little:0.0262 teacher:0.1064.:0.1836 and:0.1631)
		(.:0.0549 the:0.0518 have:0.0820 not:0.1426 little:0.0260 teacher:0.1040.:0.1865 and:0.1641)
		(.:0.0544 the:0.0540 have:0.0825 not:0.1416 little:0.0260 teacher:0.1016.:0.1885 and:0.1729)
 and
------
		(,:1.0000 I:1.0000'm:0.6719 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.0923 have:0.0796 not:0.0630 very:0.0271 that:0.1592.:0.2363 I:0.2168 I:0.1660)
		( I:0.1230 have:0.0898 not:0.1523 very:0.0278-:0.0967.:0.2051 I:0.1309 I:0.3281)
		( I:0.1094 have:0.0928 not:0.1836 professor:0.0267 teacher:0.0771.:0.1943 and:0.1230 I:0.2832)
		( I:0.0889 have:0.0898 not:0.1768 member:0.0284 teacher:0.0933.:0.1973 and:0.1226 I:0.2715)
		( I:0.0752 have:0.0889 not:0.1699 member:0.0300 teacher:0.1040.:0.1904 and:0.1309 I:0.2578)
		( I:0.0649 have:0.0869 not:0.1689 member:0.0299 teacher:0.1064.:0.1934 and:0.1377 I:0.2354)
		( I:0.0574 have:0.0889 not:0.1621 member:0.0297 teacher:0.1089.:0.1855 and:0.1455 I:0.2256)
		( I:0.0520 have:0.0850 not:0.1582 member:0.0288 teacher:0.1069.:0.1885 and:0.1562 I:0.2168)
		( the:0.0498 have:0.0859 not:0.1543 member:0.0275 teacher:0.1064.:0.1904 and:0.1553 I:0.2090)
		( the:0.0508 have:0.0820 not:0.1523 little:0.0262 teacher:0.1064.:0.1836 and:0.1631 I:0.2012)
		( the:0.0518 have:0.0820 not:0.1426 little:0.0260 teacher:0.1040.:0.1865 and:0.1641 I:0.1924)
		( the:0.0540 have:0.0825 not:0.1416 little:0.0260 teacher:0.1016.:0.1885 and:0.1729 I:0.1846)
 I'm a language model.
I'm a language
3350: sample 0: Hello, I'm a language model,
------
		(Hello:0.0053,:1.0000 I:1.0000'm:0.7305 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(.:0.0469 I:0.1299�:0.0850 I:0.0620 bit:0.0320 that:0.1445.:0.2656 I:0.1680)
		(,:0.0522 I:0.1250 have:0.0947 going:0.0669 little:0.0398 that:0.1592.:0.1914 and:0.1250)
		(,:0.0547 I:0.0835 have:0.1094 not:0.0771 little:0.0386 that:0.1011.:0.1934 and:0.1367)
		(,:0.0562 I:0.0596 have:0.1108 not:0.0811 little:0.0403 that:0.0869.:0.2129 and:0.1338)
		(,:0.0564 and:0.0596 have:0.1147 sure:0.0830 little:0.0415 teacher:0.0698.:0.2334 and:0.1416)
		(,:0.0569 and:0.0625 have:0.1118 sure:0.0869 little:0.0439 teacher:0.0781.:0.2334 and:0.1562)
		(,:0.0562 and:0.0654 have:0.1084 sure:0.0884 little:0.0442 teacher:0.0840.:0.2480 and:0.1641)
		(,:0.0569 and:0.0664 have:0.1108 sure:0.0859 little:0.0464 teacher:0.0859.:0.2500 and:0.1738)
		(,:0.0562 and:0.0693 have:0.1069 sure:0.0845 little:0.0471 teacher:0.0879.:0.2539 and:0.1738)
		(,:0.0571 and:0.0684 have:0.1089 sure:0.0811 little:0.0469 teacher:0.0908.:0.2559 and:0.1855)
		(,:0.0569 and:0.0688 have:0.1050 sure:0.0781 little:0.0483 teacher:0.0908.:0.2598 and:0.1865)
		(,:0.0562 and:0.0693 have:0.1060 sure:0.0757 little:0.0483 teacher:0.0918.:0.2617 and:0.1885)
 and
------
		(,:1.0000 I:1.0000'm:0.7305 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1299�:0.0850 I:0.0620 bit:0.0320 that:0.1445.:0.2656 I:0.1680 I:0.1641)
		( I:0.1250 have:0.0947 going:0.0669 little:0.0398 that:0.1592.:0.1914 and:0.1250 I:0.5195)
		( I:0.0835 have:0.1094 not:0.0771 little:0.0386 that:0.1011.:0.1934 and:0.1367 I:0.4824)
		( I:0.0596 have:0.1108 not:0.0811 little:0.0403 that:0.0869.:0.2129 and:0.1338 I:0.5039)
		( and:0.0596 have:0.1147 sure:0.0830 little:0.0415 teacher:0.0698.:0.2334 and:0.1416 I:0.4805)
		( and:0.0625 have:0.1118 sure:0.0869 little:0.0439 teacher:0.0781.:0.2334 and:0.1562 I:0.4453)
		( and:0.0654 have:0.1084 sure:0.0884 little:0.0442 teacher:0.0840.:0.2480 and:0.1641 I:0.4141)
		( and:0.0664 have:0.1108 sure:0.0859 little:0.0464 teacher:0.0859.:0.2500 and:0.1738 I:0.4004)
		( and:0.0693 have:0.1069 sure:0.0845 little:0.0471 teacher:0.0879.:0.2539 and:0.1738 I:0.3867)
		( and:0.0684 have:0.1089 sure:0.0811 little:0.0469 teacher:0.0908.:0.2559 and:0.1855 I:0.3750)
		( and:0.0688 have:0.1050 sure:0.0781 little:0.0483 teacher:0.0908.:0.2598 and:0.1865 I:0.3789)
		( and:0.0693 have:0.1060 sure:0.0757 little:0.0483 teacher:0.0918.:0.2617 and:0.1885 I:0.3652)
 I'm a language model. I'm a language model
3500: sample 0: Hello, I'm a language model,
------
		(Hello:0.0060,:1.0000 I:1.0000'm:0.7930 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(.:0.0410 I:0.0630�:0.1245 sure:0.0272 very:0.0393 that:0.1904,:0.1582 I:0.2266)
		(.:0.0435 I:0.0859 have:0.1035 sure:0.0500 very:0.0315 that:0.0850 for:0.1494 which:0.0977)
		(.:0.0417 I:0.0635 have:0.1025 sure:0.0649 very:0.0248 teacher:0.1025 for:0.1572 I:0.1484)
		(.:0.0417 I:0.0583 have:0.0977 sure:0.0698 member:0.0206 teacher:0.1113 for:0.1436 I:0.1406)
		(.:0.0408 I:0.0515 have:0.0918 sure:0.0767 member:0.0201 teacher:0.1206.:0.1484 I:0.1309)
		(,:0.0400 I:0.0461 have:0.0903 sure:0.0830 member:0.0190 teacher:0.1250.:0.1592 I:0.1260)
		(,:0.0396 I:0.0425 have:0.0869 sure:0.0898 member:0.0188 teacher:0.1299.:0.1689 I:0.1235)
		(,:0.0400 the:0.0396 have:0.0845 sure:0.0947 member:0.0179 teacher:0.1318.:0.1846 I:0.1177)
		(,:0.0398 the:0.0413�:0.0864 sure:0.0996 member:0.0172 teacher:0.1348.:0.1865 I:0.1162)
		(,:0.0393 the:0.0408�:0.0874 sure:0.1021 member:0.0171 teacher:0.1338.:0.1982 I:0.1152)
		(,:0.0391 the:0.0427�:0.0845 sure:0.1045 member:0.0170 teacher:0.1367.:0.2012 I:0.1143)
		(,:0.0388 the:0.0432�:0.0854 sure:0.1069 member:0.0168 teacher:0.1367.:0.2139 I:0.1108)
 I
------
		(,:1.0000 I:1.0000'm:0.7930 a:0.9961 language:1.0000 model:1.0000,:1.0000 I:1.0000)
		( I:0.0630�:0.1245 sure:0.0272 very:0.0393 that:0.1904,:0.1582 I:0.2266 have:0.0586)
		( I:0.0859 have:0.1035 sure:0.0500 very:0.0315 that:0.0850 for:0.1494 which:0.0977'm:0.2002)
		( I:0.0635 have:0.1025 sure:0.0649 very:0.0248 teacher:0.1025 for:0.1572 I:0.1484'm:0.3398)
		( I:0.0583 have:0.0977 sure:0.0698 member:0.0206 teacher:0.1113 for:0.1436 I:0.1406'm:0.3613)
		( I:0.0515 have:0.0918 sure:0.0767 member:0.0201 teacher:0.1206.:0.1484 I:0.1309'm:0.3418)
		( I:0.0461 have:0.0903 sure:0.0830 member:0.0190 teacher:0.1250.:0.1592 I:0.1260'm:0.3164)
		( I:0.0425 have:0.0869 sure:0.0898 member:0.0188 teacher:0.1299.:0.1689 I:0.1235'm:0.2969)
		( the:0.0396 have:0.0845 sure:0.0947 member:0.0179 teacher:0.1318.:0.1846 I:0.1177'm:0.2656)
		( the:0.0413�:0.0864 sure:0.0996 member:0.0172 teacher:0.1348.:0.1865 I:0.1162'm:0.2461)
		( the:0.0408�:0.0874 sure:0.1021 member:0.0171 teacher:0.1338.:0.1982 I:0.1152'm:0.2402)
		( the:0.0427�:0.0845 sure:0.1045 member:0.0170 teacher:0.1367.:0.2012 I:0.1143've:0.2236)
		( the:0.0432�:0.0854 sure:0.1069 member:0.0168 teacher:0.1367.:0.2139 I:0.1108've:0.2236)
've been reading about the world. I've been reading
3650: sample 0: Hello, I'm a language model,
------
		(staking:0.0024,:1.0000 I:1.0000'm:0.9102 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(.:0.0427 I:0.0815�:0.1416 going:0.0400 very:0.0273 that:0.1338.:0.1992 I:0.1289)
		(,:0.0503 I:0.0913 have:0.0806 going:0.0854 little:0.0359 that:0.1143.:0.1611 and:0.1147)
		(,:0.0522 I:0.0659 have:0.0742 going:0.0996 little:0.0376 language:0.0972.:0.1357 and:0.1396)
		(,:0.0537 the:0.0540�:0.0752 going:0.1089 little:0.0393 teacher:0.0752.:0.1445 and:0.1377)
		(,:0.0540 the:0.0549�:0.0781 going:0.1167 little:0.0391 teacher:0.0776.:0.1514 and:0.1475)
		(,:0.0547 the:0.0557�:0.0811 going:0.1226 little:0.0396 teacher:0.0811.:0.1592 and:0.1572)
		(,:0.0554 the:0.0562�:0.0835 going:0.1240 little:0.0396 teacher:0.0796.:0.1650 and:0.1641)
		(,:0.0547 the:0.0566�:0.0815 going:0.1279 little:0.0400 teacher:0.0811.:0.1768 and:0.1699)
		(,:0.0557 the:0.0588�:0.0835 going:0.1245 little:0.0396 teacher:0.0806.:0.1826 and:0.1777)
		(,:0.0552 the:0.0591�:0.0850 going:0.1289 little:0.0391 teacher:0.0796.:0.1836 and:0.1777)
		(,:0.0547 and:0.0610�:0.0869 going:0.1279 little:0.0388 teacher:0.0767.:0.1865 and:0.1777)
		(,:0.0542 and:0.0615�:0.0830 going:0.1270 little:0.0376 teacher:0.0757.:0.1963 and:0.1875)
 and
------
		(,:1.0000 I:1.0000'm:0.9102 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.0815�:0.1416 going:0.0400 very:0.0273 that:0.1338.:0.1992 I:0.1289 I:0.1030)
		( I:0.0913 have:0.0806 going:0.0854 little:0.0359 that:0.1143.:0.1611 and:0.1147 I:0.3438)
		( I:0.0659 have:0.0742 going:0.0996 little:0.0376 language:0.0972.:0.1357 and:0.1396 I:0.3340)
		( the:0.0540�:0.0752 going:0.1089 little:0.0393 teacher:0.0752.:0.1445 and:0.1377 I:0.3848)
		( the:0.0549�:0.0781 going:0.1167 little:0.0391 teacher:0.0776.:0.1514 and:0.1475 I:0.3887)
		( the:0.0557�:0.0811 going:0.1226 little:0.0396 teacher:0.0811.:0.1592 and:0.1572 I:0.4023)
		( the:0.0562�:0.0835 going:0.1240 little:0.0396 teacher:0.0796.:0.1650 and:0.1641 I:0.4023)
		( the:0.0566�:0.0815 going:0.1279 little:0.0400 teacher:0.0811.:0.1768 and:0.1699 I:0.4023)
		( the:0.0588�:0.0835 going:0.1245 little:0.0396 teacher:0.0806.:0.1826 and:0.1777 I:0.4043)
		( the:0.0591�:0.0850 going:0.1289 little:0.0391 teacher:0.0796.:0.1836 and:0.1777 I:0.4062)
		( and:0.0610�:0.0869 going:0.1279 little:0.0388 teacher:0.0767.:0.1865 and:0.1777 I:0.3926)
		( and:0.0615�:0.0830 going:0.1270 little:0.0376 teacher:0.0757.:0.1963 and:0.1875 I:0.3965)
 I'm a language model. I'm a language model
3800: sample 0: Hello, I'm a language model,
------
		(Hello:0.0028,:1.0000 I:1.0000'm:0.8945 a:1.0000 language:1.0000 model:1.0000,:1.0000)
		(,:0.0513 I:0.1157.:0.0679 sure:0.0806 very:0.0356 that:0.1494,:0.1670 and:0.1465)
		(,:0.0557 I:0.0796 have:0.0967 sure:0.0781 very:0.0420 that:0.1133 that:0.1465 and:0.1377)
		(,:0.0559 and:0.0825 have:0.1104 sure:0.1094 very:0.0327 that:0.0645,:0.1455 and:0.1436)
		(,:0.0554 and:0.0815 have:0.1040 sure:0.1348 very:0.0247 of:0.0557,:0.1436 and:0.1367)
		(,:0.0540 and:0.0854 have:0.1006 sure:0.1523 little:0.0212 of:0.0537,:0.1436 and:0.1426)
		(,:0.0527 and:0.0923 have:0.1040 sure:0.1611 little:0.0209 of:0.0547.:0.1475 and:0.1562)
		(,:0.0520 and:0.0972 have:0.1011 sure:0.1562 scientist:0.0221 of:0.0564.:0.1562 and:0.1670)
		(,:0.0510 and:0.1021 have:0.0981 sure:0.1543 scientist:0.0223 of:0.0569.:0.1611 and:0.1768)
		(,:0.0505 and:0.1079 have:0.0947 sure:0.1475 scientist:0.0227,:0.0557.:0.1699 and:0.1826)
		(,:0.0500 and:0.1108 have:0.0913 sure:0.1504 scientist:0.0232.:0.0581.:0.1758 and:0.1895)
		(,:0.0493 and:0.1133 have:0.0928 sure:0.1387 scientist:0.0231.:0.0605.:0.1865 and:0.1963)
		(,:0.0476 and:0.1167 have:0.0889 sure:0.1357 scientist:0.0229.:0.0630.:0.1885 and:0.1953)
 and
------
		(,:1.0000 I:1.0000'm:0.8945 a:1.0000 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1157.:0.0679 sure:0.0806 very:0.0356 that:0.1494,:0.1670 and:0.1465 I:0.1270)
		( I:0.0796 have:0.0967 sure:0.0781 very:0.0420 that:0.1133 that:0.1465 and:0.1377 I:0.3848)
		( and:0.0825 have:0.1104 sure:0.1094 very:0.0327 that:0.0645,:0.1455 and:0.1436 I:0.3652)
		( and:0.0815 have:0.1040 sure:0.1348 very:0.0247 of:0.0557,:0.1436 and:0.1367 I:0.3828)
		( and:0.0854 have:0.1006 sure:0.1523 little:0.0212 of:0.0537,:0.1436 and:0.1426 I:0.3828)
		( and:0.0923 have:0.1040 sure:0.1611 little:0.0209 of:0.0547.:0.1475 and:0.1562 I:0.3867)
		( and:0.0972 have:0.1011 sure:0.1562 scientist:0.0221 of:0.0564.:0.1562 and:0.1670 I:0.3828)
		( and:0.1021 have:0.0981 sure:0.1543 scientist:0.0223 of:0.0569.:0.1611 and:0.1768 I:0.3809)
		( and:0.1079 have:0.0947 sure:0.1475 scientist:0.0227,:0.0557.:0.1699 and:0.1826 I:0.3652)
		( and:0.1108 have:0.0913 sure:0.1504 scientist:0.0232.:0.0581.:0.1758 and:0.1895 I:0.3672)
		( and:0.1133 have:0.0928 sure:0.1387 scientist:0.0231.:0.0605.:0.1865 and:0.1963 I:0.3672)
		( and:0.1167 have:0.0889 sure:0.1357 scientist:0.0229.:0.0630.:0.1885 and:0.1953 I:0.3535)
 I'm a language model. I'm a language model
3950: sample 0: Hello, I'm a language model,
------
		(Hello:0.0047,:1.0000 I:1.0000'm:0.9180 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0481 I:0.1602 have:0.0579 sure:0.1328 very:0.0247 that:0.1196,:0.1895 I:0.1670)
		(,:0.0515 I:0.0898 have:0.0679 sure:0.1338 very:0.0396 that:0.1260.:0.1816 and:0.1396)
		(,:0.0515 I:0.0530 have:0.0625 sure:0.1650 very:0.0364 of:0.0962.:0.1816 but:0.1455)
		(,:0.0493 but:0.0476 will:0.0613 sure:0.1680 good:0.0330 of:0.1089.:0.1943 but:0.1621)
		(,:0.0493 and:0.0474 will:0.0610 sure:0.1621 good:0.0378 of:0.1143.:0.2051 but:0.1768)
		(,:0.0483 and:0.0513 will:0.0603 sure:0.1553 good:0.0398 of:0.1216.:0.2285 and:0.1738)
		(,:0.0476 and:0.0552 will:0.0591 sure:0.1514 good:0.0425 of:0.1260.:0.2305 and:0.1846)
		(,:0.0454 and:0.0579 will:0.0581 sure:0.1406 good:0.0432 of:0.1309.:0.2451 and:0.1953)
		(,:0.0449 and:0.0603 will:0.0569 sure:0.1328 good:0.0439 of:0.1328.:0.2559 and:0.1992)
		(,:0.0442 and:0.0625 will:0.0583 sure:0.1250 good:0.0437 of:0.1338.:0.2598 and:0.2012)
		(,:0.0427 and:0.0635 will:0.0566 sure:0.1260 good:0.0437 of:0.1348.:0.2734 and:0.1953)
		(,:0.0422 and:0.0659 will:0.0562 sure:0.1191 good:0.0435 of:0.1348.:0.2754 and:0.1973)
 and
------
		(,:1.0000 I:1.0000'm:0.9180 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1602 have:0.0579 sure:0.1328 very:0.0247 that:0.1196,:0.1895 I:0.1670 I:0.1157)
		( I:0.0898 have:0.0679 sure:0.1338 very:0.0396 that:0.1260.:0.1816 and:0.1396 I:0.3984)
		( I:0.0530 have:0.0625 sure:0.1650 very:0.0364 of:0.0962.:0.1816 but:0.1455 I:0.3379)
		( but:0.0476 will:0.0613 sure:0.1680 good:0.0330 of:0.1089.:0.1943 but:0.1621 I:0.3633)
		( and:0.0474 will:0.0610 sure:0.1621 good:0.0378 of:0.1143.:0.2051 but:0.1768 I:0.3555)
		( and:0.0513 will:0.0603 sure:0.1553 good:0.0398 of:0.1216.:0.2285 and:0.1738 I:0.3379)
		( and:0.0552 will:0.0591 sure:0.1514 good:0.0425 of:0.1260.:0.2305 and:0.1846 I:0.3223)
		( and:0.0579 will:0.0581 sure:0.1406 good:0.0432 of:0.1309.:0.2451 and:0.1953 I:0.3262)
		( and:0.0603 will:0.0569 sure:0.1328 good:0.0439 of:0.1328.:0.2559 and:0.1992 I:0.3125)
		( and:0.0625 will:0.0583 sure:0.1250 good:0.0437 of:0.1338.:0.2598 and:0.2012 I:0.3008)
		( and:0.0635 will:0.0566 sure:0.1260 good:0.0437 of:0.1348.:0.2734 and:0.1953 I:0.3027)
		( and:0.0659 will:0.0562 sure:0.1191 good:0.0435 of:0.1348.:0.2754 and:0.1973 I:0.2910)
 I'm a language model.
I'm a language
4100: sample 0: Hello, I'm a language model,
------
		(Hello:0.0043,:1.0000 I:1.0000'm:0.9609 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0464 the:0.1260 have:0.1074 going:0.0352 bit:0.0410 that:0.1729,:0.2383 I:0.1660)
		(,:0.0488 I:0.1118 have:0.1182 going:0.0752 very:0.0381 that:0.0947,:0.1455 and:0.1660)
		(,:0.0491 I:0.0703 have:0.1099 going:0.0815 little:0.0361 teacher:0.0854.:0.1426 and:0.1699)
		(,:0.0488 I:0.0615 have:0.1040 going:0.0918 little:0.0356 teacher:0.0835.:0.1641 and:0.1709)
		(,:0.0474 I:0.0583 have:0.1030 going:0.0962 little:0.0361 teacher:0.0796.:0.1787 and:0.1826)
		(,:0.0464 I:0.0537 have:0.1035 going:0.0952 little:0.0352 teacher:0.0767.:0.1875 and:0.1934)
		(,:0.0457 and:0.0542 have:0.0986 going:0.0972 little:0.0356 teacher:0.0747.:0.1963 and:0.2051)
		(,:0.0452 and:0.0564 have:0.0986 going:0.0947 little:0.0349 teacher:0.0728.:0.1973 and:0.2148)
		(,:0.0447 and:0.0569 have:0.0991 going:0.0884 little:0.0334.:0.0718.:0.2070 and:0.2109)
		(,:0.0442 and:0.0588 have:0.0942 going:0.0874 little:0.0330.:0.0747.:0.2080 and:0.2227)
		(,:0.0425 and:0.0593 have:0.0952 going:0.0845 little:0.0327.:0.0776.:0.2178 and:0.2217)
		(,:0.0422 and:0.0596 have:0.0952 going:0.0840 little:0.0322.:0.0811.:0.2197 and:0.2227)
 and
------
		(,:1.0000 I:1.0000'm:0.9609 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.1260 have:0.1074 going:0.0352 bit:0.0410 that:0.1729,:0.2383 I:0.1660 I:0.1309)
		( I:0.1118 have:0.1182 going:0.0752 very:0.0381 that:0.0947,:0.1455 and:0.1660 I:0.4238)
		( I:0.0703 have:0.1099 going:0.0815 little:0.0361 teacher:0.0854.:0.1426 and:0.1699 I:0.3672)
		( I:0.0615 have:0.1040 going:0.0918 little:0.0356 teacher:0.0835.:0.1641 and:0.1709 I:0.3906)
		( I:0.0583 have:0.1030 going:0.0962 little:0.0361 teacher:0.0796.:0.1787 and:0.1826 I:0.3848)
		( I:0.0537 have:0.1035 going:0.0952 little:0.0352 teacher:0.0767.:0.1875 and:0.1934 I:0.3926)
		( and:0.0542 have:0.0986 going:0.0972 little:0.0356 teacher:0.0747.:0.1963 and:0.2051 I:0.3906)
		( and:0.0564 have:0.0986 going:0.0947 little:0.0349 teacher:0.0728.:0.1973 and:0.2148 I:0.3887)
		( and:0.0569 have:0.0991 going:0.0884 little:0.0334.:0.0718.:0.2070 and:0.2109 I:0.4023)
		( and:0.0588 have:0.0942 going:0.0874 little:0.0330.:0.0747.:0.2080 and:0.2227 I:0.4023)
		( and:0.0593 have:0.0952 going:0.0845 little:0.0327.:0.0776.:0.2178 and:0.2217 I:0.4023)
		( and:0.0596 have:0.0952 going:0.0840 little:0.0322.:0.0811.:0.2197 and:0.2227 I:0.4004)
 I'm a language model. I'm a language model
4250: sample 0: Hello, I'm a language model,
------
		(Hello:0.0048,:1.0000 I:1.0000'm:0.9883 a:1.0000 language:1.0000 model:1.0000,:1.0000)
		(,:0.0310 I:0.0801�:0.1040 sure:0.0449 bit:0.0359 that:0.1514,:0.2412 I:0.1523)
		(.:0.0376 I:0.0898 will:0.1108 sure:0.0820 very:0.0374 that:0.1011.:0.1875 and:0.1523)
		(.:0.0400 I:0.0649�:0.0752 sure:0.1094 very:0.0295 that:0.0608.:0.1768 and:0.1670)
		(.:0.0408 I:0.0510�:0.0698 sure:0.1289 very:0.0262 specialist:0.0698.:0.2031 and:0.1777)
		(.:0.0410 but:0.0564 think:0.0723 sure:0.1289 great:0.0244 specialist:0.0742.:0.2266 and:0.1895)
		(.:0.0400 but:0.0645 think:0.0815 sure:0.1289 good:0.0238 specialist:0.0781.:0.2393 and:0.1973)
		(.:0.0393 but:0.0688 think:0.0879 sure:0.1240 good:0.0243 specialist:0.0781.:0.2402 and:0.2051)
		( the:0.0400 but:0.0713 think:0.0894 sure:0.1211 good:0.0244 specialist:0.0771.:0.2520 and:0.2139)
		( the:0.0420 but:0.0732 think:0.0947 sure:0.1182 good:0.0244 specialist:0.0742.:0.2539 and:0.2227)
		( the:0.0430 but:0.0757 think:0.0967 sure:0.1162 good:0.0248 specialist:0.0742.:0.2539 and:0.2217)
		( the:0.0439 but:0.0762 think:0.0977 sure:0.1147 good:0.0244 specialist:0.0723.:0.2539 and:0.2217)
		( the:0.0449 but:0.0762 think:0.0986 sure:0.1138 good:0.0240 specialist:0.0703.:0.2578 and:0.2324)
 and
------
		(,:1.0000 I:1.0000'm:0.9883 a:1.0000 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.0801�:0.1040 sure:0.0449 bit:0.0359 that:0.1514,:0.2412 I:0.1523 I:0.1387)
		( I:0.0898 will:0.1108 sure:0.0820 very:0.0374 that:0.1011.:0.1875 and:0.1523 I:0.4727)
		( I:0.0649�:0.0752 sure:0.1094 very:0.0295 that:0.0608.:0.1768 and:0.1670 I:0.4355)
		( I:0.0510�:0.0698 sure:0.1289 very:0.0262 specialist:0.0698.:0.2031 and:0.1777 I:0.4629)
		( but:0.0564 think:0.0723 sure:0.1289 great:0.0244 specialist:0.0742.:0.2266 and:0.1895 I:0.4473)
		( but:0.0645 think:0.0815 sure:0.1289 good:0.0238 specialist:0.0781.:0.2393 and:0.1973 I:0.4473)
		( but:0.0688 think:0.0879 sure:0.1240 good:0.0243 specialist:0.0781.:0.2402 and:0.2051 I:0.4336)
		( but:0.0713 think:0.0894 sure:0.1211 good:0.0244 specialist:0.0771.:0.2520 and:0.2139 I:0.4355)
		( but:0.0732 think:0.0947 sure:0.1182 good:0.0244 specialist:0.0742.:0.2539 and:0.2227 I:0.4375)
		( but:0.0757 think:0.0967 sure:0.1162 good:0.0248 specialist:0.0742.:0.2539 and:0.2217 I:0.4375)
		( but:0.0762 think:0.0977 sure:0.1147 good:0.0244 specialist:0.0723.:0.2539 and:0.2217 I:0.4551)
		( but:0.0762 think:0.0986 sure:0.1138 good:0.0240 specialist:0.0703.:0.2578 and:0.2324 I:0.4551)
 I'm a language model. I'm a language model
4400: sample 0: Hello, I'm a language model,
------
		(Hello:0.0042,:1.0000 I:1.0000'm:0.9922 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0374 you:0.0952�:0.1758 going:0.0496.:0.0576 that:0.1777 that:0.2617 I:0.1650)
		(,:0.0432 you:0.0684�:0.1416 going:0.0894 very:0.0447 that:0.2168 that:0.2490 and:0.1455)
		(,:0.0449 but:0.0801�:0.1270 sure:0.0991 very:0.0425 that:0.1196 that:0.1816 and:0.1377)
		(,:0.0449 but:0.0889�:0.1167 sure:0.1113 great:0.0417 that:0.1118.:0.1562 and:0.1436)
		(,:0.0452 but:0.0864�:0.1113 sure:0.1187 great:0.0457 that:0.1030.:0.1660 and:0.1484)
		(,:0.0444 but:0.0820�:0.1079 sure:0.1226 good:0.0479 that:0.0933.:0.1738 and:0.1621)
		(,:0.0437 but:0.0806�:0.1040 sure:0.1216 good:0.0483 that:0.0879.:0.1729 and:0.1699)
		(,:0.0432 but:0.0767�:0.1021 sure:0.1216 good:0.0483 that:0.0830.:0.1807 and:0.1729)
		(,:0.0427 and:0.0732�:0.1040 sure:0.1221 good:0.0488 of:0.0811.:0.1797 and:0.1826)
		(,:0.0425 and:0.0742�:0.1006 sure:0.1157 good:0.0481 of:0.0820.:0.1787 and:0.1836)
		(.:0.0420 and:0.0752�:0.0972 sure:0.1167 good:0.0476 of:0.0850.:0.1875 and:0.1934)
		(.:0.0420 and:0.0742�:0.0938 sure:0.1113 good:0.0459 of:0.0859.:0.1875 and:0.1973)
 and
------
		(,:1.0000 I:1.0000'm:0.9922 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( you:0.0952�:0.1758 going:0.0496.:0.0576 that:0.1777 that:0.2617 I:0.1650 I:0.1416)
		( you:0.0684�:0.1416 going:0.0894 very:0.0447 that:0.2168 that:0.2490 and:0.1455 I:0.4590)
		( but:0.0801�:0.1270 sure:0.0991 very:0.0425 that:0.1196 that:0.1816 and:0.1377 I:0.4824)
		( but:0.0889�:0.1167 sure:0.1113 great:0.0417 that:0.1118.:0.1562 and:0.1436 I:0.4805)
		( but:0.0864�:0.1113 sure:0.1187 great:0.0457 that:0.1030.:0.1660 and:0.1484 I:0.4629)
		( but:0.0820�:0.1079 sure:0.1226 good:0.0479 that:0.0933.:0.1738 and:0.1621 I:0.4473)
		( but:0.0806�:0.1040 sure:0.1216 good:0.0483 that:0.0879.:0.1729 and:0.1699 I:0.4219)
		( but:0.0767�:0.1021 sure:0.1216 good:0.0483 that:0.0830.:0.1807 and:0.1729 I:0.4102)
		( and:0.0732�:0.1040 sure:0.1221 good:0.0488 of:0.0811.:0.1797 and:0.1826 I:0.3984)
		( and:0.0742�:0.1006 sure:0.1157 good:0.0481 of:0.0820.:0.1787 and:0.1836 I:0.4023)
		( and:0.0752�:0.0972 sure:0.1167 good:0.0476 of:0.0850.:0.1875 and:0.1934 I:0.3887)
		( and:0.0742�:0.0938 sure:0.1113 good:0.0459 of:0.0859.:0.1875 and:0.1973 I:0.3926)
 I'm a language model.
I'm a language
4550: sample 0: Hello, I'm a language model,
------
		(Hello:0.0029,:1.0000 I:1.0000'm:0.9883 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0447 I:0.1069�:0.0889 going:0.0535 bit:0.0640 that:0.2422,:0.2041 I:0.1387)
		(,:0.0457 you:0.0742 will:0.0762 going:0.1445 bit:0.0513 that:0.1348 that:0.1592 and:0.1592)
		(,:0.0459 the:0.0776 have:0.0669 going:0.1611 bit:0.0491 language:0.1230.:0.1328 and:0.1260)
		(,:0.0442 the:0.0718 have:0.0654 going:0.1641 little:0.0503 that:0.0962.:0.1436 and:0.1299)
		(,:0.0444 the:0.0669 have:0.0693 going:0.1543 little:0.0530 that:0.0889.:0.1504 and:0.1318)
		(,:0.0437 and:0.0737�:0.0747 going:0.1455 little:0.0564 that:0.0796.:0.1592 and:0.1387)
		(,:0.0430 and:0.0786�:0.0801 going:0.1396 little:0.0576 that:0.0747.:0.1660 and:0.1455)
		( the:0.0437 and:0.0864�:0.0811 going:0.1299 little:0.0593 that:0.0703.:0.1689 and:0.1504)
		( the:0.0447 and:0.0898�:0.0864 going:0.1216 little:0.0598 that:0.0669.:0.1719 and:0.1553)
		( the:0.0459 and:0.0957�:0.0874 going:0.1147 little:0.0601 that:0.0649.:0.1758 and:0.1631)
		( the:0.0469 and:0.0991�:0.0928 going:0.1138 little:0.0613 that:0.0630.:0.1748 and:0.1631)
		( the:0.0481 and:0.1025�:0.0933 sure:0.1143 little:0.0605 that:0.0615.:0.1836 and:0.1719)
 and
------
		(,:1.0000 I:1.0000'm:0.9883 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1069�:0.0889 going:0.0535 bit:0.0640 that:0.2422,:0.2041 I:0.1387 I:0.1973)
		( you:0.0742 will:0.0762 going:0.1445 bit:0.0513 that:0.1348 that:0.1592 and:0.1592 I:0.3496)
		( the:0.0776 have:0.0669 going:0.1611 bit:0.0491 language:0.1230.:0.1328 and:0.1260 I:0.3809)
		( the:0.0718 have:0.0654 going:0.1641 little:0.0503 that:0.0962.:0.1436 and:0.1299 I:0.3555)
		( the:0.0669 have:0.0693 going:0.1543 little:0.0530 that:0.0889.:0.1504 and:0.1318 I:0.3457)
		( and:0.0737�:0.0747 going:0.1455 little:0.0564 that:0.0796.:0.1592 and:0.1387 I:0.3418)
		( and:0.0786�:0.0801 going:0.1396 little:0.0576 that:0.0747.:0.1660 and:0.1455 I:0.3418)
		( and:0.0864�:0.0811 going:0.1299 little:0.0593 that:0.0703.:0.1689 and:0.1504 I:0.3418)
		( and:0.0898�:0.0864 going:0.1216 little:0.0598 that:0.0669.:0.1719 and:0.1553 I:0.3301)
		( and:0.0957�:0.0874 going:0.1147 little:0.0601 that:0.0649.:0.1758 and:0.1631 I:0.3320)
		( and:0.0991�:0.0928 going:0.1138 little:0.0613 that:0.0630.:0.1748 and:0.1631 I:0.3320)
		( and:0.1025�:0.0933 sure:0.1143 little:0.0605 that:0.0615.:0.1836 and:0.1719 I:0.3203)
 I'm a language model.
I'm a language
4700: sample 0: Hello, I'm a language model,
------
		(Hello:0.0067,:1.0000 I:1.0000'm:0.9922 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0366 I:0.1416�:0.0938 sure:0.0767 bit:0.0327 that:0.0913,:0.2148 but:0.1592)
		(,:0.0369 I:0.1123 can:0.0684 sure:0.1826 little:0.0359 professor:0.0674.:0.1963 but:0.1377)
		(,:0.0374 I:0.1016�:0.0574 sure:0.2676 little:0.0369 teacher:0.0623.:0.2129 but:0.1826)
		(.:0.0371 I:0.0835�:0.0608 sure:0.2520 little:0.0366 teacher:0.0679.:0.2393 but:0.2207)
		( the:0.0374 I:0.0752�:0.0630 sure:0.2441 little:0.0378 teacher:0.0728.:0.2539 but:0.2314)
		( the:0.0381 I:0.0693�:0.0630 sure:0.2383 little:0.0383 teacher:0.0762.:0.2617 but:0.2490)
		( the:0.0398 I:0.0659�:0.0630 sure:0.2295 little:0.0383 teacher:0.0796.:0.2676 but:0.2559)
		( the:0.0408 the:0.0664�:0.0630 sure:0.2236 little:0.0381 teacher:0.0830.:0.2773 but:0.2539)
		( the:0.0415 the:0.0688�:0.0635 sure:0.2109 little:0.0383 teacher:0.0845.:0.2754 but:0.2500)
		( the:0.0425 the:0.0718�:0.0640 sure:0.2080 little:0.0388 teacher:0.0864.:0.2734 but:0.2617)
		( the:0.0437 the:0.0723�:0.0645 sure:0.2080 little:0.0391 teacher:0.0889.:0.2734 but:0.2598)
		( the:0.0435 the:0.0747�:0.0649 sure:0.2061 little:0.0386 teacher:0.0913.:0.2715 but:0.2598)
 but
------
		(,:1.0000 I:1.0000'm:0.9922 a:0.9961 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( I:0.1416�:0.0938 sure:0.0767 bit:0.0327 that:0.0913,:0.2148 but:0.1592 I:0.1934)
		( I:0.1123 can:0.0684 sure:0.1826 little:0.0359 professor:0.0674.:0.1963 but:0.1377 I:0.3906)
		( I:0.1016�:0.0574 sure:0.2676 little:0.0369 teacher:0.0623.:0.2129 but:0.1826 I:0.4473)
		( I:0.0835�:0.0608 sure:0.2520 little:0.0366 teacher:0.0679.:0.2393 but:0.2207 I:0.4512)
		( I:0.0752�:0.0630 sure:0.2441 little:0.0378 teacher:0.0728.:0.2539 but:0.2314 I:0.4668)
		( I:0.0693�:0.0630 sure:0.2383 little:0.0383 teacher:0.0762.:0.2617 but:0.2490 I:0.4785)
		( I:0.0659�:0.0630 sure:0.2295 little:0.0383 teacher:0.0796.:0.2676 but:0.2559 I:0.4941)
		( the:0.0664�:0.0630 sure:0.2236 little:0.0381 teacher:0.0830.:0.2773 but:0.2539 I:0.4922)
		( the:0.0688�:0.0635 sure:0.2109 little:0.0383 teacher:0.0845.:0.2754 but:0.2500 I:0.5078)
		( the:0.0718�:0.0640 sure:0.2080 little:0.0388 teacher:0.0864.:0.2734 but:0.2617 I:0.5078)
		( the:0.0723�:0.0645 sure:0.2080 little:0.0391 teacher:0.0889.:0.2734 but:0.2598 I:0.5117)
		( the:0.0747�:0.0649 sure:0.2061 little:0.0386 teacher:0.0913.:0.2715 but:0.2598 I:0.5234)
 I'm a language model. I'm a language model
4850: sample 0: Hello, I'm a language model,
------
		(Hello:0.0042,:1.0000 I:1.0000'm:0.9883 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0310 the:0.0830 have:0.0894 going:0.0742 bit:0.0610 that:0.0972.:0.1758 and:0.1426)
		(.:0.0334 I:0.0801 have:0.0776 going:0.1167 bit:0.0630-:0.0854.:0.1572 and:0.1553)
		(.:0.0352 I:0.0767 have:0.0679 sure:0.1074 bit:0.0713-:0.0459.:0.1426 and:0.1514)
		(.:0.0361 I:0.0776 have:0.0669 sure:0.1177 bit:0.0698 of:0.0427.:0.1582 and:0.1514)
		(.:0.0364 I:0.0776 have:0.0713 sure:0.1309 bit:0.0664 of:0.0459.:0.1670 and:0.1582)
		(.:0.0359 I:0.0767 have:0.0723 sure:0.1377 little:0.0640 of:0.0461.:0.1807 and:0.1602)
		(.:0.0366 I:0.0752 have:0.0728 sure:0.1406 little:0.0615 of:0.0481.:0.1855 and:0.1650)
		(.:0.0361 I:0.0737 have:0.0742 sure:0.1455 little:0.0591 of:0.0491.:0.1924 and:0.1729)
		(.:0.0371 I:0.0718 have:0.0747 sure:0.1523 little:0.0579 of:0.0483.:0.2002 and:0.1719)
		(.:0.0366 I:0.0684 have:0.0752 sure:0.1514 little:0.0569 of:0.0496.:0.2080 and:0.1807)
		(.:0.0364 I:0.0669 have:0.0757 sure:0.1494 little:0.0557 of:0.0493.:0.2061 and:0.1807)
		(.:0.0364 I:0.0659 have:0.0767 sure:0.1484 little:0.0552 of:0.0508.:0.2139 and:0.1816)
 and
------
		(,:1.0000 I:1.0000'm:0.9883 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0830 have:0.0894 going:0.0742 bit:0.0610 that:0.0972.:0.1758 and:0.1426 I:0.0996)
		( I:0.0801 have:0.0776 going:0.1167 bit:0.0630-:0.0854.:0.1572 and:0.1553 I:0.3535)
		( I:0.0767 have:0.0679 sure:0.1074 bit:0.0713-:0.0459.:0.1426 and:0.1514 I:0.3867)
		( I:0.0776 have:0.0669 sure:0.1177 bit:0.0698 of:0.0427.:0.1582 and:0.1514 I:0.4004)
		( I:0.0776 have:0.0713 sure:0.1309 bit:0.0664 of:0.0459.:0.1670 and:0.1582 I:0.3809)
		( I:0.0767 have:0.0723 sure:0.1377 little:0.0640 of:0.0461.:0.1807 and:0.1602 I:0.3711)
		( I:0.0752 have:0.0728 sure:0.1406 little:0.0615 of:0.0481.:0.1855 and:0.1650 I:0.3633)
		( I:0.0737 have:0.0742 sure:0.1455 little:0.0591 of:0.0491.:0.1924 and:0.1729 I:0.3594)
		( I:0.0718 have:0.0747 sure:0.1523 little:0.0579 of:0.0483.:0.2002 and:0.1719 I:0.3711)
		( I:0.0684 have:0.0752 sure:0.1514 little:0.0569 of:0.0496.:0.2080 and:0.1807 I:0.3691)
		( I:0.0669 have:0.0757 sure:0.1494 little:0.0557 of:0.0493.:0.2061 and:0.1807 I:0.3672)
		( I:0.0659 have:0.0767 sure:0.1484 little:0.0552 of:0.0508.:0.2139 and:0.1816 I:0.3672)
 I'm a language model. I'm a language model
5000: sample 0: Hello, I'm a language model,
------
		(astrous:0.0033,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0374 I:0.2188�:0.1157 sure:0.0459 bit:0.0400 that:0.1348 that:0.3418 I:0.1177)
		(,:0.0403 I:0.1758�:0.0947 sure:0.0815 very:0.0457 that:0.0811 that:0.3223 and:0.1387)
		(,:0.0408 I:0.1416�:0.0981 sure:0.0981 bit:0.0415 teacher:0.0981 that:0.2490 and:0.1367)
		(,:0.0408 I:0.1250�:0.1040 sure:0.1108 bit:0.0437 teacher:0.0889 that:0.1953 but:0.1533)
		(,:0.0400 I:0.1143�:0.1050 sure:0.1108 bit:0.0427 teacher:0.0874 that:0.1797 but:0.1562)
		(,:0.0393 I:0.1055�:0.1118 sure:0.1157 bit:0.0410 teacher:0.0879 that:0.1621 but:0.1562)
		(,:0.0400 I:0.0996�:0.1133 sure:0.1162 bit:0.0391 teacher:0.0884 that:0.1494 and:0.1611)
		(,:0.0386 I:0.0942�:0.1201 sure:0.1172 bit:0.0378 teacher:0.0869 that:0.1338 and:0.1680)
		(,:0.0393 I:0.0884�:0.1206 sure:0.1206 bit:0.0371 teacher:0.0879 that:0.1235 and:0.1680)
		( the:0.0405 I:0.0850�:0.1279 sure:0.1182 bit:0.0366 teacher:0.0898 that:0.1177 and:0.1768)
		( the:0.0403 I:0.0820�:0.1279 sure:0.1157 bit:0.0361 teacher:0.0898 that:0.1128 and:0.1787)
		( the:0.0398 the:0.0786�:0.1279 sure:0.1196 bit:0.0349 teacher:0.0894.:0.1074 and:0.1875)
 and
------
		(,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.2188�:0.1157 sure:0.0459 bit:0.0400 that:0.1348 that:0.3418 I:0.1177 I:0.1621)
		( I:0.1758�:0.0947 sure:0.0815 very:0.0457 that:0.0811 that:0.3223 and:0.1387 I:0.6250)
		( I:0.1416�:0.0981 sure:0.0981 bit:0.0415 teacher:0.0981 that:0.2490 and:0.1367 I:0.5430)
		( I:0.1250�:0.1040 sure:0.1108 bit:0.0437 teacher:0.0889 that:0.1953 but:0.1533 I:0.4395)
		( I:0.1143�:0.1050 sure:0.1108 bit:0.0427 teacher:0.0874 that:0.1797 but:0.1562 I:0.4297)
		( I:0.1055�:0.1118 sure:0.1157 bit:0.0410 teacher:0.0879 that:0.1621 but:0.1562 I:0.4219)
		( I:0.0996�:0.1133 sure:0.1162 bit:0.0391 teacher:0.0884 that:0.1494 and:0.1611 I:0.4336)
		( I:0.0942�:0.1201 sure:0.1172 bit:0.0378 teacher:0.0869 that:0.1338 and:0.1680 I:0.4316)
		( I:0.0884�:0.1206 sure:0.1206 bit:0.0371 teacher:0.0879 that:0.1235 and:0.1680 I:0.4316)
		( I:0.0850�:0.1279 sure:0.1182 bit:0.0366 teacher:0.0898 that:0.1177 and:0.1768 I:0.4473)
		( I:0.0820�:0.1279 sure:0.1157 bit:0.0361 teacher:0.0898 that:0.1128 and:0.1787 I:0.4473)
		( the:0.0786�:0.1279 sure:0.1196 bit:0.0349 teacher:0.0894.:0.1074 and:0.1875 I:0.4473)
 I'm a language model. I'm a language model
5150: sample 0: Hello, I'm a language model,
------
		(afort:0.0038,:1.0000 I:1.0000'm:0.9922 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0265 I:0.1943�:0.0918 sure:0.0317 bit:0.0439 language:0.1050 that:0.2012 and:0.2217)
		(,:0.0288 I:0.1201�:0.0688 sure:0.0525 very:0.0603 teacher:0.1855.:0.1758 and:0.1348)
		(.:0.0298 I:0.0889�:0.0830 sure:0.0679 very:0.0574 teacher:0.1885.:0.1631 I:0.1641)
		(.:0.0309 I:0.0757�:0.0938 sorry:0.0757 great:0.0505 teacher:0.1748.:0.1768 I:0.1553)
		(.:0.0311 I:0.0693�:0.0947 sure:0.0747 great:0.0525 teacher:0.1602.:0.1914 I:0.1465)
		(.:0.0311 I:0.0649�:0.0962 sure:0.0762 great:0.0530 teacher:0.1504.:0.1953 I:0.1367)
		( the:0.0322 I:0.0615�:0.0923 sure:0.0757 great:0.0525 teacher:0.1396.:0.2021 I:0.1289)
		( the:0.0330 I:0.0583�:0.0942 sure:0.0752 great:0.0520 teacher:0.1309.:0.2090 but:0.1299)
		( the:0.0332 I:0.0557�:0.0898 sure:0.0757 great:0.0508 teacher:0.1245.:0.2168 and:0.1309)
		( the:0.0337 I:0.0547�:0.0918 sure:0.0762 great:0.0496 teacher:0.1191.:0.2158 and:0.1338)
		( the:0.0344 I:0.0520�:0.0879 sure:0.0762 great:0.0483 teacher:0.1133.:0.2148 and:0.1406)
		( the:0.0342 the:0.0527�:0.0894 sure:0.0767 great:0.0471 teacher:0.1084.:0.2148 and:0.1436)
 and
------
		(,:1.0000 I:1.0000'm:0.9922 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1943�:0.0918 sure:0.0317 bit:0.0439 language:0.1050 that:0.2012 and:0.2217 I:0.1138)
		( I:0.1201�:0.0688 sure:0.0525 very:0.0603 teacher:0.1855.:0.1758 and:0.1348 I:0.2930)
		( I:0.0889�:0.0830 sure:0.0679 very:0.0574 teacher:0.1885.:0.1631 I:0.1641 I:0.3340)
		( I:0.0757�:0.0938 sorry:0.0757 great:0.0505 teacher:0.1748.:0.1768 I:0.1553 I:0.2930)
		( I:0.0693�:0.0947 sure:0.0747 great:0.0525 teacher:0.1602.:0.1914 I:0.1465 I:0.2832)
		( I:0.0649�:0.0962 sure:0.0762 great:0.0530 teacher:0.1504.:0.1953 I:0.1367 I:0.2754)
		( I:0.0615�:0.0923 sure:0.0757 great:0.0525 teacher:0.1396.:0.2021 I:0.1289 I:0.2832)
		( I:0.0583�:0.0942 sure:0.0752 great:0.0520 teacher:0.1309.:0.2090 but:0.1299 I:0.2930)
		( I:0.0557�:0.0898 sure:0.0757 great:0.0508 teacher:0.1245.:0.2168 and:0.1309 I:0.2910)
		( I:0.0547�:0.0918 sure:0.0762 great:0.0496 teacher:0.1191.:0.2158 and:0.1338 I:0.2891)
		( I:0.0520�:0.0879 sure:0.0762 great:0.0483 teacher:0.1133.:0.2148 and:0.1406 I:0.2891)
		( the:0.0527�:0.0894 sure:0.0767 great:0.0471 teacher:0.1084.:0.2148 and:0.1436 I:0.3008)
 I'm a language model. I'm a language model
5300: sample 0: Hello, I'm a language model,
------
		(Hello:0.0024,:1.0000 I:1.0000'm:0.9922 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0413 and:0.0781 have:0.1030 sure:0.0608 bit:0.0713 language:0.1045 that:0.1836 and:0.0972)
		(,:0.0439 the:0.0825 have:0.0825 sure:0.0986 little:0.0776 teacher:0.0781.:0.1680 and:0.1094)
		(,:0.0447 the:0.0693 have:0.0850 sure:0.1338 little:0.0879 teacher:0.0723.:0.1826 I:0.1582)
		(,:0.0447 the:0.0684 have:0.0854 sure:0.1318 little:0.0840 teacher:0.0796.:0.2148 I:0.1230)
		(,:0.0452 the:0.0713 have:0.0864 sure:0.1309 little:0.0767 teacher:0.0869.:0.2480 and:0.1177)
		(,:0.0444 the:0.0737 have:0.0879 sure:0.1289 little:0.0737 teacher:0.0889.:0.2637 and:0.1250)
		(,:0.0452 the:0.0767 have:0.0894 not:0.1240 little:0.0684 teacher:0.0884.:0.2695 and:0.1299)
		(,:0.0449 the:0.0796 have:0.0913 not:0.1211 little:0.0659 teacher:0.0884.:0.2754 and:0.1357)
		(,:0.0444 the:0.0825 have:0.0938 not:0.1260 little:0.0640 professor:0.0918.:0.2871 and:0.1377)
		(,:0.0442 the:0.0840 have:0.0952 sorry:0.1318 little:0.0605 professor:0.0947.:0.2949 and:0.1396)
		(,:0.0439 the:0.0869 have:0.0967 sorry:0.1309 little:0.0574 professor:0.0977.:0.2930 and:0.1436)
		(,:0.0437 the:0.0879 have:0.0981 sorry:0.1309 little:0.0559 professor:0.1016.:0.2891 and:0.1465)
 and
------
		(,:1.0000 I:1.0000'm:0.9922 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( and:0.0781 have:0.1030 sure:0.0608 bit:0.0713 language:0.1045 that:0.1836 and:0.0972 I:0.0913)
		( the:0.0825 have:0.0825 sure:0.0986 little:0.0776 teacher:0.0781.:0.1680 and:0.1094 I:0.3848)
		( the:0.0693 have:0.0850 sure:0.1338 little:0.0879 teacher:0.0723.:0.1826 I:0.1582 I:0.3633)
		( the:0.0684 have:0.0854 sure:0.1318 little:0.0840 teacher:0.0796.:0.2148 I:0.1230 I:0.3281)
		( the:0.0713 have:0.0864 sure:0.1309 little:0.0767 teacher:0.0869.:0.2480 and:0.1177 I:0.3066)
		( the:0.0737 have:0.0879 sure:0.1289 little:0.0737 teacher:0.0889.:0.2637 and:0.1250 I:0.3027)
		( the:0.0767 have:0.0894 not:0.1240 little:0.0684 teacher:0.0884.:0.2695 and:0.1299 I:0.3008)
		( the:0.0796 have:0.0913 not:0.1211 little:0.0659 teacher:0.0884.:0.2754 and:0.1357 I:0.2988)
		( the:0.0825 have:0.0938 not:0.1260 little:0.0640 professor:0.0918.:0.2871 and:0.1377 I:0.2852)
		( the:0.0840 have:0.0952 sorry:0.1318 little:0.0605 professor:0.0947.:0.2949 and:0.1396 I:0.2852)
		( the:0.0869 have:0.0967 sorry:0.1309 little:0.0574 professor:0.0977.:0.2930 and:0.1436 I:0.2852)
		( the:0.0879 have:0.0981 sorry:0.1309 little:0.0559 professor:0.1016.:0.2891 and:0.1465 I:0.2871)
 I'm a language model. I'm a language model
5450: sample 0: Hello, I'm a language model,
------
		(afort:0.0024,:1.0000 I:1.0000'm:0.9883 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0391 I:0.1445�:0.1318 sure:0.0889 bit:0.0393 language:0.1846 that:0.1904 and:0.1631)
		(,:0.0417 I:0.0938�:0.0879 sure:0.1670 little:0.0659 teacher:0.0967 that:0.1963 and:0.1641)
		(,:0.0432 I:0.1113�:0.0962 sure:0.2090 little:0.0845 teacher:0.0957 that:0.1621 but:0.1670)
		(,:0.0432 I:0.1270�:0.0947 sure:0.2129 little:0.0850 teacher:0.1045.:0.1729 but:0.1846)
		(,:0.0449 I:0.1206�:0.0938 sure:0.2041 little:0.0811 teacher:0.1011.:0.1797 but:0.1846)
		(,:0.0444 I:0.1157�:0.0918 sure:0.2021 little:0.0762 teacher:0.0977.:0.1865 but:0.1895)
		(,:0.0437 I:0.1079�:0.0894 sure:0.1934 little:0.0737 teacher:0.0938.:0.1855 but:0.1846)
		(,:0.0447 I:0.1035�:0.0869 sure:0.1846 little:0.0688 teacher:0.0913.:0.1934 but:0.1836)
		(,:0.0444 I:0.0996�:0.0889 sure:0.1777 little:0.0640 teacher:0.0894.:0.1924 but:0.1826)
		(,:0.0439 I:0.0933�:0.0864 sure:0.1719 little:0.0603 teacher:0.0874.:0.1914 but:0.1826)
		(,:0.0437 I:0.0918�:0.0840 sure:0.1748 little:0.0583 teacher:0.0859.:0.1914 but:0.1836)
		(,:0.0437 I:0.0879�:0.0850 sure:0.1689 little:0.0549 teacher:0.0845.:0.1914 but:0.1826)
 but
------
		(,:1.0000 I:1.0000'm:0.9883 a:0.9961 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( I:0.1445�:0.1318 sure:0.0889 bit:0.0393 language:0.1846 that:0.1904 and:0.1631 I:0.1846)
		( I:0.0938�:0.0879 sure:0.1670 little:0.0659 teacher:0.0967 that:0.1963 and:0.1641 I:0.2754)
		( I:0.1113�:0.0962 sure:0.2090 little:0.0845 teacher:0.0957 that:0.1621 but:0.1670 I:0.3965)
		( I:0.1270�:0.0947 sure:0.2129 little:0.0850 teacher:0.1045.:0.1729 but:0.1846 I:0.3828)
		( I:0.1206�:0.0938 sure:0.2041 little:0.0811 teacher:0.1011.:0.1797 but:0.1846 I:0.3906)
		( I:0.1157�:0.0918 sure:0.2021 little:0.0762 teacher:0.0977.:0.1865 but:0.1895 I:0.3867)
		( I:0.1079�:0.0894 sure:0.1934 little:0.0737 teacher:0.0938.:0.1855 but:0.1846 I:0.3848)
		( I:0.1035�:0.0869 sure:0.1846 little:0.0688 teacher:0.0913.:0.1934 but:0.1836 I:0.3848)
		( I:0.0996�:0.0889 sure:0.1777 little:0.0640 teacher:0.0894.:0.1924 but:0.1826 I:0.3867)
		( I:0.0933�:0.0864 sure:0.1719 little:0.0603 teacher:0.0874.:0.1914 but:0.1826 I:0.3867)
		( I:0.0918�:0.0840 sure:0.1748 little:0.0583 teacher:0.0859.:0.1914 but:0.1836 I:0.3887)
		( I:0.0879�:0.0850 sure:0.1689 little:0.0549 teacher:0.0845.:0.1914 but:0.1826 I:0.3906)
 I'm a language model. I'm a language model
5600: sample 0: Hello, I'm a language model,
------
		(heartedly:0.0029,:1.0000 I:1.0000'm:0.9922 a:1.0000 language:1.0000 model:1.0000,:1.0000)
		(,:0.0376 I:0.2021.:0.0640 sure:0.1011 little:0.0388 language:0.1226 that:0.1982 I:0.1270)
		(,:0.0381 I:0.1348 have:0.0591 sure:0.1514 little:0.0320 teacher:0.0603,:0.1436 I:0.2021)
		(,:0.0376 I:0.1260 am:0.0586 sure:0.1719 little:0.0327 teacher:0.0640,:0.1387 I:0.2148)
		(,:0.0376 I:0.1162 am:0.0635 sure:0.1660 little:0.0291 teacher:0.0752.:0.1494 I:0.1914)
		(,:0.0369 I:0.1074 am:0.0679 sure:0.1602 fan:0.0275 teacher:0.0776.:0.1562 I:0.1641)
		(,:0.0369 I:0.0996 am:0.0698 sure:0.1484 fan:0.0289 teacher:0.0811.:0.1631 I:0.1484)
		(,:0.0364 I:0.0908 am:0.0718 sure:0.1455 fan:0.0302 teacher:0.0840.:0.1631 but:0.1396)
		(,:0.0361 I:0.0845 am:0.0713 sure:0.1445 fan:0.0305 expert:0.0869.:0.1670 but:0.1406)
		(.:0.0364 I:0.0791 am:0.0752 sure:0.1348 fan:0.0311 expert:0.0898.:0.1641 but:0.1406)
		(.:0.0361 and:0.0757 am:0.0747 sure:0.1348 fan:0.0320 expert:0.0942.:0.1660 but:0.1406)
		(.:0.0359 and:0.0781 am:0.0742 sure:0.1279 fan:0.0317 expert:0.0938.:0.1650 but:0.1406)
		(.:0.0364 and:0.0776 am:0.0791 sure:0.1270 member:0.0317 expert:0.0962.:0.1621 and:0.1416)
 and
------
		(,:1.0000 I:1.0000'm:0.9922 a:1.0000 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.2021.:0.0640 sure:0.1011 little:0.0388 language:0.1226 that:0.1982 I:0.1270 I:0.1289)
		( I:0.1348 have:0.0591 sure:0.1514 little:0.0320 teacher:0.0603,:0.1436 I:0.2021 I:0.5117)
		( I:0.1260 am:0.0586 sure:0.1719 little:0.0327 teacher:0.0640,:0.1387 I:0.2148 I:0.4668)
		( I:0.1162 am:0.0635 sure:0.1660 little:0.0291 teacher:0.0752.:0.1494 I:0.1914 I:0.4551)
		( I:0.1074 am:0.0679 sure:0.1602 fan:0.0275 teacher:0.0776.:0.1562 I:0.1641 I:0.4043)
		( I:0.0996 am:0.0698 sure:0.1484 fan:0.0289 teacher:0.0811.:0.1631 I:0.1484 I:0.4004)
		( I:0.0908 am:0.0718 sure:0.1455 fan:0.0302 teacher:0.0840.:0.1631 but:0.1396 I:0.3809)
		( I:0.0845 am:0.0713 sure:0.1445 fan:0.0305 expert:0.0869.:0.1670 but:0.1406 I:0.3809)
		( I:0.0791 am:0.0752 sure:0.1348 fan:0.0311 expert:0.0898.:0.1641 but:0.1406 I:0.3789)
		( and:0.0757 am:0.0747 sure:0.1348 fan:0.0320 expert:0.0942.:0.1660 but:0.1406 I:0.3789)
		( and:0.0781 am:0.0742 sure:0.1279 fan:0.0317 expert:0.0938.:0.1650 but:0.1406 I:0.3770)
		( and:0.0776 am:0.0791 sure:0.1270 member:0.0317 expert:0.0962.:0.1621 and:0.1416 I:0.3770)
 I'm a language model. I'm a language model
5750: sample 0: Hello, I'm a language model,
------
		(Hello:0.0033,:1.0000 I:1.0000'm:0.9922 a:1.0000 language:1.0000 model:1.0000,:1.0000)
		(,:0.0349 I:0.1943�:0.1035 sure:0.0557 bit:0.0281 language:0.1426 that:0.2236 and:0.1709)
		(,:0.0371 I:0.2129 can:0.0703 not:0.0938 little:0.0378 teacher:0.1309.:0.1895 and:0.1406)
		(.:0.0383 I:0.2148 am:0.0986 not:0.1138 little:0.0469 teacher:0.0815.:0.1875 and:0.1504)
		(.:0.0398 I:0.2500�:0.0981 not:0.1299 little:0.0481 teacher:0.0830.:0.2139 and:0.1523)
		(.:0.0396 I:0.2480�:0.0977 not:0.1318 little:0.0483 teacher:0.0786.:0.2227 and:0.1533)
		(.:0.0398 I:0.2393�:0.0957 not:0.1279 little:0.0474 teacher:0.0732.:0.2266 and:0.1572)
		(.:0.0398 I:0.2246 am:0.0996 not:0.1260 little:0.0461 teacher:0.0688.:0.2324 and:0.1592)
		(.:0.0393 I:0.2158 am:0.0996 not:0.1235 little:0.0439 teacher:0.0659.:0.2402 and:0.1621)
		(.:0.0403 I:0.2070 am:0.0996 not:0.1226 little:0.0437 teacher:0.0618.:0.2383 and:0.1650)
		(.:0.0396 I:0.1982 am:0.1006 not:0.1221 little:0.0435 teacher:0.0618.:0.2363 and:0.1650)
		(.:0.0398 I:0.1895 am:0.1011 not:0.1211 little:0.0422 lear:0.0640.:0.2461 and:0.1660)
		(.:0.0391 I:0.1816 am:0.1025 not:0.1206 little:0.0405 lear:0.0649.:0.2441 and:0.1699)
 and
------
		(,:1.0000 I:1.0000'm:0.9922 a:1.0000 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1943�:0.1035 sure:0.0557 bit:0.0281 language:0.1426 that:0.2236 and:0.1709 I:0.1387)
		( I:0.2129 can:0.0703 not:0.0938 little:0.0378 teacher:0.1309.:0.1895 and:0.1406 I:0.4629)
		( I:0.2148 am:0.0986 not:0.1138 little:0.0469 teacher:0.0815.:0.1875 and:0.1504 I:0.4883)
		( I:0.2500�:0.0981 not:0.1299 little:0.0481 teacher:0.0830.:0.2139 and:0.1523 I:0.4727)
		( I:0.2480�:0.0977 not:0.1318 little:0.0483 teacher:0.0786.:0.2227 and:0.1533 I:0.4805)
		( I:0.2393�:0.0957 not:0.1279 little:0.0474 teacher:0.0732.:0.2266 and:0.1572 I:0.4785)
		( I:0.2246 am:0.0996 not:0.1260 little:0.0461 teacher:0.0688.:0.2324 and:0.1592 I:0.4746)
		( I:0.2158 am:0.0996 not:0.1235 little:0.0439 teacher:0.0659.:0.2402 and:0.1621 I:0.4766)
		( I:0.2070 am:0.0996 not:0.1226 little:0.0437 teacher:0.0618.:0.2383 and:0.1650 I:0.4766)
		( I:0.1982 am:0.1006 not:0.1221 little:0.0435 teacher:0.0618.:0.2363 and:0.1650 I:0.4766)
		( I:0.1895 am:0.1011 not:0.1211 little:0.0422 lear:0.0640.:0.2461 and:0.1660 I:0.4629)
		( I:0.1816 am:0.1025 not:0.1206 little:0.0405 lear:0.0649.:0.2441 and:0.1699 I:0.4648)
 I'm a language model. I'm a language model
5900: sample 0: Hello, I'm a language model,
------
		( horr:0.0030,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0339 I:0.1865�:0.1904.:0.0435 bit:0.0317 language:0.1953.:0.1895 and:0.1318)
		(,:0.0366 I:0.1748 will:0.1035 sure:0.0942 very:0.0388 expert:0.0874.:0.1816 and:0.1377)
		(,:0.0378 I:0.1729�:0.0820 sure:0.1357 very:0.0366 teacher:0.0908.:0.1641 I:0.1855)
		(,:0.0386 I:0.1562�:0.0801 sure:0.1318 very:0.0332 teacher:0.0933.:0.1680 I:0.1650)
		(,:0.0383 I:0.1445�:0.0752 sure:0.1289 very:0.0300 expert:0.1089.:0.1689 and:0.1787)
		(,:0.0383 I:0.1309�:0.0762 sure:0.1226 very:0.0287 expert:0.1152.:0.1670 and:0.1914)
		( the:0.0398 I:0.1221�:0.0732 sure:0.1113 very:0.0273 expert:0.1201.:0.1660 and:0.2041)
		( the:0.0405 I:0.1138�:0.0703 sure:0.1089 very:0.0256 expert:0.1230.:0.1670 and:0.2139)
		( the:0.0410 I:0.1064 am:0.0718 sure:0.1011 very:0.0253 expert:0.1240.:0.1689 and:0.2227)
		( the:0.0413 I:0.0986�:0.0693 sure:0.0996 very:0.0240 expert:0.1250.:0.1699 and:0.2334)
		( the:0.0425 I:0.0947 am:0.0703 sure:0.0923 very:0.0237 expert:0.1270.:0.1680 and:0.2324)
		( the:0.0422 I:0.0908�:0.0674 sure:0.0913 very:0.0228 expert:0.1250.:0.1709 and:0.2451)
 and
------
		(,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1865�:0.1904.:0.0435 bit:0.0317 language:0.1953.:0.1895 and:0.1318 I:0.1279)
		( I:0.1748 will:0.1035 sure:0.0942 very:0.0388 expert:0.0874.:0.1816 and:0.1377 I:0.4102)
		( I:0.1729�:0.0820 sure:0.1357 very:0.0366 teacher:0.0908.:0.1641 I:0.1855 I:0.5430)
		( I:0.1562�:0.0801 sure:0.1318 very:0.0332 teacher:0.0933.:0.1680 I:0.1650 I:0.5430)
		( I:0.1445�:0.0752 sure:0.1289 very:0.0300 expert:0.1089.:0.1689 and:0.1787 I:0.5273)
		( I:0.1309�:0.0762 sure:0.1226 very:0.0287 expert:0.1152.:0.1670 and:0.1914 I:0.5234)
		( I:0.1221�:0.0732 sure:0.1113 very:0.0273 expert:0.1201.:0.1660 and:0.2041 I:0.5273)
		( I:0.1138�:0.0703 sure:0.1089 very:0.0256 expert:0.1230.:0.1670 and:0.2139 I:0.5117)
		( I:0.1064 am:0.0718 sure:0.1011 very:0.0253 expert:0.1240.:0.1689 and:0.2227 I:0.5117)
		( I:0.0986�:0.0693 sure:0.0996 very:0.0240 expert:0.1250.:0.1699 and:0.2334 I:0.5000)
		( I:0.0947 am:0.0703 sure:0.0923 very:0.0237 expert:0.1270.:0.1680 and:0.2324 I:0.5039)
		( I:0.0908�:0.0674 sure:0.0913 very:0.0228 expert:0.1250.:0.1709 and:0.2451 I:0.5039)
 I'm a language model. I'm a language model
6050: sample 0: Hello, I'm a language model,
------
		(afort:0.0035,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0312 I:0.4102�:0.1118 going:0.0771 bit:0.1279 that:0.1064.:0.2070 and:0.1235)
		(,:0.0337 I:0.2910 have:0.0898 going:0.0991 little:0.1084 teacher:0.1738.:0.1855 I:0.2314)
		(,:0.0344 I:0.2061 am:0.0962 sure:0.1118 little:0.1426 teacher:0.1592.:0.1719 I:0.2852)
		(,:0.0347 I:0.1826 am:0.1050 sure:0.1079 little:0.1309 teacher:0.1973.:0.1797 I:0.2734)
		(.:0.0352 I:0.1670 am:0.1162 sure:0.1006 little:0.1230 teacher:0.2051.:0.1855 I:0.2256)
		(.:0.0352 I:0.1553 am:0.1221 sure:0.1025 little:0.1201 teacher:0.2100.:0.1855 I:0.2070)
		(.:0.0354 I:0.1494 am:0.1216 sure:0.1021 little:0.1118 teacher:0.2119.:0.1836 I:0.1895)
		(.:0.0356 I:0.1436 am:0.1279 sure:0.1021 little:0.1055 teacher:0.2158.:0.1865 I:0.1846)
		(.:0.0359 I:0.1367 am:0.1289 sure:0.0977 little:0.0996 teacher:0.2139.:0.1816 and:0.1709)
		(.:0.0356 I:0.1357 am:0.1279 sure:0.1006 little:0.0942 teacher:0.2129.:0.1787 and:0.1689)
		(.:0.0354 I:0.1299 am:0.1279 sure:0.0972 little:0.0898 teacher:0.2129.:0.1846 and:0.1787)
		(.:0.0354 I:0.1279 am:0.1289 sure:0.0957 little:0.0854 teacher:0.2139.:0.1816 and:0.1875)
 and
------
		(,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.4102�:0.1118 going:0.0771 bit:0.1279 that:0.1064.:0.2070 and:0.1235 I:0.1064)
		( I:0.2910 have:0.0898 going:0.0991 little:0.1084 teacher:0.1738.:0.1855 I:0.2314 I:0.4805)
		( I:0.2061 am:0.0962 sure:0.1118 little:0.1426 teacher:0.1592.:0.1719 I:0.2852 I:0.5273)
		( I:0.1826 am:0.1050 sure:0.1079 little:0.1309 teacher:0.1973.:0.1797 I:0.2734 I:0.5234)
		( I:0.1670 am:0.1162 sure:0.1006 little:0.1230 teacher:0.2051.:0.1855 I:0.2256 I:0.5000)
		( I:0.1553 am:0.1221 sure:0.1025 little:0.1201 teacher:0.2100.:0.1855 I:0.2070 I:0.5117)
		( I:0.1494 am:0.1216 sure:0.1021 little:0.1118 teacher:0.2119.:0.1836 I:0.1895 I:0.5078)
		( I:0.1436 am:0.1279 sure:0.1021 little:0.1055 teacher:0.2158.:0.1865 I:0.1846 I:0.5078)
		( I:0.1367 am:0.1289 sure:0.0977 little:0.0996 teacher:0.2139.:0.1816 and:0.1709 I:0.5117)
		( I:0.1357 am:0.1279 sure:0.1006 little:0.0942 teacher:0.2129.:0.1787 and:0.1689 I:0.5117)
		( I:0.1299 am:0.1279 sure:0.0972 little:0.0898 teacher:0.2129.:0.1846 and:0.1787 I:0.5117)
		( I:0.1279 am:0.1289 sure:0.0957 little:0.0854 teacher:0.2139.:0.1816 and:0.1875 I:0.5156)
 I'm a teacher. I'm a teacher, and
6200: sample 0: Hello, I'm a language model,
------
		(Hello:0.0026,:1.0000 I:1.0000'm:0.9961 a:1.0000 language:1.0000 model:1.0000,:1.0000)
		(,:0.0381 I:0.1250�:0.1846 sure:0.0864 little:0.0479 language:0.1816 that:0.1855 and:0.1768)
		(,:0.0410 I:0.1572 will:0.0693 going:0.0933 little:0.0967 teacher:0.2266.:0.1484 and:0.1621)
		(,:0.0417 I:0.1094�:0.0806 going:0.0942 little:0.1299 teacher:0.2012.:0.1650 and:0.1660)
		(,:0.0425 I:0.0967�:0.0776 going:0.0903 little:0.1240 teacher:0.2217.:0.1768 and:0.1533)
		(,:0.0422 I:0.0903�:0.0752 going:0.0835 little:0.1128 teacher:0.2148.:0.1836 and:0.1543)
		(,:0.0425 I:0.0908�:0.0737 sure:0.0845 little:0.1001 teacher:0.2119.:0.1934 and:0.1572)
		(,:0.0425 I:0.0889�:0.0732 sure:0.0859 little:0.0913 teacher:0.2061.:0.1963 and:0.1611)
		(.:0.0420 I:0.0845�:0.0688 sure:0.0850 little:0.0850 teacher:0.2041.:0.1904 and:0.1670)
		(.:0.0425 I:0.0835�:0.0693 sure:0.0830 little:0.0791 teacher:0.2041.:0.1973 and:0.1738)
		(.:0.0427 I:0.0815�:0.0693 sure:0.0825 little:0.0723 teacher:0.2061.:0.1934 and:0.1777)
		(.:0.0425 I:0.0786�:0.0703 sure:0.0820 little:0.0674 teacher:0.2061.:0.1924 and:0.1777)
		(.:0.0430 I:0.0771�:0.0708 not:0.0767 little:0.0645 teacher:0.2090.:0.2002 and:0.1855)
 and
------
		(,:1.0000 I:1.0000'm:0.9961 a:1.0000 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1250�:0.1846 sure:0.0864 little:0.0479 language:0.1816 that:0.1855 and:0.1768 I:0.0884)
		( I:0.1572 will:0.0693 going:0.0933 little:0.0967 teacher:0.2266.:0.1484 and:0.1621 I:0.3691)
		( I:0.1094�:0.0806 going:0.0942 little:0.1299 teacher:0.2012.:0.1650 and:0.1660 I:0.4180)
		( I:0.0967�:0.0776 going:0.0903 little:0.1240 teacher:0.2217.:0.1768 and:0.1533 I:0.4375)
		( I:0.0903�:0.0752 going:0.0835 little:0.1128 teacher:0.2148.:0.1836 and:0.1543 I:0.4336)
		( I:0.0908�:0.0737 sure:0.0845 little:0.1001 teacher:0.2119.:0.1934 and:0.1572 I:0.4375)
		( I:0.0889�:0.0732 sure:0.0859 little:0.0913 teacher:0.2061.:0.1963 and:0.1611 I:0.4434)
		( I:0.0845�:0.0688 sure:0.0850 little:0.0850 teacher:0.2041.:0.1904 and:0.1670 I:0.4395)
		( I:0.0835�:0.0693 sure:0.0830 little:0.0791 teacher:0.2041.:0.1973 and:0.1738 I:0.4355)
		( I:0.0815�:0.0693 sure:0.0825 little:0.0723 teacher:0.2061.:0.1934 and:0.1777 I:0.4336)
		( I:0.0786�:0.0703 sure:0.0820 little:0.0674 teacher:0.2061.:0.1924 and:0.1777 I:0.4492)
		( I:0.0771�:0.0708 not:0.0767 little:0.0645 teacher:0.2090.:0.2002 and:0.1855 I:0.4316)
 I'm not a language model.
I'm not
6350: sample 0: Hello, I'm a language model,
------
		(afort:0.0045,:1.0000 I:1.0000'm:0.9961 a:1.0000 language:1.0000 model:1.0000,:1.0000)
		(,:0.0376 I:0.2217.:0.1992 sure:0.0981 little:0.0728 language:0.1201.:0.2139 and:0.1602)
		(,:0.0403 I:0.1494 have:0.0669 sure:0.1562 little:0.1309 teacher:0.0786.:0.2041 and:0.1436)
		(,:0.0417 I:0.1094�:0.0747 sure:0.1875 little:0.1445 teacher:0.0669.:0.1826 but:0.1445)
		(,:0.0425 I:0.1016�:0.0835 sure:0.1680 little:0.1318 teacher:0.0747.:0.1846 but:0.1699)
		(,:0.0427 I:0.0952�:0.0781 sure:0.1484 little:0.1162 teacher:0.0728.:0.1934 but:0.1816)
		(,:0.0427 I:0.0913�:0.0811 sure:0.1357 little:0.1128 teacher:0.0723.:0.2012 but:0.1904)
		(,:0.0422 I:0.0884�:0.0747 sure:0.1245 little:0.1045 expert:0.0742.:0.2012 but:0.2021)
		(,:0.0425 I:0.0879�:0.0747 sure:0.1147 little:0.1035 teacher:0.0728.:0.2070 but:0.2041)
		(,:0.0420 I:0.0845 have:0.0693 sure:0.1123 little:0.0972 teacher:0.0728.:0.2041 but:0.2129)
		(,:0.0417 I:0.0835 have:0.0698 sure:0.1055 little:0.0942 teacher:0.0737.:0.2031 but:0.2119)
		(.:0.0422 I:0.0801 have:0.0703 sure:0.1045 little:0.0908 teacher:0.0747.:0.2012 but:0.2119)
		(.:0.0417 I:0.0791 have:0.0747 sure:0.0981 little:0.0859 teacher:0.0742.:0.1992 but:0.2217)
 but
------
		(,:1.0000 I:1.0000'm:0.9961 a:1.0000 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( I:0.2217.:0.1992 sure:0.0981 little:0.0728 language:0.1201.:0.2139 and:0.1602 I:0.3242)
		( I:0.1494 have:0.0669 sure:0.1562 little:0.1309 teacher:0.0786.:0.2041 and:0.1436 I:0.3809)
		( I:0.1094�:0.0747 sure:0.1875 little:0.1445 teacher:0.0669.:0.1826 but:0.1445 I:0.4473)
		( I:0.1016�:0.0835 sure:0.1680 little:0.1318 teacher:0.0747.:0.1846 but:0.1699 I:0.4688)
		( I:0.0952�:0.0781 sure:0.1484 little:0.1162 teacher:0.0728.:0.1934 but:0.1816 I:0.4590)
		( I:0.0913�:0.0811 sure:0.1357 little:0.1128 teacher:0.0723.:0.2012 but:0.1904 I:0.4531)
		( I:0.0884�:0.0747 sure:0.1245 little:0.1045 expert:0.0742.:0.2012 but:0.2021 I:0.4707)
		( I:0.0879�:0.0747 sure:0.1147 little:0.1035 teacher:0.0728.:0.2070 but:0.2041 I:0.4727)
		( I:0.0845 have:0.0693 sure:0.1123 little:0.0972 teacher:0.0728.:0.2041 but:0.2129 I:0.4590)
		( I:0.0835 have:0.0698 sure:0.1055 little:0.0942 teacher:0.0737.:0.2031 but:0.2119 I:0.4629)
		( I:0.0801 have:0.0703 sure:0.1045 little:0.0908 teacher:0.0747.:0.2012 but:0.2119 I:0.4648)
		( I:0.0791 have:0.0747 sure:0.0981 little:0.0859 teacher:0.0742.:0.1992 but:0.2217 I:0.4707)
 I'm not a language model. I'm a language
6500: sample 0: Hello, I'm a language model,
------
		(afort:0.0041,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0293 I:0.1895�:0.1416 going:0.0698 bit:0.0388 language:0.1035.:0.1719 and:0.1768)
		(,:0.0322 I:0.1338 have:0.0830 going:0.1348 little:0.0481 teacher:0.1807.:0.1475 but:0.1592)
		(.:0.0334 and:0.0967 have:0.0742 going:0.1367 little:0.0518 teacher:0.1729.:0.1406 but:0.1943)
		(.:0.0352 and:0.0996�:0.0854 going:0.1377 little:0.0469 teacher:0.1738.:0.1377 but:0.1846)
		(.:0.0356 and:0.1011�:0.0918 going:0.1279 great:0.0471 teacher:0.1699 for:0.1465 but:0.1914)
		(.:0.0364 and:0.1021�:0.0923 going:0.1147 great:0.0471 teacher:0.1631 for:0.1504 but:0.1885)
		(.:0.0364 and:0.1035�:0.0972 going:0.1118 great:0.0459 teacher:0.1611.:0.1504 but:0.1865)
		(.:0.0366 and:0.1050�:0.0972 going:0.1035 great:0.0435 teacher:0.1543.:0.1514 but:0.1855)
		( the:0.0369 and:0.1030�:0.0962 going:0.0972 great:0.0430 teacher:0.1582.:0.1553 but:0.1865)
		(.:0.0366 and:0.1045�:0.0957 going:0.0967 great:0.0403 teacher:0.1553.:0.1543 and:0.1846)
		( the:0.0376 and:0.1030�:0.0952 going:0.0913 great:0.0391 teacher:0.1523.:0.1553 and:0.1846)
		( the:0.0376 and:0.1045�:0.0957 going:0.0908 great:0.0366 teacher:0.1504.:0.1514 and:0.1943)
 and
------
		(,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1895�:0.1416 going:0.0698 bit:0.0388 language:0.1035.:0.1719 and:0.1768 I:0.1436)
		( I:0.1338 have:0.0830 going:0.1348 little:0.0481 teacher:0.1807.:0.1475 but:0.1592 I:0.5898)
		( and:0.0967 have:0.0742 going:0.1367 little:0.0518 teacher:0.1729.:0.1406 but:0.1943 I:0.6641)
		( and:0.0996�:0.0854 going:0.1377 little:0.0469 teacher:0.1738.:0.1377 but:0.1846 I:0.6250)
		( and:0.1011�:0.0918 going:0.1279 great:0.0471 teacher:0.1699 for:0.1465 but:0.1914 I:0.6055)
		( and:0.1021�:0.0923 going:0.1147 great:0.0471 teacher:0.1631 for:0.1504 but:0.1885 I:0.5898)
		( and:0.1035�:0.0972 going:0.1118 great:0.0459 teacher:0.1611.:0.1504 but:0.1865 I:0.5586)
		( and:0.1050�:0.0972 going:0.1035 great:0.0435 teacher:0.1543.:0.1514 but:0.1855 I:0.5586)
		( and:0.1030�:0.0962 going:0.0972 great:0.0430 teacher:0.1582.:0.1553 but:0.1865 I:0.5469)
		( and:0.1045�:0.0957 going:0.0967 great:0.0403 teacher:0.1553.:0.1543 and:0.1846 I:0.5312)
		( and:0.1030�:0.0952 going:0.0913 great:0.0391 teacher:0.1523.:0.1553 and:0.1846 I:0.5312)
		( and:0.1045�:0.0957 going:0.0908 great:0.0366 teacher:0.1504.:0.1514 and:0.1943 I:0.5156)
 I'm a language model. I'm a language model
6650: sample 0: Hello, I'm a language model,
------
		(afort:0.0031,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0344 I:0.2500�:0.2080 going:0.0752 bit:0.0334 language:0.1250.:0.2578 and:0.1523)
		(,:0.0364 I:0.2598�:0.1050 going:0.1650 bit:0.0439 teacher:0.1807.:0.1924 but:0.1250)
		(,:0.0374 I:0.1484�:0.1348 going:0.1562 bit:0.0471 teacher:0.1011.:0.1670 but:0.1758)
		(,:0.0374 I:0.1235�:0.1318 going:0.1602 bit:0.0454 teacher:0.1084.:0.1602 but:0.2041)
		(,:0.0376 I:0.1064�:0.1328 going:0.1504 bit:0.0437 teacher:0.1025.:0.1602 but:0.2178)
		(,:0.0383 I:0.0913�:0.1270 going:0.1475 bit:0.0408 teacher:0.0894.:0.1572 but:0.2305)
		(.:0.0388 I:0.0811�:0.1226 going:0.1406 bit:0.0383 teacher:0.0850.:0.1553 but:0.2344)
		(.:0.0386 I:0.0737�:0.1172 going:0.1357 bit:0.0361 teacher:0.0776.:0.1504 but:0.2412)
		(.:0.0393 I:0.0674�:0.1196 going:0.1318 bit:0.0334 teacher:0.0737.:0.1465 but:0.2383)
		(.:0.0391 and:0.0664�:0.1138 going:0.1299 bit:0.0320 programmer:0.0708.:0.1436 but:0.2363)
		(.:0.0388 and:0.0684�:0.1157 going:0.1260 bit:0.0308 programmer:0.0728.:0.1416 but:0.2324)
		(.:0.0386 and:0.0679�:0.1172 going:0.1250 bit:0.0298 programmer:0.0742.:0.1387 but:0.2432)
 but
------
		(,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( I:0.2500�:0.2080 going:0.0752 bit:0.0334 language:0.1250.:0.2578 and:0.1523 I:0.3242)
		( I:0.2598�:0.1050 going:0.1650 bit:0.0439 teacher:0.1807.:0.1924 but:0.1250 I:0.4961)
		( I:0.1484�:0.1348 going:0.1562 bit:0.0471 teacher:0.1011.:0.1670 but:0.1758 I:0.5156)
		( I:0.1235�:0.1318 going:0.1602 bit:0.0454 teacher:0.1084.:0.1602 but:0.2041 I:0.4863)
		( I:0.1064�:0.1328 going:0.1504 bit:0.0437 teacher:0.1025.:0.1602 but:0.2178 I:0.4688)
		( I:0.0913�:0.1270 going:0.1475 bit:0.0408 teacher:0.0894.:0.1572 but:0.2305 I:0.4570)
		( I:0.0811�:0.1226 going:0.1406 bit:0.0383 teacher:0.0850.:0.1553 but:0.2344 I:0.4512)
		( I:0.0737�:0.1172 going:0.1357 bit:0.0361 teacher:0.0776.:0.1504 but:0.2412 I:0.4492)
		( I:0.0674�:0.1196 going:0.1318 bit:0.0334 teacher:0.0737.:0.1465 but:0.2383 I:0.4609)
		( and:0.0664�:0.1138 going:0.1299 bit:0.0320 programmer:0.0708.:0.1436 but:0.2363 I:0.4609)
		( and:0.0684�:0.1157 going:0.1260 bit:0.0308 programmer:0.0728.:0.1416 but:0.2324 I:0.4609)
		( and:0.0679�:0.1172 going:0.1250 bit:0.0298 programmer:0.0742.:0.1387 but:0.2432 I:0.4629)
 I'm not a language model. I'm a language
6800: sample 0: Hello, I'm a language model,
------
		(afort:0.0024,:1.0000 I:1.0000'm:0.9922 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0381 I:0.4141�:0.2910 sure:0.2041 bit:0.0422 that:0.0977.:0.2695 and:0.1689)
		(,:0.0403 I:0.3398 will:0.0952 sure:0.1855 bit:0.0444 teacher:0.1064.:0.2324 and:0.1436)
		(,:0.0408 I:0.2158�:0.1113 sure:0.2236 little:0.0496 teacher:0.0820.:0.2070 but:0.1494)
		(,:0.0413 I:0.1826�:0.1172 sure:0.2178 little:0.0486 teacher:0.0962.:0.1934 but:0.1504)
		(,:0.0415 I:0.1455�:0.1172 sure:0.2041 little:0.0481 teacher:0.0938.:0.1797 but:0.1514)
		(,:0.0415 I:0.1245�:0.1167 sure:0.1943 little:0.0464 teacher:0.0938.:0.1758 and:0.1523)
		(,:0.0415 I:0.1089�:0.1108 sure:0.1885 fan:0.0483 teacher:0.0908.:0.1709 and:0.1553)
		(,:0.0410 I:0.0986�:0.1123 sure:0.1836 fan:0.0513 teacher:0.0898.:0.1641 and:0.1562)
		(,:0.0408 I:0.0889�:0.1133 sure:0.1797 fan:0.0537 teacher:0.0898.:0.1650 and:0.1621)
		(,:0.0403 and:0.0850�:0.1138 sure:0.1689 fan:0.0554 teacher:0.0884.:0.1621 and:0.1650)
		(,:0.0400 and:0.0864�:0.1099 sure:0.1670 fan:0.0562 teacher:0.0898.:0.1562 and:0.1680)
		( the:0.0398 and:0.0850�:0.1113 sure:0.1660 fan:0.0569 teacher:0.0879.:0.1543 and:0.1748)
 and
------
		(,:1.0000 I:1.0000'm:0.9922 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.4141�:0.2910 sure:0.2041 bit:0.0422 that:0.0977.:0.2695 and:0.1689 I:0.1631)
		( I:0.3398 will:0.0952 sure:0.1855 bit:0.0444 teacher:0.1064.:0.2324 and:0.1436 I:0.4355)
		( I:0.2158�:0.1113 sure:0.2236 little:0.0496 teacher:0.0820.:0.2070 but:0.1494 I:0.6016)
		( I:0.1826�:0.1172 sure:0.2178 little:0.0486 teacher:0.0962.:0.1934 but:0.1504 I:0.5078)
		( I:0.1455�:0.1172 sure:0.2041 little:0.0481 teacher:0.0938.:0.1797 but:0.1514 I:0.4492)
		( I:0.1245�:0.1167 sure:0.1943 little:0.0464 teacher:0.0938.:0.1758 and:0.1523 I:0.4277)
		( I:0.1089�:0.1108 sure:0.1885 fan:0.0483 teacher:0.0908.:0.1709 and:0.1553 I:0.4082)
		( I:0.0986�:0.1123 sure:0.1836 fan:0.0513 teacher:0.0898.:0.1641 and:0.1562 I:0.3945)
		( I:0.0889�:0.1133 sure:0.1797 fan:0.0537 teacher:0.0898.:0.1650 and:0.1621 I:0.3789)
		( and:0.0850�:0.1138 sure:0.1689 fan:0.0554 teacher:0.0884.:0.1621 and:0.1650 I:0.3633)
		( and:0.0864�:0.1099 sure:0.1670 fan:0.0562 teacher:0.0898.:0.1562 and:0.1680 I:0.3496)
		( and:0.0850�:0.1113 sure:0.1660 fan:0.0569 teacher:0.0879.:0.1543 and:0.1748 I:0.3516)
 I'm a language model. I'm a language model
6950: sample 0: Hello, I'm a language model,
------
		(afort:0.0027,:1.0000 I:1.0000'm:0.9961 a:1.0000 language:1.0000 model:1.0000,:1.0000)
		(,:0.0359 I:0.1523�:0.1719 going:0.1021 teacher:0.0267 that:0.1338.:0.2266 and:0.1318)
		(,:0.0376 I:0.2354 have:0.0693 going:0.1270 teacher:0.0237 teacher:0.2070.:0.2002 I:0.1582)
		(,:0.0381 I:0.1602�:0.0869 going:0.1377 little:0.0262 teacher:0.1787.:0.1855 I:0.1299)
		(,:0.0388 I:0.1299�:0.0864 going:0.1260 great:0.0236 teacher:0.2051 for:0.1689 and:0.1299)
		(,:0.0386 I:0.1182�:0.0840 going:0.1206 great:0.0245 teacher:0.2041 for:0.1719 and:0.1416)
		(,:0.0383 I:0.1104�:0.0845 going:0.1133 great:0.0247 teacher:0.2080 for:0.1797 and:0.1504)
		(,:0.0378 I:0.1011�:0.0811 going:0.1050 great:0.0244 teacher:0.2070 for:0.1836 and:0.1523)
		(,:0.0381 I:0.0957�:0.0806 going:0.0996 member:0.0253 teacher:0.1982 for:0.1875 and:0.1621)
		(,:0.0376 I:0.0908�:0.0811 going:0.0933 member:0.0264 teacher:0.1943 for:0.1875 and:0.1680)
		(,:0.0374 I:0.0864�:0.0820 going:0.0884 member:0.0275 teacher:0.2002 for:0.1846 and:0.1758)
		(,:0.0366 I:0.0845�:0.0820 going:0.0835 member:0.0286 teacher:0.1865 for:0.1904 and:0.1748)
		(,:0.0361 I:0.0806�:0.0825 going:0.0786 member:0.0289 teacher:0.1855 for:0.1885 and:0.1826)
 and
------
		(,:1.0000 I:1.0000'm:0.9961 a:1.0000 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1523�:0.1719 going:0.1021 teacher:0.0267 that:0.1338.:0.2266 and:0.1318 I:0.1865)
		( I:0.2354 have:0.0693 going:0.1270 teacher:0.0237 teacher:0.2070.:0.2002 I:0.1582 I:0.5039)
		( I:0.1602�:0.0869 going:0.1377 little:0.0262 teacher:0.1787.:0.1855 I:0.1299 I:0.4980)
		( I:0.1299�:0.0864 going:0.1260 great:0.0236 teacher:0.2051 for:0.1689 and:0.1299 I:0.4785)
		( I:0.1182�:0.0840 going:0.1206 great:0.0245 teacher:0.2041 for:0.1719 and:0.1416 I:0.4492)
		( I:0.1104�:0.0845 going:0.1133 great:0.0247 teacher:0.2080 for:0.1797 and:0.1504 I:0.4590)
		( I:0.1011�:0.0811 going:0.1050 great:0.0244 teacher:0.2070 for:0.1836 and:0.1523 I:0.4570)
		( I:0.0957�:0.0806 going:0.0996 member:0.0253 teacher:0.1982 for:0.1875 and:0.1621 I:0.4570)
		( I:0.0908�:0.0811 going:0.0933 member:0.0264 teacher:0.1943 for:0.1875 and:0.1680 I:0.4570)
		( I:0.0864�:0.0820 going:0.0884 member:0.0275 teacher:0.2002 for:0.1846 and:0.1758 I:0.4434)
		( I:0.0845�:0.0820 going:0.0835 member:0.0286 teacher:0.1865 for:0.1904 and:0.1748 I:0.4473)
		( I:0.0806�:0.0825 going:0.0786 member:0.0289 teacher:0.1855 for:0.1885 and:0.1826 I:0.4492)
 I'm a language model.
I'm a language
7100: sample 0: Hello, I'm a language model,
------
		(Hello:0.0024,:1.0000 I:1.0000'm:0.9961 a:1.0000 language:1.0000 model:1.0000,:1.0000)
		(,:0.0325 I:0.3184�:0.2617 sure:0.1348 student:0.0361.:0.1250.:0.2480 and:0.1201)
		(,:0.0349 I:0.2617 have:0.0962 sure:0.1328 student:0.0272 teacher:0.0742.:0.2363 and:0.1104)
		(,:0.0364 I:0.2432 have:0.0786 not:0.1245 bit:0.0276 teacher:0.0564.:0.2246 I:0.1201)
		(,:0.0366 I:0.2402 have:0.0825 not:0.1299 bit:0.0237 teacher:0.0630.:0.2119 I:0.1494)
		(,:0.0376 I:0.2432 have:0.0859 not:0.1387 professional:0.0219 teacher:0.0630.:0.2012 I:0.1318)
		(,:0.0369 I:0.2334 have:0.0850 not:0.1436 professional:0.0242 programmer:0.0742.:0.1924 I:0.1289)
		(,:0.0371 I:0.2256 have:0.0903 not:0.1465 professional:0.0260 programmer:0.0767.:0.1865 I:0.1226)
		( the:0.0378 I:0.2129 have:0.0913 not:0.1494 professional:0.0269 programmer:0.0786.:0.1865 and:0.1216)
		( the:0.0381 I:0.2061 have:0.0923 not:0.1484 professional:0.0278 programmer:0.0806.:0.1875 and:0.1235)
		( the:0.0383 I:0.1982 have:0.0928 not:0.1543 professional:0.0281 programmer:0.0801.:0.1836 and:0.1270)
		( the:0.0381 I:0.1865 have:0.0942 not:0.1533 professional:0.0277 programmer:0.0830.:0.1865 and:0.1299)
		( the:0.0378 I:0.1807 have:0.0952 not:0.1514 professional:0.0284 programmer:0.0820.:0.1836 and:0.1328)
 and
------
		(,:1.0000 I:1.0000'm:0.9961 a:1.0000 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.3184�:0.2617 sure:0.1348 student:0.0361.:0.1250.:0.2480 and:0.1201 I:0.1445)
		( I:0.2617 have:0.0962 sure:0.1328 student:0.0272 teacher:0.0742.:0.2363 and:0.1104 I:0.5938)
		( I:0.2432 have:0.0786 not:0.1245 bit:0.0276 teacher:0.0564.:0.2246 I:0.1201 I:0.5000)
		( I:0.2402 have:0.0825 not:0.1299 bit:0.0237 teacher:0.0630.:0.2119 I:0.1494 I:0.5391)
		( I:0.2432 have:0.0859 not:0.1387 professional:0.0219 teacher:0.0630.:0.2012 I:0.1318 I:0.5000)
		( I:0.2334 have:0.0850 not:0.1436 professional:0.0242 programmer:0.0742.:0.1924 I:0.1289 I:0.4941)
		( I:0.2256 have:0.0903 not:0.1465 professional:0.0260 programmer:0.0767.:0.1865 I:0.1226 I:0.4902)
		( I:0.2129 have:0.0913 not:0.1494 professional:0.0269 programmer:0.0786.:0.1865 and:0.1216 I:0.4766)
		( I:0.2061 have:0.0923 not:0.1484 professional:0.0278 programmer:0.0806.:0.1875 and:0.1235 I:0.4766)
		( I:0.1982 have:0.0928 not:0.1543 professional:0.0281 programmer:0.0801.:0.1836 and:0.1270 I:0.4629)
		( I:0.1865 have:0.0942 not:0.1533 professional:0.0277 programmer:0.0830.:0.1865 and:0.1299 I:0.4629)
		( I:0.1807 have:0.0952 not:0.1514 professional:0.0284 programmer:0.0820.:0.1836 and:0.1328 I:0.4668)
 I'm a language model. I'm a language model
7250: sample 0: Hello, I'm a language model,
------
		(Hello:0.0028,:1.0000 I:1.0000'm:1.0000 a:1.0000 language:1.0000 model:1.0000,:1.0000)
		(,:0.0374 I:0.1895 have:0.1338 not:0.0752 very:0.0332 that:0.0830.:0.2236 and:0.1943)
		(,:0.0398 I:0.2246 have:0.0879 not:0.1484 student:0.0282 teacher:0.1416.:0.1719 and:0.1709)
		(,:0.0403 I:0.1787�:0.1406 not:0.1226 very:0.0270 teacher:0.1436.:0.1289 and:0.2314)
		(,:0.0410 I:0.1562�:0.1377 not:0.1157 fan:0.0297 teacher:0.1553 and:0.1245 and:0.2256)
		(,:0.0413 I:0.1484�:0.1299 not:0.1118 fan:0.0334 teacher:0.1484 and:0.1309 and:0.2354)
		(,:0.0420 I:0.1367�:0.1309 not:0.1113 fan:0.0344 teacher:0.1484 and:0.1338 and:0.2402)
		(,:0.0413 I:0.1270�:0.1250 not:0.1108 fan:0.0349 teacher:0.1494 and:0.1387 and:0.2363)
		(,:0.0408 I:0.1221�:0.1201 not:0.1118 member:0.0344 teacher:0.1455 and:0.1406 and:0.2451)
		(,:0.0410 I:0.1172�:0.1226 not:0.1133 member:0.0356 teacher:0.1416 and:0.1396 and:0.2441)
		(,:0.0408 I:0.1152�:0.1240 not:0.1147 member:0.0371 teacher:0.1328 and:0.1406 and:0.2539)
		(,:0.0400 I:0.1108�:0.1196 not:0.1147 member:0.0371 teacher:0.1309 and:0.1455 and:0.2559)
		(.:0.0403 I:0.1064�:0.1211 not:0.1162 member:0.0386 teacher:0.1309 and:0.1475 and:0.2676)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:1.0000 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1895 have:0.1338 not:0.0752 very:0.0332 that:0.0830.:0.2236 and:0.1943 I:0.2188)
		( I:0.2246 have:0.0879 not:0.1484 student:0.0282 teacher:0.1416.:0.1719 and:0.1709 I:0.5273)
		( I:0.1787�:0.1406 not:0.1226 very:0.0270 teacher:0.1436.:0.1289 and:0.2314 I:0.5117)
		( I:0.1562�:0.1377 not:0.1157 fan:0.0297 teacher:0.1553 and:0.1245 and:0.2256 I:0.4785)
		( I:0.1484�:0.1299 not:0.1118 fan:0.0334 teacher:0.1484 and:0.1309 and:0.2354 I:0.4258)
		( I:0.1367�:0.1309 not:0.1113 fan:0.0344 teacher:0.1484 and:0.1338 and:0.2402 I:0.4199)
		( I:0.1270�:0.1250 not:0.1108 fan:0.0349 teacher:0.1494 and:0.1387 and:0.2363 I:0.4023)
		( I:0.1221�:0.1201 not:0.1118 member:0.0344 teacher:0.1455 and:0.1406 and:0.2451 I:0.4043)
		( I:0.1172�:0.1226 not:0.1133 member:0.0356 teacher:0.1416 and:0.1396 and:0.2441 I:0.4043)
		( I:0.1152�:0.1240 not:0.1147 member:0.0371 teacher:0.1328 and:0.1406 and:0.2539 I:0.4062)
		( I:0.1108�:0.1196 not:0.1147 member:0.0371 teacher:0.1309 and:0.1455 and:0.2559 I:0.4082)
		( I:0.1064�:0.1211 not:0.1162 member:0.0386 teacher:0.1309 and:0.1475 and:0.2676 I:0.3945)
 I'm a language model.
I'm a language
7400: sample 0: Hello, I'm a language model,
------
		(afort:0.0026,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0381 I:0.1357 have:0.0996 going:0.0566 teacher:0.0393 language:0.0981.:0.2461 and:0.2158)
		(,:0.0408 I:0.1836 will:0.0938 not:0.1367 member:0.0304 teacher:0.2363.:0.1895 but:0.1875)
		(,:0.0408 I:0.1475�:0.0825 not:0.1553 great:0.0283 teacher:0.1543.:0.1826 but:0.1846)
		(,:0.0408 I:0.1475�:0.0859 not:0.1611 member:0.0400 teacher:0.1592.:0.1787 but:0.1699)
		(,:0.0410 I:0.1367�:0.0781 not:0.1553 member:0.0481 teacher:0.1514.:0.1836 and:0.1689)
		(,:0.0410 I:0.1226�:0.0776 not:0.1494 member:0.0544 teacher:0.1309.:0.1758 and:0.1846)
		(,:0.0410 I:0.1128�:0.0767 not:0.1455 member:0.0583 teacher:0.1279.:0.1777 and:0.1797)
		(,:0.0405 I:0.1035�:0.0723 not:0.1455 member:0.0610 programmer:0.1240.:0.1816 and:0.1875)
		(,:0.0400 I:0.0972�:0.0728 not:0.1445 member:0.0623 programmer:0.1279.:0.1787 and:0.1953)
		(,:0.0398 I:0.0913�:0.0732 not:0.1367 member:0.0645 programmer:0.1260.:0.1836 and:0.2051)
		(.:0.0396 I:0.0854�:0.0698 not:0.1377 member:0.0664 programmer:0.1260.:0.1807 and:0.2051)
		(.:0.0393 I:0.0796�:0.0703 not:0.1377 member:0.0654 programmer:0.1250.:0.1777 and:0.2158)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1357 have:0.0996 going:0.0566 teacher:0.0393 language:0.0981.:0.2461 and:0.2158 I:0.2012)
		( I:0.1836 will:0.0938 not:0.1367 member:0.0304 teacher:0.2363.:0.1895 but:0.1875 I:0.6328)
		( I:0.1475�:0.0825 not:0.1553 great:0.0283 teacher:0.1543.:0.1826 but:0.1846 I:0.5352)
		( I:0.1475�:0.0859 not:0.1611 member:0.0400 teacher:0.1592.:0.1787 but:0.1699 I:0.5547)
		( I:0.1367�:0.0781 not:0.1553 member:0.0481 teacher:0.1514.:0.1836 and:0.1689 I:0.5078)
		( I:0.1226�:0.0776 not:0.1494 member:0.0544 teacher:0.1309.:0.1758 and:0.1846 I:0.4980)
		( I:0.1128�:0.0767 not:0.1455 member:0.0583 teacher:0.1279.:0.1777 and:0.1797 I:0.4922)
		( I:0.1035�:0.0723 not:0.1455 member:0.0610 programmer:0.1240.:0.1816 and:0.1875 I:0.5078)
		( I:0.0972�:0.0728 not:0.1445 member:0.0623 programmer:0.1279.:0.1787 and:0.1953 I:0.5039)
		( I:0.0913�:0.0732 not:0.1367 member:0.0645 programmer:0.1260.:0.1836 and:0.2051 I:0.5039)
		( I:0.0854�:0.0698 not:0.1377 member:0.0664 programmer:0.1260.:0.1807 and:0.2051 I:0.5078)
		( I:0.0796�:0.0703 not:0.1377 member:0.0654 programmer:0.1250.:0.1777 and:0.2158 I:0.5078)
 I'm a language programmer. I'm a language programmer
7550: sample 0: Hello, I'm a language model,
------
		(Hello:0.0047,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0381 I:0.1040 want:0.1104 going:0.0522 little:0.0312 and:0.0791.:0.2559 and:0.1885)
		(,:0.0405 I:0.3281 want:0.0806 going:0.0938 student:0.0356 teacher:0.3281.:0.2148 but:0.1455)
		(,:0.0417 I:0.2637 am:0.0757 going:0.1089 little:0.0310 teacher:0.2461.:0.2129 but:0.1465)
		(,:0.0430 I:0.2217 am:0.0854 going:0.1191 member:0.0283 teacher:0.3066.:0.2178 I:0.1641)
		(,:0.0432 I:0.2031 am:0.0884 going:0.1177 member:0.0330 teacher:0.3262.:0.2188 I:0.1436)
		(,:0.0432 I:0.1836 am:0.0933 going:0.1157 member:0.0364 teacher:0.3125.:0.2109 I:0.1377)
		(,:0.0430 I:0.1680 am:0.0986 going:0.1167 member:0.0381 teacher:0.3066.:0.2051 and:0.1387)
		(,:0.0432 I:0.1592 am:0.0986 going:0.1123 member:0.0398 teacher:0.3086.:0.2021 and:0.1455)
		(,:0.0427 I:0.1533 am:0.0991 going:0.1099 member:0.0405 teacher:0.3027.:0.1973 and:0.1484)
		(,:0.0425 I:0.1445 am:0.0996 going:0.1021 member:0.0415 teacher:0.2988.:0.1924 and:0.1562)
		(,:0.0422 I:0.1387 am:0.0996 going:0.1001 member:0.0415 teacher:0.2988.:0.1846 and:0.1650)
		(,:0.0413 I:0.1338 am:0.1016 going:0.0996 member:0.0410 teacher:0.2969.:0.1865 and:0.1650)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1040 want:0.1104 going:0.0522 little:0.0312 and:0.0791.:0.2559 and:0.1885 I:0.1992)
		( I:0.3281 want:0.0806 going:0.0938 student:0.0356 teacher:0.3281.:0.2148 but:0.1455 I:0.4902)
		( I:0.2637 am:0.0757 going:0.1089 little:0.0310 teacher:0.2461.:0.2129 but:0.1465 I:0.3789)
		( I:0.2217 am:0.0854 going:0.1191 member:0.0283 teacher:0.3066.:0.2178 I:0.1641 I:0.4062)
		( I:0.2031 am:0.0884 going:0.1177 member:0.0330 teacher:0.3262.:0.2188 I:0.1436 I:0.3789)
		( I:0.1836 am:0.0933 going:0.1157 member:0.0364 teacher:0.3125.:0.2109 I:0.1377 I:0.3730)
		( I:0.1680 am:0.0986 going:0.1167 member:0.0381 teacher:0.3066.:0.2051 and:0.1387 I:0.3691)
		( I:0.1592 am:0.0986 going:0.1123 member:0.0398 teacher:0.3086.:0.2021 and:0.1455 I:0.3652)
		( I:0.1533 am:0.0991 going:0.1099 member:0.0405 teacher:0.3027.:0.1973 and:0.1484 I:0.3652)
		( I:0.1445 am:0.0996 going:0.1021 member:0.0415 teacher:0.2988.:0.1924 and:0.1562 I:0.3652)
		( I:0.1387 am:0.0996 going:0.1001 member:0.0415 teacher:0.2988.:0.1846 and:0.1650 I:0.3652)
		( I:0.1338 am:0.1016 going:0.0996 member:0.0410 teacher:0.2969.:0.1865 and:0.1650 I:0.3652)
 I'm a language model. I'm a language model
7700: sample 0: Hello, I'm a language model,
------
		(Hello:0.0040,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0364 I:0.4453 have:0.0713 sure:0.0498 bit:0.0415 language:0.0757.:0.1963 and:0.2070)
		(,:0.0391 I:0.3184 am:0.0588 sure:0.0664 little:0.0266 teacher:0.2422 and:0.1553 and:0.1855)
		(,:0.0403 I:0.1914 am:0.0884 going:0.0698 little:0.0320 teacher:0.1631.:0.1680 but:0.1748)
		(,:0.0408 I:0.1553 am:0.0981 not:0.0767 bit:0.0265 teacher:0.1729.:0.1611 but:0.1729)
		(,:0.0410 I:0.1357 am:0.1045 not:0.0884 bit:0.0261 teacher:0.1572.:0.1582 but:0.1660)
		(,:0.0410 I:0.1235 am:0.1074 not:0.0938 member:0.0297 teacher:0.1445.:0.1504 and:0.1641)
		(,:0.0410 I:0.1147 am:0.1094 not:0.1006 member:0.0317 teacher:0.1348.:0.1445 and:0.1689)
		(.:0.0413 I:0.1064 am:0.1123 not:0.1021 member:0.0344 teacher:0.1299.:0.1406 and:0.1748)
		(.:0.0408 I:0.0996 am:0.1079 not:0.1045 member:0.0361 expert:0.1357.:0.1377 and:0.1748)
		(.:0.0410 I:0.0952 am:0.1104 not:0.1040 member:0.0374 expert:0.1348.:0.1318 and:0.1816)
		(.:0.0413 I:0.0913 am:0.1064 not:0.1074 member:0.0393 expert:0.1348.:0.1299 and:0.1846)
		(.:0.0405 I:0.0879 am:0.1084 not:0.1074 member:0.0396 expert:0.1357.:0.1289 and:0.1904)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.4453 have:0.0713 sure:0.0498 bit:0.0415 language:0.0757.:0.1963 and:0.2070 I:0.2578)
		( I:0.3184 am:0.0588 sure:0.0664 little:0.0266 teacher:0.2422 and:0.1553 and:0.1855 I:0.7070)
		( I:0.1914 am:0.0884 going:0.0698 little:0.0320 teacher:0.1631.:0.1680 but:0.1748 I:0.5625)
		( I:0.1553 am:0.0981 not:0.0767 bit:0.0265 teacher:0.1729.:0.1611 but:0.1729 I:0.5742)
		( I:0.1357 am:0.1045 not:0.0884 bit:0.0261 teacher:0.1572.:0.1582 but:0.1660 I:0.5430)
		( I:0.1235 am:0.1074 not:0.0938 member:0.0297 teacher:0.1445.:0.1504 and:0.1641 I:0.5312)
		( I:0.1147 am:0.1094 not:0.1006 member:0.0317 teacher:0.1348.:0.1445 and:0.1689 I:0.5156)
		( I:0.1064 am:0.1123 not:0.1021 member:0.0344 teacher:0.1299.:0.1406 and:0.1748 I:0.5234)
		( I:0.0996 am:0.1079 not:0.1045 member:0.0361 expert:0.1357.:0.1377 and:0.1748 I:0.5117)
		( I:0.0952 am:0.1104 not:0.1040 member:0.0374 expert:0.1348.:0.1318 and:0.1816 I:0.5156)
		( I:0.0913 am:0.1064 not:0.1074 member:0.0393 expert:0.1348.:0.1299 and:0.1846 I:0.5000)
		( I:0.0879 am:0.1084 not:0.1074 member:0.0396 expert:0.1357.:0.1289 and:0.1904 I:0.5039)
 I'm a language model. I'm a language model
7850: sample 0: Hello, I'm a language model,
------
		(Hello:0.0065,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0349 I:0.2930 have:0.0869 sure:0.1035 new:0.0275 that:0.1396.:0.2432 and:0.2021)
		(,:0.0381 I:0.2637'm:0.0698 sure:0.1982 new:0.0291 expert:0.1611.:0.2617 I:0.1494)
		(,:0.0393 I:0.1865'm:0.0859 sure:0.1885 little:0.0282 expert:0.1089.:0.2578 but:0.1406)
		(,:0.0403 I:0.1465'm:0.0835 sure:0.1680 little:0.0250 expert:0.1494.:0.2598 I:0.1445)
		(,:0.0400 I:0.1299'm:0.0806 sure:0.1602 little:0.0234 expert:0.1650.:0.2539 but:0.1553)
		(,:0.0405 I:0.1104'm:0.0776 sure:0.1494 member:0.0237 expert:0.1572.:0.2559 but:0.1543)
		(,:0.0400 I:0.0972'm:0.0786 sure:0.1328 member:0.0261 expert:0.1553.:0.2480 but:0.1592)
		(,:0.0400 I:0.0874'm:0.0757 sure:0.1250 member:0.0276 expert:0.1582.:0.2422 but:0.1572)
		(,:0.0396 I:0.0796'm:0.0767 sure:0.1196 member:0.0291 expert:0.1533.:0.2383 but:0.1611)
		(,:0.0393 I:0.0737'm:0.0732 not:0.1152 member:0.0300 expert:0.1504.:0.2363 and:0.1611)
		(,:0.0391 I:0.0688'm:0.0742 not:0.1177 member:0.0311 expert:0.1484.:0.2334 and:0.1660)
		(,:0.0386 I:0.0645'm:0.0708 not:0.1196 member:0.0312 expert:0.1484.:0.2207 and:0.1709)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.2930 have:0.0869 sure:0.1035 new:0.0275 that:0.1396.:0.2432 and:0.2021 I:0.1650)
		( I:0.2637'm:0.0698 sure:0.1982 new:0.0291 expert:0.1611.:0.2617 I:0.1494 I:0.4160)
		( I:0.1865'm:0.0859 sure:0.1885 little:0.0282 expert:0.1089.:0.2578 but:0.1406 I:0.3613)
		( I:0.1465'm:0.0835 sure:0.1680 little:0.0250 expert:0.1494.:0.2598 I:0.1445 I:0.4160)
		( I:0.1299'm:0.0806 sure:0.1602 little:0.0234 expert:0.1650.:0.2539 but:0.1553 I:0.3984)
		( I:0.1104'm:0.0776 sure:0.1494 member:0.0237 expert:0.1572.:0.2559 but:0.1543 I:0.4082)
		( I:0.0972'm:0.0786 sure:0.1328 member:0.0261 expert:0.1553.:0.2480 but:0.1592 I:0.4082)
		( I:0.0874'm:0.0757 sure:0.1250 member:0.0276 expert:0.1582.:0.2422 but:0.1572 I:0.4102)
		( I:0.0796'm:0.0767 sure:0.1196 member:0.0291 expert:0.1533.:0.2383 but:0.1611 I:0.4121)
		( I:0.0737'm:0.0732 not:0.1152 member:0.0300 expert:0.1504.:0.2363 and:0.1611 I:0.4121)
		( I:0.0688'm:0.0742 not:0.1177 member:0.0311 expert:0.1484.:0.2334 and:0.1660 I:0.4141)
		( I:0.0645'm:0.0708 not:0.1196 member:0.0312 expert:0.1484.:0.2207 and:0.1709 I:0.4180)
 I'm a language model. I'm a language model
8000: sample 0: Hello, I'm a language model,
------
		(Hello:0.0045,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0344 I:0.2637�:0.1670 going:0.0752 teacher:0.0312 that:0.0928.:0.2051 and:0.1943)
		(,:0.0378 I:0.3555�:0.1108 sure:0.0781 teacher:0.0267 teacher:0.2031.:0.2314 and:0.1406)
		(,:0.0398 I:0.2676�:0.1299 sorry:0.0942 great:0.0195 teacher:0.1523.:0.2148 but:0.1475)
		(,:0.0410 I:0.1982�:0.1230 sorry:0.1035 great:0.0194 teacher:0.1641.:0.2148 but:0.1504)
		(,:0.0413 I:0.1602�:0.1118 sorry:0.1064 member:0.0192 teacher:0.1543.:0.2109 and:0.1631)
		(,:0.0413 I:0.1348�:0.1045 sorry:0.1016 member:0.0211 teacher:0.1309.:0.2041 and:0.1787)
		(,:0.0417 I:0.1157�:0.1040 sorry:0.0986 member:0.0221 teacher:0.1270.:0.2002 and:0.1924)
		(,:0.0413 I:0.1055�:0.0986 sorry:0.0918 member:0.0228 teacher:0.1133.:0.1943 and:0.2031)
		(.:0.0420 I:0.0957�:0.0991 sorry:0.0864 member:0.0234 teacher:0.1079.:0.1895 and:0.2148)
		(.:0.0415 and:0.0923�:0.1001 going:0.0820 member:0.0234 teacher:0.0991.:0.1846 and:0.2217)
		(.:0.0413 and:0.0913�:0.1011 going:0.0806 member:0.0244 teacher:0.0898.:0.1914 and:0.2285)
		(.:0.0417 and:0.0908�:0.0967 going:0.0811 member:0.0245 teacher:0.0879.:0.1875 and:0.2363)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.2637�:0.1670 going:0.0752 teacher:0.0312 that:0.0928.:0.2051 and:0.1943 I:0.1338)
		( I:0.3555�:0.1108 sure:0.0781 teacher:0.0267 teacher:0.2031.:0.2314 and:0.1406 I:0.4297)
		( I:0.2676�:0.1299 sorry:0.0942 great:0.0195 teacher:0.1523.:0.2148 but:0.1475 I:0.3984)
		( I:0.1982�:0.1230 sorry:0.1035 great:0.0194 teacher:0.1641.:0.2148 but:0.1504 I:0.3965)
		( I:0.1602�:0.1118 sorry:0.1064 member:0.0192 teacher:0.1543.:0.2109 and:0.1631 I:0.3613)
		( I:0.1348�:0.1045 sorry:0.1016 member:0.0211 teacher:0.1309.:0.2041 and:0.1787 I:0.3594)
		( I:0.1157�:0.1040 sorry:0.0986 member:0.0221 teacher:0.1270.:0.2002 and:0.1924 I:0.3438)
		( I:0.1055�:0.0986 sorry:0.0918 member:0.0228 teacher:0.1133.:0.1943 and:0.2031 I:0.3438)
		( I:0.0957�:0.0991 sorry:0.0864 member:0.0234 teacher:0.1079.:0.1895 and:0.2148 I:0.3438)
		( and:0.0923�:0.1001 going:0.0820 member:0.0234 teacher:0.0991.:0.1846 and:0.2217 I:0.3301)
		( and:0.0913�:0.1011 going:0.0806 member:0.0244 teacher:0.0898.:0.1914 and:0.2285 I:0.3301)
		( and:0.0908�:0.0967 going:0.0811 member:0.0245 teacher:0.0879.:0.1875 and:0.2363 I:0.3301)
 I'm a language model. I'm a language model
8150: sample 0: Hello, I'm a language model,
------
		(Hello:0.0038,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0337 I:0.1426�:0.1504 going:0.0801 teacher:0.0452 and:0.1357.:0.2070 and:0.1631)
		(,:0.0356 I:0.1230�:0.1143 going:0.0986 teacher:0.0273 teacher:0.1436.:0.2500 but:0.1455)
		(,:0.0364 I:0.0952�:0.1187 sorry:0.1187 teacher:0.0238 teacher:0.1108.:0.3008 but:0.1650)
		(,:0.0369 I:0.0869�:0.0923 sorry:0.1494 teacher:0.0231 teacher:0.1494.:0.3262 but:0.1504)
		( the:0.0376 I:0.0762�:0.0835 sorry:0.1572 fan:0.0206 teacher:0.1621.:0.3164 but:0.1602)
		( the:0.0386 I:0.0679�:0.0732 sorry:0.1680 fan:0.0232 teacher:0.1592.:0.3066 but:0.1611)
		( the:0.0386 I:0.0610�:0.0698 sorry:0.1650 fan:0.0261 teacher:0.1621.:0.2891 but:0.1641)
		( the:0.0388 and:0.0569�:0.0703 sorry:0.1621 fan:0.0278 teacher:0.1592.:0.2832 but:0.1660)
		( the:0.0388 and:0.0583�:0.0679 sorry:0.1611 fan:0.0293 teacher:0.1514.:0.2715 but:0.1709)
		( the:0.0391 and:0.0615�:0.0693 sorry:0.1523 fan:0.0306 teacher:0.1465.:0.2695 but:0.1748)
		( the:0.0388 and:0.0610�:0.0664 sorry:0.1504 fan:0.0315 teacher:0.1416.:0.2676 but:0.1758)
		( the:0.0383 and:0.0625�:0.0679 sorry:0.1426 fan:0.0322 teacher:0.1377.:0.2676 but:0.1797)
 but
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 but:1.0000)
		( I:0.1426�:0.1504 going:0.0801 teacher:0.0452 and:0.1357.:0.2070 and:0.1631 I:0.2314)
		( I:0.1230�:0.1143 going:0.0986 teacher:0.0273 teacher:0.1436.:0.2500 but:0.1455 I:0.2559)
		( I:0.0952�:0.1187 sorry:0.1187 teacher:0.0238 teacher:0.1108.:0.3008 but:0.1650 I:0.2793)
		( I:0.0869�:0.0923 sorry:0.1494 teacher:0.0231 teacher:0.1494.:0.3262 but:0.1504 I:0.2520)
		( I:0.0762�:0.0835 sorry:0.1572 fan:0.0206 teacher:0.1621.:0.3164 but:0.1602 I:0.2656)
		( I:0.0679�:0.0732 sorry:0.1680 fan:0.0232 teacher:0.1592.:0.3066 but:0.1611 I:0.2598)
		( I:0.0610�:0.0698 sorry:0.1650 fan:0.0261 teacher:0.1621.:0.2891 but:0.1641 I:0.2715)
		( and:0.0569�:0.0703 sorry:0.1621 fan:0.0278 teacher:0.1592.:0.2832 but:0.1660 I:0.2715)
		( and:0.0583�:0.0679 sorry:0.1611 fan:0.0293 teacher:0.1514.:0.2715 but:0.1709 I:0.2852)
		( and:0.0615�:0.0693 sorry:0.1523 fan:0.0306 teacher:0.1465.:0.2695 but:0.1748 I:0.2871)
		( and:0.0610�:0.0664 sorry:0.1504 fan:0.0315 teacher:0.1416.:0.2676 but:0.1758 I:0.2891)
		( and:0.0625�:0.0679 sorry:0.1426 fan:0.0322 teacher:0.1377.:0.2676 but:0.1797 I:0.3027)
 I'm not a language model. I'm a language
8300: sample 0: Hello, I'm a language model,
------
		(Hello:0.0044,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0381 I:0.0859 have:0.0952 sure:0.0859 little:0.0298 language:0.1025.:0.2236 and:0.1631)
		(,:0.0408 I:0.1084 have:0.0913 not:0.1157 very:0.0305 teacher:0.2158.:0.1641 and:0.1318)
		(,:0.0417 I:0.0908 have:0.0776 not:0.1123 very:0.0405 teacher:0.1729.:0.1895 and:0.1484)
		(,:0.0420 I:0.0835 have:0.0737 going:0.1191 very:0.0361 teacher:0.1973.:0.1963 and:0.1406)
		(,:0.0422 I:0.0811 have:0.0767 going:0.1133 very:0.0342 teacher:0.2061.:0.1973 and:0.1494)
		(,:0.0420 I:0.0757 have:0.0747 going:0.1143 member:0.0354 teacher:0.2090.:0.1943 and:0.1602)
		(,:0.0420 I:0.0698 have:0.0767 going:0.1104 member:0.0381 teacher:0.2139.:0.1953 and:0.1680)
		(,:0.0413 I:0.0645 have:0.0747 going:0.1060 member:0.0400 teacher:0.2148.:0.1934 and:0.1738)
		(,:0.0408 and:0.0596 have:0.0762 a:0.0991 member:0.0413 teacher:0.2070.:0.1934 and:0.1797)
		(,:0.0405 and:0.0598 have:0.0776 a:0.1011 member:0.0415 teacher:0.2119.:0.1934 and:0.1865)
		(,:0.0400 and:0.0598 have:0.0796 a:0.1030 member:0.0417 teacher:0.2070.:0.1895 and:0.1934)
		(,:0.0391 and:0.0596 have:0.0767 a:0.1089 member:0.0410 teacher:0.2051.:0.1914 and:0.1953)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.0859 have:0.0952 sure:0.0859 little:0.0298 language:0.1025.:0.2236 and:0.1631 I:0.1855)
		( I:0.1084 have:0.0913 not:0.1157 very:0.0305 teacher:0.2158.:0.1641 and:0.1318 I:0.3457)
		( I:0.0908 have:0.0776 not:0.1123 very:0.0405 teacher:0.1729.:0.1895 and:0.1484 I:0.3320)
		( I:0.0835 have:0.0737 going:0.1191 very:0.0361 teacher:0.1973.:0.1963 and:0.1406 I:0.3379)
		( I:0.0811 have:0.0767 going:0.1133 very:0.0342 teacher:0.2061.:0.1973 and:0.1494 I:0.3105)
		( I:0.0757 have:0.0747 going:0.1143 member:0.0354 teacher:0.2090.:0.1943 and:0.1602 I:0.3105)
		( I:0.0698 have:0.0767 going:0.1104 member:0.0381 teacher:0.2139.:0.1953 and:0.1680 I:0.2969)
		( I:0.0645 have:0.0747 going:0.1060 member:0.0400 teacher:0.2148.:0.1934 and:0.1738 I:0.3008)
		( and:0.0596 have:0.0762 a:0.0991 member:0.0413 teacher:0.2070.:0.1934 and:0.1797 I:0.2891)
		( and:0.0598 have:0.0776 a:0.1011 member:0.0415 teacher:0.2119.:0.1934 and:0.1865 I:0.2891)
		( and:0.0598 have:0.0796 a:0.1030 member:0.0417 teacher:0.2070.:0.1895 and:0.1934 I:0.2930)
		( and:0.0596 have:0.0767 a:0.1089 member:0.0410 teacher:0.2051.:0.1914 and:0.1953 I:0.2891)
 I'm a language model. I'm a language model
8450: sample 0: Hello, I'm a language model,
------
		(Hello:0.0059,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0359 I:0.1377 have:0.1787 sure:0.1021 little:0.0420 language:0.0820 that:0.1729 and:0.2041)
		(,:0.0391 I:0.1011 have:0.1177 not:0.1138 very:0.0297 teacher:0.2773 and:0.1631 but:0.1572)
		(,:0.0415 I:0.0840 have:0.0850 sure:0.1055 very:0.0306 teacher:0.2559 and:0.1787 but:0.1562)
		(,:0.0420 I:0.0757 have:0.0791 going:0.1069 member:0.0239 teacher:0.2871 and:0.1680 I:0.1523)
		(,:0.0422 I:0.0737 have:0.0757 going:0.1138 member:0.0302 teacher:0.2949 and:0.1533 and:0.1484)
		(,:0.0427 I:0.0703 have:0.0732 going:0.1138 member:0.0339 teacher:0.2871 and:0.1455 and:0.1592)
		(,:0.0427 I:0.0688 have:0.0723 going:0.1138 member:0.0361 teacher:0.2832 for:0.1494 and:0.1680)
		(,:0.0420 I:0.0659 have:0.0718 going:0.1201 member:0.0371 teacher:0.2871 for:0.1475 and:0.1787)
		(,:0.0422 I:0.0630 have:0.0723 going:0.1147 member:0.0378 teacher:0.2910 for:0.1475 and:0.1865)
		(,:0.0417 I:0.0623 have:0.0767 going:0.1147 member:0.0381 teacher:0.2852 for:0.1475 and:0.1934)
		(.:0.0415 I:0.0598 have:0.0767 going:0.1147 member:0.0381 teacher:0.2812 for:0.1445 and:0.1963)
		(.:0.0413 the:0.0591 have:0.0776 going:0.1147 member:0.0381 teacher:0.2793 for:0.1465 and:0.2031)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1377 have:0.1787 sure:0.1021 little:0.0420 language:0.0820 that:0.1729 and:0.2041 I:0.3809)
		( I:0.1011 have:0.1177 not:0.1138 very:0.0297 teacher:0.2773 and:0.1631 but:0.1572 I:0.4531)
		( I:0.0840 have:0.0850 sure:0.1055 very:0.0306 teacher:0.2559 and:0.1787 but:0.1562 I:0.4609)
		( I:0.0757 have:0.0791 going:0.1069 member:0.0239 teacher:0.2871 and:0.1680 I:0.1523 I:0.4824)
		( I:0.0737 have:0.0757 going:0.1138 member:0.0302 teacher:0.2949 and:0.1533 and:0.1484 I:0.4473)
		( I:0.0703 have:0.0732 going:0.1138 member:0.0339 teacher:0.2871 and:0.1455 and:0.1592 I:0.4316)
		( I:0.0688 have:0.0723 going:0.1138 member:0.0361 teacher:0.2832 for:0.1494 and:0.1680 I:0.4160)
		( I:0.0659 have:0.0718 going:0.1201 member:0.0371 teacher:0.2871 for:0.1475 and:0.1787 I:0.4180)
		( I:0.0630 have:0.0723 going:0.1147 member:0.0378 teacher:0.2910 for:0.1475 and:0.1865 I:0.4082)
		( I:0.0623 have:0.0767 going:0.1147 member:0.0381 teacher:0.2852 for:0.1475 and:0.1934 I:0.4102)
		( I:0.0598 have:0.0767 going:0.1147 member:0.0381 teacher:0.2812 for:0.1445 and:0.1963 I:0.3965)
		( the:0.0591 have:0.0776 going:0.1147 member:0.0381 teacher:0.2793 for:0.1465 and:0.2031 I:0.4004)
 I'm a language teacher. I'm a language teacher
8600: sample 0: Hello, I'm a language model,
------
		(Hello:0.0047,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0359 I:0.1748�:0.0698 sure:0.1289 student:0.0356.:0.0820.:0.2031 and:0.1260)
		(,:0.0378 I:0.2461'm:0.1006 not:0.1826 student:0.0327 teacher:0.0806.:0.2119 but:0.1592)
		(,:0.0388 I:0.2676'm:0.1035 not:0.1621 student:0.0242 teacher:0.0659.:0.1797 but:0.1719)
		(,:0.0398 I:0.1973'm:0.1006 not:0.1797 member:0.0238 teacher:0.0713.:0.1816 I:0.1680)
		(,:0.0396 I:0.1650'm:0.0938 not:0.1758 member:0.0287 writer:0.0737.:0.1748 but:0.1602)
		(,:0.0393 I:0.1494'm:0.0942 not:0.1748 member:0.0315 writer:0.0781.:0.1729 but:0.1553)
		(,:0.0396 I:0.1367'm:0.0952 not:0.1650 member:0.0327 writer:0.0796.:0.1699 and:0.1562)
		(,:0.0391 I:0.1338'm:0.0913 not:0.1660 member:0.0320 writer:0.0811.:0.1631 and:0.1641)
		(,:0.0386 I:0.1250'm:0.0928 not:0.1650 member:0.0317 writer:0.0781.:0.1592 and:0.1670)
		(,:0.0381 I:0.1221'm:0.0894 not:0.1572 member:0.0309 writer:0.0806.:0.1562 and:0.1758)
		(,:0.0378 I:0.1177'm:0.0913 not:0.1582 member:0.0303 writer:0.0791.:0.1543 and:0.1777)
		(.:0.0376 I:0.1133'm:0.0879 not:0.1504 member:0.0297 writer:0.0786.:0.1514 and:0.1807)
 and
------
		(,:1.0000 I:1.0000'm:0.9961 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.1748�:0.0698 sure:0.1289 student:0.0356.:0.0820.:0.2031 and:0.1260 I:0.2100)
		( I:0.2461'm:0.1006 not:0.1826 student:0.0327 teacher:0.0806.:0.2119 but:0.1592 I:0.4434)
		( I:0.2676'm:0.1035 not:0.1621 student:0.0242 teacher:0.0659.:0.1797 but:0.1719 I:0.4395)
		( I:0.1973'm:0.1006 not:0.1797 member:0.0238 teacher:0.0713.:0.1816 I:0.1680 I:0.4004)
		( I:0.1650'm:0.0938 not:0.1758 member:0.0287 writer:0.0737.:0.1748 but:0.1602 I:0.3730)
		( I:0.1494'm:0.0942 not:0.1748 member:0.0315 writer:0.0781.:0.1729 but:0.1553 I:0.3613)
		( I:0.1367'm:0.0952 not:0.1650 member:0.0327 writer:0.0796.:0.1699 and:0.1562 I:0.3496)
		( I:0.1338'm:0.0913 not:0.1660 member:0.0320 writer:0.0811.:0.1631 and:0.1641 I:0.3398)
		( I:0.1250'm:0.0928 not:0.1650 member:0.0317 writer:0.0781.:0.1592 and:0.1670 I:0.3438)
		( I:0.1221'm:0.0894 not:0.1572 member:0.0309 writer:0.0806.:0.1562 and:0.1758 I:0.3301)
		( I:0.1177'm:0.0913 not:0.1582 member:0.0303 writer:0.0791.:0.1543 and:0.1777 I:0.3340)
		( I:0.1133'm:0.0879 not:0.1504 member:0.0297 writer:0.0786.:0.1514 and:0.1807 I:0.3359)
 I'm a language model.
I'm a language
8750: sample 0: Hello, I'm a language model,
------
		(Hello:0.0052,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0349 I:0.5117 have:0.0767 like:0.0474 teacher:0.0284.:0.0981.:0.1660 and:0.1475)
		(,:0.0378 I:0.3184'm:0.0669 not:0.0791 little:0.0374 teacher:0.2236.:0.1543 I:0.1719)
		(,:0.0396 I:0.2119 am:0.0588 not:0.0864 little:0.0493 teacher:0.2031.:0.1641 and:0.1484)
		(,:0.0405 I:0.1641 am:0.0598 not:0.0864 little:0.0488 teacher:0.2090.:0.1660 and:0.1543)
		(,:0.0413 I:0.1475 am:0.0635 not:0.0859 little:0.0449 teacher:0.1992.:0.1738 and:0.1670)
		(,:0.0410 I:0.1328 am:0.0679 not:0.0845 little:0.0430 teacher:0.1973.:0.1748 and:0.1797)
		(,:0.0410 I:0.1270 am:0.0684 a:0.0840 little:0.0417 teacher:0.1895.:0.1738 and:0.1904)
		(,:0.0405 I:0.1206 am:0.0693 a:0.0928 little:0.0398 teacher:0.1807.:0.1748 and:0.2002)
		(,:0.0398 I:0.1152 am:0.0742 a:0.1016 little:0.0383 teacher:0.1729.:0.1719 and:0.2070)
		(,:0.0400 I:0.1104 am:0.0752 a:0.1089 little:0.0359 teacher:0.1689.:0.1738 and:0.2139)
		(,:0.0396 I:0.1089 am:0.0757 a:0.1162 little:0.0344 teacher:0.1582.:0.1729 and:0.2207)
		(,:0.0393 I:0.1040 am:0.0771 a:0.1216 little:0.0337 teacher:0.1494.:0.1719 and:0.2217)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( I:0.5117 have:0.0767 like:0.0474 teacher:0.0284.:0.0981.:0.1660 and:0.1475 I:0.3340)
		( I:0.3184'm:0.0669 not:0.0791 little:0.0374 teacher:0.2236.:0.1543 I:0.1719 I:0.5664)
		( I:0.2119 am:0.0588 not:0.0864 little:0.0493 teacher:0.2031.:0.1641 and:0.1484 I:0.4668)
		( I:0.1641 am:0.0598 not:0.0864 little:0.0488 teacher:0.2090.:0.1660 and:0.1543 I:0.5039)
		( I:0.1475 am:0.0635 not:0.0859 little:0.0449 teacher:0.1992.:0.1738 and:0.1670 I:0.4648)
		( I:0.1328 am:0.0679 not:0.0845 little:0.0430 teacher:0.1973.:0.1748 and:0.1797 I:0.4590)
		( I:0.1270 am:0.0684 a:0.0840 little:0.0417 teacher:0.1895.:0.1738 and:0.1904 I:0.4395)
		( I:0.1206 am:0.0693 a:0.0928 little:0.0398 teacher:0.1807.:0.1748 and:0.2002 I:0.4375)
		( I:0.1152 am:0.0742 a:0.1016 little:0.0383 teacher:0.1729.:0.1719 and:0.2070 I:0.4395)
		( I:0.1104 am:0.0752 a:0.1089 little:0.0359 teacher:0.1689.:0.1738 and:0.2139 I:0.4219)
		( I:0.1089 am:0.0757 a:0.1162 little:0.0344 teacher:0.1582.:0.1729 and:0.2207 I:0.4219)
		( I:0.1040 am:0.0771 a:0.1216 little:0.0337 teacher:0.1494.:0.1719 and:0.2217 I:0.4238)
 I'm a language model. I'm a language model
8900: sample 0: Hello, I'm a language model,
------
		(Hello:0.0107,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0361 the:0.0417�:0.1445 going:0.1709 teacher:0.0542.:0.0757.:0.2129 and:0.2178)
		(,:0.0413,:0.0444�:0.0874 going:0.1650 little:0.0266 teacher:0.1455 and:0.1416 and:0.2100)
		(,:0.0447,:0.0474 have:0.0820 going:0.1465 little:0.0253 programmer:0.1157 and:0.1631 and:0.2383)
		(,:0.0459,:0.0491 have:0.0874 sure:0.1592 little:0.0231 programmer:0.1318 and:0.1738 and:0.2412)
		(,:0.0476,:0.0498 have:0.0977 sure:0.1660 great:0.0208 programmer:0.1279 and:0.1758 and:0.2559)
		(,:0.0481,:0.0503 have:0.1030 sure:0.1689 professional:0.0234 programmer:0.1455 and:0.1807 and:0.2734)
		(,:0.0479,:0.0500 have:0.1104 sure:0.1660 professional:0.0255 programmer:0.1484 and:0.1807 and:0.2812)
		(,:0.0481,:0.0503 have:0.1187 sure:0.1641 professional:0.0272 programmer:0.1533 and:0.1836 and:0.2910)
		(,:0.0481,:0.0496 have:0.1216 sure:0.1631 professional:0.0283 programmer:0.1592 and:0.1836 and:0.3027)
		(,:0.0476,:0.0491 have:0.1309 sure:0.1631 professional:0.0297 programmer:0.1592 and:0.1826 and:0.3027)
		(,:0.0479,:0.0486 have:0.1328 sure:0.1621 professional:0.0304 programmer:0.1592 and:0.1865 and:0.3027)
		(,:0.0474,:0.0481 have:0.1367 sure:0.1543 professional:0.0310 programmer:0.1602 and:0.1826 and:0.3125)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0417�:0.1445 going:0.1709 teacher:0.0542.:0.0757.:0.2129 and:0.2178 I:0.1982)
		(,:0.0444�:0.0874 going:0.1650 little:0.0266 teacher:0.1455 and:0.1416 and:0.2100 I:0.2344)
		(,:0.0474 have:0.0820 going:0.1465 little:0.0253 programmer:0.1157 and:0.1631 and:0.2383 I:0.3750)
		(,:0.0491 have:0.0874 sure:0.1592 little:0.0231 programmer:0.1318 and:0.1738 and:0.2412 I:0.3125)
		(,:0.0498 have:0.0977 sure:0.1660 great:0.0208 programmer:0.1279 and:0.1758 and:0.2559 I:0.3438)
		(,:0.0503 have:0.1030 sure:0.1689 professional:0.0234 programmer:0.1455 and:0.1807 and:0.2734 I:0.3262)
		(,:0.0500 have:0.1104 sure:0.1660 professional:0.0255 programmer:0.1484 and:0.1807 and:0.2812 I:0.3281)
		(,:0.0503 have:0.1187 sure:0.1641 professional:0.0272 programmer:0.1533 and:0.1836 and:0.2910 I:0.3164)
		(,:0.0496 have:0.1216 sure:0.1631 professional:0.0283 programmer:0.1592 and:0.1836 and:0.3027 I:0.3184)
		(,:0.0491 have:0.1309 sure:0.1631 professional:0.0297 programmer:0.1592 and:0.1826 and:0.3027 I:0.3184)
		(,:0.0486 have:0.1328 sure:0.1621 professional:0.0304 programmer:0.1592 and:0.1865 and:0.3027 I:0.3203)
		(,:0.0481 have:0.1367 sure:0.1543 professional:0.0310 programmer:0.1602 and:0.1826 and:0.3125 I:0.3223)
 I'm a language model. I'm a language model
9050: sample 0: Hello, I'm a language model,
------
		(Hello:0.0081,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0391 the:0.0454�:0.1748 not:0.0791 teacher:0.0530.:0.0962.:0.2354 and:0.2021)
		(,:0.0420 the:0.0471�:0.0801 not:0.1279 very:0.0525 teacher:0.2236.:0.1523 I:0.2002)
		(,:0.0430 the:0.0469�:0.0986 sure:0.1475 very:0.0488 teacher:0.1895.:0.1533 I:0.1885)
		(,:0.0444 the:0.0471�:0.1011 sure:0.1562 very:0.0371 teacher:0.2031.:0.1455 I:0.2432)
		(,:0.0439 the:0.0469�:0.1050 sure:0.1523 very:0.0309 teacher:0.1963.:0.1396 I:0.1963)
		(,:0.0442 the:0.0464�:0.1079 sure:0.1455 little:0.0297 teacher:0.1963.:0.1367 I:0.1865)
		(,:0.0439 the:0.0454�:0.1104 sure:0.1367 member:0.0320 teacher:0.1914.:0.1357 I:0.1758)
		(,:0.0432 the:0.0447�:0.1069 sure:0.1357 member:0.0337 teacher:0.1875.:0.1328 I:0.1738)
		(,:0.0427 the:0.0435�:0.1084 sure:0.1289 member:0.0359 teacher:0.1787.:0.1299 I:0.1641)
		(,:0.0422 the:0.0427�:0.1104 sure:0.1226 member:0.0361 teacher:0.1729.:0.1270 I:0.1611)
		(,:0.0417 the:0.0425�:0.1118 sure:0.1167 member:0.0376 teacher:0.1680.:0.1221 I:0.1611)
		(,:0.0413 the:0.0413�:0.1133 sure:0.1113 member:0.0388 teacher:0.1641.:0.1196 and:0.1562)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0454�:0.1748 not:0.0791 teacher:0.0530.:0.0962.:0.2354 and:0.2021 I:0.1396)
		( the:0.0471�:0.0801 not:0.1279 very:0.0525 teacher:0.2236.:0.1523 I:0.2002 I:0.4062)
		( the:0.0469�:0.0986 sure:0.1475 very:0.0488 teacher:0.1895.:0.1533 I:0.1885 I:0.4258)
		( the:0.0471�:0.1011 sure:0.1562 very:0.0371 teacher:0.2031.:0.1455 I:0.2432 I:0.5000)
		( the:0.0469�:0.1050 sure:0.1523 very:0.0309 teacher:0.1963.:0.1396 I:0.1963 I:0.4395)
		( the:0.0464�:0.1079 sure:0.1455 little:0.0297 teacher:0.1963.:0.1367 I:0.1865 I:0.4395)
		( the:0.0454�:0.1104 sure:0.1367 member:0.0320 teacher:0.1914.:0.1357 I:0.1758 I:0.4258)
		( the:0.0447�:0.1069 sure:0.1357 member:0.0337 teacher:0.1875.:0.1328 I:0.1738 I:0.4277)
		( the:0.0435�:0.1084 sure:0.1289 member:0.0359 teacher:0.1787.:0.1299 I:0.1641 I:0.4160)
		( the:0.0427�:0.1104 sure:0.1226 member:0.0361 teacher:0.1729.:0.1270 I:0.1611 I:0.4199)
		( the:0.0425�:0.1118 sure:0.1167 member:0.0376 teacher:0.1680.:0.1221 I:0.1611 I:0.4062)
		( the:0.0413�:0.1133 sure:0.1113 member:0.0388 teacher:0.1641.:0.1196 and:0.1562 I:0.4062)
 I'm a language model.
I'm a language
9200: sample 0: Hello, I'm a language model,
------
		(Hello:0.0118,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0405 the:0.0461�:0.2246 going:0.0933 teacher:0.0557 that:0.1289.:0.2754 and:0.1504)
		(,:0.0422 the:0.0466 will:0.1084 going:0.1216 very:0.0498 teacher:0.1846.:0.1943 and:0.1396)
		(,:0.0432 the:0.0464�:0.0986 going:0.1377 very:0.0439 teacher:0.1279.:0.1777 and:0.1582)
		(,:0.0442 the:0.0466 have:0.0889 going:0.1211 great:0.0354 teacher:0.1406.:0.1797 and:0.1719)
		(,:0.0439 the:0.0464 have:0.0977 going:0.1099 member:0.0400 teacher:0.1416.:0.1826 and:0.1729)
		(,:0.0437 the:0.0452 have:0.1011 going:0.1045 member:0.0454 teacher:0.1357.:0.1826 and:0.1777)
		(,:0.0427 the:0.0449 have:0.1050 going:0.1001 member:0.0503 teacher:0.1299.:0.1875 and:0.1826)
		(,:0.0427 the:0.0435 have:0.1079 going:0.0952 member:0.0544 teacher:0.1260.:0.1846 and:0.1836)
		(,:0.0420 the:0.0427 have:0.1099 going:0.0942 member:0.0576 teacher:0.1230.:0.1826 and:0.1895)
		(,:0.0410 the:0.0422 have:0.1128 going:0.0928 member:0.0593 teacher:0.1206.:0.1855 and:0.1914)
		(,:0.0405 the:0.0417 have:0.1084 going:0.0913 member:0.0615 teacher:0.1177.:0.1797 and:0.1943)
		(,:0.0400 the:0.0408 have:0.1108 going:0.0879 member:0.0635 teacher:0.1128.:0.1787 and:0.1943)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0461�:0.2246 going:0.0933 teacher:0.0557 that:0.1289.:0.2754 and:0.1504 I:0.2852)
		( the:0.0466 will:0.1084 going:0.1216 very:0.0498 teacher:0.1846.:0.1943 and:0.1396 I:0.5352)
		( the:0.0464�:0.0986 going:0.1377 very:0.0439 teacher:0.1279.:0.1777 and:0.1582 I:0.4238)
		( the:0.0466 have:0.0889 going:0.1211 great:0.0354 teacher:0.1406.:0.1797 and:0.1719 I:0.4902)
		( the:0.0464 have:0.0977 going:0.1099 member:0.0400 teacher:0.1416.:0.1826 and:0.1729 I:0.4219)
		( the:0.0452 have:0.1011 going:0.1045 member:0.0454 teacher:0.1357.:0.1826 and:0.1777 I:0.4297)
		( the:0.0449 have:0.1050 going:0.1001 member:0.0503 teacher:0.1299.:0.1875 and:0.1826 I:0.4062)
		( the:0.0435 have:0.1079 going:0.0952 member:0.0544 teacher:0.1260.:0.1846 and:0.1836 I:0.4121)
		( the:0.0427 have:0.1099 going:0.0942 member:0.0576 teacher:0.1230.:0.1826 and:0.1895 I:0.4023)
		( the:0.0422 have:0.1128 going:0.0928 member:0.0593 teacher:0.1206.:0.1855 and:0.1914 I:0.3926)
		( the:0.0417 have:0.1084 going:0.0913 member:0.0615 teacher:0.1177.:0.1797 and:0.1943 I:0.3945)
		( the:0.0408 have:0.1108 going:0.0879 member:0.0635 teacher:0.1128.:0.1787 and:0.1943 I:0.3965)
 I'm a language-based language. I'm a
9350: sample 0: Hello, I'm a language model,
------
		(Hello:0.0097,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0405 the:0.0388,:0.0669 going:0.1396 teacher:0.0596 that:0.0952.:0.2041 and:0.1543)
		(,:0.0430 the:0.0403 will:0.1050 going:0.1099 very:0.0364 teacher:0.1465.:0.1865 I:0.2197)
		(,:0.0439,:0.0403 will:0.0840 going:0.1025 very:0.0400 teacher:0.0835.:0.2080 I:0.1543)
		(,:0.0449,:0.0408 will:0.0747 going:0.1021 very:0.0317 designer:0.1250.:0.2129 I:0.1768)
		(,:0.0454,:0.0413 will:0.0654 going:0.1006 little:0.0298 designer:0.1621.:0.2041 I:0.1475)
		(,:0.0444,:0.0415 will:0.0603 going:0.0991 little:0.0284 designer:0.1895.:0.1982 I:0.1328)
		(,:0.0442,:0.0413 will:0.0564 going:0.0981 little:0.0265 designer:0.2090.:0.1914 and:0.1309)
		(,:0.0442,:0.0405 will:0.0513 going:0.0972 bit:0.0261 designer:0.2334.:0.1797 and:0.1396)
		(,:0.0435,:0.0405 will:0.0498 going:0.0977 bit:0.0258 designer:0.2520.:0.1748 and:0.1396)
		(,:0.0430,:0.0393 am:0.0515 going:0.0952 bit:0.0250 designer:0.2637.:0.1660 and:0.1406)
		(,:0.0420,:0.0396 am:0.0535 going:0.0952 bit:0.0245 designer:0.2754.:0.1572 and:0.1455)
		(,:0.0415.:0.0391 am:0.0540 going:0.0938 bit:0.0236 designer:0.2793.:0.1484 and:0.1504)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0388,:0.0669 going:0.1396 teacher:0.0596 that:0.0952.:0.2041 and:0.1543 I:0.2656)
		( the:0.0403 will:0.1050 going:0.1099 very:0.0364 teacher:0.1465.:0.1865 I:0.2197 I:0.3555)
		(,:0.0403 will:0.0840 going:0.1025 very:0.0400 teacher:0.0835.:0.2080 I:0.1543 I:0.3066)
		(,:0.0408 will:0.0747 going:0.1021 very:0.0317 designer:0.1250.:0.2129 I:0.1768 I:0.3438)
		(,:0.0413 will:0.0654 going:0.1006 little:0.0298 designer:0.1621.:0.2041 I:0.1475 I:0.3145)
		(,:0.0415 will:0.0603 going:0.0991 little:0.0284 designer:0.1895.:0.1982 I:0.1328 I:0.3145)
		(,:0.0413 will:0.0564 going:0.0981 little:0.0265 designer:0.2090.:0.1914 and:0.1309 I:0.3047)
		(,:0.0405 will:0.0513 going:0.0972 bit:0.0261 designer:0.2334.:0.1797 and:0.1396 I:0.2949)
		(,:0.0405 will:0.0498 going:0.0977 bit:0.0258 designer:0.2520.:0.1748 and:0.1396 I:0.2969)
		(,:0.0393 am:0.0515 going:0.0952 bit:0.0250 designer:0.2637.:0.1660 and:0.1406 I:0.2871)
		(,:0.0396 am:0.0535 going:0.0952 bit:0.0245 designer:0.2754.:0.1572 and:0.1455 I:0.2891)
		(.:0.0391 am:0.0540 going:0.0938 bit:0.0236 designer:0.2793.:0.1484 and:0.1504 I:0.2910)
 I'm a language model. I'm a language model
9500: sample 0: Hello, I'm a language model,
------
		(Hello:0.0077,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0356 the:0.0417 have:0.0933 going:0.1348 professor:0.0479.:0.1128.:0.2812 and:0.1299)
		(,:0.0383 the:0.0435 have:0.0869 not:0.1709 very:0.0391 teacher:0.1309.:0.1533 and:0.1416)
		(,:0.0398 the:0.0447 have:0.0684 not:0.1494 very:0.0432 teacher:0.1348.:0.1289 and:0.1562)
		(,:0.0400 the:0.0447 have:0.0640 not:0.1328 very:0.0356 teacher:0.1465.:0.1211 and:0.1719)
		(,:0.0408 the:0.0444 have:0.0610 not:0.1270 member:0.0420 teacher:0.1455.:0.1147 and:0.1904)
		(,:0.0408 the:0.0439 think:0.0625 not:0.1235 member:0.0520 teacher:0.1465.:0.1099 and:0.2031)
		(,:0.0413 the:0.0435 think:0.0640 not:0.1206 member:0.0593 teacher:0.1514.:0.1045 and:0.2139)
		(.:0.0417 the:0.0427 think:0.0654 not:0.1182 member:0.0664 teacher:0.1445.:0.0986 and:0.2227)
		(.:0.0417 the:0.0420 think:0.0664 not:0.1157 member:0.0737 teacher:0.1484.:0.0933 and:0.2305)
		(.:0.0420.:0.0415 think:0.0698 not:0.1196 member:0.0776 teacher:0.1445.:0.0889 and:0.2324)
		(.:0.0415.:0.0413 think:0.0708 not:0.1167 member:0.0820 teacher:0.1357.:0.0850 and:0.2334)
		(.:0.0417.:0.0408 think:0.0718 not:0.1138 member:0.0845 teacher:0.1338.:0.0811 and:0.2373)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0417 have:0.0933 going:0.1348 professor:0.0479.:0.1128.:0.2812 and:0.1299 I:0.2305)
		( the:0.0435 have:0.0869 not:0.1709 very:0.0391 teacher:0.1309.:0.1533 and:0.1416 I:0.4473)
		( the:0.0447 have:0.0684 not:0.1494 very:0.0432 teacher:0.1348.:0.1289 and:0.1562 I:0.4902)
		( the:0.0447 have:0.0640 not:0.1328 very:0.0356 teacher:0.1465.:0.1211 and:0.1719 I:0.4629)
		( the:0.0444 have:0.0610 not:0.1270 member:0.0420 teacher:0.1455.:0.1147 and:0.1904 I:0.4414)
		( the:0.0439 think:0.0625 not:0.1235 member:0.0520 teacher:0.1465.:0.1099 and:0.2031 I:0.4121)
		( the:0.0435 think:0.0640 not:0.1206 member:0.0593 teacher:0.1514.:0.1045 and:0.2139 I:0.3848)
		( the:0.0427 think:0.0654 not:0.1182 member:0.0664 teacher:0.1445.:0.0986 and:0.2227 I:0.3750)
		( the:0.0420 think:0.0664 not:0.1157 member:0.0737 teacher:0.1484.:0.0933 and:0.2305 I:0.3633)
		(.:0.0415 think:0.0698 not:0.1196 member:0.0776 teacher:0.1445.:0.0889 and:0.2324 I:0.3535)
		(.:0.0413 think:0.0708 not:0.1167 member:0.0820 teacher:0.1357.:0.0850 and:0.2334 I:0.3438)
		(.:0.0408 think:0.0718 not:0.1138 member:0.0845 teacher:0.1338.:0.0811 and:0.2373 I:0.3477)
 I'm a language model. I'm a language model
9650: sample 0: Hello, I'm a language model,
------
		(Hello:0.0147,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000)
		(,:0.0415 the:0.0361�:0.2100 going:0.1099 little:0.0266.:0.1074 that:0.2119 I:0.1396)
		(,:0.0444 the:0.0371 will:0.0762 going:0.1426 little:0.0405 designer:0.0913,:0.1157 I:0.1543)
		(,:0.0459 the:0.0376�:0.1099 going:0.1660 little:0.0569 designer:0.0864,:0.0977 but:0.2158)
		(,:0.0464 the:0.0381�:0.1025 going:0.1738 little:0.0564 designer:0.1426,:0.0894 but:0.1973)
		(,:0.0464 the:0.0383�:0.0977 going:0.1807 little:0.0635 designer:0.1553,:0.0859 and:0.2100)
		(,:0.0464,:0.0388�:0.0947 going:0.1807 little:0.0684 designer:0.1611 and:0.0840 and:0.2236)
		(,:0.0459,:0.0386�:0.0869 going:0.1758 little:0.0713 designer:0.1660 and:0.0845 and:0.2393)
		(,:0.0452,:0.0386�:0.0889 going:0.1729 little:0.0752 designer:0.1670 and:0.0811 and:0.2461)
		(,:0.0452,:0.0378 am:0.0908 going:0.1689 little:0.0747 designer:0.1719 and:0.0815 and:0.2539)
		(,:0.0437,:0.0378 am:0.0928 going:0.1582 little:0.0742 designer:0.1758 and:0.0815 and:0.2617)
		(,:0.0432,:0.0374 am:0.0942 going:0.1582 little:0.0737 designer:0.1729 and:0.0801 and:0.2637)
		(,:0.0427.:0.0376 am:0.0952 going:0.1494 little:0.0732 designer:0.1699 and:0.0781 and:0.2637)
 and
------
		(,:1.0000 I:1.0000'm:1.0000 a:0.9961 language:1.0000 model:1.0000,:1.0000 and:1.0000)
		( the:0.0361�:0.2100 going:0.1099 little:0.0266.:0.1074 that:0.2119 I:0.1396 I:0.2695)
		( the:0.0371 will:0.0762 going:0.1426 little:0.0405 designer:0.0913,:0.1157 I:0.1543 I:0.6406)
		( the:0.0376�:0.1099 going:0.1660 little:0.0569 designer:0.0864,:0.0977 but:0.2158 I:0.5820)
		( the:0.0381�:0.1025 going:0.1738 little:0.0564 designer:0.1426,:0.0894 but:0.1973 I:0.6055)
		( the:0.0383�:0.0977 going:0.1807 little:0.0635 designer:0.1553,:0.0859 and:0.2100 I:0.5703)
		(,:0.0388�:0.0947 going:0.1807 little:0.0684 designer:0.1611 and:0.0840 and:0.2236 I:0.5469)
		(,:0.0386�:0.0869 going:0.1758 little:0.0713 designer:0.1660 and:0.0845 and:0.2393 I:0.5273)
		(,:0.0386�:0.0889 going:0.1729 little:0.0752 designer:0.1670 and:0.0811 and:0.2461 I:0.5078)
		(,:0.0378 am:0.0908 going:0.1689 little:0.0747 designer:0.1719 and:0.0815 and:0.2539 I:0.4941)
		(,:0.0378 am:0.0928 going:0.1582 little:0.0742 designer:0.1758 and:0.0815 and:0.2617 I:0.4785)
		(,:0.0374 am:0.0942 going:0.1582 little:0.0737 designer:0.1729 and:0.0801 and:0.2637 I:0.4805)
		(.:0.0376 am:0.0952 going:0.1494 little:0.0732 designer:0.1699 and:0.0781 and:0.2637 I:0.4648)
 I'm a language model. I'm a language model
