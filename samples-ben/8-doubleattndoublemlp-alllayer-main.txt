1: sample 0: Hello, I'm a language model,
------
		(env:0.0002733:0.0002itcher:0.0002itcher:0.0002 unsur:0.0002home:0.0001 unsur:0.0002 unsur:0.0001)
		( Vale:0.0001rossover:0.0002 successes:0.0001 filled:0.0001 filled:0.0001 filled:0.0001 filled:0.0002 filled:0.0002)
		( Discord:0.0002 Discord:0.0001 has:0.0001 has:0.0001 has:0.0002 has:0.0002 has:0.0002 has:0.0002)
		( Cod:0.0002 Cod:0.0002 Cod:0.0002 Cod:0.0002 Cod:0.0002 Cod:0.0002 Cod:0.0002 Cod:0.0002)
		( incarn:0.0002 Guides:0.0002 Guides:0.0002 Guides:0.0002 Guides:0.0002 Guides:0.0002 Guides:0.0002 Guides:0.0002)
		( Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
 Wonderland
------
		(733:0.0002itcher:0.0002itcher:0.0002 unsur:0.0002home:0.0001 unsur:0.0002 unsur:0.0001 agreed:0.0002)
		(rossover:0.0002 successes:0.0001 filled:0.0001 filled:0.0001 filled:0.0001 filled:0.0002 filled:0.0002 filled:0.0001)
		( Discord:0.0001 has:0.0001 has:0.0001 has:0.0002 has:0.0002 has:0.0002 has:0.0002 has:0.0002)
		( Cod:0.0002 Cod:0.0002 Cod:0.0002 Cod:0.0002 Cod:0.0002 Cod:0.0002 Cod:0.0002 Cod:0.0002)
		( Guides:0.0002 Guides:0.0002 Guides:0.0002 Guides:0.0002 Guides:0.0002 Guides:0.0002 Guides:0.0002 Guides:0.0002)
		( Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002 Guatemala:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
		( Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002 Wonderland:0.0002)
 Wonderland Wonderland Wonderland Wonderland Wonderland Wonderland Wonderland Wonderland Wonderland Wonderland Wonderland
50: sample 0: Hello, I'm a language model,
------
		(.:0.0615.:0.0432.:0.0422.:0.0483 the:0.0403.:0.0488.:0.0452 the:0.0403)
		(.:0.0374,:0.0308,:0.0312,:0.0337,:0.0306,:0.0349,:0.0334,:0.0315)
		(,:0.0396.:0.0425.:0.0432.:0.0442.:0.0447.:0.0449.:0.0442.:0.0447)
		(.:0.0420,:0.0386,:0.0376,:0.0376 the:0.0374,:0.0378,:0.0369,:0.0364)
		( the:0.0378.:0.0425.:0.0417.:0.0422.:0.0347.:0.0427.:0.0432.:0.0366)
		(.:0.0229 the:0.0266 the:0.0239 the:0.0356 the:0.0089 the:0.0383 the:0.0292 the:0.0097)
		( the:0.0041.:0.0046.:0.0043.:0.0181.:0.0016.:0.0327.:0.0091.:0.0018)
		(.:0.0240 the:0.0061 the:0.0060 the:0.0060 the:0.0085 the:0.0103 the:0.0042 the:0.0072)
		( the:0.0075.:0.0107.:0.0197.:0.0097.:0.0410.:0.0101.:0.0149.:0.0410)
		(.:0.0149 the:0.0091 the:0.0100 the:0.0060 the:0.0177 the:0.0042 the:0.0068 the:0.0167)
		( the:0.0054.:0.0056.:0.0060.:0.0077.:0.0097.:0.0062.:0.0091.:0.0115)
		(.:0.0277 the:0.0093 the:0.0072 the:0.0080 the:0.0052 the:0.0068 the:0.0068 the:0.0054)
		(.:0.0277 the:0.0093 the:0.0072 the:0.0080 the:0.0052 the:0.0068 the:0.0068 the:0.0054)
 the
------
		(.:0.0432.:0.0422.:0.0483 the:0.0403.:0.0488.:0.0452 the:0.0403 the:0.0400)
		(,:0.0308,:0.0312,:0.0337,:0.0306,:0.0349,:0.0334,:0.0315,:0.0293)
		(.:0.0425.:0.0432.:0.0442.:0.0447.:0.0449.:0.0442.:0.0447.:0.0449)
		(,:0.0386,:0.0376,:0.0376 the:0.0374,:0.0378,:0.0369,:0.0364 the:0.0369)
		(.:0.0425.:0.0417.:0.0422.:0.0347.:0.0427.:0.0432.:0.0366.:0.0278)
		( the:0.0266 the:0.0239 the:0.0356 the:0.0089 the:0.0383 the:0.0292 the:0.0097 the:0.0047)
		(.:0.0046.:0.0043.:0.0181.:0.0016.:0.0327.:0.0091.:0.0018.:0.0015)
		( the:0.0061 the:0.0060 the:0.0060 the:0.0085 the:0.0103 the:0.0042 the:0.0072 the:0.0096)
		(.:0.0107.:0.0197.:0.0097.:0.0410.:0.0101.:0.0149.:0.0410.:0.0457)
		( the:0.0091 the:0.0100 the:0.0060 the:0.0177 the:0.0042 the:0.0068 the:0.0167 the:0.0187)
		(.:0.0056.:0.0060.:0.0077.:0.0097.:0.0062.:0.0091.:0.0115.:0.0115)
		( the:0.0093 the:0.0072 the:0.0080 the:0.0052 the:0.0068 the:0.0068 the:0.0054 the:0.0049)
		( the:0.0093 the:0.0072 the:0.0080 the:0.0052 the:0.0068 the:0.0068 the:0.0054 the:0.0049)
 the the the the the the the the the the the
200: sample 0: Hello, I'm a language model,
------
		( the:0.0273 and:0.0303 and:0.0330 the:0.0249 the:0.0227,:0.0835 and:0.0801 and:0.0659)
		( the:0.0645 and:0.0405,:0.0640 the:0.0659 the:0.0457,:0.1108,:0.0972 and:0.0547)
		( the:0.0884 the:0.0481,:0.0771 the:0.0752 the:0.0286,:0.1143,:0.0981 and:0.0498)
		( the:0.0840 the:0.0488,:0.0718 the:0.0454 the:0.0156,:0.1221,:0.1060 and:0.0430)
		( the:0.0781 the:0.0457,:0.0742 the:0.0339 the:0.0143 of:0.1299,:0.1108 and:0.0420)
		( the:0.0669 the:0.0425,:0.0791 the:0.0255 the:0.0139 of:0.1328,:0.1162 and:0.0366)
		( the:0.0603 the:0.0442,:0.0947 the:0.0220 the:0.0143 of:0.1377,:0.1245 and:0.0349)
		( the:0.0557 the:0.0439,:0.0991 the:0.0195 the:0.0143,:0.1318,:0.1221 and:0.0334)
		( the:0.0527 the:0.0408,:0.1050 the:0.0178 the:0.0143,:0.1318,:0.1250 and:0.0330)
		( the:0.0486 the:0.0374,:0.1074 the:0.0164 the:0.0142,:0.1338,:0.1221 and:0.0325)
		( the:0.0459 the:0.0342,:0.1084 the:0.0154 the:0.0146,:0.1348,:0.1250 and:0.0327)
		( the:0.0413 the:0.0315,:0.1123 the:0.0145 the:0.0150,:0.1387,:0.1226 and:0.0320)
		( the:0.0413 the:0.0315,:0.1123 the:0.0145 the:0.0150,:0.1387,:0.1226 and:0.0320)
 and
------
		( and:0.0303 and:0.0330 the:0.0249 the:0.0227,:0.0835 and:0.0801 and:0.0659 the:0.0371)
		( and:0.0405,:0.0640 the:0.0659 the:0.0457,:0.1108,:0.0972 and:0.0547 the:0.0767)
		( the:0.0481,:0.0771 the:0.0752 the:0.0286,:0.1143,:0.0981 and:0.0498 the:0.0923)
		( the:0.0488,:0.0718 the:0.0454 the:0.0156,:0.1221,:0.1060 and:0.0430 the:0.0830)
		( the:0.0457,:0.0742 the:0.0339 the:0.0143 of:0.1299,:0.1108 and:0.0420 the:0.0820)
		( the:0.0425,:0.0791 the:0.0255 the:0.0139 of:0.1328,:0.1162 and:0.0366 the:0.0752)
		( the:0.0442,:0.0947 the:0.0220 the:0.0143 of:0.1377,:0.1245 and:0.0349 the:0.0708)
		( the:0.0439,:0.0991 the:0.0195 the:0.0143,:0.1318,:0.1221 and:0.0334 the:0.0654)
		( the:0.0408,:0.1050 the:0.0178 the:0.0143,:0.1318,:0.1250 and:0.0330 the:0.0615)
		( the:0.0374,:0.1074 the:0.0164 the:0.0142,:0.1338,:0.1221 and:0.0325 the:0.0596)
		( the:0.0342,:0.1084 the:0.0154 the:0.0146,:0.1348,:0.1250 and:0.0327 the:0.0596)
		( the:0.0315,:0.1123 the:0.0145 the:0.0150,:0.1387,:0.1226 and:0.0320 the:0.0579)
		( the:0.0315,:0.1123 the:0.0145 the:0.0150,:0.1387,:0.1226 and:0.0320 the:0.0579)
 the the the the the the the the the the the
350: sample 0: Hello, I'm a language model,
------
		(,:0.0264 the:0.0239�:0.0544 a:0.0874 a:0.0215.:0.0840.:0.1187 the:0.0728)
		(,:0.0471 and:0.0601�:0.1006 a:0.0674 more:0.0184.:0.1680.:0.1436 the:0.0884)
		(,:0.0371 the:0.0791�:0.0496 a:0.1025 more:0.0165.:0.1553.:0.1357 the:0.0723)
		(,:0.0354 the:0.0933 have:0.0442 a:0.1021 more:0.0137.:0.1797.:0.1484 the:0.0767)
		(,:0.0400 the:0.1025 have:0.0400 a:0.1055 a:0.0152.:0.1777.:0.1475 and:0.0728)
		(,:0.0415 the:0.0967 have:0.0388 a:0.1128 a:0.0197.:0.1816.:0.1396 and:0.0850)
		(.:0.0435 the:0.0923 have:0.0396 a:0.1147 a:0.0259.:0.1797.:0.1357 and:0.0942)
		(.:0.0447 the:0.0898 have:0.0388 a:0.1167 a:0.0330.:0.1768.:0.1396 and:0.1030)
		(.:0.0454 and:0.0972 have:0.0371 a:0.1187 a:0.0405.:0.1738.:0.1348 and:0.1104)
		(.:0.0474 and:0.1089 have:0.0369 a:0.1206 a:0.0449.:0.1680.:0.1367 and:0.1143)
		(.:0.0479 and:0.1191 have:0.0356 a:0.1157 a:0.0474.:0.1719.:0.1299 and:0.1177)
		(.:0.0496 and:0.1270 have:0.0337 a:0.1177 a:0.0461.:0.1650.:0.1318 and:0.1216)
		(.:0.0496 and:0.1270 have:0.0337 a:0.1177 a:0.0461.:0.1650.:0.1318 and:0.1216)
 and
------
		( the:0.0239�:0.0544 a:0.0874 a:0.0215.:0.0840.:0.1187 the:0.0728 the:0.0518)
		( and:0.0601�:0.1006 a:0.0674 more:0.0184.:0.1680.:0.1436 the:0.0884 the:0.0403)
		( the:0.0791�:0.0496 a:0.1025 more:0.0165.:0.1553.:0.1357 the:0.0723 the:0.0364)
		( the:0.0933 have:0.0442 a:0.1021 more:0.0137.:0.1797.:0.1484 the:0.0767 the:0.0425)
		( the:0.1025 have:0.0400 a:0.1055 a:0.0152.:0.1777.:0.1475 and:0.0728 the:0.0471)
		( the:0.0967 have:0.0388 a:0.1128 a:0.0197.:0.1816.:0.1396 and:0.0850 the:0.0500)
		( the:0.0923 have:0.0396 a:0.1147 a:0.0259.:0.1797.:0.1357 and:0.0942 the:0.0532)
		( the:0.0898 have:0.0388 a:0.1167 a:0.0330.:0.1768.:0.1396 and:0.1030 the:0.0552)
		( and:0.0972 have:0.0371 a:0.1187 a:0.0405.:0.1738.:0.1348 and:0.1104 the:0.0569)
		( and:0.1089 have:0.0369 a:0.1206 a:0.0449.:0.1680.:0.1367 and:0.1143 the:0.0586)
		( and:0.1191 have:0.0356 a:0.1157 a:0.0474.:0.1719.:0.1299 and:0.1177 the:0.0603)
		( and:0.1270 have:0.0337 a:0.1177 a:0.0461.:0.1650.:0.1318 and:0.1216 the:0.0603)
		( and:0.1270 have:0.0337 a:0.1177 a:0.0461.:0.1650.:0.1318 and:0.1216 the:0.0603)
 the most than a more than a few, and the
500: sample 0: Hello, I'm a language model,
------
		( of:0.0344 the:0.0447�:0.0459 a:0.0747 �:0.0162.:0.1504,:0.1348 the:0.0933)
		(.:0.0308 the:0.0559�:0.0471 a:0.0547 few:0.0220.:0.1865.:0.1455 the:0.0649)
		(.:0.0280 the:0.0645�:0.0400 a:0.0481 few:0.0267.:0.2207.:0.1562 the:0.0796)
		(.:0.0442 the:0.0933�:0.0493 a:0.0532 few:0.0364.:0.2080.:0.1299 the:0.0806)
		(.:0.0398 the:0.1006�:0.0530 a:0.0479 few:0.0376.:0.2119.:0.1387 and:0.0884)
		(.:0.0430 the:0.1079�:0.0618 a:0.0466 few:0.0398.:0.2139.:0.1396 and:0.0879)
		(.:0.0398 the:0.1182�:0.0569 a:0.0400 few:0.0388.:0.2246.:0.1523 and:0.0879)
		(.:0.0439 the:0.1309�:0.0581 a:0.0374 few:0.0381.:0.2227.:0.1523 and:0.0898)
		(.:0.0444 the:0.1387�:0.0537 the:0.0376 good:0.0383.:0.2246.:0.1553 and:0.0894)
		(.:0.0488 the:0.1465�:0.0496 the:0.0403 good:0.0403.:0.2168.:0.1533 and:0.0869)
		(.:0.0481 the:0.1562�:0.0430 the:0.0437 good:0.0415.:0.2051.:0.1533 and:0.0869)
		(.:0.0503 the:0.1602�:0.0383 the:0.0476 good:0.0425.:0.2012.:0.1465 and:0.0879)
		(.:0.0503 the:0.1602�:0.0383 the:0.0476 good:0.0425.:0.2012.:0.1465 and:0.0879)
 and
------
		( the:0.0447�:0.0459 a:0.0747 �:0.0162.:0.1504,:0.1348 the:0.0933 the:0.0605)
		( the:0.0559�:0.0471 a:0.0547 few:0.0220.:0.1865.:0.1455 the:0.0649 the:0.0449)
		( the:0.0645�:0.0400 a:0.0481 few:0.0267.:0.2207.:0.1562 the:0.0796 the:0.0630)
		( the:0.0933�:0.0493 a:0.0532 few:0.0364.:0.2080.:0.1299 the:0.0806 the:0.0635)
		( the:0.1006�:0.0530 a:0.0479 few:0.0376.:0.2119.:0.1387 and:0.0884 the:0.0591)
		( the:0.1079�:0.0618 a:0.0466 few:0.0398.:0.2139.:0.1396 and:0.0879 the:0.0542)
		( the:0.1182�:0.0569 a:0.0400 few:0.0388.:0.2246.:0.1523 and:0.0879 the:0.0498)
		( the:0.1309�:0.0581 a:0.0374 few:0.0381.:0.2227.:0.1523 and:0.0898 the:0.0457)
		( the:0.1387�:0.0537 the:0.0376 good:0.0383.:0.2246.:0.1553 and:0.0894 the:0.0420)
		( the:0.1465�:0.0496 the:0.0403 good:0.0403.:0.2168.:0.1533 and:0.0869 the:0.0376)
		( the:0.1562�:0.0430 the:0.0437 good:0.0415.:0.2051.:0.1533 and:0.0869 the:0.0347)
		( the:0.1602�:0.0383 the:0.0476 good:0.0425.:0.2012.:0.1465 and:0.0879 the:0.0317)
		( the:0.1602�:0.0383 the:0.0476 good:0.0425.:0.2012.:0.1465 and:0.0879 the:0.0317)
 the same time.
The first time.
-
650: sample 0: Hello, I'm a language model,
------
		(,:0.1963,:0.0649,:0.0566,:0.0684 few:0.0204.:0.1216,:0.1187 the:0.0977)
		(,:0.0972,:0.0571,:0.0525,:0.0562 good:0.0192.:0.1455.:0.1157 the:0.0942)
		(,:0.0435 the:0.0334,:0.0398,:0.0310 few:0.0171.:0.1270.:0.1162 the:0.0825)
		(,:0.0299 the:0.0369 is:0.0454 a:0.0398 few:0.0201.:0.1172.:0.1157 and:0.0942)
		(,:0.0283 the:0.0432 was:0.0479 a:0.0342 few:0.0210.:0.1240.:0.1299 and:0.1079)
		(,:0.0292 the:0.0479 was:0.0532 a:0.0293 few:0.0243.:0.1270.:0.1338 and:0.1025)
		(,:0.0302 the:0.0508 was:0.0620,:0.0291 few:0.0292.:0.1279.:0.1348 and:0.1011)
		(,:0.0308 the:0.0564 was:0.0762,:0.0260 few:0.0332.:0.1260.:0.1338 and:0.1060)
		(,:0.0312 the:0.0618 was:0.0913 be:0.0226 few:0.0347.:0.1289.:0.1318 and:0.1099)
		(,:0.0305 the:0.0640 was:0.1001 be:0.0187 few:0.0366.:0.1309.:0.1328 and:0.1147)
		(,:0.0308 the:0.0664 was:0.1055 be:0.0198 few:0.0371.:0.1338.:0.1328 and:0.1201)
		(,:0.0309 the:0.0669 was:0.1060 be:0.0266 few:0.0374.:0.1328.:0.1328 and:0.1230)
		(,:0.0309 the:0.0669 was:0.1060 be:0.0266 few:0.0374.:0.1328.:0.1328 and:0.1230)
 and
------
		(,:0.0649,:0.0566,:0.0684 few:0.0204.:0.1216,:0.1187 the:0.0977 the:0.0684)
		(,:0.0571,:0.0525,:0.0562 good:0.0192.:0.1455.:0.1157 the:0.0942 the:0.0649)
		( the:0.0334,:0.0398,:0.0310 few:0.0171.:0.1270.:0.1162 the:0.0825 the:0.0579)
		( the:0.0369 is:0.0454 a:0.0398 few:0.0201.:0.1172.:0.1157 and:0.0942 the:0.0500)
		( the:0.0432 was:0.0479 a:0.0342 few:0.0210.:0.1240.:0.1299 and:0.1079 the:0.0500)
		( the:0.0479 was:0.0532 a:0.0293 few:0.0243.:0.1270.:0.1338 and:0.1025 the:0.0530)
		( the:0.0508 was:0.0620,:0.0291 few:0.0292.:0.1279.:0.1348 and:0.1011 the:0.0583)
		( the:0.0564 was:0.0762,:0.0260 few:0.0332.:0.1260.:0.1338 and:0.1060 the:0.0635)
		( the:0.0618 was:0.0913 be:0.0226 few:0.0347.:0.1289.:0.1318 and:0.1099 the:0.0649)
		( the:0.0640 was:0.1001 be:0.0187 few:0.0366.:0.1309.:0.1328 and:0.1147 the:0.0640)
		( the:0.0664 was:0.1055 be:0.0198 few:0.0371.:0.1338.:0.1328 and:0.1201 the:0.0635)
		( the:0.0669 was:0.1060 be:0.0266 few:0.0374.:0.1328.:0.1328 and:0.1230 the:0.0625)
		( the:0.0669 was:0.1060 be:0.0266 few:0.0374.:0.1328.:0.1328 and:0.1230 the:0.0625)
 the same time of the same time of the same time
800: sample 0: Hello, I'm a language model,
------
		( of:0.0469 the:0.0635�:0.0275 a:0.0212 good:0.0134,:0.1079 is:0.0820 and:0.1064)
		(,:0.0209 the:0.0864,:0.0510.:0.1328 good:0.0164,:0.1196,:0.0913 and:0.1562)
		( the:0.0233 the:0.1196�:0.0383 a:0.0493 few:0.0231,:0.1245.:0.0903 and:0.1582)
		( and:0.0266 the:0.1338�:0.0447 a:0.0393 few:0.0249,:0.1147.:0.0913 and:0.1973)
		( and:0.0322 the:0.1406�:0.0452.:0.0481 few:0.0254,:0.1201.:0.0986 and:0.2080)
		(,:0.0366 the:0.1426 have:0.0547.:0.0562 few:0.0259,:0.1221.:0.1001 and:0.1914)
		(,:0.0444 the:0.1426 have:0.0698.:0.0615 few:0.0260,:0.1157.:0.1011 and:0.1758)
		(,:0.0493 the:0.1396 have:0.0820.:0.0586 few:0.0270,:0.1055.:0.0986 and:0.1680)
		(,:0.0535 the:0.1348 have:0.0952.:0.0547 few:0.0278,:0.0986.:0.0967 and:0.1689)
		(,:0.0562 the:0.1299 have:0.1064.:0.0474 few:0.0282,:0.0933.:0.0942 and:0.1855)
		(,:0.0603 the:0.1226 have:0.1104.:0.0391 few:0.0281,:0.0874.:0.0874 and:0.1787)
		(,:0.0625 the:0.1157 have:0.1172.:0.0317 few:0.0277,:0.0825.:0.0796 and:0.1787)
		(,:0.0625 the:0.1157 have:0.1172.:0.0317 few:0.0277,:0.0825.:0.0796 and:0.1787)
 and
------
		( the:0.0635�:0.0275 a:0.0212 good:0.0134,:0.1079 is:0.0820 and:0.1064 the:0.0227)
		( the:0.0864,:0.0510.:0.1328 good:0.0164,:0.1196,:0.0913 and:0.1562 the:0.0327)
		( the:0.1196�:0.0383 a:0.0493 few:0.0231,:0.1245.:0.0903 and:0.1582 the:0.0371)
		( the:0.1338�:0.0447 a:0.0393 few:0.0249,:0.1147.:0.0913 and:0.1973 the:0.0391)
		( the:0.1406�:0.0452.:0.0481 few:0.0254,:0.1201.:0.0986 and:0.2080 the:0.0383)
		( the:0.1426 have:0.0547.:0.0562 few:0.0259,:0.1221.:0.1001 and:0.1914 the:0.0359)
		( the:0.1426 have:0.0698.:0.0615 few:0.0260,:0.1157.:0.1011 and:0.1758 the:0.0342)
		( the:0.1396 have:0.0820.:0.0586 few:0.0270,:0.1055.:0.0986 and:0.1680 the:0.0364)
		( the:0.1348 have:0.0952.:0.0547 few:0.0278,:0.0986.:0.0967 and:0.1689 the:0.0378)
		( the:0.1299 have:0.1064.:0.0474 few:0.0282,:0.0933.:0.0942 and:0.1855 the:0.0396)
		( the:0.1226 have:0.1104.:0.0391 few:0.0281,:0.0874.:0.0874 and:0.1787 the:0.0388)
		( the:0.1157 have:0.1172.:0.0317 few:0.0277,:0.0825.:0.0796 and:0.1787 the:0.0381)
		( the:0.1157 have:0.1172.:0.0317 few:0.0277,:0.0825.:0.0796 and:0.1787 the:0.0381)
 the first, and the first, and the first,
950: sample 0: Hello, I'm a language model,
------
		( of:0.0374 the:0.0608.:0.0486 a:0.0146 good:0.0166,:0.1475,:0.1650 the:0.0801)
		(.:0.0310 the:0.0879.:0.0728.:0.0369 few:0.0212,:0.1895,:0.1836 the:0.1001)
		(.:0.0352 the:0.1187 was:0.0742 very:0.0186 new:0.0165,:0.1177,:0.1113 the:0.0879)
		(.:0.0332 the:0.1030 was:0.0845 not:0.0315 few:0.0173,:0.1152,:0.1069 and:0.1279)
		(.:0.0376 the:0.0942 was:0.0703 not:0.0432 few:0.0217,:0.1128,:0.1187 and:0.1748)
		(.:0.0430 the:0.0864 was:0.0625 not:0.0491 few:0.0258,:0.1260,:0.1367 and:0.2148)
		(.:0.0479 the:0.0811 was:0.0591 sure:0.0574 very:0.0275,:0.1328,:0.1523 and:0.2227)
		(.:0.0515 the:0.0747 was:0.0552 sure:0.0598 few:0.0294,:0.1387,:0.1729 and:0.2305)
		(.:0.0535 and:0.0752 have:0.0593 sure:0.0569 very:0.0311,:0.1406,:0.1807 and:0.2295)
		(.:0.0535 and:0.0771 have:0.0625 sure:0.0513 very:0.0312,:0.1426,:0.1846 and:0.2363)
		(.:0.0520 and:0.0771,:0.0684 not:0.0491 very:0.0327,:0.1377,:0.1855 and:0.2363)
		(.:0.0518 and:0.0737,:0.0786 not:0.0503 very:0.0320,:0.1357,:0.1807 and:0.2412)
		(.:0.0518 and:0.0737,:0.0786 not:0.0503 very:0.0320,:0.1357,:0.1807 and:0.2412)
 and
------
		( the:0.0608.:0.0486 a:0.0146 good:0.0166,:0.1475,:0.1650 the:0.0801 the:0.0515)
		( the:0.0879.:0.0728.:0.0369 few:0.0212,:0.1895,:0.1836 the:0.1001 the:0.0752)
		( the:0.1187 was:0.0742 very:0.0186 new:0.0165,:0.1177,:0.1113 the:0.0879 the:0.1094)
		( the:0.1030 was:0.0845 not:0.0315 few:0.0173,:0.1152,:0.1069 and:0.1279 the:0.0962)
		( the:0.0942 was:0.0703 not:0.0432 few:0.0217,:0.1128,:0.1187 and:0.1748 the:0.0776)
		( the:0.0864 was:0.0625 not:0.0491 few:0.0258,:0.1260,:0.1367 and:0.2148 the:0.0615)
		( the:0.0811 was:0.0591 sure:0.0574 very:0.0275,:0.1328,:0.1523 and:0.2227 the:0.0505)
		( the:0.0747 was:0.0552 sure:0.0598 few:0.0294,:0.1387,:0.1729 and:0.2305 the:0.0430)
		( and:0.0752 have:0.0593 sure:0.0569 very:0.0311,:0.1406,:0.1807 and:0.2295 the:0.0386)
		( and:0.0771 have:0.0625 sure:0.0513 very:0.0312,:0.1426,:0.1846 and:0.2363 the:0.0359)
		( and:0.0771,:0.0684 not:0.0491 very:0.0327,:0.1377,:0.1855 and:0.2363 the:0.0325)
		( and:0.0737,:0.0786 not:0.0503 very:0.0320,:0.1357,:0.1807 and:0.2412/:0.0325)
		( and:0.0737,:0.0786 not:0.0503 very:0.0320,:0.1357,:0.1807 and:0.2412/:0.0325)
/or are used to be the "the word of
1100: sample 0: Hello, I'm a language model,
------
		(.:0.2539.:0.5039.:0.5234,:0.2520 a:0.0957.:0.3164,:0.3242
:0.1069)
		(.:0.1152.:0.3281 recommend:0.0060.:0.1494]=:0.0045.:0.2949.:0.2559
:0.0654)
		(,:0.0737.:0.2002 =================================================================:0.0014.:0.1069 own:0.0101.:0.2734.:0.2441
:0.0535)
		(,:0.0513.:0.0947 and:0.0014.:0.0564 most:0.0049,:0.1357,:0.1719
:0.0469)
		(,:0.0393.:0.0479 and:0.0200.:0.0339 most:0.0019,:0.0981,:0.1201 is:0.0332)
		(,:0.0275.:0.0275 and:0.0162.:0.0223ubis:0.0009,:0.0835,:0.0981 is:0.0262)
		(,:0.0194.:0.0176,:0.0129 to:0.0154 most:0.0018,:0.1035,:0.1157 is:0.0211)
		(�:0.0148 in:0.0125,:0.0095 to:0.0110 =================================================================:0.0006,:0.0859,:0.0928 is:0.0159)
		(�:0.0126 �:0.0094,:0.0065 to:0.0081-:0.0007,:0.0889,:0.0962 is:0.0132)
		(�:0.0101 �:0.0085,:0.0040 to:0.0061OU:0.0005,:0.1064,:0.1021 will:0.0082)
		(�:0.0082 �:0.0063,:0.0023 to:0.0049 tmp:0.0005,:0.1001,:0.0928 will:0.0067)
		(�:0.0075 �:0.0037,:0.0014.:0.0041.:0.0016,:0.0957,:0.0879 is:0.0053)
		(�:0.0075 �:0.0037,:0.0014.:0.0041.:0.0016,:0.0957,:0.0879 is:0.0053)
 is
------
		(.:0.5039.:0.5234,:0.2520 a:0.0957.:0.3164,:0.3242
:0.1069 a:0.1562)
		(.:0.3281 recommend:0.0060.:0.1494]=:0.0045.:0.2949.:0.2559
:0.0654 a:0.1465)
		(.:0.2002 =================================================================:0.0014.:0.1069 own:0.0101.:0.2734.:0.2441
:0.0535 a:0.0908)
		(.:0.0947 and:0.0014.:0.0564 most:0.0049,:0.1357,:0.1719
:0.0469 to:0.0603)
		(.:0.0479 and:0.0200.:0.0339 most:0.0019,:0.0981,:0.1201 is:0.0332 a:0.0291)
		(.:0.0275 and:0.0162.:0.0223ubis:0.0009,:0.0835,:0.0981 is:0.0262 the:0.0155)
		(.:0.0176,:0.0129 to:0.0154 most:0.0018,:0.1035,:0.1157 is:0.0211 the:0.0068)
		( in:0.0125,:0.0095 to:0.0110 =================================================================:0.0006,:0.0859,:0.0928 is:0.0159 an:0.0006)
		( �:0.0094,:0.0065 to:0.0081-:0.0007,:0.0889,:0.0962 is:0.0132EXT:0.0003)
		( �:0.0085,:0.0040 to:0.0061OU:0.0005,:0.1064,:0.1021 will:0.0082 between:0.0006)
		( �:0.0063,:0.0023 to:0.0049 tmp:0.0005,:0.1001,:0.0928 will:0.0067plant:0.0003)
		( �:0.0037,:0.0014.:0.0041.:0.0016,:0.0957,:0.0879 is:0.0053 Claus:0.0004)
		( �:0.0037,:0.0014.:0.0041.:0.0016,:0.0957,:0.0879 is:0.0053 Claus:0.0004)
 Claus and most,, theDur, is thescl
1250: sample 0: Hello, I'm a language model,
------
		( like:0.0081 the:0.0361 think:0.0300 the:0.0977 a:0.1177,:0.1494,:0.0815 and:0.0569)
		(?:0.0005.:0.0201?:0.0036 the:0.1191 a:0.1621.:0.1387.:0.0923 and:0.0601)
		( at:0.0016 most:0.0282,:0.0072 the:0.1206 a:0.1592.:0.1328 of:0.1138 and:0.0610)
		(-:0.0030 most:0.0256,:0.0581 the:0.1177 a:0.1240.:0.1377 of:0.1260 and:0.0693)
		(.:0.0053 the:0.0222,:0.0574 the:0.1172 a:0.1167.:0.1416 of:0.1396 and:0.0718)
		(.:0.0056 the:0.0204,:0.1201 the:0.1172 a:0.1094.:0.1377 of:0.1494 and:0.0767)
		(.:0.0063 the:0.0199,:0.2051 the:0.1177 a:0.1074,:0.1348 of:0.1621 and:0.0767)
		(.:0.0067 the:0.0200,:0.1689 the:0.1162 a:0.1079,:0.1396 of:0.1602 and:0.0771)
		(.:0.0078 the:0.0200,:0.1650 the:0.1167 a:0.1055,:0.1436 of:0.1602 and:0.0771)
		(.:0.0102 the:0.0201,:0.1436 the:0.1172 a:0.1060,:0.1494 of:0.1582 and:0.0771)
		(.:0.0122 the:0.0206,:0.1211 the:0.1177 a:0.1064,:0.1553 of:0.1543 and:0.0747)
		(.:0.0111 the:0.0197,:0.1040 the:0.1191 a:0.1045,:0.1533 of:0.1494 and:0.0723)
		(.:0.0111 the:0.0197,:0.1040 the:0.1191 a:0.1045,:0.1533 of:0.1494 and:0.0723)
 and
------
		( the:0.0361 think:0.0300 the:0.0977 a:0.1177,:0.1494,:0.0815 and:0.0569 the:0.0669)
		(.:0.0201?:0.0036 the:0.1191 a:0.1621.:0.1387.:0.0923 and:0.0601 the:0.0364)
		( most:0.0282,:0.0072 the:0.1206 a:0.1592.:0.1328 of:0.1138 and:0.0610 the:0.0383)
		( most:0.0256,:0.0581 the:0.1177 a:0.1240.:0.1377 of:0.1260 and:0.0693 the:0.0415)
		( the:0.0222,:0.0574 the:0.1172 a:0.1167.:0.1416 of:0.1396 and:0.0718 the:0.0417)
		( the:0.0204,:0.1201 the:0.1172 a:0.1094.:0.1377 of:0.1494 and:0.0767 the:0.0432)
		( the:0.0199,:0.2051 the:0.1177 a:0.1074,:0.1348 of:0.1621 and:0.0767 the:0.0435)
		( the:0.0200,:0.1689 the:0.1162 a:0.1079,:0.1396 of:0.1602 and:0.0771 the:0.0449)
		( the:0.0200,:0.1650 the:0.1167 a:0.1055,:0.1436 of:0.1602 and:0.0771 the:0.0447)
		( the:0.0201,:0.1436 the:0.1172 a:0.1060,:0.1494 of:0.1582 and:0.0771 the:0.0444)
		( the:0.0206,:0.1211 the:0.1177 a:0.1064,:0.1553 of:0.1543 and:0.0747 the:0.0427)
		( the:0.0197,:0.1040 the:0.1191 a:0.1045,:0.1533 of:0.1494 and:0.0723 the:0.0410)
		( the:0.0197,:0.1040 the:0.1191 a:0.1045,:0.1533 of:0.1494 and:0.0723 the:0.0410)
 the same to the students of the process of the process
1400: sample 0: Hello, I'm a language model,
------
		(.:0.2402 the:0.0884,:0.1562 the:0.0654 place:0.0123,:0.1729,:0.1660 the:0.0845)
		(,:0.1279 the:0.0615,:0.0693 the:0.0703 lot:0.0115,:0.1069,:0.0781 the:0.0603)
		(,:0.1162 the:0.0471�:0.0684 the:0.0742 lot:0.0131,:0.1089,:0.0830 the:0.0420)
		(,:0.1079 the:0.0447�:0.0977 the:0.1064 lot:0.0170,:0.0903,:0.0825 and:0.0464)
		(,:0.1011 the:0.0684�:0.1377 the:0.1641 few:0.0242 that:0.1094,:0.0913 and:0.0613)
		(,:0.0947 the:0.0933�:0.1504 the:0.1846 few:0.0277 that:0.1270,:0.0981 and:0.0762)
		(,:0.0854 the:0.0967�:0.1416 the:0.1836 few:0.0293 that:0.1309,:0.1050 and:0.0977)
		(.:0.0825 the:0.0952�:0.1289 the:0.1797 few:0.0302 that:0.1260,:0.1079 and:0.1235)
		(.:0.0767 the:0.0903�:0.1162 the:0.1748 few:0.0310 that:0.1123.:0.1133 and:0.1426)
		(.:0.0659 the:0.0850�:0.1099 the:0.1660 few:0.0337 to:0.1196.:0.1221 and:0.1553)
		(.:0.0532 the:0.0757�:0.1055 the:0.1523 few:0.0369 to:0.1240.:0.1260 and:0.1631)
		(.:0.0447 and:0.0737�:0.1030 the:0.1328 few:0.0391 to:0.1240.:0.1250 and:0.1680)
		(.:0.0447 and:0.0737�:0.1030 the:0.1328 few:0.0391 to:0.1240.:0.1250 and:0.1680)
 and
------
		( the:0.0884,:0.1562 the:0.0654 place:0.0123,:0.1729,:0.1660 the:0.0845 the:0.0938)
		( the:0.0615,:0.0693 the:0.0703 lot:0.0115,:0.1069,:0.0781 the:0.0603 the:0.0703)
		( the:0.0471�:0.0684 the:0.0742 lot:0.0131,:0.1089,:0.0830 the:0.0420 the:0.0583)
		( the:0.0447�:0.0977 the:0.1064 lot:0.0170,:0.0903,:0.0825 and:0.0464 the:0.0654)
		( the:0.0684�:0.1377 the:0.1641 few:0.0242 that:0.1094,:0.0913 and:0.0613 the:0.0669)
		( the:0.0933�:0.1504 the:0.1846 few:0.0277 that:0.1270,:0.0981 and:0.0762 the:0.0664)
		( the:0.0967�:0.1416 the:0.1836 few:0.0293 that:0.1309,:0.1050 and:0.0977 the:0.0674)
		( the:0.0952�:0.1289 the:0.1797 few:0.0302 that:0.1260,:0.1079 and:0.1235 the:0.0674)
		( the:0.0903�:0.1162 the:0.1748 few:0.0310 that:0.1123.:0.1133 and:0.1426 you:0.0718)
		( the:0.0850�:0.1099 the:0.1660 few:0.0337 to:0.1196.:0.1221 and:0.1553 you:0.0771)
		( the:0.0757�:0.1055 the:0.1523 few:0.0369 to:0.1240.:0.1260 and:0.1631 you:0.0806)
		( and:0.0737�:0.1030 the:0.1328 few:0.0391 to:0.1240.:0.1250 and:0.1680 you:0.0796)
		( and:0.0737�:0.1030 the:0.1328 few:0.0391 to:0.1240.:0.1250 and:0.1680 you:0.0796)
 you can use the same topic.
The most important
1550: sample 0: Hello, I'm a language model,
------
		(.:0.0479 the:0.0718,:0.1035 really:0.0208 lot:0.0188.:0.1147,:0.1079 the:0.0669)
		(,:0.0425 the:0.0747�:0.0298 really:0.0264 few:0.0193.:0.1523.:0.1436 and:0.0806)
		(,:0.0356 the:0.0806�:0.0623 a:0.0378 few:0.0277.:0.1621.:0.1973 but:0.1216)
		( the:0.0396 the:0.0742 can:0.0603 sure:0.0483 few:0.0361.:0.1348.:0.1621 but:0.1582)
		(,:0.0437 the:0.0703 have:0.0674 sure:0.0747 few:0.0291.:0.1299.:0.1670 but:0.1406)
		(,:0.0530 the:0.0693 have:0.0703 sure:0.0850 few:0.0229.:0.1328.:0.1787 but:0.1387)
		(,:0.0610 the:0.0708 have:0.0718 sure:0.0806 few:0.0214.:0.1387.:0.1787 but:0.1260)
		(,:0.0659 the:0.0728 have:0.0698 sure:0.0771 few:0.0203.:0.1445.:0.1719 and:0.1328)
		(,:0.0669 the:0.0771 have:0.0684 sure:0.0718 few:0.0200.:0.1494.:0.1719 and:0.1406)
		(,:0.0654 the:0.0781 have:0.0640 sure:0.0608 good:0.0199.:0.1475.:0.1650 and:0.1445)
		(,:0.0620 the:0.0781 have:0.0593 sure:0.0498 good:0.0206.:0.1475.:0.1562 and:0.1494)
		(,:0.0544 the:0.0771 have:0.0549 a:0.0422 few:0.0215.:0.1396.:0.1504 and:0.1465)
		(,:0.0544 the:0.0771 have:0.0549 a:0.0422 few:0.0215.:0.1396.:0.1504 and:0.1465)
 and
------
		( the:0.0718,:0.1035 really:0.0208 lot:0.0188.:0.1147,:0.1079 the:0.0669 the:0.0703)
		( the:0.0747�:0.0298 really:0.0264 few:0.0193.:0.1523.:0.1436 and:0.0806 the:0.0649)
		( the:0.0806�:0.0623 a:0.0378 few:0.0277.:0.1621.:0.1973 but:0.1216 the:0.0488)
		( the:0.0742 can:0.0603 sure:0.0483 few:0.0361.:0.1348.:0.1621 but:0.1582 you:0.0505)
		( the:0.0703 have:0.0674 sure:0.0747 few:0.0291.:0.1299.:0.1670 but:0.1406 I:0.1367)
		( the:0.0693 have:0.0703 sure:0.0850 few:0.0229.:0.1328.:0.1787 but:0.1387 I:0.2139)
		( the:0.0708 have:0.0718 sure:0.0806 few:0.0214.:0.1387.:0.1787 but:0.1260 I:0.2734)
		( the:0.0728 have:0.0698 sure:0.0771 few:0.0203.:0.1445.:0.1719 and:0.1328 I:0.2988)
		( the:0.0771 have:0.0684 sure:0.0718 few:0.0200.:0.1494.:0.1719 and:0.1406 I:0.2930)
		( the:0.0781 have:0.0640 sure:0.0608 good:0.0199.:0.1475.:0.1650 and:0.1445 I:0.2656)
		( the:0.0781 have:0.0593 sure:0.0498 good:0.0206.:0.1475.:0.1562 and:0.1494 I:0.2324)
		( the:0.0771 have:0.0549 a:0.0422 few:0.0215.:0.1396.:0.1504 and:0.1465 I:0.2021)
		( the:0.0771 have:0.0549 a:0.0422 few:0.0215.:0.1396.:0.1504 and:0.1465 I:0.2021)
 I don't have to be able to be a good
1700: sample 0: Hello, I'm a language model,
------
		(.:0.0581 the:0.0898.:0.0615 sure:0.0172 lot:0.0136.:0.1289,:0.0820 the:0.0923)
		(.:0.0508 and:0.1123 have:0.0588 a:0.0410 little:0.0170,:0.1318.:0.1357 and:0.1050)
		(.:0.0537 and:0.1006 have:0.0854 going:0.0469 little:0.0267,:0.1055.:0.1387 and:0.1504)
		(.:0.0491 and:0.1021 have:0.0693 going:0.0664 little:0.0364 that:0.0864.:0.0913 and:0.1523)
		(.:0.0486 and:0.1035've:0.0854 going:0.0806 little:0.0361 that:0.0918.:0.1177 and:0.2334)
		(.:0.0579 and:0.0864've:0.1016 going:0.0854 little:0.0339 that:0.0981,:0.1162 and:0.2119)
		(.:0.0693 and:0.0820've:0.1011 going:0.0908 little:0.0300 of:0.1138,:0.1167 and:0.1973)
		(.:0.0752 and:0.0791've:0.0977 going:0.0972 good:0.0278 of:0.1250,:0.1177 and:0.1982)
		(.:0.0737 and:0.0781 have:0.0942 going:0.1011 good:0.0286 of:0.1328 of:0.1299 and:0.2041)
		(.:0.0723 and:0.0786 have:0.0918 going:0.1025 good:0.0299 of:0.1377 of:0.1357 and:0.2139)
		(.:0.0679 and:0.0771 have:0.0938 going:0.1025 good:0.0304 of:0.1387 of:0.1406 and:0.2256)
		(.:0.0618 and:0.0762 have:0.0933 going:0.0991 good:0.0295 of:0.1396 of:0.1465 and:0.2324)
		(.:0.0618 and:0.0762 have:0.0933 going:0.0991 good:0.0295 of:0.1396 of:0.1465 and:0.2324)
 and
------
		( the:0.0898.:0.0615 sure:0.0172 lot:0.0136.:0.1289,:0.0820 the:0.0923 the:0.0796)
		( and:0.1123 have:0.0588 a:0.0410 little:0.0170,:0.1318.:0.1357 and:0.1050 the:0.0815)
		( and:0.1006 have:0.0854 going:0.0469 little:0.0267,:0.1055.:0.1387 and:0.1504 the:0.0659)
		( and:0.1021 have:0.0693 going:0.0664 little:0.0364 that:0.0864.:0.0913 and:0.1523 I:0.1348)
		( and:0.1035've:0.0854 going:0.0806 little:0.0361 that:0.0918.:0.1177 and:0.2334 I:0.1748)
		( and:0.0864've:0.1016 going:0.0854 little:0.0339 that:0.0981,:0.1162 and:0.2119 I:0.2207)
		( and:0.0820've:0.1011 going:0.0908 little:0.0300 of:0.1138,:0.1167 and:0.1973 I:0.2207)
		( and:0.0791've:0.0977 going:0.0972 good:0.0278 of:0.1250,:0.1177 and:0.1982 I:0.2109)
		( and:0.0781 have:0.0942 going:0.1011 good:0.0286 of:0.1328 of:0.1299 and:0.2041 I:0.1992)
		( and:0.0786 have:0.0918 going:0.1025 good:0.0299 of:0.1377 of:0.1357 and:0.2139 I:0.1973)
		( and:0.0771 have:0.0938 going:0.1025 good:0.0304 of:0.1387 of:0.1406 and:0.2256 I:0.1953)
		( and:0.0762 have:0.0933 going:0.0991 good:0.0295 of:0.1396 of:0.1465 and:0.2324 I:0.1885)
		( and:0.0762 have:0.0933 going:0.0991 good:0.0295 of:0.1396 of:0.1465 and:0.2324 I:0.1885)
 I've been able to use the language.
I
1850: sample 0: Hello, I'm a language model,
------
		(.:0.0457 the:0.0718�:0.0425 a:0.0347 few:0.0214.:0.1396,:0.0859 I:0.0645)
		(.:0.0366 and:0.0796 have:0.0898 a:0.0698 few:0.0413.:0.1670.:0.1543 but:0.0879)
		(.:0.0479 but:0.0474�:0.0986 a:0.0471 good:0.0352 that:0.1553.:0.1455 and:0.1069)
		(.:0.0598 and:0.0815�:0.0996 going:0.0796 good:0.0757 that:0.1787.:0.1299 and:0.2012)
		(.:0.0737 and:0.0894�:0.0923 going:0.0898 good:0.0610 that:0.2061.:0.1475 and:0.2217)
		(.:0.0864 and:0.0728 have:0.0864 going:0.1025 good:0.0640 that:0.2051 that:0.1494 and:0.1992)
		(.:0.0913 and:0.0708 have:0.0928 going:0.1050 good:0.0645 that:0.2041 that:0.1484 and:0.1953)
		(.:0.0898 and:0.0698 have:0.0889 going:0.1128 good:0.0640 that:0.2031 that:0.1455 and:0.1973)
		(.:0.0898 and:0.0713 have:0.0898 going:0.1143 good:0.0620 that:0.2021 that:0.1426 and:0.2041)
		(.:0.0835 and:0.0703 have:0.0859 going:0.1147 good:0.0605 that:0.1914 that:0.1406 and:0.2100)
		(.:0.0767 and:0.0698 have:0.0815 going:0.1128 good:0.0581 that:0.1904 that:0.1377 and:0.2119)
		(.:0.0684 and:0.0718 have:0.0791 going:0.1089 good:0.0549 that:0.1904 that:0.1357 and:0.2129)
		(.:0.0684 and:0.0718 have:0.0791 going:0.1089 good:0.0549 that:0.1904 that:0.1357 and:0.2129)
 and
------
		( the:0.0718�:0.0425 a:0.0347 few:0.0214.:0.1396,:0.0859 I:0.0645 the:0.0464)
		( and:0.0796 have:0.0898 a:0.0698 few:0.0413.:0.1670.:0.1543 but:0.0879 then:0.0503)
		( but:0.0474�:0.0986 a:0.0471 good:0.0352 that:0.1553.:0.1455 and:0.1069 it:0.0825)
		( and:0.0815�:0.0996 going:0.0796 good:0.0757 that:0.1787.:0.1299 and:0.2012 we:0.1162)
		( and:0.0894�:0.0923 going:0.0898 good:0.0610 that:0.2061.:0.1475 and:0.2217 I:0.1299)
		( and:0.0728 have:0.0864 going:0.1025 good:0.0640 that:0.2051 that:0.1494 and:0.1992 I:0.1338)
		( and:0.0708 have:0.0928 going:0.1050 good:0.0645 that:0.2041 that:0.1484 and:0.1953 I:0.1299)
		( and:0.0698 have:0.0889 going:0.1128 good:0.0640 that:0.2031 that:0.1455 and:0.1973 I:0.1260)
		( and:0.0713 have:0.0898 going:0.1143 good:0.0620 that:0.2021 that:0.1426 and:0.2041 I:0.1245)
		( and:0.0703 have:0.0859 going:0.1147 good:0.0605 that:0.1914 that:0.1406 and:0.2100 I:0.1235)
		( and:0.0698 have:0.0815 going:0.1128 good:0.0581 that:0.1904 that:0.1377 and:0.2119 I:0.1221)
		( and:0.0718 have:0.0791 going:0.1089 good:0.0549 that:0.1904 that:0.1357 and:0.2129 I:0.1240)
		( and:0.0718 have:0.0791 going:0.1089 good:0.0549 that:0.1904 that:0.1357 and:0.2129 I:0.1240)
 I'm going to be able to make a new language
