{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911cec80860b48449e006709474eda71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142fd62059744ea3a2ace21682dea0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1014e42ab79c4d75be7d7d0f1943bc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight torch.Size([50257, 768])\n",
      "transformer.wpe.weight torch.Size([1024, 768])\n",
      "transformer.h.0.ln_1.weight torch.Size([768])\n",
      "transformer.h.0.ln_1.bias torch.Size([768])\n",
      "transformer.h.0.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.0.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.0.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.0.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.0.ln_2.weight torch.Size([768])\n",
      "transformer.h.0.ln_2.bias torch.Size([768])\n",
      "transformer.h.0.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.0.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.0.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.0.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.1.ln_1.weight torch.Size([768])\n",
      "transformer.h.1.ln_1.bias torch.Size([768])\n",
      "transformer.h.1.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.1.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.1.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.1.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.1.ln_2.weight torch.Size([768])\n",
      "transformer.h.1.ln_2.bias torch.Size([768])\n",
      "transformer.h.1.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.1.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.1.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.1.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.2.ln_1.weight torch.Size([768])\n",
      "transformer.h.2.ln_1.bias torch.Size([768])\n",
      "transformer.h.2.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.2.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.2.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.2.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.2.ln_2.weight torch.Size([768])\n",
      "transformer.h.2.ln_2.bias torch.Size([768])\n",
      "transformer.h.2.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.2.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.2.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.2.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.3.ln_1.weight torch.Size([768])\n",
      "transformer.h.3.ln_1.bias torch.Size([768])\n",
      "transformer.h.3.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.3.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.3.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.3.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.3.ln_2.weight torch.Size([768])\n",
      "transformer.h.3.ln_2.bias torch.Size([768])\n",
      "transformer.h.3.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.3.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.3.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.3.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.4.ln_1.weight torch.Size([768])\n",
      "transformer.h.4.ln_1.bias torch.Size([768])\n",
      "transformer.h.4.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.4.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.4.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.4.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.4.ln_2.weight torch.Size([768])\n",
      "transformer.h.4.ln_2.bias torch.Size([768])\n",
      "transformer.h.4.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.4.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.4.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.4.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.5.ln_1.weight torch.Size([768])\n",
      "transformer.h.5.ln_1.bias torch.Size([768])\n",
      "transformer.h.5.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.5.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.5.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.5.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.5.ln_2.weight torch.Size([768])\n",
      "transformer.h.5.ln_2.bias torch.Size([768])\n",
      "transformer.h.5.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.5.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.5.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.5.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.6.ln_1.weight torch.Size([768])\n",
      "transformer.h.6.ln_1.bias torch.Size([768])\n",
      "transformer.h.6.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.6.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.6.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.6.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.6.ln_2.weight torch.Size([768])\n",
      "transformer.h.6.ln_2.bias torch.Size([768])\n",
      "transformer.h.6.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.6.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.6.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.6.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.7.ln_1.weight torch.Size([768])\n",
      "transformer.h.7.ln_1.bias torch.Size([768])\n",
      "transformer.h.7.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.7.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.7.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.7.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.7.ln_2.weight torch.Size([768])\n",
      "transformer.h.7.ln_2.bias torch.Size([768])\n",
      "transformer.h.7.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.7.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.7.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.7.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.8.ln_1.weight torch.Size([768])\n",
      "transformer.h.8.ln_1.bias torch.Size([768])\n",
      "transformer.h.8.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.8.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.8.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.8.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.8.ln_2.weight torch.Size([768])\n",
      "transformer.h.8.ln_2.bias torch.Size([768])\n",
      "transformer.h.8.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.8.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.8.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.8.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.9.ln_1.weight torch.Size([768])\n",
      "transformer.h.9.ln_1.bias torch.Size([768])\n",
      "transformer.h.9.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.9.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.9.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.9.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.9.ln_2.weight torch.Size([768])\n",
      "transformer.h.9.ln_2.bias torch.Size([768])\n",
      "transformer.h.9.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.9.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.9.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.9.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.10.ln_1.weight torch.Size([768])\n",
      "transformer.h.10.ln_1.bias torch.Size([768])\n",
      "transformer.h.10.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.10.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.10.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.10.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.10.ln_2.weight torch.Size([768])\n",
      "transformer.h.10.ln_2.bias torch.Size([768])\n",
      "transformer.h.10.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.10.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.10.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.10.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.11.ln_1.weight torch.Size([768])\n",
      "transformer.h.11.ln_1.bias torch.Size([768])\n",
      "transformer.h.11.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.11.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.11.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.11.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.11.ln_2.weight torch.Size([768])\n",
      "transformer.h.11.ln_2.bias torch.Size([768])\n",
      "transformer.h.11.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.11.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.11.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.11.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.ln_f.weight torch.Size([768])\n",
      "transformer.ln_f.bias torch.Size([768])\n",
      "lm_head.weight torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\") # 124M\n",
    "sd_hf = model_hf.state_dict()\n",
    "\n",
    "for k, v in sd_hf.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_hf[\"transformer.wpe.weight\"].view(-1)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(sd_hf[\"transformer.wpe.weight\"], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 150])\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 200])\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sd_hf[\"transformer.h.1.attn.c_attn.weight\"][:300,:300], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's instead sample manually\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\") # 124M\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "tokens = [15496, 11, 314, 1101, 257, 3303, 2746, 11] # \"Hello, I'm a language model,\"\n",
    "tokens = torch.tensor(tokens, dtype=torch.long) # (8,)\n",
    "tokens = tokens.unsqueeze(0).repeat(5, 1) # (5, 8)\n",
    "x = tokens.to('cuda')\n",
    "\n",
    "# generate!\n",
    "while x.size(1) < 30: # max_length=30\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)[0] # (B, T, vocab_size)\n",
    "        # take the logits at the last position\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        # get the probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # do top-k sampling of 50 (huggingface pipeline default)\n",
    "        # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        # select a token from the top-k probabilities\n",
    "        # note: multinomial does not demand the input to sum to 1\n",
    "        ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
    "        # gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        # append to the sequence\n",
    "        x = torch.cat((x, xcol), dim=1)\n",
    "\n",
    "# print the generated text\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "for i in range(5):\n",
    "    tokens = x[i, :30].tolist()\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny shakespeare dataset\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "data = text[:1000] # first 1,000 characters\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(data)\n",
    "print(tokens[:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "buf = torch.tensor(tokens[:24 + 1])\n",
    "x = buf[:-1].view(4, 6)\n",
    "y = buf[1:].view(4, 6)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd_hf[\"lm_head.weight\"].shape)\n",
    "print(sd_hf[\"transformer.wte.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sd_hf[\"lm_head.weight\"] == sd_hf[\"transformer.wte.weight\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd_hf[\"lm_head.weight\"].data_ptr())\n",
    "print(sd_hf[\"transformer.wte.weight\"].data_ptr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# standard deviation grows inside the residual stream\n",
    "x = torch.zeros(768)\n",
    "n = 100 # e.g. 100 layers\n",
    "for i in range(n):\n",
    "    x += n**-0.5 * torch.randn(768)\n",
    "\n",
    "print(x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1694, -0.1044, -0.0037,  0.1483, -0.0090,  0.0520, -0.0467, -0.1234,\n",
      "        -0.2225,  0.0657])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# super simple little MLP\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(16, 32),\n",
    "    torch.nn.GELU(),\n",
    "    torch.nn.Linear(32, 1)\n",
    ")\n",
    "torch.random.manual_seed(42)\n",
    "x = torch.randn(4, 16)\n",
    "y = torch.randn(4, 1)\n",
    "net.zero_grad()\n",
    "yhat = net(x)\n",
    "loss = torch.nn.functional.mse_loss(yhat, y)\n",
    "loss.backward()\n",
    "print(net[0].weight.grad.view(-1)[:10])\n",
    "\n",
    "# the loss objective here is (due to readuction='mean')\n",
    "# L = 1/4 * [\n",
    "#            (y[0] - yhat[0])**2 +\n",
    "#            (y[1] - yhat[1])**2 +\n",
    "#            (y[2] - yhat[2])**2 +\n",
    "#            (y[3] - yhat[3])**2\n",
    "#           ]\n",
    "# NOTE: 1/4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# now let's do it with grad_accum_steps of 4, and B=1\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# the loss objective here is different because\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# accumulation in gradient <---> SUM in loss\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# L = L0 + L1 + L2 + L3\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# NOTE: the \"normalizer\" of 1/4 is lost\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m     13\u001b[0m     yhat \u001b[38;5;241m=\u001b[39m net(x[i])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "# now let's do it with grad_accum_steps of 4, and B=1\n",
    "# the loss objective here is different because\n",
    "# accumulation in gradient <---> SUM in loss\n",
    "# i.e. we instead get:\n",
    "# L0 = 1/4(y[0] - yhat[0])**2\n",
    "# L1 = 1/4(y[1] - yhat[1])**2\n",
    "# L2 = 1/4(y[2] - yhat[2])**2\n",
    "# L3 = 1/4(y[3] - yhat[3])**2\n",
    "# L = L0 + L1 + L2 + L3\n",
    "# NOTE: the \"normalizer\" of 1/4 is lost\n",
    "net.zero_grad()\n",
    "for i in range(4):\n",
    "    yhat = net(x[i])\n",
    "    loss = torch.nn.functional.mse_loss(yhat, y[i])\n",
    "    loss = loss / 4 # <-- have to add back the \"normalizer\"!\n",
    "    loss.backward()\n",
    "print(net[0].weight.grad.view(-1)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Train Loss (base): 3.4373\n",
      "Min Train Loss (tests): 4.8445\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parse and visualize the logfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sz = \"124M\"\n",
    "\n",
    "loss_baseline = {\n",
    "    \"124M\": 3.2924,\n",
    "}[sz]\n",
    "hella2_baseline = { # HellaSwag for GPT-2\n",
    "    \"124M\": 0.294463,\n",
    "    \"350M\": 0.375224,\n",
    "    \"774M\": 0.431986,\n",
    "    \"1558M\": 0.488946,\n",
    "}[sz]\n",
    "hella3_baseline = { # HellaSwag for GPT-3\n",
    "    \"124M\": 0.337,\n",
    "    \"350M\": 0.436,\n",
    "    \"774M\": 0.510,\n",
    "    \"1558M\": 0.547,\n",
    "}[sz]\n",
    "\n",
    "def gen_points(filename):\n",
    "    # load the log file\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # parse the individual lines, group by stream (train,val,hella)\n",
    "    streams = {}\n",
    "    idx = 0\n",
    "    for line in lines:\n",
    "        idx += 1\n",
    "        tokens = line.strip().split()\n",
    "        if len(tokens) >= 1:\n",
    "            if tokens[0] != \"@\":\n",
    "                continue\n",
    "            step, stream, val = tokens[1], tokens[2], tokens[3].replace(',','')\n",
    "            if stream not in streams:\n",
    "                streams[stream] = {}\n",
    "            streams[stream][int(step)] = float(val)\n",
    "\n",
    "    # convert each stream from {step: val} to (steps[], vals[])\n",
    "    # so it's easier for plotting\n",
    "    streams_xy = {}\n",
    "    for k, v in streams.items():\n",
    "        # get all (step, val) items, sort them\n",
    "        xy = sorted(list(v.items()))\n",
    "        # unpack the list of tuples to tuple of lists\n",
    "        streams_xy[k] = list(zip(*xy))\n",
    "    return streams_xy\n",
    "\n",
    "testname = \"10-plustimes\"\n",
    "# testname = \"8-everylayer-nores-true\"\n",
    "# testname = \"7-test-2\"\n",
    "streams_xy_0 = gen_points(\"log-ben/7-test-2-log.txt\")\n",
    "streams_xy_test = gen_points(f\"log-ben/{testname}-log.txt\")\n",
    "\n",
    "# create figure\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "\n",
    "# Panel 1: losses: both train and val\n",
    "plt.subplot(121)\n",
    "\n",
    "xs, ys = streams_xy_0[\"train\"] # training loss\n",
    "ys = np.array(ys)\n",
    "plt.plot(xs, ys, label=f'nanogpt ({sz}) train loss base', alpha=0.7)\n",
    "print(\"Min Train Loss (base):\", min(ys))\n",
    "\n",
    "\n",
    "xs, ys = streams_xy_test[\"train\"] # training loss\n",
    "ys = np.array(ys)\n",
    "plt.plot(xs, ys, label=f'nanogpt ({sz}) train loss test', alpha=0.7)\n",
    "print(\"Min Train Loss (tests):\", min(ys))\n",
    "\n",
    "plt.savefig(f\"img/{testname}i.png\")\n",
    "\n",
    "\n",
    "\n",
    "# xs, ys = streams_xy_test[\"val\"] # validation loss\n",
    "# plt.plot(xs, ys, label=f'nanogpt ({sz}) val loss test')\n",
    "# xs, ys = streams_xy_0[\"val\"] # validation loss\n",
    "# plt.plot(xs, ys, label=f'nanogpt ({sz}) val loss base')\n",
    "# # horizontal line at GPT-2 baseline\n",
    "# if loss_baseline is not None:\n",
    "#     plt.axhline(y=loss_baseline, color='r', linestyle='--', label=f\"OpenAI GPT-2 ({sz}) checkpoint val loss\")\n",
    "# plt.xlabel(\"steps\")\n",
    "# plt.ylabel(\"loss\")\n",
    "# plt.yscale('log')\n",
    "# plt.ylim(top=8.0)\n",
    "# plt.xlim(right=30000)\n",
    "# plt.legend()\n",
    "# plt.title(\"Loss\")\n",
    "# print(\"Min Validation Loss:\", min(ys))\n",
    "\n",
    "# # Panel 2: HellaSwag eval\n",
    "# plt.subplot(122)\n",
    "# xs, ys = streams_xy_test[\"hellaswag\"] # HellaSwag eval\n",
    "# ys = np.array(ys)\n",
    "# plt.plot(xs, ys, label=f\"nanogpt ({sz})\")\n",
    "# # horizontal line at GPT-2 baseline\n",
    "# if hella2_baseline:\n",
    "#     plt.axhline(y=hella2_baseline, color='r', linestyle='--', label=f\"OpenAI GPT-2 ({sz}) checkpoint\")\n",
    "# if hella3_baseline:\n",
    "#     plt.axhline(y=hella3_baseline, color='g', linestyle='--', label=f\"OpenAI GPT-3 ({sz}) checkpoint\")\n",
    "# plt.xlabel(\"steps\")\n",
    "# plt.ylabel(\"accuracy\")\n",
    "# plt.legend()\n",
    "# plt.title(\"HellaSwag eval\")\n",
    "# print(\"Max Hellaswag eval:\", max(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
